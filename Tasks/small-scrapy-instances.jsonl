{"repo": "scrapy/scrapy", "pull_number": 6475, "instance_id": "scrapy__scrapy-6475", "issue_numbers": ["6433"], "base_commit": "67ab8d4650c1e9212c9508803c7b5265e166cbaa", "patch": "diff --git a/scrapy/core/engine.py b/scrapy/core/engine.py\nindex 63d84339dcd..fd9a5f7817e 100644\n--- a/scrapy/core/engine.py\n+++ b/scrapy/core/engine.py\n@@ -39,7 +39,6 @@\n from scrapy.signalmanager import SignalManager\n from scrapy.utils.log import failure_to_exc_info, logformatter_adapter\n from scrapy.utils.misc import build_from_crawler, load_object\n-from scrapy.utils.python import global_object_name\n from scrapy.utils.reactor import CallLaterOnce\n \n if TYPE_CHECKING:\n@@ -325,10 +324,6 @@ def _schedule_request(self, request: Request, spider: Spider) -> None:\n         )\n         for handler, result in request_scheduled_result:\n             if isinstance(result, Failure) and isinstance(result.value, IgnoreRequest):\n-                logger.debug(\n-                    f\"Signal handler {global_object_name(handler)} dropped \"\n-                    f\"request {request} before it reached the scheduler.\"\n-                )\n                 return\n         if not self.slot.scheduler.enqueue_request(request):  # type: ignore[union-attr]\n             self.signals.send_catch_log(\n", "test_patch": "diff --git a/tests/test_engine.py b/tests/test_engine.py\nindex 86526420f83..2ebc0b5e449 100644\n--- a/tests/test_engine.py\n+++ b/tests/test_engine.py\n@@ -499,7 +499,6 @@ def signal_handler(request: Request, spider: Spider) -> None:\n     assert scheduler.enqueued == [\n         keep_request\n     ], f\"{scheduler.enqueued!r} != [{keep_request!r}]\"\n-    assert \"dropped request <GET https://drop.example>\" in caplog.text\n     crawler.signals.disconnect(signal_handler, request_scheduled)\n \n \n", "problem_statement": "core.engine/Signal handler polluting log\n### Description\r\n\r\nThe `OffsiteMiddleware` logs a single message for each domain filtered. Great!\r\nBut then the `core.engine` logs a message for every single url filtered by the OffsiteMiddleware.\r\n(LOG_LEVEL: DEBUG)\r\n\r\nThe websites I am scraping have like 10 external links to twitter/youtube/etc in each page. For hundreds pages scrapped, the only thing I can see in the logs is `Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request`. \r\n\r\nI don't know if this is intended behavior. If so, it is obviously not a bug.\r\nBut nonetheless, it is very different behavior compared to previous 1.x Scrapy versions. (I don't know when it has changed and I couldn't find anything in the release notes about that.)\r\n\r\nIf not a bug, maybe we could discuss the possibility of changing this behavior so we can have logs less polluted when debugging.\r\n\r\n### Steps to Reproduce\r\n\r\n#### Just run the following spider.\r\n(url taken from another issue).\r\n\r\n```python\r\nimport scrapy\r\n\r\nclass TestSpider(scrapy.spiders.CrawlSpider):\r\n    name = 'test'\r\n    allowed_domains = ['capybala.com']\r\n    start_urls = ['https://capybala.com/']\r\n    custom_settings = {\r\n        'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\r\n        'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',\r\n        'LOG_LEVEL': 'DEBUG'\r\n    }\r\n\r\n    rules = (scrapy.spiders.Rule(scrapy.linkextractors.LinkExtractor(), callback='parse', follow=True),)\r\n    \r\n    def parse(self, response):\r\n        print('noop')\r\n```\r\n\r\n#### Output: \r\n```txt\r\n2024-07-08 16:34:43 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: scrapybot)\r\n2024-07-08 16:34:43 [scrapy.utils.log] INFO: Versions: lxml 5.2.2.0, libxml2 2.12.6, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.3.0, Python 3.12.4 (main, Jul  3 2024, 16:55:58) [GCC 11.2.0], pyOpenSSL 24.1.0 (OpenSSL 3.2.2 4 Jun 2024), cryptography 42.0.8, Platform Linux-5.15.145-x86_64-AMD_Ryzen_9_5980HX_with_Radeon_Graphics-with-glibc2.33\r\n2024-07-08 16:34:43 [scrapy.addons] INFO: Enabled addons:\r\n[]\r\n2024-07-08 16:34:43 [asyncio] DEBUG: Using selector: EpollSelector\r\n2024-07-08 16:34:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\r\n2024-07-08 16:34:43 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\r\n2024-07-08 16:34:43 [scrapy.extensions.telnet] INFO: Telnet Password: d2c4cce2938fba32\r\n2024-07-08 16:34:43 [scrapy.middleware] INFO: Enabled extensions:\r\n['scrapy.extensions.corestats.CoreStats',\r\n 'scrapy.extensions.telnet.TelnetConsole',\r\n 'scrapy.extensions.memusage.MemoryUsage',\r\n 'scrapy.extensions.logstats.LogStats']\r\n2024-07-08 16:34:43 [scrapy.crawler] INFO: Overridden settings:\r\n{'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\r\n 'SPIDER_LOADER_WARN_ONLY': True,\r\n 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\r\n2024-07-08 16:34:43 [scrapy.middleware] INFO: Enabled downloader middlewares:\r\n['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\r\n 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\r\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\r\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\r\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\r\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\r\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\r\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\r\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\r\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\r\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\r\n2024-07-08 16:34:43 [scrapy.middleware] INFO: Enabled spider middlewares:\r\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\r\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\r\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\r\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\r\n2024-07-08 16:34:43 [scrapy.middleware] INFO: Enabled item pipelines:\r\n[]\r\n2024-07-08 16:34:43 [scrapy.core.engine] INFO: Spider opened\r\n2024-07-08 16:34:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n2024-07-08 16:34:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://capybala.com/> (referer: None)\r\n2024-07-08 16:34:44 [scrapy.downloadermiddlewares.offsite] DEBUG: Filtered offsite request to 'bokuran.com': <GET https://bokuran.com/>\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET https://bokuran.com/> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.downloadermiddlewares.offsite] DEBUG: Filtered offsite request to 'webooker.info': <GET http://webooker.info/2013/10/ebook1-release/>\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET http://webooker.info/2013/10/ebook1-release/> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.downloadermiddlewares.offsite] DEBUG: Filtered offsite request to 'ebook-1.com': <GET https://ebook-1.com/>\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET https://ebook-1.com/> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://capybala.com/> (referer: https://capybala.com/)\r\n2024-07-08 16:34:44 [scrapy.downloadermiddlewares.offsite] DEBUG: Filtered offsite request to 'chrome.google.com': <GET https://chrome.google.com/webstore/detail/find-ebook-edition/jhhpocdmfelpmobcnmjfppdpnbepkono>\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET https://chrome.google.com/webstore/detail/find-ebook-edition/jhhpocdmfelpmobcnmjfppdpnbepkono> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.downloadermiddlewares.offsite] DEBUG: Filtered offsite request to 'twitter.com': <GET https://twitter.com/orangain>\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET https://twitter.com/orangain> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET https://twitter.com/webooker_log> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET http://webooker.info/> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://capybala.com/find-kindle-edition/> (referer: https://capybala.com/)\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://capybala.com/bokuran/> (referer: https://capybala.com/)\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://capybala.com/ebook-1/> (referer: https://capybala.com/)\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://capybala.com/dendrogram/> (referer: https://capybala.com/)\r\nnoop\r\n2024-07-08 16:34:44 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://capybala.com/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET https://bokuran.com/> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET http://webooker.info/2013/10/ebook1-release/> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET https://ebook-1.com/> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET https://chrome.google.com/webstore/detail/find-ebook-edition/jhhpocdmfelpmobcnmjfppdpnbepkono> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET https://twitter.com/orangain> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET https://twitter.com/webooker_log> before it reached the scheduler.\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET http://webooker.info/> before it reached the scheduler.\r\nnoop\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET https://chrome.google.com/webstore/detail/find-ebook-edition/jhhpocdmfelpmobcnmjfppdpnbepkono> before it reached the scheduler.\r\nnoop\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET https://bokuran.com/> before it reached the scheduler.\r\nnoop\r\nnoop\r\n2024-07-08 16:34:44 [scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET http://webooker.info/2013/10/ebook1-release/> before it reached the scheduler.\r\n2024-07-08 16:34:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://tree.capybala.com/> (referer: https://capybala.com/)\r\nnoop\r\n2024-07-08 16:34:45 [scrapy.core.engine] INFO: Closing spider (finished)\r\n2024-07-08 16:34:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\r\n{'downloader/request_bytes': 1735,\r\n 'downloader/request_count': 7,\r\n 'downloader/request_method_count/GET': 7,\r\n 'downloader/response_bytes': 17486,\r\n 'downloader/response_count': 7,\r\n 'downloader/response_status_count/200': 7,\r\n 'dupefilter/filtered': 16,\r\n 'elapsed_time_seconds': 1.950522,\r\n 'finish_reason': 'finished',\r\n 'finish_time': datetime.datetime(2024, 7, 8, 19, 34, 45, 376469, tzinfo=datetime.timezone.utc),\r\n 'httpcompression/response_bytes': 29892,\r\n 'httpcompression/response_count': 7,\r\n 'log_count/DEBUG': 33,\r\n 'log_count/INFO': 10,\r\n 'memusage/max': 70103040,\r\n 'memusage/startup': 70103040,\r\n 'offsite/domains': 5,\r\n 'offsite/filtered': 17,\r\n 'request_depth_max': 2,\r\n 'response_received_count': 7,\r\n 'scheduler/dequeued': 7,\r\n 'scheduler/dequeued/memory': 7,\r\n 'scheduler/enqueued': 7,\r\n 'scheduler/enqueued/memory': 7,\r\n 'start_time': datetime.datetime(2024, 7, 8, 19, 34, 43, 425947, tzinfo=datetime.timezone.utc)}\r\n2024-07-08 16:34:45 [scrapy.core.engine] INFO: Spider closed (finished)\r\n\r\n```\r\n\r\n**Expected behavior:**\r\n\r\nI was not expecting to see so many `[scrapy.core.engine] DEBUG: Signal handler scrapy.downloadermiddlewares.offsite.OffsiteMiddleware.request_scheduled dropped request <GET [...]> before it reached the scheduler.` messages. I believe just the messages given by the OffsiteMiddleware are enough.\r\n\r\n**Actual behavior:**\r\n\r\nThere are **a lot** of  \"dropped request\" messages.\r\nFurthermore the same message is replicated several times if the same url is found more than one time. (e.g. https://twitter.com/orangain or https://twitter.com/webooker_log in the previous log)\r\n\r\n**Reproduces how often:** always\r\n\r\n### Versions\r\n\r\n$  scrapy version --verbose\r\nScrapy       : 2.11.2\r\nlxml         : 5.2.2.0\r\nlibxml2      : 2.12.6\r\ncssselect    : 1.2.0\r\nparsel       : 1.9.1\r\nw3lib        : 2.2.1\r\nTwisted      : 24.3.0\r\nPython       : 3.12.4 (main, Jul  3 2024, 16:55:58) [GCC 11.2.0]\r\npyOpenSSL    : 24.1.0 (OpenSSL 3.2.2 4 Jun 2024)\r\ncryptography : 42.0.8\r\nPlatform     : Linux-5.15.145-x86_64-AMD_Ryzen_9_5980HX_with_Radeon_Graphics-with-glibc2.33\r\n\r\n### Additional context\r\n\r\nI believe this has nothing to do with the `CrawlSpider`, but that is what I am using.\n", "hints_text": "In fact Scrapy version 2.11.1 has the previous and expected behavior.  The current behavior was introduced in Scrapy 2.11.2 by the commit f149ea4b804. Could we revert to the previous behavior?\nI\u2019m OK with removing the log message or adding a setting to silence it and silencing it by default.\nHi @Gallaecio can you assign me to this issue please? Both are working so which option do you prefer?\r\n\r\n1: simply remove the log message\r\n\r\n2: add a setting to`scrapy/settings/default_settings.py` enabling users to silence the message (silenced by default) \nWe rarely assign tickets, but feel free to give it a try!\r\n\r\n@wRAR @kmike Any preference about the approach to follow?\nI would prefer removing it.", "created_at": "2024-09-09T19:44:42Z"}