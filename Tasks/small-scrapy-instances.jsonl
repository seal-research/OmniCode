{"repo": "scrapy/scrapy", "pull_number": 6324, "instance_id": "scrapy__scrapy-6324", "issue_numbers": ["6323"], "base_commit": "a5da77d01dccbc91206d053396fb5b80e1a6b15b", "patch": "diff --git a/scrapy/spiders/__init__.py b/scrapy/spiders/__init__.py\nindex 72c2aaba7f5..0a653bd4155 100644\n--- a/scrapy/spiders/__init__.py\n+++ b/scrapy/spiders/__init__.py\n@@ -22,6 +22,7 @@\n \n     from scrapy.crawler import Crawler\n     from scrapy.settings import BaseSettings\n+    from scrapy.utils.log import SpiderLoggerAdapter\n \n \n class Spider(object_ref):\n@@ -42,9 +43,11 @@ def __init__(self, name: Optional[str] = None, **kwargs: Any):\n             self.start_urls: List[str] = []\n \n     @property\n-    def logger(self) -> logging.LoggerAdapter:\n+    def logger(self) -> SpiderLoggerAdapter:\n+        from scrapy.utils.log import SpiderLoggerAdapter\n+\n         logger = logging.getLogger(self.name)\n-        return logging.LoggerAdapter(logger, {\"spider\": self})\n+        return SpiderLoggerAdapter(logger, {\"spider\": self})\n \n     def log(self, message: Any, level: int = logging.DEBUG, **kw: Any) -> None:\n         \"\"\"Log the given message at the given log level\ndiff --git a/scrapy/utils/log.py b/scrapy/utils/log.py\nindex 2a38f151a16..430a91e9592 100644\n--- a/scrapy/utils/log.py\n+++ b/scrapy/utils/log.py\n@@ -4,7 +4,17 @@\n import sys\n from logging.config import dictConfig\n from types import TracebackType\n-from typing import TYPE_CHECKING, Any, List, Optional, Tuple, Type, Union, cast\n+from typing import (\n+    TYPE_CHECKING,\n+    Any,\n+    List,\n+    MutableMapping,\n+    Optional,\n+    Tuple,\n+    Type,\n+    Union,\n+    cast,\n+)\n \n from twisted.python import log as twisted_log\n from twisted.python.failure import Failure\n@@ -238,3 +248,16 @@ def logformatter_adapter(logkws: dict) -> Tuple[int, str, dict]:\n     args = logkws if not logkws.get(\"args\") else logkws[\"args\"]\n \n     return (level, message, args)\n+\n+\n+class SpiderLoggerAdapter(logging.LoggerAdapter):\n+    def process(\n+        self, msg: str, kwargs: MutableMapping[str, Any]\n+    ) -> Tuple[str, MutableMapping[str, Any]]:\n+        \"\"\"Method that augments logging with additional 'extra' data\"\"\"\n+        if isinstance(kwargs.get(\"extra\"), MutableMapping):\n+            kwargs[\"extra\"].update(self.extra)\n+        else:\n+            kwargs[\"extra\"] = self.extra\n+\n+        return msg, kwargs\n", "test_patch": "diff --git a/tests/spiders.py b/tests/spiders.py\nindex 94969db993d..ea419afbdac 100644\n--- a/tests/spiders.py\n+++ b/tests/spiders.py\n@@ -4,6 +4,7 @@\n \n import asyncio\n import time\n+from typing import Optional\n from urllib.parse import urlencode\n \n from twisted.internet import defer\n@@ -78,6 +79,28 @@ def errback(self, failure):\n         self.t2_err = time.time()\n \n \n+class LogSpider(MetaSpider):\n+    name = \"log_spider\"\n+\n+    def log_debug(self, message: str, extra: Optional[dict] = None):\n+        self.logger.debug(message, extra=extra)\n+\n+    def log_info(self, message: str, extra: Optional[dict] = None):\n+        self.logger.info(message, extra=extra)\n+\n+    def log_warning(self, message: str, extra: Optional[dict] = None):\n+        self.logger.warning(message, extra=extra)\n+\n+    def log_error(self, message: str, extra: Optional[dict] = None):\n+        self.logger.error(message, extra=extra)\n+\n+    def log_critical(self, message: str, extra: Optional[dict] = None):\n+        self.logger.critical(message, extra=extra)\n+\n+    def parse(self, response):\n+        pass\n+\n+\n class SlowSpider(DelaySpider):\n     name = \"slow\"\n \ndiff --git a/tests/test_utils_log.py b/tests/test_utils_log.py\nindex eae744df5e4..a8d0808222e 100644\n--- a/tests/test_utils_log.py\n+++ b/tests/test_utils_log.py\n@@ -1,18 +1,26 @@\n+import json\n import logging\n+import re\n import sys\n import unittest\n+from io import StringIO\n+from typing import Any, Dict, Mapping, MutableMapping\n+from unittest import TestCase\n \n+import pytest\n from testfixtures import LogCapture\n from twisted.python.failure import Failure\n \n from scrapy.extensions import telnet\n from scrapy.utils.log import (\n     LogCounterHandler,\n+    SpiderLoggerAdapter,\n     StreamLogger,\n     TopLevelFormatter,\n     failure_to_exc_info,\n )\n from scrapy.utils.test import get_crawler\n+from tests.spiders import LogSpider\n \n \n class FailureToExcInfoTest(unittest.TestCase):\n@@ -106,3 +114,180 @@ def test_redirect(self):\n         with LogCapture() as log:\n             print(\"test log msg\")\n         log.check((\"test\", \"ERROR\", \"test log msg\"))\n+\n+\n+@pytest.mark.parametrize(\n+    (\"base_extra\", \"log_extra\", \"expected_extra\"),\n+    (\n+        (\n+            {\"spider\": \"test\"},\n+            {\"extra\": {\"log_extra\": \"info\"}},\n+            {\"extra\": {\"log_extra\": \"info\", \"spider\": \"test\"}},\n+        ),\n+        (\n+            {\"spider\": \"test\"},\n+            {\"extra\": None},\n+            {\"extra\": {\"spider\": \"test\"}},\n+        ),\n+        (\n+            {\"spider\": \"test\"},\n+            {\"extra\": {\"spider\": \"test2\"}},\n+            {\"extra\": {\"spider\": \"test\"}},\n+        ),\n+    ),\n+)\n+def test_spider_logger_adapter_process(\n+    base_extra: Mapping[str, Any], log_extra: MutableMapping, expected_extra: Dict\n+):\n+    logger = logging.getLogger(\"test\")\n+    spider_logger_adapter = SpiderLoggerAdapter(logger, base_extra)\n+\n+    log_message = \"test_log_message\"\n+    result_message, result_kwargs = spider_logger_adapter.process(\n+        log_message, log_extra\n+    )\n+\n+    assert result_message == log_message\n+    assert result_kwargs == expected_extra\n+\n+\n+class LoggingTestCase(TestCase):\n+    def setUp(self):\n+        self.log_stream = StringIO()\n+        handler = logging.StreamHandler(self.log_stream)\n+        logger = logging.getLogger(\"log_spider\")\n+        logger.addHandler(handler)\n+        logger.setLevel(logging.DEBUG)\n+        self.handler = handler\n+        self.logger = logger\n+        self.spider = LogSpider()\n+\n+    def tearDown(self):\n+        self.logger.removeHandler(self.handler)\n+\n+    def test_debug_logging(self):\n+        log_message = \"Foo message\"\n+        self.spider.log_debug(log_message)\n+        log_contents = self.log_stream.getvalue()\n+\n+        assert log_contents == f\"{log_message}\\n\"\n+\n+    def test_info_logging(self):\n+        log_message = \"Bar message\"\n+        self.spider.log_info(log_message)\n+        log_contents = self.log_stream.getvalue()\n+\n+        assert log_contents == f\"{log_message}\\n\"\n+\n+    def test_warning_logging(self):\n+        log_message = \"Baz message\"\n+        self.spider.log_warning(log_message)\n+        log_contents = self.log_stream.getvalue()\n+\n+        assert log_contents == f\"{log_message}\\n\"\n+\n+    def test_error_logging(self):\n+        log_message = \"Foo bar message\"\n+        self.spider.log_error(log_message)\n+        log_contents = self.log_stream.getvalue()\n+\n+        assert log_contents == f\"{log_message}\\n\"\n+\n+    def test_critical_logging(self):\n+        log_message = \"Foo bar baz message\"\n+        self.spider.log_critical(log_message)\n+        log_contents = self.log_stream.getvalue()\n+\n+        assert log_contents == f\"{log_message}\\n\"\n+\n+\n+class LoggingWithExtraTestCase(TestCase):\n+    def setUp(self):\n+        self.log_stream = StringIO()\n+        handler = logging.StreamHandler(self.log_stream)\n+        formatter = logging.Formatter(\n+            '{\"levelname\": \"%(levelname)s\", \"message\": \"%(message)s\", \"spider\": \"%(spider)s\", \"important_info\": \"%(important_info)s\"}'\n+        )\n+        handler.setFormatter(formatter)\n+        logger = logging.getLogger(\"log_spider\")\n+        logger.addHandler(handler)\n+        logger.setLevel(logging.DEBUG)\n+        self.handler = handler\n+        self.logger = logger\n+        self.spider = LogSpider()\n+        self.regex_pattern = re.compile(r\"^<LogSpider\\s'log_spider'\\sat\\s[^>]+>$\")\n+\n+    def tearDown(self):\n+        self.logger.removeHandler(self.handler)\n+\n+    def test_debug_logging(self):\n+        log_message = \"Foo message\"\n+        extra = {\"important_info\": \"foo\"}\n+        self.spider.log_debug(log_message, extra)\n+        log_contents = self.log_stream.getvalue()\n+        log_contents = json.loads(log_contents)\n+\n+        assert log_contents[\"levelname\"] == \"DEBUG\"\n+        assert log_contents[\"message\"] == log_message\n+        assert self.regex_pattern.match(log_contents[\"spider\"])\n+        assert log_contents[\"important_info\"] == extra[\"important_info\"]\n+\n+    def test_info_logging(self):\n+        log_message = \"Bar message\"\n+        extra = {\"important_info\": \"bar\"}\n+        self.spider.log_info(log_message, extra)\n+        log_contents = self.log_stream.getvalue()\n+        log_contents = json.loads(log_contents)\n+\n+        assert log_contents[\"levelname\"] == \"INFO\"\n+        assert log_contents[\"message\"] == log_message\n+        assert self.regex_pattern.match(log_contents[\"spider\"])\n+        assert log_contents[\"important_info\"] == extra[\"important_info\"]\n+\n+    def test_warning_logging(self):\n+        log_message = \"Baz message\"\n+        extra = {\"important_info\": \"baz\"}\n+        self.spider.log_warning(log_message, extra)\n+        log_contents = self.log_stream.getvalue()\n+        log_contents = json.loads(log_contents)\n+\n+        assert log_contents[\"levelname\"] == \"WARNING\"\n+        assert log_contents[\"message\"] == log_message\n+        assert self.regex_pattern.match(log_contents[\"spider\"])\n+        assert log_contents[\"important_info\"] == extra[\"important_info\"]\n+\n+    def test_error_logging(self):\n+        log_message = \"Foo bar message\"\n+        extra = {\"important_info\": \"foo bar\"}\n+        self.spider.log_error(log_message, extra)\n+        log_contents = self.log_stream.getvalue()\n+        log_contents = json.loads(log_contents)\n+\n+        assert log_contents[\"levelname\"] == \"ERROR\"\n+        assert log_contents[\"message\"] == log_message\n+        assert self.regex_pattern.match(log_contents[\"spider\"])\n+        assert log_contents[\"important_info\"] == extra[\"important_info\"]\n+\n+    def test_critical_logging(self):\n+        log_message = \"Foo bar baz message\"\n+        extra = {\"important_info\": \"foo bar baz\"}\n+        self.spider.log_critical(log_message, extra)\n+        log_contents = self.log_stream.getvalue()\n+        log_contents = json.loads(log_contents)\n+\n+        assert log_contents[\"levelname\"] == \"CRITICAL\"\n+        assert log_contents[\"message\"] == log_message\n+        assert self.regex_pattern.match(log_contents[\"spider\"])\n+        assert log_contents[\"important_info\"] == extra[\"important_info\"]\n+\n+    def test_overwrite_spider_extra(self):\n+        log_message = \"Foo message\"\n+        extra = {\"important_info\": \"foo\", \"spider\": \"shouldn't change\"}\n+        self.spider.log_error(log_message, extra)\n+        log_contents = self.log_stream.getvalue()\n+        log_contents = json.loads(log_contents)\n+\n+        assert log_contents[\"levelname\"] == \"ERROR\"\n+        assert log_contents[\"message\"] == log_message\n+        assert self.regex_pattern.match(log_contents[\"spider\"])\n+        assert log_contents[\"important_info\"] == extra[\"important_info\"]\n", "problem_statement": "Spider.logger not logging custom extra information\nI noticed the implicit behavior of the Spider.logger: when logging with extra, extra ultimately do not end up in the log because they are overwritten by default `process` method of [LoggerAdapter](https://github.com/scrapy/scrapy/blob/master/scrapy/spiders/__init__.py#L47)\r\n\r\nCurrent logic:\r\n```py\r\n>>> self.logger.info(\"test log\", extra={\"test\": \"very important information\"})\r\n{\"message\": \"test log\", \"spider\": \"spider_name\"}\r\n```\r\n\r\n\r\n\r\nExpected logic:\r\n```py\r\n>>> self.logger.info(\"test log\", extra={\"test\": \"very important information\"})\r\n{\"message\": \"test log\", \"spider\": \"spider_name\", \"test\": \"very important information\"}\r\n```\r\n\r\n\n", "hints_text": "", "created_at": "2024-04-27T16:58:30Z"}