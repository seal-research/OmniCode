diff --git a/pyproject.toml b/pyproject.toml
index 8c985753fce..571a61f1c81 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -72,9 +72,9 @@ version = {file = "./scrapy/VERSION"}
 
 [tool.mypy]
 ignore_missing_imports = true
+implicit_reexport = false
 
 # Interface classes are hard to support
-
 [[tool.mypy.overrides]]
 module = "twisted.internet.interfaces"
 follow_imports = "skip"
@@ -92,6 +92,14 @@ follow_imports = "skip"
 module = "scrapy.settings.default_settings"
 ignore_errors = true
 
+[[tool.mypy.overrides]]
+module = "itemadapter"
+implicit_reexport = true
+
+[[tool.mypy.overrides]]
+module = "twisted"
+implicit_reexport = true
+
 [tool.bumpversion]
 current_version = "2.12.0"
 commit = true
@@ -359,13 +367,9 @@ ignore = [
 ]
 
 [tool.ruff.lint.per-file-ignores]
-# Exclude files that are meant to provide top-level imports
-"scrapy/__init__.py" = ["E402"]
-"scrapy/core/downloader/handlers/http.py" = ["F401"]
-"scrapy/http/__init__.py" = ["F401"]
-"scrapy/linkextractors/__init__.py" = ["E402", "F401"]
-"scrapy/selector/__init__.py" = ["F401"]
-"scrapy/spiders/__init__.py" = ["E402", "F401"]
+# Circular import workarounds
+"scrapy/linkextractors/__init__.py" = ["E402"]
+"scrapy/spiders/__init__.py" = ["E402"]
 
 # Skip bandit in tests
 "tests/**" = ["S"]
diff --git a/scrapy/core/downloader/handlers/http.py b/scrapy/core/downloader/handlers/http.py
index 52535bd8b58..93b96c779d1 100644
--- a/scrapy/core/downloader/handlers/http.py
+++ b/scrapy/core/downloader/handlers/http.py
@@ -2,3 +2,8 @@
 from scrapy.core.downloader.handlers.http11 import (
     HTTP11DownloadHandler as HTTPDownloadHandler,
 )
+
+__all__ = [
+    "HTTP10DownloadHandler",
+    "HTTPDownloadHandler",
+]
diff --git a/scrapy/http/__init__.py b/scrapy/http/__init__.py
index d0b726bad90..0e5c2b53b05 100644
--- a/scrapy/http/__init__.py
+++ b/scrapy/http/__init__.py
@@ -15,3 +15,16 @@
 from scrapy.http.response.json import JsonResponse
 from scrapy.http.response.text import TextResponse
 from scrapy.http.response.xml import XmlResponse
+
+__all__ = [
+    "FormRequest",
+    "Headers",
+    "HtmlResponse",
+    "JsonRequest",
+    "JsonResponse",
+    "Request",
+    "Response",
+    "TextResponse",
+    "XmlResponse",
+    "XmlRpcRequest",
+]
diff --git a/scrapy/linkextractors/__init__.py b/scrapy/linkextractors/__init__.py
index 1c7e96ae0df..b39859f7b31 100644
--- a/scrapy/linkextractors/__init__.py
+++ b/scrapy/linkextractors/__init__.py
@@ -126,3 +126,8 @@ def _is_valid_url(url: str) -> bool:
 
 # Top-level imports
 from scrapy.linkextractors.lxmlhtml import LxmlLinkExtractor as LinkExtractor
+
+__all__ = [
+    "IGNORED_EXTENSIONS",
+    "LinkExtractor",
+]
diff --git a/scrapy/selector/__init__.py b/scrapy/selector/__init__.py
index 85c500d6665..7cfa3c36439 100644
--- a/scrapy/selector/__init__.py
+++ b/scrapy/selector/__init__.py
@@ -4,3 +4,8 @@
 
 # top-level imports
 from scrapy.selector.unified import Selector, SelectorList
+
+__all__ = [
+    "Selector",
+    "SelectorList",
+]
diff --git a/scrapy/spiders/__init__.py b/scrapy/spiders/__init__.py
index 6136dabc70a..e255e91cc1f 100644
--- a/scrapy/spiders/__init__.py
+++ b/scrapy/spiders/__init__.py
@@ -117,3 +117,12 @@ def __repr__(self) -> str:
 from scrapy.spiders.crawl import CrawlSpider, Rule
 from scrapy.spiders.feed import CSVFeedSpider, XMLFeedSpider
 from scrapy.spiders.sitemap import SitemapSpider
+
+__all__ = [
+    "CSVFeedSpider",
+    "CrawlSpider",
+    "Rule",
+    "SitemapSpider",
+    "Spider",
+    "XMLFeedSpider",
+]
