{"repo": "apache/airflow", "pull_number": 46883, "instance_id": "apache__airflow-46883", "issue_numbers": ["46804"], "base_commit": "4833b53705acfc4bd0a26bf3e4dd4fc7a22b0bfa", "patch": "diff --git a/airflow/api_fastapi/core_api/routes/public/task_instances.py b/airflow/api_fastapi/core_api/routes/public/task_instances.py\nindex 4b6dc2d836a17..174c398e0d639 100644\n--- a/airflow/api_fastapi/core_api/routes/public/task_instances.py\n+++ b/airflow/api_fastapi/core_api/routes/public/task_instances.py\n@@ -61,7 +61,6 @@\n )\n from airflow.api_fastapi.core_api.openapi.exceptions import create_openapi_http_exception_doc\n from airflow.exceptions import TaskNotFound\n-from airflow.jobs.scheduler_job_runner import DR\n from airflow.models import Base, DagRun\n from airflow.models.dag import DAG\n from airflow.models.taskinstance import TaskInstance as TI, clear_task_instances\n@@ -625,7 +624,9 @@ def post_clear_task_instances(\n     upstream = body.include_upstream\n \n     if dag_run_id is not None:\n-        dag_run: DR | None = session.scalar(select(DR).where(DR.dag_id == dag_id, DR.run_id == dag_run_id))\n+        dag_run: DagRun | None = session.scalar(\n+            select(DagRun).where(DagRun.dag_id == dag_id, DagRun.run_id == dag_run_id)\n+        )\n         if dag_run is None:\n             error_message = f\"Dag Run id {dag_run_id} not found in dag {dag_id}\"\n             raise HTTPException(status.HTTP_404_NOT_FOUND, error_message)\n@@ -653,6 +654,7 @@ def post_clear_task_instances(\n \n     task_instances = dag.clear(\n         dry_run=True,\n+        run_id=None if past or future else dag_run_id,\n         task_ids=task_ids,\n         dag_bag=request.app.state.dag_bag,\n         session=session,\n", "test_patch": "diff --git a/tests/api_fastapi/core_api/routes/public/test_task_instances.py b/tests/api_fastapi/core_api/routes/public/test_task_instances.py\nindex a28565d451d6d..761f3074aadbc 100644\n--- a/tests/api_fastapi/core_api/routes/public/test_task_instances.py\n+++ b/tests/api_fastapi/core_api/routes/public/test_task_instances.py\n@@ -2238,7 +2238,20 @@ def test_should_respond_200_with_reset_dag_run(self, test_client, session):\n         assert response.json()[\"total_entries\"] == 6\n         assert failed_dag_runs == 0\n \n-    def test_should_respond_200_with_dag_run_id(self, test_client, session):\n+    @pytest.mark.parametrize(\n+        \"target_logical_date, response_logical_date\",\n+        [\n+            pytest.param(DEFAULT_DATETIME_1, \"2020-01-01T00:00:00Z\", id=\"date\"),\n+            pytest.param(None, None, id=\"null\"),\n+        ],\n+    )\n+    def test_should_respond_200_with_dag_run_id(\n+        self,\n+        test_client,\n+        session,\n+        target_logical_date,\n+        response_logical_date,\n+    ):\n         dag_id = \"example_python_operator\"\n         payload = {\n             \"dry_run\": False,\n@@ -2247,29 +2260,14 @@ def test_should_respond_200_with_dag_run_id(self, test_client, session):\n             \"only_running\": True,\n             \"dag_run_id\": \"TEST_DAG_RUN_ID_0\",\n         }\n-        task_instances = [\n-            {\"logical_date\": DEFAULT_DATETIME_1, \"state\": State.RUNNING},\n-            {\n-                \"logical_date\": DEFAULT_DATETIME_1 + dt.timedelta(days=1),\n-                \"state\": State.RUNNING,\n-            },\n-            {\n-                \"logical_date\": DEFAULT_DATETIME_1 + dt.timedelta(days=2),\n-                \"state\": State.RUNNING,\n-            },\n-            {\n-                \"logical_date\": DEFAULT_DATETIME_1 + dt.timedelta(days=3),\n-                \"state\": State.RUNNING,\n-            },\n-            {\n-                \"logical_date\": DEFAULT_DATETIME_1 + dt.timedelta(days=4),\n-                \"state\": State.RUNNING,\n-            },\n-            {\n-                \"logical_date\": DEFAULT_DATETIME_1 + dt.timedelta(days=5),\n-                \"state\": State.RUNNING,\n-            },\n-        ]\n+        if target_logical_date:\n+            task_instances = [\n+                {\"logical_date\": target_logical_date + dt.timedelta(days=i), \"state\": State.RUNNING}\n+                for i in range(6)\n+            ]\n+        else:\n+            self.ti_extras[\"run_after\"] = DEFAULT_DATETIME_1\n+            task_instances = [{\"logical_date\": target_logical_date, \"state\": State.RUNNING} for _ in range(6)]\n \n         self.create_task_instances(\n             session,\n@@ -2296,7 +2294,7 @@ def test_should_respond_200_with_dag_run_id(self, test_client, session):\n                 \"executor_config\": \"{}\",\n                 \"hostname\": \"\",\n                 \"id\": mock.ANY,\n-                \"logical_date\": \"2020-01-01T00:00:00Z\",\n+                \"logical_date\": response_logical_date,\n                 \"map_index\": -1,\n                 \"max_tries\": 0,\n                 \"note\": \"placeholder-note\",\n", "problem_statement": "Clear task instance API is picking up TIs from previous runs\n\n\nIf I am on an individual task instance page and hit the \"Clear Task Instance\" button on a manually triggered run(might be relevant) the TIs being returned from the dry-run response are showing TIs from the previous runs too!\n\n<img width=\"1465\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/15aad060-b77a-450f-b098-e54147e539f8\" />\n\nThe request it makes:\n\n```json\n{\n    \"dry_run\":true,\n    \"dag_run_id\":\"manual__2025-02-16T12:01:03.692059+00:00_3WJ3YS91\",\n    \"include_downstream\":false,\n    \"include_future\":false,\n    \"include_past\":false,\n    \"include_upstream\":false,\n    \"only_failed\":false,\n    \"task_ids\":[\"waiter\"]\n}\n```\n\nThe response is showing TIs from the previous two runs. (The dag in question is one with just a single TI, `waiter`, and there are three triggered runs.)\n\n```json\n{\n\t\"task_instances\": [\n\t\t{\n\t\t\t\"id\": \"01950e95-2c03-70c6-a089-308bc7020827\",\n\t\t\t\"task_id\": \"waiter\",\n\t\t\t\"dag_id\": \"trigger_test\",\n\t\t\t\"dag_run_id\": \"manual__2025-02-16T11:46:52.024510+00:00_RZIbCTvh\",\n\t\t\t\"map_index\": -1,\n\t\t\t\"logical_date\": null,\n\t\t\t\"start_date\": \"2025-02-16T11:46:52.637006Z\",\n\t\t\t\"end_date\": \"2025-02-16T11:46:52.695007Z\",\n\t\t\t\"duration\": 0.058001,\n\t\t\t\"state\": \"failed\",\n\t\t\t\"try_number\": 1,\n\t\t\t\"max_tries\": 0,\n\t\t\t\"task_display_name\": \"waiter\",\n\t\t\t\"hostname\": \"87ff8343cda4\",\n\t\t\t\"unixname\": \"root\",\n\t\t\t\"pool\": \"default_pool\",\n\t\t\t\"pool_slots\": 1,\n\t\t\t\"queue\": \"default\",\n\t\t\t\"priority_weight\": 1,\n\t\t\t\"operator\": \"TimeDeltaSensorAsync\",\n\t\t\t\"queued_when\": \"2025-02-16T11:46:52.595300Z\",\n\t\t\t\"scheduled_when\": \"2025-02-16T11:46:52.586181Z\",\n\t\t\t\"pid\": 341,\n\t\t\t\"executor\": null,\n\t\t\t\"executor_config\": \"{}\",\n\t\t\t\"note\": null,\n\t\t\t\"rendered_map_index\": null,\n\t\t\t\"rendered_fields\": {},\n\t\t\t\"trigger\": null,\n\t\t\t\"triggerer_job\": null,\n\t\t\t\"dag_version\": {\n\t\t\t\t\"id\": \"01950e94-bff7-7914-8ddd-3c833b81905e\",\n\t\t\t\t\"version_number\": 1,\n\t\t\t\t\"dag_id\": \"trigger_test\",\n\t\t\t\t\"bundle_name\": \"dags-folder\",\n\t\t\t\t\"bundle_version\": null,\n\t\t\t\t\"created_at\": \"2025-02-16T11:46:24.375982Z\",\n\t\t\t\t\"bundle_url\": null\n\t\t\t}\n\t\t},\n\t\t{\n\t\t\t\"id\": \"01950ea0-d504-7a4c-ad51-cd8e25d7707a\",\n\t\t\t\"task_id\": \"waiter\",\n\t\t\t\"dag_id\": \"trigger_test\",\n\t\t\t\"dag_run_id\": \"manual__2025-02-16T11:59:36.187699+00:00_Swy78lS9\",\n\t\t\t\"map_index\": -1,\n\t\t\t\"logical_date\": null,\n\t\t\t\"start_date\": \"2025-02-16T11:59:36.870397Z\",\n\t\t\t\"end_date\": \"2025-02-16T12:00:06.642179Z\",\n\t\t\t\"duration\": 29.771782,\n\t\t\t\"state\": \"failed\",\n\t\t\t\"try_number\": 1,\n\t\t\t\"max_tries\": 0,\n\t\t\t\"task_display_name\": \"waiter\",\n\t\t\t\"hostname\": \"87ff8343cda4\",\n\t\t\t\"unixname\": \"root\",\n\t\t\t\"pool\": \"default_pool\",\n\t\t\t\"pool_slots\": 1,\n\t\t\t\"queue\": \"default\",\n\t\t\t\"priority_weight\": 1,\n\t\t\t\"operator\": \"WaitSensor\",\n\t\t\t\"queued_when\": \"2025-02-16T11:59:36.839518Z\",\n\t\t\t\"scheduled_when\": \"2025-02-16T11:59:36.829959Z\",\n\t\t\t\"pid\": 397,\n\t\t\t\"executor\": null,\n\t\t\t\"executor_config\": \"{}\",\n\t\t\t\"note\": null,\n\t\t\t\"rendered_map_index\": null,\n\t\t\t\"rendered_fields\": {},\n\t\t\t\"trigger\": null,\n\t\t\t\"triggerer_job\": null,\n\t\t\t\"dag_version\": {\n\t\t\t\t\"id\": \"01950ea0-b284-79ca-a004-d0f8e6680a2e\",\n\t\t\t\t\"version_number\": 2,\n\t\t\t\t\"dag_id\": \"trigger_test\",\n\t\t\t\t\"bundle_name\": \"dags-folder\",\n\t\t\t\t\"bundle_version\": null,\n\t\t\t\t\"created_at\": \"2025-02-16T11:59:27.364077Z\",\n\t\t\t\t\"bundle_url\": null\n\t\t\t}\n\t\t},\n\t\t{\n\t\t\t\"id\": \"01950ea2-2ad5-74fa-b8d8-671a4f4acc22\",\n\t\t\t\"task_id\": \"waiter\",\n\t\t\t\"dag_id\": \"trigger_test\",\n\t\t\t\"dag_run_id\": \"manual__2025-02-16T12:01:03.692059+00:00_3WJ3YS91\",\n\t\t\t\"map_index\": -1,\n\t\t\t\"logical_date\": null,\n\t\t\t\"start_date\": \"2025-02-16T12:01:04.468535Z\",\n\t\t\t\"end_date\": \"2025-02-16T12:01:05.510885Z\",\n\t\t\t\"duration\": 1.04235,\n\t\t\t\"state\": \"failed\",\n\t\t\t\"try_number\": 1,\n\t\t\t\"max_tries\": 0,\n\t\t\t\"task_display_name\": \"waiter\",\n\t\t\t\"hostname\": \"87ff8343cda4\",\n\t\t\t\"unixname\": \"root\",\n\t\t\t\"pool\": \"default_pool\",\n\t\t\t\"pool_slots\": 1,\n\t\t\t\"queue\": \"default\",\n\t\t\t\"priority_weight\": 1,\n\t\t\t\"operator\": \"WaitSensor\",\n\t\t\t\"queued_when\": \"2025-02-16T12:01:04.433072Z\",\n\t\t\t\"scheduled_when\": \"2025-02-16T12:01:04.426619Z\",\n\t\t\t\"pid\": 422,\n\t\t\t\"executor\": null,\n\t\t\t\"executor_config\": \"{}\",\n\t\t\t\"note\": null,\n\t\t\t\"rendered_map_index\": null,\n\t\t\t\"rendered_fields\": {},\n\t\t\t\"trigger\": null,\n\t\t\t\"triggerer_job\": null,\n\t\t\t\"dag_version\": {\n\t\t\t\t\"id\": \"01950ea0-b284-79ca-a004-d0f8e6680a2e\",\n\t\t\t\t\"version_number\": 2,\n\t\t\t\t\"dag_id\": \"trigger_test\",\n\t\t\t\t\"bundle_name\": \"dags-folder\",\n\t\t\t\t\"bundle_version\": null,\n\t\t\t\t\"created_at\": \"2025-02-16T11:59:27.364077Z\",\n\t\t\t\t\"bundle_url\": null\n\t\t\t}\n\t\t}\n\t]\n}\n```\n\n", "hints_text": "", "created_at": "2025-02-19T07:25:05Z"}
{"repo": "apache/airflow", "pull_number": 46869, "instance_id": "apache__airflow-46869", "issue_numbers": ["45449"], "base_commit": "ae5afd97dd63fc76a1a770c1d7160ac931b4b80f", "patch": "diff --git a/airflow/api_fastapi/app.py b/airflow/api_fastapi/app.py\nindex cd7985a3eb97f..3c812cde05645 100644\n--- a/airflow/api_fastapi/app.py\n+++ b/airflow/api_fastapi/app.py\n@@ -88,7 +88,7 @@ def create_app(apps: str = \"all\") -> FastAPI:\n         init_middlewares(app)\n \n     if \"execution\" in apps_list or \"all\" in apps_list:\n-        task_exec_api_app = create_task_execution_api_app(app)\n+        task_exec_api_app = create_task_execution_api_app()\n         init_error_handlers(task_exec_api_app)\n         app.mount(\"/execution\", task_exec_api_app)\n \ndiff --git a/airflow/api_fastapi/execution_api/app.py b/airflow/api_fastapi/execution_api/app.py\nindex 2b85be363f25f..cee567f2d4999 100644\n--- a/airflow/api_fastapi/execution_api/app.py\n+++ b/airflow/api_fastapi/execution_api/app.py\n@@ -18,10 +18,16 @@\n from __future__ import annotations\n \n from contextlib import asynccontextmanager\n+from functools import cached_property\n+from typing import TYPE_CHECKING\n \n+import attrs\n from fastapi import FastAPI\n from fastapi.openapi.utils import get_openapi\n \n+if TYPE_CHECKING:\n+    import httpx\n+\n \n @asynccontextmanager\n async def lifespan(app: FastAPI):\n@@ -30,7 +36,7 @@ async def lifespan(app: FastAPI):\n     yield\n \n \n-def create_task_execution_api_app(app: FastAPI) -> FastAPI:\n+def create_task_execution_api_app() -> FastAPI:\n     \"\"\"Create FastAPI app for task execution API.\"\"\"\n     from airflow.api_fastapi.execution_api.routes import execution_api_router\n \n@@ -88,3 +94,37 @@ def get_extra_schemas() -> dict[str, dict]:\n         # as that has different payload requirements\n         \"TerminalTIState\": {\"type\": \"string\", \"enum\": list(TerminalTIState)},\n     }\n+\n+\n+@attrs.define()\n+class InProcessExecuctionAPI:\n+    \"\"\"\n+    A helper class to make it possible to run the ExecutionAPI \"in-process\".\n+\n+    The sync version of this makes use of a2wsgi which runs the async loop in a separate thread. This is\n+    needed so that we can use the sync httpx client\n+    \"\"\"\n+\n+    _app: FastAPI | None = None\n+\n+    @cached_property\n+    def app(self):\n+        if not self._app:\n+            from airflow.api_fastapi.execution_api.app import create_task_execution_api_app\n+\n+            self._app = create_task_execution_api_app()\n+\n+        return self._app\n+\n+    @cached_property\n+    def transport(self) -> httpx.WSGITransport:\n+        import httpx\n+        from a2wsgi import ASGIMiddleware\n+\n+        return httpx.WSGITransport(app=ASGIMiddleware(self.app))  # type: ignore[arg-type]\n+\n+    @cached_property\n+    def atransport(self) -> httpx.ASGITransport:\n+        import httpx\n+\n+        return httpx.ASGITransport(app=self.app)\ndiff --git a/airflow/dag_processing/processor.py b/airflow/dag_processing/processor.py\nindex 058d59c9ed1d7..7360f0b7c7a5d 100644\n--- a/airflow/dag_processing/processor.py\n+++ b/airflow/dag_processing/processor.py\n@@ -16,6 +16,7 @@\n # under the License.\n from __future__ import annotations\n \n+import functools\n import os\n import sys\n import traceback\n@@ -32,7 +33,7 @@\n )\n from airflow.configuration import conf\n from airflow.models.dagbag import DagBag\n-from airflow.sdk.execution_time.comms import GetConnection, GetVariable\n+from airflow.sdk.execution_time.comms import ConnectionResult, GetConnection, GetVariable, VariableResult\n from airflow.sdk.execution_time.supervisor import WatchedSubprocess\n from airflow.serialization.serialized_objects import LazyDeserializedDAG, SerializedDAG\n from airflow.stats import Stats\n@@ -40,9 +41,21 @@\n if TYPE_CHECKING:\n     from structlog.typing import FilteringBoundLogger\n \n+    from airflow.api_fastapi.execution_api.app import InProcessExecuctionAPI\n+    from airflow.sdk.api.client import Client\n     from airflow.sdk.definitions.context import Context\n     from airflow.typing_compat import Self\n \n+ToManager = Annotated[\n+    Union[\"DagFileParsingResult\", GetConnection, GetVariable],\n+    Field(discriminator=\"type\"),\n+]\n+\n+ToDagProcessor = Annotated[\n+    Union[\"DagFileParseRequest\", ConnectionResult, VariableResult],\n+    Field(discriminator=\"type\"),\n+]\n+\n \n def _parse_file_entrypoint():\n     import os\n@@ -51,19 +64,24 @@ def _parse_file_entrypoint():\n \n     from airflow.sdk.execution_time import task_runner\n     from airflow.settings import configure_orm\n+\n     # Parse DAG file, send JSON back up!\n \n     # We need to reconfigure the orm here, as DagFileProcessorManager does db queries for bundles, and\n     # the session across forks blows things up.\n     configure_orm()\n \n-    comms_decoder = task_runner.CommsDecoder[DagFileParseRequest, DagFileParsingResult](\n+    comms_decoder = task_runner.CommsDecoder[ToDagProcessor, ToManager](\n         input=sys.stdin,\n-        decoder=TypeAdapter[DagFileParseRequest](DagFileParseRequest),\n+        decoder=TypeAdapter[ToDagProcessor](ToDagProcessor),\n     )\n+\n     msg = comms_decoder.get_message()\n+    if not isinstance(msg, DagFileParseRequest):\n+        raise RuntimeError(f\"Required first message to be a DagFileParseRequest, it was {msg}\")\n     comms_decoder.request_socket = os.fdopen(msg.requests_fd, \"wb\", buffering=0)\n \n+    task_runner.SUPERVISOR_COMMS = comms_decoder\n     log = structlog.get_logger(logger_name=\"task\")\n \n     result = _parse_file(msg, log)\n@@ -188,10 +206,12 @@ class DagFileParsingResult(BaseModel):\n     type: Literal[\"DagFileParsingResult\"] = \"DagFileParsingResult\"\n \n \n-ToParent = Annotated[\n-    Union[DagFileParsingResult, GetConnection, GetVariable],\n-    Field(discriminator=\"type\"),\n-]\n+@functools.cache\n+def in_process_api_server() -> InProcessExecuctionAPI:\n+    from airflow.api_fastapi.execution_api.app import InProcessExecuctionAPI\n+\n+    api = InProcessExecuctionAPI()\n+    return api\n \n \n @attrs.define(kw_only=True)\n@@ -207,7 +227,7 @@ class DagFileProcessorProcess(WatchedSubprocess):\n     \"\"\"\n \n     parsing_result: DagFileParsingResult | None = None\n-    decoder: ClassVar[TypeAdapter[ToParent]] = TypeAdapter[ToParent](ToParent)\n+    decoder: ClassVar[TypeAdapter[ToManager]] = TypeAdapter[ToManager](ToManager)\n \n     @classmethod\n     def start(  # type: ignore[override]\n@@ -237,12 +257,36 @@ def _on_child_started(\n         )\n         self.stdin.write(msg.model_dump_json().encode() + b\"\\n\")\n \n-    def _handle_request(self, msg: ToParent, log: FilteringBoundLogger) -> None:  # type: ignore[override]\n-        # TODO: GetVariable etc -- parsing a dag can run top level code that asks for an Airflow Variable\n+    @functools.cached_property\n+    def client(self) -> Client:\n+        from airflow.sdk.api.client import Client\n+\n+        client = Client(base_url=None, token=\"\", dry_run=True, transport=in_process_api_server().transport)\n+        # Mypy is wrong -- the setter accepts a string on the property setter! `URLType = URL | str`\n+        client.base_url = \"http://in-process.invalid./\"  # type: ignore[assignment]\n+        return client\n+\n+    def _handle_request(self, msg: ToManager, log: FilteringBoundLogger) -> None:  # type: ignore[override]\n+        from airflow.sdk.api.datamodels._generated import ConnectionResponse, VariableResponse\n+\n         resp = None\n         if isinstance(msg, DagFileParsingResult):\n             self.parsing_result = msg\n             return\n+        elif isinstance(msg, GetConnection):\n+            conn = self.client.connections.get(msg.conn_id)\n+            if isinstance(conn, ConnectionResponse):\n+                conn_result = ConnectionResult.from_conn_response(conn)\n+                resp = conn_result.model_dump_json(exclude_unset=True).encode()\n+            else:\n+                resp = conn.model_dump_json().encode()\n+        elif isinstance(msg, GetVariable):\n+            var = self.client.variables.get(msg.key)\n+            if isinstance(var, VariableResponse):\n+                var_result = VariableResult.from_variable_response(var)\n+                resp = var_result.model_dump_json(exclude_unset=True).encode()\n+            else:\n+                resp = var.model_dump_json().encode()\n         else:\n             log.error(\"Unhandled request\", msg=msg)\n             return\ndiff --git a/airflow/models/variable.py b/airflow/models/variable.py\nindex b4568ad09c489..d2532e1203e22 100644\n--- a/airflow/models/variable.py\n+++ b/airflow/models/variable.py\n@@ -19,6 +19,8 @@\n \n import json\n import logging\n+import sys\n+import warnings\n from typing import TYPE_CHECKING, Any\n \n from sqlalchemy import Boolean, Column, Integer, String, Text, delete, select\n@@ -136,6 +138,28 @@ def get(\n         :param default_var: Default value of the Variable if the Variable doesn't exist\n         :param deserialize_json: Deserialize the value to a Python dict\n         \"\"\"\n+        # TODO: This is not the best way of having compat, but it's \"better than erroring\" for now. This still\n+        # means SQLA etc is loaded, but we can't avoid that unless/until we add import shims as a big\n+        # back-compat layer\n+\n+        # If this is set it means are in some kind of execution context (Task, Dag Parse or Triggerer perhaps)\n+        # and should use the Task SDK API server path\n+        if hasattr(sys.modules.get(\"airflow.sdk.execution_time.task_runner\"), \"SUPERVISOR_COMMS\"):\n+            warnings.warn(\n+                \"Using Variable.get from `airflow.models` is deprecated. Please use `from airflow.sdk import\"\n+                \"Variable` instead\",\n+                DeprecationWarning,\n+                stacklevel=1,\n+            )\n+            from airflow.sdk import Variable as TaskSDKVariable\n+            from airflow.sdk.definitions._internal.types import NOTSET\n+\n+            return TaskSDKVariable.get(\n+                key,\n+                default=NOTSET if default_var is cls.__NO_DEFAULT_SENTINEL else default_var,\n+                deserialize_json=deserialize_json,\n+            )\n+\n         var_val = Variable.get_variable_from_secrets(key=key)\n         if var_val is None:\n             if default_var is not cls.__NO_DEFAULT_SENTINEL:\ndiff --git a/hatch_build.py b/hatch_build.py\nindex d5bd397570dcc..ae611b55778cc 100644\n--- a/hatch_build.py\n+++ b/hatch_build.py\n@@ -342,6 +342,7 @@\n }\n \n DEPENDENCIES = [\n+    \"a2wsgi>=1.10.8\",\n     # Alembic is important to handle our migrations in predictable and performant way. It is developed\n     # together with SQLAlchemy. Our experience with Alembic is that it very stable in minor version\n     # The 1.13.0 of alembic marked some migration code as SQLAlchemy 2+ only so we limit it to 1.13.1\ndiff --git a/task_sdk/src/airflow/sdk/__init__.py b/task_sdk/src/airflow/sdk/__init__.py\nindex 95b08be37aa09..1fabbd2bd0308 100644\n--- a/task_sdk/src/airflow/sdk/__init__.py\n+++ b/task_sdk/src/airflow/sdk/__init__.py\n@@ -29,6 +29,7 @@\n     \"Label\",\n     \"MappedOperator\",\n     \"TaskGroup\",\n+    \"Variable\",\n     \"XComArg\",\n     \"dag\",\n     \"get_current_context\",\n@@ -46,6 +47,7 @@\n     from airflow.sdk.definitions.edges import EdgeModifier, Label\n     from airflow.sdk.definitions.mappedoperator import MappedOperator\n     from airflow.sdk.definitions.taskgroup import TaskGroup\n+    from airflow.sdk.definitions.variable import Variable\n     from airflow.sdk.definitions.xcom_arg import XComArg\n \n __lazy_imports: dict[str, str] = {\ndiff --git a/task_sdk/src/airflow/sdk/api/client.py b/task_sdk/src/airflow/sdk/api/client.py\nindex 5d81c32eefa4b..6e5e6d5a2de9a 100644\n--- a/task_sdk/src/airflow/sdk/api/client.py\n+++ b/task_sdk/src/airflow/sdk/api/client.py\n@@ -384,8 +384,8 @@ def __init__(self, *, base_url: str | None, dry_run: bool = False, token: str, *\n         if dry_run:\n             # If dry run is requested, install a no op handler so that simple tasks can \"heartbeat\" using a\n             # real client, but just don't make any HTTP requests\n-            kwargs[\"transport\"] = httpx.MockTransport(noop_handler)\n-            kwargs[\"base_url\"] = \"dry-run://server\"\n+            kwargs.setdefault(\"transport\", httpx.MockTransport(noop_handler))\n+            kwargs.setdefault(\"base_url\", \"dry-run://server\")\n         else:\n             kwargs[\"base_url\"] = base_url\n         pyver = f\"{'.'.join(map(str, sys.version_info[:3]))}\"\ndiff --git a/task_sdk/src/airflow/sdk/definitions/variable.py b/task_sdk/src/airflow/sdk/definitions/variable.py\nindex 5f458580065c5..46742e965ed5e 100644\n--- a/task_sdk/src/airflow/sdk/definitions/variable.py\n+++ b/task_sdk/src/airflow/sdk/definitions/variable.py\n@@ -21,6 +21,8 @@\n \n import attrs\n \n+from airflow.sdk.definitions._internal.types import NOTSET\n+\n \n @attrs.define\n class Variable:\n@@ -39,3 +41,14 @@ class Variable:\n     description: str | None = None\n \n     # TODO: Extend this definition for reading/writing variables without context\n+    @classmethod\n+    def get(cls, key: str, default: Any = NOTSET, deserialize_json: bool = False):\n+        from airflow.sdk.exceptions import AirflowRuntimeError, ErrorType\n+        from airflow.sdk.execution_time.context import _get_variable\n+\n+        try:\n+            return _get_variable(key, deserialize_json=deserialize_json).value\n+        except AirflowRuntimeError as e:\n+            if e.error.error == ErrorType.VARIABLE_NOT_FOUND and default is not NOTSET:\n+                return default\n+            raise\n", "test_patch": "diff --git a/tests/api_fastapi/test_app.py b/tests/api_fastapi/test_app.py\nindex 249fbdba15aa4..e2a15988d4b47 100644\n--- a/tests/api_fastapi/test_app.py\n+++ b/tests/api_fastapi/test_app.py\n@@ -57,10 +57,10 @@ def test_core_api_app(\n def test_execution_api_app(\n     mock_create_task_exec_api, mock_init_plugins, mock_init_views, mock_init_dag_bag, client\n ):\n-    test_app = client(apps=\"execution\").app\n+    client(apps=\"execution\")\n \n     # Assert that execution-related functions were called\n-    mock_create_task_exec_api.assert_called_once_with(test_app)\n+    mock_create_task_exec_api.assert_called_once()\n \n     # Assert that core-related functions were NOT called\n     mock_init_dag_bag.assert_not_called()\n@@ -91,4 +91,4 @@ def test_all_apps(mock_create_task_exec_api, mock_init_plugins, mock_init_views,\n     mock_init_plugins.assert_called_once_with(test_app)\n \n     # Assert that execution-related functions were also called\n-    mock_create_task_exec_api.assert_called_once_with(test_app)\n+    mock_create_task_exec_api.assert_called_once_with()\ndiff --git a/tests/dag_processing/test_processor.py b/tests/dag_processing/test_processor.py\nindex a01d3edb2ff3b..a20be18d3583a 100644\n--- a/tests/dag_processing/test_processor.py\n+++ b/tests/dag_processing/test_processor.py\n@@ -17,10 +17,12 @@\n # under the License.\n from __future__ import annotations\n \n+import inspect\n import pathlib\n import sys\n+import textwrap\n from socket import socketpair\n-from typing import TYPE_CHECKING\n+from typing import TYPE_CHECKING, Callable\n from unittest.mock import patch\n \n import pytest\n@@ -32,6 +34,7 @@\n from airflow.dag_processing.processor import (\n     DagFileParseRequest,\n     DagFileParsingResult,\n+    DagFileProcessorProcess,\n     _parse_file,\n )\n from airflow.models import DagBag, TaskInstance\n@@ -51,16 +54,9 @@\n pytestmark = pytest.mark.db_test\n \n DEFAULT_DATE = timezone.datetime(2016, 1, 1)\n-PY311 = sys.version_info >= (3, 11)\n-\n-# Include the words \"airflow\" and \"dag\" in the file contents,\n-# tricking airflow into thinking these\n-# files contain a DAG (otherwise Airflow will skip them)\n-PARSEABLE_DAG_FILE_CONTENTS = '\"airflow DAG\"'\n \n # Filename to be used for dags that are created in an ad-hoc manner and can be removed/\n # created at runtime\n-TEMP_DAG_FILENAME = \"temp_dag.py\"\n TEST_DAG_FOLDER = pathlib.Path(__file__).parents[1].resolve() / \"dags\"\n \n \n@@ -133,44 +129,45 @@ def fake_collect_dags(dagbag: DagBag, *args, **kwargs):\n         assert resp.import_errors is not None\n         assert \"a.py\" in resp.import_errors\n \n+    # @pytest.mark.execution_timeout(10)\n+    def test_top_level_variable_access(\n+        self, spy_agency: SpyAgency, tmp_path: pathlib.Path, monkeypatch: pytest.MonkeyPatch\n+    ):\n+        # Create the dag in a fn, and use inspect.getsource to write it to a file so that\n+        # a) the test dag is directly viewable here in the tests\n+        # b) that it shows to IDEs/mypy etc.\n+        def dag_in_a_fn():\n+            from airflow.sdk import DAG, Variable\n+\n+            with DAG(f\"test_{Variable.get('myvar')}\"):\n+                ...\n+\n+        path = write_dag_in_a_fn_to_file(dag_in_a_fn, tmp_path)\n+\n+        monkeypatch.setenv(\"AIRFLOW_VAR_MYVAR\", \"abc\")\n+        proc = DagFileProcessorProcess.start(\n+            id=1,\n+            path=path,\n+            bundle_path=tmp_path,\n+            callbacks=[],\n+        )\n+\n+        while not proc.is_ready:\n+            proc._service_subprocess(0.1)\n \n-#     @conf_vars({(\"logging\", \"dag_processor_log_target\"): \"stdout\"})\n-#     @mock.patch(\"airflow.dag_processing.processor.settings.dispose_orm\", MagicMock)\n-#     @mock.patch(\"airflow.dag_processing.processor.redirect_stdout\")\n-#     def test_dag_parser_output_when_logging_to_stdout(self, mock_redirect_stdout_for_file):\n-#         processor = DagFileProcessorProcess(\n-#             file_path=\"abc.txt\",\n-#             dag_directory=[],\n-#             callback_requests=[],\n-#         )\n-#         processor._run_file_processor(\n-#             result_channel=MagicMock(),\n-#             parent_channel=MagicMock(),\n-#             file_path=\"fake_file_path\",\n-#             thread_name=\"fake_thread_name\",\n-#             callback_requests=[],\n-#             dag_directory=[],\n-#         )\n-#         mock_redirect_stdout_for_file.assert_not_called()\n-#\n-#     @conf_vars({(\"logging\", \"dag_processor_log_target\"): \"file\"})\n-#     @mock.patch(\"airflow.dag_processing.processor.settings.dispose_orm\", MagicMock)\n-#     @mock.patch(\"airflow.dag_processing.processor.redirect_stdout\")\n-#     def test_dag_parser_output_when_logging_to_file(self, mock_redirect_stdout_for_file):\n-#         processor = DagFileProcessorProcess(\n-#             file_path=\"abc.txt\",\n-#             dag_directory=[],\n-#             callback_requests=[],\n-#         )\n-#         processor._run_file_processor(\n-#             result_channel=MagicMock(),\n-#             parent_channel=MagicMock(),\n-#             file_path=\"fake_file_path\",\n-#             thread_name=\"fake_thread_name\",\n-#             callback_requests=[],\n-#             dag_directory=[],\n-#         )\n-#         mock_redirect_stdout_for_file.assert_called_once()\n+        result = proc.parsing_result\n+        assert result is not None\n+        assert result.import_errors == {}\n+        assert result.serialized_dags[0].dag_id == \"test_abc\"\n+\n+\n+def write_dag_in_a_fn_to_file(fn: Callable[[], None], folder: pathlib.Path) -> pathlib.Path:\n+    assert folder.is_dir()\n+    name = fn.__name__\n+    path = folder.joinpath(name + \".py\")\n+    path.write_text(textwrap.dedent(inspect.getsource(fn)) + f\"\\n\\n{name}()\")\n+\n+    return path\n \n \n @pytest.fixture\n", "problem_statement": "AIP-72: Add support to get Variables in task sdk outside of context\n### Body\n\nTo write dags using the task sdk, we need to add support to get variables using client side definitions and the task sdk machinery.\n\nMove Secrets Backend on the client side!\n\nCurrently, Secrets Backends are only supported (and configured) on the API Server. The Python Task SDK client\u00a0does not\u00a0do any lookup locally and relies on Server. \n\nThis is for supporting the following use-case:\n\n>Deploying tasks in transient or ephemeral environments (e.g., GPU cloud services) where secrets need to be retrieved dynamically via the API\n\nThis allows for Secrets to be defined once and allows central management with fewer configurations on the worker.\n\nHowever, there is a complementary use case as below\n\n>An organization processes sensitive customer data for financial transactions. Regulatory and security policies mandate that certain credentials (e.g., database credentials, API keys, encryption keys) cannot leave a specific network zone. This includes ensuring that the Airflow scheduler, API server, or other components outside this zone cannot access these secrets.\n\nThis use-case means we need a way where secrets are already provisioned locally on the worker. \n\nSecrets Backend will be available to be configured on the Client by default. Packaging-wise: The External Secrets Backend will be part of Providers, which depend on Task SDK. \n\nFor the API-Server, by default it will only look at Env Variable and then Database by default.\n1. Optionally, if users want the API server to fetch secrets from the External Secrets backend, they will have to install the Task SDK (and relevant providers like Hashicorp) with the scheduler/Airflow core code.\n2. Longer term: we might be able to remove requirements on Task SDK by implementing some protocol but this will be discussed again post AF 3.0.\n", "hints_text": "", "created_at": "2025-02-18T18:34:28Z"}
{"repo": "apache/airflow", "pull_number": 46851, "instance_id": "apache__airflow-46851", "issue_numbers": ["42315"], "base_commit": "647a2d1cbec2887d3cdf5d04d0e51b5279f2ffce", "patch": "diff --git a/task_sdk/src/airflow/sdk/definitions/asset/decorators.py b/task_sdk/src/airflow/sdk/definitions/asset/decorators.py\nindex 579cc94b3ce34..c70a224858b1b 100644\n--- a/task_sdk/src/airflow/sdk/definitions/asset/decorators.py\n+++ b/task_sdk/src/airflow/sdk/definitions/asset/decorators.py\n@@ -171,6 +171,7 @@ def create_dag(self, *, dag_id: str) -> DAG:\n             dag_id=dag_id,\n             schedule=self.schedule,\n             is_paused_upon_creation=self.is_paused_upon_creation,\n+            catchup=False,\n             dag_display_name=self.display_name or dag_id,\n             description=self.description,\n             params=self.params,\n@@ -196,8 +197,6 @@ class multi(_DAGFactory):\n         outlets: Collection[BaseAsset]  # TODO: Support non-asset outlets?\n \n         def __call__(self, f: Callable) -> MultiAssetDefinition:\n-            if self.schedule is not None:\n-                raise NotImplementedError(\"asset scheduling not implemented yet\")\n             if f.__name__ != f.__qualname__:\n                 raise ValueError(\"nested function not supported\")\n             if not self.outlets:\n@@ -205,12 +204,8 @@ def __call__(self, f: Callable) -> MultiAssetDefinition:\n             return MultiAssetDefinition(function=f, source=self)\n \n     def __call__(self, f: Callable) -> AssetDefinition:\n-        if self.schedule is not None:\n-            raise NotImplementedError(\"asset scheduling not implemented yet\")\n-\n         if (name := f.__name__) != f.__qualname__:\n             raise ValueError(\"nested function not supported\")\n-\n         return AssetDefinition(\n             name=name,\n             uri=name if self.uri is None else str(self.uri),\n", "test_patch": "diff --git a/task_sdk/tests/definitions/test_asset_decorators.py b/task_sdk/tests/definitions/test_asset_decorators.py\nindex 5cac8b8181364..4467397f07244 100644\n--- a/task_sdk/tests/definitions/test_asset_decorators.py\n+++ b/task_sdk/tests/definitions/test_asset_decorators.py\n@@ -132,6 +132,7 @@ def test__attrs_post_init__(self, DAG, from_definition, example_asset_func_with_\n             dag_display_name=\"example_asset_func\",\n             description=None,\n             schedule=None,\n+            catchup=False,\n             is_paused_upon_creation=None,\n             on_failure_callback=None,\n             on_success_callback=None,\n@@ -155,6 +156,7 @@ def test__attrs_post_init__(self, DAG, from_definition, example_asset_func_with_\n             dag_display_name=\"example_asset_func\",\n             description=None,\n             schedule=None,\n+            catchup=False,\n             is_paused_upon_creation=None,\n             on_failure_callback=None,\n             on_success_callback=None,\n", "problem_statement": "Implement schedule on @asset\n### Description\n\n[Schedules](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=311627076#AIP75NewAssetCentricSyntax-Schedules)\n\nThis will probably be achieve by using `AssetRef` to access Asset by name\n\nThis one could be deferred to \"Data Completeness\"\n\n### Use case/motivation\n\n[Rationale](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=311626828#AIP73ExpandedDataAwareness-Rationale)\n\n### Related issues\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [X] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/apache/airflow/blob/main/CODE_OF_CONDUCT.md)\n\n", "hints_text": "PR to add asset reference support https://github.com/apache/airflow/pull/45028\nThere\u2019s a second part to come later to implement modern schedule dates (logical date at the end, no data intervals).\nPR for asset ref merged.\nThere\u2019s still this part of the AIP left https://cwiki.apache.org/confluence/x/RA2TEg\r\n\r\n> The key difference is, since we are decoupling partitioning from scheduling, the schedule parameter no longer controls the interval, i.e. not designed around the logical/execution date. It simply controls when the next round should happen.\r\n>\r\n> It is expected that scheduling of non-asset workflows (DAGs) will also be changed in a similar way to match the behavior for assets. Existing operators must be reviewed to ensure they account for the new scheduling semantic, but we should provide a transition interface to assist rewrites and better allow providers to develop a implementation both compatible to 2 and 3. The timetable protocol will also require new methods to implement the new semantic, but both old and new should be able to both implemented on the same class, with each major version only calling methods its uses.\r\n\r\nThis behaviour is partially in line with the amendments proposed for AIP-83, and will be implemented together with changes to the DAG class. https://cwiki.apache.org/confluence/x/Ngv0Ew\r\n\r\nSpecifically:\r\n\r\n* A DAG run backing an `@asset` materialisation will have its logical date and data interval values set to null in the database.\r\n* The `@asset` function\u2019s execution context dict will _not_ contain keys `logical_date` (and derived values such as `ds`), `data_interval_start`, and `data_interval_end`.\r\n* The run will be represented in user-facing interfaces by the `run_after` date (in line with all logical-date-less DAG runs in the amendment).\nDepends on #46192 ", "created_at": "2025-02-18T05:52:43Z"}
{"repo": "apache/airflow", "pull_number": 46741, "instance_id": "apache__airflow-46741", "issue_numbers": ["46735"], "base_commit": "d9b4f64a5bbdf170284c38fd0c38299a4fbbf0fc", "patch": "diff --git a/airflow/api_fastapi/core_api/datamodels/task_instances.py b/airflow/api_fastapi/core_api/datamodels/task_instances.py\nindex 7c849a9e86a72..b7fa74e16ae59 100644\n--- a/airflow/api_fastapi/core_api/datamodels/task_instances.py\n+++ b/airflow/api_fastapi/core_api/datamodels/task_instances.py\n@@ -47,6 +47,7 @@ class TaskInstanceResponse(BaseModel):\n     run_id: str = Field(alias=\"dag_run_id\")\n     map_index: int\n     logical_date: datetime | None\n+    run_after: datetime\n     start_date: datetime | None\n     end_date: datetime | None\n     duration: float | None\n@@ -104,6 +105,8 @@ class TaskInstancesBatchBody(StrictBaseModel):\n     dag_run_ids: list[str] | None = None\n     task_ids: list[str] | None = None\n     state: list[TaskInstanceState | None] | None = None\n+    run_after_gte: AwareDatetime | None = None\n+    run_after_lte: AwareDatetime | None = None\n     logical_date_gte: AwareDatetime | None = None\n     logical_date_lte: AwareDatetime | None = None\n     start_date_gte: AwareDatetime | None = None\ndiff --git a/airflow/api_fastapi/core_api/openapi/v1-generated.yaml b/airflow/api_fastapi/core_api/openapi/v1-generated.yaml\nindex 6394e43847221..1d2cbcfba5aed 100644\n--- a/airflow/api_fastapi/core_api/openapi/v1-generated.yaml\n+++ b/airflow/api_fastapi/core_api/openapi/v1-generated.yaml\n@@ -4834,6 +4834,24 @@ paths:\n         schema:\n           type: string\n           title: Task Id\n+      - name: run_after_gte\n+        in: query\n+        required: false\n+        schema:\n+          anyOf:\n+          - type: string\n+            format: date-time\n+          - type: 'null'\n+          title: Run After Gte\n+      - name: run_after_lte\n+        in: query\n+        required: false\n+        schema:\n+          anyOf:\n+          - type: string\n+            format: date-time\n+          - type: 'null'\n+          title: Run After Lte\n       - name: logical_date_gte\n         in: query\n         required: false\n@@ -5456,6 +5474,24 @@ paths:\n           - type: string\n           - type: 'null'\n           title: Task Id\n+      - name: run_after_gte\n+        in: query\n+        required: false\n+        schema:\n+          anyOf:\n+          - type: string\n+            format: date-time\n+          - type: 'null'\n+          title: Run After Gte\n+      - name: run_after_lte\n+        in: query\n+        required: false\n+        schema:\n+          anyOf:\n+          - type: string\n+            format: date-time\n+          - type: 'null'\n+          title: Run After Lte\n       - name: logical_date_gte\n         in: query\n         required: false\n@@ -10139,6 +10175,10 @@ components:\n             format: date-time\n           - type: 'null'\n           title: Logical Date\n+        run_after:\n+          type: string\n+          format: date-time\n+          title: Run After\n         start_date:\n           anyOf:\n           - type: string\n@@ -10259,6 +10299,7 @@ components:\n       - dag_run_id\n       - map_index\n       - logical_date\n+      - run_after\n       - start_date\n       - end_date\n       - duration\n@@ -10395,6 +10436,18 @@ components:\n             type: array\n           - type: 'null'\n           title: State\n+        run_after_gte:\n+          anyOf:\n+          - type: string\n+            format: date-time\n+          - type: 'null'\n+          title: Run After Gte\n+        run_after_lte:\n+          anyOf:\n+          - type: string\n+            format: date-time\n+          - type: 'null'\n+          title: Run After Lte\n         logical_date_gte:\n           anyOf:\n           - type: string\ndiff --git a/airflow/api_fastapi/core_api/routes/public/task_instances.py b/airflow/api_fastapi/core_api/routes/public/task_instances.py\nindex 927f62028a85d..4b6dc2d836a17 100644\n--- a/airflow/api_fastapi/core_api/routes/public/task_instances.py\n+++ b/airflow/api_fastapi/core_api/routes/public/task_instances.py\n@@ -114,6 +114,7 @@ def get_mapped_task_instances(\n     dag_run_id: str,\n     task_id: str,\n     request: Request,\n+    run_after_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"run_after\", TI))],\n     logical_date_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"logical_date\", TI))],\n     start_date_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"start_date\", TI))],\n     end_date_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"end_date\", TI))],\n@@ -139,12 +140,14 @@ def get_mapped_task_instances(\n                     \"map_index\",\n                     \"try_number\",\n                     \"logical_date\",\n+                    \"run_after\",\n                     \"data_interval_start\",\n                     \"data_interval_end\",\n                     \"rendered_map_index\",\n                 ],\n                 TI,\n                 to_replace={\n+                    \"run_after\": DagRun.run_after,\n                     \"logical_date\": DagRun.logical_date,\n                     \"data_interval_start\": DagRun.data_interval_start,\n                     \"data_interval_end\": DagRun.data_interval_end,\n@@ -180,6 +183,7 @@ def get_mapped_task_instances(\n     task_instance_select, total_entries = paginated_select(\n         statement=query,\n         filters=[\n+            run_after_range,\n             logical_date_range,\n             start_date_range,\n             end_date_range,\n@@ -360,7 +364,8 @@ def get_task_instances(\n     dag_run_id: str,\n     request: Request,\n     task_id: Annotated[FilterParam[str | None], Depends(filter_param_factory(TI.task_id, str | None))],\n-    logical_date: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"logical_date\", TI))],\n+    run_after_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"run_after\", TI))],\n+    logical_date_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"logical_date\", TI))],\n     start_date_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"start_date\", TI))],\n     end_date_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"end_date\", TI))],\n     update_at_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"updated_at\", TI))],\n@@ -386,6 +391,7 @@ def get_task_instances(\n                     \"map_index\",\n                     \"try_number\",\n                     \"logical_date\",\n+                    \"run_after\",\n                     \"data_interval_start\",\n                     \"data_interval_end\",\n                     \"rendered_map_index\",\n@@ -393,6 +399,7 @@ def get_task_instances(\n                 TI,\n                 to_replace={\n                     \"logical_date\": DagRun.logical_date,\n+                    \"run_after\": DagRun.run_after,\n                     \"data_interval_start\": DagRun.data_interval_start,\n                     \"data_interval_end\": DagRun.data_interval_end,\n                 },\n@@ -427,7 +434,8 @@ def get_task_instances(\n     task_instance_select, total_entries = paginated_select(\n         statement=query,\n         filters=[\n-            logical_date,\n+            run_after_range,\n+            logical_date_range,\n             start_date_range,\n             end_date_range,\n             update_at_range,\n@@ -467,6 +475,10 @@ def get_task_instances_batch(\n     dag_ids = FilterParam(TI.dag_id, body.dag_ids, FilterOptionEnum.IN)\n     dag_run_ids = FilterParam(TI.run_id, body.dag_run_ids, FilterOptionEnum.IN)\n     task_ids = FilterParam(TI.task_id, body.task_ids, FilterOptionEnum.IN)\n+    run_after = RangeFilter(\n+        Range(lower_bound=body.run_after_gte, upper_bound=body.run_after_lte),\n+        attribute=TI.run_after,\n+    )\n     logical_date = RangeFilter(\n         Range(lower_bound=body.logical_date_gte, upper_bound=body.logical_date_lte),\n         attribute=TI.logical_date,\n@@ -503,6 +515,7 @@ def get_task_instances_batch(\n             dag_ids,\n             dag_run_ids,\n             task_ids,\n+            run_after,\n             logical_date,\n             start_date,\n             end_date,\ndiff --git a/airflow/models/taskinstance.py b/airflow/models/taskinstance.py\nindex d5eaefaf2d7c9..f47fae789f8f9 100644\n--- a/airflow/models/taskinstance.py\n+++ b/airflow/models/taskinstance.py\n@@ -1734,6 +1734,7 @@ class TaskInstance(Base, LoggingMixin):\n     triggerer_job = association_proxy(\"trigger\", \"triggerer_job\")\n     dag_run = relationship(\"DagRun\", back_populates=\"task_instances\", lazy=\"joined\", innerjoin=True)\n     rendered_task_instance_fields = relationship(\"RenderedTaskInstanceFields\", lazy=\"noload\", uselist=False)\n+    run_after = association_proxy(\"dag_run\", \"run_after\")\n     logical_date = association_proxy(\"dag_run\", \"logical_date\")\n     task_instance_note = relationship(\n         \"TaskInstanceNote\",\ndiff --git a/airflow/ui/openapi-gen/queries/common.ts b/airflow/ui/openapi-gen/queries/common.ts\nindex 8bc70e1fb5700..070fb63fdee72 100644\n--- a/airflow/ui/openapi-gen/queries/common.ts\n+++ b/airflow/ui/openapi-gen/queries/common.ts\n@@ -990,6 +990,8 @@ export const UseTaskInstanceServiceGetMappedTaskInstancesKeyFn = (\n     orderBy,\n     pool,\n     queue,\n+    runAfterGte,\n+    runAfterLte,\n     startDateGte,\n     startDateLte,\n     state,\n@@ -1012,6 +1014,8 @@ export const UseTaskInstanceServiceGetMappedTaskInstancesKeyFn = (\n     orderBy?: string;\n     pool?: string[];\n     queue?: string[];\n+    runAfterGte?: string;\n+    runAfterLte?: string;\n     startDateGte?: string;\n     startDateLte?: string;\n     state?: string[];\n@@ -1039,6 +1043,8 @@ export const UseTaskInstanceServiceGetMappedTaskInstancesKeyFn = (\n       orderBy,\n       pool,\n       queue,\n+      runAfterGte,\n+      runAfterLte,\n       startDateGte,\n       startDateLte,\n       state,\n@@ -1201,6 +1207,8 @@ export const UseTaskInstanceServiceGetTaskInstancesKeyFn = (\n     orderBy,\n     pool,\n     queue,\n+    runAfterGte,\n+    runAfterLte,\n     startDateGte,\n     startDateLte,\n     state,\n@@ -1224,6 +1232,8 @@ export const UseTaskInstanceServiceGetTaskInstancesKeyFn = (\n     orderBy?: string;\n     pool?: string[];\n     queue?: string[];\n+    runAfterGte?: string;\n+    runAfterLte?: string;\n     startDateGte?: string;\n     startDateLte?: string;\n     state?: string[];\n@@ -1252,6 +1262,8 @@ export const UseTaskInstanceServiceGetTaskInstancesKeyFn = (\n       orderBy,\n       pool,\n       queue,\n+      runAfterGte,\n+      runAfterLte,\n       startDateGte,\n       startDateLte,\n       state,\ndiff --git a/airflow/ui/openapi-gen/queries/prefetch.ts b/airflow/ui/openapi-gen/queries/prefetch.ts\nindex ee687ae7be69c..9e4d361eacfd3 100644\n--- a/airflow/ui/openapi-gen/queries/prefetch.ts\n+++ b/airflow/ui/openapi-gen/queries/prefetch.ts\n@@ -1336,6 +1336,8 @@ export const prefetchUseTaskInstanceServiceGetTaskInstance = (\n  * @param data.dagId\n  * @param data.dagRunId\n  * @param data.taskId\n+ * @param data.runAfterGte\n+ * @param data.runAfterLte\n  * @param data.logicalDateGte\n  * @param data.logicalDateLte\n  * @param data.startDateGte\n@@ -1374,6 +1376,8 @@ export const prefetchUseTaskInstanceServiceGetMappedTaskInstances = (\n     orderBy,\n     pool,\n     queue,\n+    runAfterGte,\n+    runAfterLte,\n     startDateGte,\n     startDateLte,\n     state,\n@@ -1396,6 +1400,8 @@ export const prefetchUseTaskInstanceServiceGetMappedTaskInstances = (\n     orderBy?: string;\n     pool?: string[];\n     queue?: string[];\n+    runAfterGte?: string;\n+    runAfterLte?: string;\n     startDateGte?: string;\n     startDateLte?: string;\n     state?: string[];\n@@ -1421,6 +1427,8 @@ export const prefetchUseTaskInstanceServiceGetMappedTaskInstances = (\n       orderBy,\n       pool,\n       queue,\n+      runAfterGte,\n+      runAfterLte,\n       startDateGte,\n       startDateLte,\n       state,\n@@ -1445,6 +1453,8 @@ export const prefetchUseTaskInstanceServiceGetMappedTaskInstances = (\n         orderBy,\n         pool,\n         queue,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\n@@ -1623,6 +1633,8 @@ export const prefetchUseTaskInstanceServiceGetMappedTaskInstance = (\n  * @param data.dagId\n  * @param data.dagRunId\n  * @param data.taskId\n+ * @param data.runAfterGte\n+ * @param data.runAfterLte\n  * @param data.logicalDateGte\n  * @param data.logicalDateLte\n  * @param data.startDateGte\n@@ -1662,6 +1674,8 @@ export const prefetchUseTaskInstanceServiceGetTaskInstances = (\n     orderBy,\n     pool,\n     queue,\n+    runAfterGte,\n+    runAfterLte,\n     startDateGte,\n     startDateLte,\n     state,\n@@ -1685,6 +1699,8 @@ export const prefetchUseTaskInstanceServiceGetTaskInstances = (\n     orderBy?: string;\n     pool?: string[];\n     queue?: string[];\n+    runAfterGte?: string;\n+    runAfterLte?: string;\n     startDateGte?: string;\n     startDateLte?: string;\n     state?: string[];\n@@ -1711,6 +1727,8 @@ export const prefetchUseTaskInstanceServiceGetTaskInstances = (\n       orderBy,\n       pool,\n       queue,\n+      runAfterGte,\n+      runAfterLte,\n       startDateGte,\n       startDateLte,\n       state,\n@@ -1736,6 +1754,8 @@ export const prefetchUseTaskInstanceServiceGetTaskInstances = (\n         orderBy,\n         pool,\n         queue,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\ndiff --git a/airflow/ui/openapi-gen/queries/queries.ts b/airflow/ui/openapi-gen/queries/queries.ts\nindex 999a5f744b004..3aa0a8782798e 100644\n--- a/airflow/ui/openapi-gen/queries/queries.ts\n+++ b/airflow/ui/openapi-gen/queries/queries.ts\n@@ -1603,6 +1603,8 @@ export const useTaskInstanceServiceGetTaskInstance = <\n  * @param data.dagId\n  * @param data.dagRunId\n  * @param data.taskId\n+ * @param data.runAfterGte\n+ * @param data.runAfterLte\n  * @param data.logicalDateGte\n  * @param data.logicalDateLte\n  * @param data.startDateGte\n@@ -1644,6 +1646,8 @@ export const useTaskInstanceServiceGetMappedTaskInstances = <\n     orderBy,\n     pool,\n     queue,\n+    runAfterGte,\n+    runAfterLte,\n     startDateGte,\n     startDateLte,\n     state,\n@@ -1666,6 +1670,8 @@ export const useTaskInstanceServiceGetMappedTaskInstances = <\n     orderBy?: string;\n     pool?: string[];\n     queue?: string[];\n+    runAfterGte?: string;\n+    runAfterLte?: string;\n     startDateGte?: string;\n     startDateLte?: string;\n     state?: string[];\n@@ -1694,6 +1700,8 @@ export const useTaskInstanceServiceGetMappedTaskInstances = <\n         orderBy,\n         pool,\n         queue,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\n@@ -1720,6 +1728,8 @@ export const useTaskInstanceServiceGetMappedTaskInstances = <\n         orderBy,\n         pool,\n         queue,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\n@@ -1932,6 +1942,8 @@ export const useTaskInstanceServiceGetMappedTaskInstance = <\n  * @param data.dagId\n  * @param data.dagRunId\n  * @param data.taskId\n+ * @param data.runAfterGte\n+ * @param data.runAfterLte\n  * @param data.logicalDateGte\n  * @param data.logicalDateLte\n  * @param data.startDateGte\n@@ -1974,6 +1986,8 @@ export const useTaskInstanceServiceGetTaskInstances = <\n     orderBy,\n     pool,\n     queue,\n+    runAfterGte,\n+    runAfterLte,\n     startDateGte,\n     startDateLte,\n     state,\n@@ -1997,6 +2011,8 @@ export const useTaskInstanceServiceGetTaskInstances = <\n     orderBy?: string;\n     pool?: string[];\n     queue?: string[];\n+    runAfterGte?: string;\n+    runAfterLte?: string;\n     startDateGte?: string;\n     startDateLte?: string;\n     state?: string[];\n@@ -2026,6 +2042,8 @@ export const useTaskInstanceServiceGetTaskInstances = <\n         orderBy,\n         pool,\n         queue,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\n@@ -2053,6 +2071,8 @@ export const useTaskInstanceServiceGetTaskInstances = <\n         orderBy,\n         pool,\n         queue,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\ndiff --git a/airflow/ui/openapi-gen/queries/suspense.ts b/airflow/ui/openapi-gen/queries/suspense.ts\nindex 1c156671d5e1f..4abf14c5479ba 100644\n--- a/airflow/ui/openapi-gen/queries/suspense.ts\n+++ b/airflow/ui/openapi-gen/queries/suspense.ts\n@@ -1580,6 +1580,8 @@ export const useTaskInstanceServiceGetTaskInstanceSuspense = <\n  * @param data.dagId\n  * @param data.dagRunId\n  * @param data.taskId\n+ * @param data.runAfterGte\n+ * @param data.runAfterLte\n  * @param data.logicalDateGte\n  * @param data.logicalDateLte\n  * @param data.startDateGte\n@@ -1621,6 +1623,8 @@ export const useTaskInstanceServiceGetMappedTaskInstancesSuspense = <\n     orderBy,\n     pool,\n     queue,\n+    runAfterGte,\n+    runAfterLte,\n     startDateGte,\n     startDateLte,\n     state,\n@@ -1643,6 +1647,8 @@ export const useTaskInstanceServiceGetMappedTaskInstancesSuspense = <\n     orderBy?: string;\n     pool?: string[];\n     queue?: string[];\n+    runAfterGte?: string;\n+    runAfterLte?: string;\n     startDateGte?: string;\n     startDateLte?: string;\n     state?: string[];\n@@ -1671,6 +1677,8 @@ export const useTaskInstanceServiceGetMappedTaskInstancesSuspense = <\n         orderBy,\n         pool,\n         queue,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\n@@ -1697,6 +1705,8 @@ export const useTaskInstanceServiceGetMappedTaskInstancesSuspense = <\n         orderBy,\n         pool,\n         queue,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\n@@ -1909,6 +1919,8 @@ export const useTaskInstanceServiceGetMappedTaskInstanceSuspense = <\n  * @param data.dagId\n  * @param data.dagRunId\n  * @param data.taskId\n+ * @param data.runAfterGte\n+ * @param data.runAfterLte\n  * @param data.logicalDateGte\n  * @param data.logicalDateLte\n  * @param data.startDateGte\n@@ -1951,6 +1963,8 @@ export const useTaskInstanceServiceGetTaskInstancesSuspense = <\n     orderBy,\n     pool,\n     queue,\n+    runAfterGte,\n+    runAfterLte,\n     startDateGte,\n     startDateLte,\n     state,\n@@ -1974,6 +1988,8 @@ export const useTaskInstanceServiceGetTaskInstancesSuspense = <\n     orderBy?: string;\n     pool?: string[];\n     queue?: string[];\n+    runAfterGte?: string;\n+    runAfterLte?: string;\n     startDateGte?: string;\n     startDateLte?: string;\n     state?: string[];\n@@ -2003,6 +2019,8 @@ export const useTaskInstanceServiceGetTaskInstancesSuspense = <\n         orderBy,\n         pool,\n         queue,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\n@@ -2030,6 +2048,8 @@ export const useTaskInstanceServiceGetTaskInstancesSuspense = <\n         orderBy,\n         pool,\n         queue,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\ndiff --git a/airflow/ui/openapi-gen/requests/schemas.gen.ts b/airflow/ui/openapi-gen/requests/schemas.gen.ts\nindex fb44814b4f6d5..18fedc3282839 100644\n--- a/airflow/ui/openapi-gen/requests/schemas.gen.ts\n+++ b/airflow/ui/openapi-gen/requests/schemas.gen.ts\n@@ -4903,6 +4903,11 @@ export const $TaskInstanceResponse = {\n       ],\n       title: \"Logical Date\",\n     },\n+    run_after: {\n+      type: \"string\",\n+      format: \"date-time\",\n+      title: \"Run After\",\n+    },\n     start_date: {\n       anyOf: [\n         {\n@@ -5139,6 +5144,7 @@ export const $TaskInstanceResponse = {\n     \"dag_run_id\",\n     \"map_index\",\n     \"logical_date\",\n+    \"run_after\",\n     \"start_date\",\n     \"end_date\",\n     \"duration\",\n@@ -5330,6 +5336,30 @@ export const $TaskInstancesBatchBody = {\n       ],\n       title: \"State\",\n     },\n+    run_after_gte: {\n+      anyOf: [\n+        {\n+          type: \"string\",\n+          format: \"date-time\",\n+        },\n+        {\n+          type: \"null\",\n+        },\n+      ],\n+      title: \"Run After Gte\",\n+    },\n+    run_after_lte: {\n+      anyOf: [\n+        {\n+          type: \"string\",\n+          format: \"date-time\",\n+        },\n+        {\n+          type: \"null\",\n+        },\n+      ],\n+      title: \"Run After Lte\",\n+    },\n     logical_date_gte: {\n       anyOf: [\n         {\ndiff --git a/airflow/ui/openapi-gen/requests/services.gen.ts b/airflow/ui/openapi-gen/requests/services.gen.ts\nindex ac82c3896e32a..8bed03375d7dc 100644\n--- a/airflow/ui/openapi-gen/requests/services.gen.ts\n+++ b/airflow/ui/openapi-gen/requests/services.gen.ts\n@@ -2055,6 +2055,8 @@ export class TaskInstanceService {\n    * @param data.dagId\n    * @param data.dagRunId\n    * @param data.taskId\n+   * @param data.runAfterGte\n+   * @param data.runAfterLte\n    * @param data.logicalDateGte\n    * @param data.logicalDateLte\n    * @param data.startDateGte\n@@ -2088,6 +2090,8 @@ export class TaskInstanceService {\n         task_id: data.taskId,\n       },\n       query: {\n+        run_after_gte: data.runAfterGte,\n+        run_after_lte: data.runAfterLte,\n         logical_date_gte: data.logicalDateGte,\n         logical_date_lte: data.logicalDateLte,\n         start_date_gte: data.startDateGte,\n@@ -2330,6 +2334,8 @@ export class TaskInstanceService {\n    * @param data.dagId\n    * @param data.dagRunId\n    * @param data.taskId\n+   * @param data.runAfterGte\n+   * @param data.runAfterLte\n    * @param data.logicalDateGte\n    * @param data.logicalDateLte\n    * @param data.startDateGte\n@@ -2362,6 +2368,8 @@ export class TaskInstanceService {\n       },\n       query: {\n         task_id: data.taskId,\n+        run_after_gte: data.runAfterGte,\n+        run_after_lte: data.runAfterLte,\n         logical_date_gte: data.logicalDateGte,\n         logical_date_lte: data.logicalDateLte,\n         start_date_gte: data.startDateGte,\ndiff --git a/airflow/ui/openapi-gen/requests/types.gen.ts b/airflow/ui/openapi-gen/requests/types.gen.ts\nindex 192d110860eab..b07025e15384c 100644\n--- a/airflow/ui/openapi-gen/requests/types.gen.ts\n+++ b/airflow/ui/openapi-gen/requests/types.gen.ts\n@@ -1266,6 +1266,7 @@ export type TaskInstanceResponse = {\n   dag_run_id: string;\n   map_index: number;\n   logical_date: string | null;\n+  run_after: string;\n   start_date: string | null;\n   end_date: string | null;\n   duration: number | null;\n@@ -1341,6 +1342,8 @@ export type TaskInstancesBatchBody = {\n   dag_run_ids?: Array<string> | null;\n   task_ids?: Array<string> | null;\n   state?: Array<TaskInstanceState | null> | null;\n+  run_after_gte?: string | null;\n+  run_after_lte?: string | null;\n   logical_date_gte?: string | null;\n   logical_date_lte?: string | null;\n   start_date_gte?: string | null;\n@@ -2086,6 +2089,8 @@ export type GetMappedTaskInstancesData = {\n   orderBy?: string;\n   pool?: Array<string>;\n   queue?: Array<string>;\n+  runAfterGte?: string | null;\n+  runAfterLte?: string | null;\n   startDateGte?: string | null;\n   startDateLte?: string | null;\n   state?: Array<string>;\n@@ -2168,6 +2173,8 @@ export type GetTaskInstancesData = {\n   orderBy?: string;\n   pool?: Array<string>;\n   queue?: Array<string>;\n+  runAfterGte?: string | null;\n+  runAfterLte?: string | null;\n   startDateGte?: string | null;\n   startDateLte?: string | null;\n   state?: Array<string>;\ndiff --git a/airflow/ui/src/components/DurationChart.tsx b/airflow/ui/src/components/DurationChart.tsx\nindex f07247a3d399c..6eefcd480057a 100644\n--- a/airflow/ui/src/components/DurationChart.tsx\n+++ b/airflow/ui/src/components/DurationChart.tsx\n@@ -136,9 +136,7 @@ export const DurationChart = ({\n               label: \"Run duration\",\n             },\n           ],\n-          labels: entries.map((entry: RunResponse) =>\n-            dayjs(entry.logical_date).format(\"YYYY-MM-DD, hh:mm:ss\"),\n-          ),\n+          labels: entries.map((entry: RunResponse) => dayjs(entry.run_after).format(\"YYYY-MM-DD, hh:mm:ss\")),\n         }}\n         datasetIdKey=\"id\"\n         options={{\n@@ -157,7 +155,7 @@ export const DurationChart = ({\n               ticks: {\n                 maxTicksLimit: 3,\n               },\n-              title: { align: \"end\", display: true, text: \"Logical Date\" },\n+              title: { align: \"end\", display: true, text: \"Run After\" },\n             },\n \n             y: {\ndiff --git a/airflow/ui/src/pages/Dag/Overview/Overview.tsx b/airflow/ui/src/pages/Dag/Overview/Overview.tsx\nindex 3e6e213196b93..8cdfae619bde8 100644\n--- a/airflow/ui/src/pages/Dag/Overview/Overview.tsx\n+++ b/airflow/ui/src/pages/Dag/Overview/Overview.tsx\n@@ -38,8 +38,8 @@ export const Overview = () => {\n   const { data: failedTasks, isLoading } = useTaskInstanceServiceGetTaskInstances({\n     dagId: dagId ?? \"\",\n     dagRunId: \"~\",\n-    logicalDateGte: startDate,\n-    logicalDateLte: endDate,\n+    runAfterGte: startDate,\n+    runAfterLte: endDate,\n     state: [\"failed\"],\n   });\n \ndiff --git a/airflow/ui/src/pages/Dag/Tasks/TaskCard.tsx b/airflow/ui/src/pages/Dag/Tasks/TaskCard.tsx\nindex e49f563eef52d..1efb1513193c4 100644\n--- a/airflow/ui/src/pages/Dag/Tasks/TaskCard.tsx\n+++ b/airflow/ui/src/pages/Dag/Tasks/TaskCard.tsx\n@@ -42,7 +42,7 @@ export const TaskCard = ({ dagId, task }: Props) => {\n       dagId,\n       dagRunId: \"~\",\n       limit: 14,\n-      orderBy: \"-logical_date\",\n+      orderBy: \"-run_after\",\n       taskId: task.task_id ?? \"\",\n     },\n     undefined,\ndiff --git a/airflow/ui/src/pages/Task/Overview/Overview.tsx b/airflow/ui/src/pages/Task/Overview/Overview.tsx\nindex 09f86f569bc60..4e4f36d8816f6 100644\n--- a/airflow/ui/src/pages/Task/Overview/Overview.tsx\n+++ b/airflow/ui/src/pages/Task/Overview/Overview.tsx\n@@ -40,8 +40,8 @@ export const Overview = () => {\n       dagId,\n       dagRunId: \"~\",\n       limit: 14,\n-      logicalDateGte: startDate,\n-      logicalDateLte: endDate,\n+      runAfterGte: startDate,\n+      runAfterLte: endDate,\n       state: [\"failed\"],\n       taskId,\n     });\n@@ -50,7 +50,7 @@ export const Overview = () => {\n     dagId,\n     dagRunId: \"~\",\n     limit: 14,\n-    orderBy: \"-logical_date\",\n+    orderBy: \"-run_after\",\n     taskId,\n   });\n \ndiff --git a/airflow/ui/src/pages/TaskInstances.tsx b/airflow/ui/src/pages/TaskInstances.tsx\nindex 2e67334f73012..76a43dd4e2d5b 100644\n--- a/airflow/ui/src/pages/TaskInstances.tsx\n+++ b/airflow/ui/src/pages/TaskInstances.tsx\n@@ -62,16 +62,15 @@ const taskInstanceColumns = (\n     ? []\n     : [\n         {\n-          accessorKey: \"run_id\",\n+          accessorKey: \"run_after\",\n           cell: ({ row: { original } }: TaskInstanceRow) => (\n             <Link asChild color=\"fg.info\" fontWeight=\"bold\">\n               <RouterLink to={`/dags/${original.dag_id}/runs/${original.dag_run_id}`}>\n-                {original.dag_run_id}\n+                <Time datetime={original.run_after} />\n               </RouterLink>\n             </Link>\n           ),\n-          enableSorting: false,\n-          header: \"Run ID\",\n+          header: \"Dag Run\",\n         },\n       ]),\n   ...(Boolean(taskId)\ndiff --git a/scripts/ci/pre_commit/check_ti_vs_tis_attributes.py b/scripts/ci/pre_commit/check_ti_vs_tis_attributes.py\nindex c8cb358960f17..b7d42b7322e93 100755\n--- a/scripts/ci/pre_commit/check_ti_vs_tis_attributes.py\n+++ b/scripts/ci/pre_commit/check_ti_vs_tis_attributes.py\n@@ -43,6 +43,7 @@ def compare_attributes(path1, path2):\n         get_class_attributes(path2, \"TaskInstanceHistory\")\n     )\n     diff = diff - {\n+        \"run_after\",\n         \"_logger_name\",\n         \"_task_display_property_value\",\n         \"task_instance_note\",\n", "test_patch": "diff --git a/tests/api_fastapi/core_api/routes/public/test_task_instances.py b/tests/api_fastapi/core_api/routes/public/test_task_instances.py\nindex cae77d3dd2456..a28565d451d6d 100644\n--- a/tests/api_fastapi/core_api/routes/public/test_task_instances.py\n+++ b/tests/api_fastapi/core_api/routes/public/test_task_instances.py\n@@ -201,6 +201,7 @@ def test_should_respond_200(self, test_client, session):\n             \"dag_run_id\": \"TEST_DAG_RUN_ID\",\n             \"rendered_fields\": {},\n             \"rendered_map_index\": None,\n+            \"run_after\": \"2020-01-01T00:00:00Z\",\n             \"trigger\": None,\n             \"triggerer_job\": None,\n         }\n@@ -249,6 +250,7 @@ def test_should_respond_200_with_versions(self, test_client, run_id, expected_ve\n             \"note\": None,\n             \"rendered_map_index\": None,\n             \"rendered_fields\": {},\n+            \"run_after\": mock.ANY,\n             \"trigger\": None,\n             \"triggerer_job\": None,\n             \"dag_version\": {\n@@ -316,6 +318,7 @@ def test_should_respond_200_with_task_state_in_deferred(self, test_client, sessi\n             \"try_number\": 0,\n             \"unixname\": getuser(),\n             \"dag_run_id\": \"TEST_DAG_RUN_ID\",\n+            \"run_after\": \"2020-01-01T00:00:00Z\",\n             \"rendered_fields\": {},\n             \"rendered_map_index\": None,\n             \"trigger\": {\n@@ -367,6 +370,7 @@ def test_should_respond_200_with_task_state_in_removed(self, test_client, sessio\n             \"dag_run_id\": \"TEST_DAG_RUN_ID\",\n             \"rendered_fields\": {},\n             \"rendered_map_index\": None,\n+            \"run_after\": \"2020-01-01T00:00:00Z\",\n             \"trigger\": None,\n             \"triggerer_job\": None,\n         }\n@@ -412,6 +416,7 @@ def test_should_respond_200_task_instance_with_rendered(self, test_client, sessi\n             \"dag_run_id\": \"TEST_DAG_RUN_ID\",\n             \"rendered_fields\": {\"op_args\": \"()\", \"op_kwargs\": {}, \"templates_dict\": None},\n             \"rendered_map_index\": None,\n+            \"run_after\": \"2020-01-01T00:00:00Z\",\n             \"trigger\": None,\n             \"triggerer_job\": None,\n         }\n@@ -514,6 +519,7 @@ def test_should_respond_200_mapped_task_instance_with_rtif(self, test_client, se\n                 \"dag_run_id\": \"TEST_DAG_RUN_ID\",\n                 \"rendered_fields\": {\"op_args\": \"()\", \"op_kwargs\": {}, \"templates_dict\": None},\n                 \"rendered_map_index\": None,\n+                \"run_after\": \"2020-01-01T00:00:00Z\",\n                 \"trigger\": None,\n                 \"triggerer_job\": None,\n             }\n@@ -2304,6 +2310,7 @@ def test_should_respond_200_with_dag_run_id(self, test_client, session):\n                 \"scheduled_when\": None,\n                 \"rendered_fields\": {},\n                 \"rendered_map_index\": None,\n+                \"run_after\": \"2020-01-01T00:00:00Z\",\n                 \"start_date\": \"2020-01-02T00:00:00Z\",\n                 \"state\": \"restarting\",\n                 \"task_display_name\": \"print_the_context\",\n@@ -2943,6 +2950,7 @@ def test_should_call_mocked_api(self, mock_set_ti_state, test_client, session):\n             \"unixname\": getuser(),\n             \"rendered_fields\": {},\n             \"rendered_map_index\": None,\n+            \"run_after\": \"2020-01-01T00:00:00Z\",\n             \"trigger\": None,\n             \"triggerer_job\": None,\n         }\n@@ -3139,6 +3147,7 @@ def test_should_raise_422_for_invalid_task_instance_state(self, payload, expecte\n                     \"unixname\": getuser(),\n                     \"rendered_fields\": {},\n                     \"rendered_map_index\": None,\n+                    \"run_after\": \"2020-01-01T00:00:00Z\",\n                     \"trigger\": None,\n                     \"triggerer_job\": None,\n                 },\n@@ -3240,6 +3249,7 @@ def test_update_mask_set_note_should_respond_200(self, test_client, session, new\n             \"dag_run_id\": self.RUN_ID,\n             \"rendered_fields\": {},\n             \"rendered_map_index\": None,\n+            \"run_after\": \"2020-01-01T00:00:00Z\",\n             \"trigger\": None,\n             \"triggerer_job\": None,\n         }\n@@ -3282,6 +3292,7 @@ def test_set_note_should_respond_200(self, test_client, session):\n             \"dag_run_id\": self.RUN_ID,\n             \"rendered_fields\": {},\n             \"rendered_map_index\": None,\n+            \"run_after\": \"2020-01-01T00:00:00Z\",\n             \"trigger\": None,\n             \"triggerer_job\": None,\n         }\n@@ -3338,6 +3349,7 @@ def test_set_note_should_respond_200_mapped_task_instance_with_rtif(self, test_c\n                 \"dag_run_id\": self.RUN_ID,\n                 \"rendered_fields\": {\"op_args\": \"()\", \"op_kwargs\": {}, \"templates_dict\": None},\n                 \"rendered_map_index\": None,\n+                \"run_after\": \"2020-01-01T00:00:00Z\",\n                 \"trigger\": None,\n                 \"triggerer_job\": None,\n             }\n@@ -3437,6 +3449,7 @@ def test_should_call_mocked_api(self, mock_set_ti_state, test_client, session):\n                     \"unixname\": getuser(),\n                     \"rendered_fields\": {},\n                     \"rendered_map_index\": None,\n+                    \"run_after\": \"2020-01-01T00:00:00Z\",\n                     \"trigger\": None,\n                     \"triggerer_job\": None,\n                 }\n@@ -3660,6 +3673,7 @@ def test_should_raise_422_for_invalid_task_instance_state(self, payload, expecte\n                             \"unixname\": getuser(),\n                             \"rendered_fields\": {},\n                             \"rendered_map_index\": None,\n+                            \"run_after\": \"2020-01-01T00:00:00Z\",\n                             \"trigger\": None,\n                             \"triggerer_job\": None,\n                         }\n", "problem_statement": "AIP-84 Swap logical_date with run_after in all Task Instance responses\nFor Task Instances, Mapped Task Instances, and Task Instance History, we need to swap `logical_date` for `run_after`.\n\nWe also need to change the `logical_date_gte`, `logical_date_lte` filters to also use `run_after`\n", "hints_text": "", "created_at": "2025-02-13T23:27:16Z"}
{"repo": "apache/airflow", "pull_number": 46739, "instance_id": "apache__airflow-46739", "issue_numbers": ["46731"], "base_commit": "a10ae15440b812e146d57de1a5d5a02b3ec9c4c7", "patch": "diff --git a/airflow/api_fastapi/core_api/datamodels/dag_run.py b/airflow/api_fastapi/core_api/datamodels/dag_run.py\nindex 77a5bedcde14e..77727406bcea9 100644\n--- a/airflow/api_fastapi/core_api/datamodels/dag_run.py\n+++ b/airflow/api_fastapi/core_api/datamodels/dag_run.py\n@@ -116,6 +116,8 @@ class DAGRunsBatchBody(StrictBaseModel):\n     page_limit: NonNegativeInt = 100\n     dag_ids: list[str] | None = None\n     states: list[DagRunState | None] | None = None\n+    run_after_gte: AwareDatetime | None = None\n+    run_after_lte: AwareDatetime | None = None\n     logical_date_gte: AwareDatetime | None = None\n     logical_date_lte: AwareDatetime | None = None\n     start_date_gte: AwareDatetime | None = None\ndiff --git a/airflow/api_fastapi/core_api/openapi/v1-generated.yaml b/airflow/api_fastapi/core_api/openapi/v1-generated.yaml\nindex 660f1c243483f..550c7747ee34c 100644\n--- a/airflow/api_fastapi/core_api/openapi/v1-generated.yaml\n+++ b/airflow/api_fastapi/core_api/openapi/v1-generated.yaml\n@@ -2230,6 +2230,24 @@ paths:\n           minimum: 0\n           default: 0\n           title: Offset\n+      - name: run_after_gte\n+        in: query\n+        required: false\n+        schema:\n+          anyOf:\n+          - type: string\n+            format: date-time\n+          - type: 'null'\n+          title: Run After Gte\n+      - name: run_after_lte\n+        in: query\n+        required: false\n+        schema:\n+          anyOf:\n+          - type: string\n+            format: date-time\n+          - type: 'null'\n+          title: Run After Lte\n       - name: logical_date_gte\n         in: query\n         required: false\n@@ -8418,6 +8436,18 @@ components:\n             type: array\n           - type: 'null'\n           title: States\n+        run_after_gte:\n+          anyOf:\n+          - type: string\n+            format: date-time\n+          - type: 'null'\n+          title: Run After Gte\n+        run_after_lte:\n+          anyOf:\n+          - type: string\n+            format: date-time\n+          - type: 'null'\n+          title: Run After Lte\n         logical_date_gte:\n           anyOf:\n           - type: string\ndiff --git a/airflow/api_fastapi/core_api/routes/public/dag_run.py b/airflow/api_fastapi/core_api/routes/public/dag_run.py\nindex c1ce04c31f94f..fc4397447da12 100644\n--- a/airflow/api_fastapi/core_api/routes/public/dag_run.py\n+++ b/airflow/api_fastapi/core_api/routes/public/dag_run.py\n@@ -269,6 +269,7 @@ def get_dag_runs(\n     dag_id: str,\n     limit: QueryLimit,\n     offset: QueryOffset,\n+    run_after: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"run_after\", DagRun))],\n     logical_date: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"logical_date\", DagRun))],\n     start_date_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"start_date\", DagRun))],\n     end_date_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(\"end_date\", DagRun))],\n@@ -284,6 +285,7 @@ def get_dag_runs(\n                     \"dag_id\",\n                     \"run_id\",\n                     \"logical_date\",\n+                    \"run_after\",\n                     \"start_date\",\n                     \"end_date\",\n                     \"updated_at\",\n@@ -314,7 +316,7 @@ def get_dag_runs(\n \n     dag_run_select, total_entries = paginated_select(\n         statement=query,\n-        filters=[logical_date, start_date_range, end_date_range, update_at_range, state],\n+        filters=[run_after, logical_date, start_date_range, end_date_range, update_at_range, state],\n         order_by=order_by,\n         offset=offset,\n         limit=limit,\n@@ -416,6 +418,10 @@ def get_list_dag_runs_batch(\n         Range(lower_bound=body.logical_date_gte, upper_bound=body.logical_date_lte),\n         attribute=DagRun.logical_date,\n     )\n+    run_after = RangeFilter(\n+        Range(lower_bound=body.run_after_gte, upper_bound=body.run_after_lte),\n+        attribute=DagRun.run_after,\n+    )\n     start_date = RangeFilter(\n         Range(lower_bound=body.start_date_gte, upper_bound=body.start_date_lte),\n         attribute=DagRun.start_date,\n@@ -434,6 +440,7 @@ def get_list_dag_runs_batch(\n             \"id\",\n             \"state\",\n             \"dag_id\",\n+            \"run_after\",\n             \"logical_date\",\n             \"run_id\",\n             \"start_date\",\n@@ -449,7 +456,7 @@ def get_list_dag_runs_batch(\n     base_query = select(DagRun)\n     dag_runs_select, total_entries = paginated_select(\n         statement=base_query,\n-        filters=[dag_ids, logical_date, start_date, end_date, state],\n+        filters=[dag_ids, logical_date, run_after, start_date, end_date, state],\n         order_by=order_by,\n         offset=offset,\n         limit=limit,\ndiff --git a/airflow/api_fastapi/core_api/routes/ui/dags.py b/airflow/api_fastapi/core_api/routes/ui/dags.py\nindex 0ed999c1c99cf..e89855fe5426f 100644\n--- a/airflow/api_fastapi/core_api/routes/ui/dags.py\n+++ b/airflow/api_fastapi/core_api/routes/ui/dags.py\n@@ -74,39 +74,39 @@ def recent_dag_runs(\n     recent_runs_subquery = (\n         select(\n             DagRun.dag_id,\n-            DagRun.logical_date,\n+            DagRun.run_after,\n             func.rank()\n             .over(\n                 partition_by=DagRun.dag_id,\n-                order_by=DagRun.logical_date.desc(),\n+                order_by=DagRun.run_after.desc(),\n             )\n             .label(\"rank\"),\n         )\n-        .order_by(DagRun.logical_date.desc())\n+        .order_by(DagRun.run_after.desc())\n         .subquery()\n     )\n     dags_with_recent_dag_runs_select = (\n         select(\n             DagRun,\n             DagModel,\n-            recent_runs_subquery.c.logical_date,\n+            recent_runs_subquery.c.run_after,\n         )\n         .join(DagModel, DagModel.dag_id == recent_runs_subquery.c.dag_id)\n         .join(\n             DagRun,\n             and_(\n                 DagRun.dag_id == DagModel.dag_id,\n-                DagRun.logical_date == recent_runs_subquery.c.logical_date,\n+                DagRun.run_after == recent_runs_subquery.c.run_after,\n             ),\n         )\n         .where(recent_runs_subquery.c.rank <= dag_runs_limit)\n         .group_by(\n             DagModel.dag_id,\n-            recent_runs_subquery.c.logical_date,\n-            DagRun.logical_date,\n+            recent_runs_subquery.c.run_after,\n+            DagRun.run_after,\n             DagRun.id,\n         )\n-        .order_by(recent_runs_subquery.c.logical_date.desc())\n+        .order_by(recent_runs_subquery.c.run_after.desc())\n     )\n     dags_with_recent_dag_runs_select_filter, _ = paginated_select(\n         statement=dags_with_recent_dag_runs_select,\ndiff --git a/airflow/ui/openapi-gen/queries/common.ts b/airflow/ui/openapi-gen/queries/common.ts\nindex d89d185783965..5d9d328739d73 100644\n--- a/airflow/ui/openapi-gen/queries/common.ts\n+++ b/airflow/ui/openapi-gen/queries/common.ts\n@@ -578,6 +578,8 @@ export const UseDagRunServiceGetDagRunsKeyFn = (\n     logicalDateLte,\n     offset,\n     orderBy,\n+    runAfterGte,\n+    runAfterLte,\n     startDateGte,\n     startDateLte,\n     state,\n@@ -592,6 +594,8 @@ export const UseDagRunServiceGetDagRunsKeyFn = (\n     logicalDateLte?: string;\n     offset?: number;\n     orderBy?: string;\n+    runAfterGte?: string;\n+    runAfterLte?: string;\n     startDateGte?: string;\n     startDateLte?: string;\n     state?: string[];\n@@ -611,6 +615,8 @@ export const UseDagRunServiceGetDagRunsKeyFn = (\n       logicalDateLte,\n       offset,\n       orderBy,\n+      runAfterGte,\n+      runAfterLte,\n       startDateGte,\n       startDateLte,\n       state,\ndiff --git a/airflow/ui/openapi-gen/queries/prefetch.ts b/airflow/ui/openapi-gen/queries/prefetch.ts\nindex b3c706fad9695..b2ee8421e4c5c 100644\n--- a/airflow/ui/openapi-gen/queries/prefetch.ts\n+++ b/airflow/ui/openapi-gen/queries/prefetch.ts\n@@ -771,6 +771,8 @@ export const prefetchUseDagRunServiceGetUpstreamAssetEvents = (\n  * @param data.dagId\n  * @param data.limit\n  * @param data.offset\n+ * @param data.runAfterGte\n+ * @param data.runAfterLte\n  * @param data.logicalDateGte\n  * @param data.logicalDateLte\n  * @param data.startDateGte\n@@ -795,6 +797,8 @@ export const prefetchUseDagRunServiceGetDagRuns = (\n     logicalDateLte,\n     offset,\n     orderBy,\n+    runAfterGte,\n+    runAfterLte,\n     startDateGte,\n     startDateLte,\n     state,\n@@ -809,6 +813,8 @@ export const prefetchUseDagRunServiceGetDagRuns = (\n     logicalDateLte?: string;\n     offset?: number;\n     orderBy?: string;\n+    runAfterGte?: string;\n+    runAfterLte?: string;\n     startDateGte?: string;\n     startDateLte?: string;\n     state?: string[];\n@@ -826,6 +832,8 @@ export const prefetchUseDagRunServiceGetDagRuns = (\n       logicalDateLte,\n       offset,\n       orderBy,\n+      runAfterGte,\n+      runAfterLte,\n       startDateGte,\n       startDateLte,\n       state,\n@@ -842,6 +850,8 @@ export const prefetchUseDagRunServiceGetDagRuns = (\n         logicalDateLte,\n         offset,\n         orderBy,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\ndiff --git a/airflow/ui/openapi-gen/queries/queries.ts b/airflow/ui/openapi-gen/queries/queries.ts\nindex 531102d2dd2c1..226127fc337c4 100644\n--- a/airflow/ui/openapi-gen/queries/queries.ts\n+++ b/airflow/ui/openapi-gen/queries/queries.ts\n@@ -939,6 +939,8 @@ export const useDagRunServiceGetUpstreamAssetEvents = <\n  * @param data.dagId\n  * @param data.limit\n  * @param data.offset\n+ * @param data.runAfterGte\n+ * @param data.runAfterLte\n  * @param data.logicalDateGte\n  * @param data.logicalDateLte\n  * @param data.startDateGte\n@@ -966,6 +968,8 @@ export const useDagRunServiceGetDagRuns = <\n     logicalDateLte,\n     offset,\n     orderBy,\n+    runAfterGte,\n+    runAfterLte,\n     startDateGte,\n     startDateLte,\n     state,\n@@ -980,6 +984,8 @@ export const useDagRunServiceGetDagRuns = <\n     logicalDateLte?: string;\n     offset?: number;\n     orderBy?: string;\n+    runAfterGte?: string;\n+    runAfterLte?: string;\n     startDateGte?: string;\n     startDateLte?: string;\n     state?: string[];\n@@ -1000,6 +1006,8 @@ export const useDagRunServiceGetDagRuns = <\n         logicalDateLte,\n         offset,\n         orderBy,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\n@@ -1018,6 +1026,8 @@ export const useDagRunServiceGetDagRuns = <\n         logicalDateLte,\n         offset,\n         orderBy,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\ndiff --git a/airflow/ui/openapi-gen/queries/suspense.ts b/airflow/ui/openapi-gen/queries/suspense.ts\nindex 8b304aa8d6d14..27a58d791ed7d 100644\n--- a/airflow/ui/openapi-gen/queries/suspense.ts\n+++ b/airflow/ui/openapi-gen/queries/suspense.ts\n@@ -916,6 +916,8 @@ export const useDagRunServiceGetUpstreamAssetEventsSuspense = <\n  * @param data.dagId\n  * @param data.limit\n  * @param data.offset\n+ * @param data.runAfterGte\n+ * @param data.runAfterLte\n  * @param data.logicalDateGte\n  * @param data.logicalDateLte\n  * @param data.startDateGte\n@@ -943,6 +945,8 @@ export const useDagRunServiceGetDagRunsSuspense = <\n     logicalDateLte,\n     offset,\n     orderBy,\n+    runAfterGte,\n+    runAfterLte,\n     startDateGte,\n     startDateLte,\n     state,\n@@ -957,6 +961,8 @@ export const useDagRunServiceGetDagRunsSuspense = <\n     logicalDateLte?: string;\n     offset?: number;\n     orderBy?: string;\n+    runAfterGte?: string;\n+    runAfterLte?: string;\n     startDateGte?: string;\n     startDateLte?: string;\n     state?: string[];\n@@ -977,6 +983,8 @@ export const useDagRunServiceGetDagRunsSuspense = <\n         logicalDateLte,\n         offset,\n         orderBy,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\n@@ -995,6 +1003,8 @@ export const useDagRunServiceGetDagRunsSuspense = <\n         logicalDateLte,\n         offset,\n         orderBy,\n+        runAfterGte,\n+        runAfterLte,\n         startDateGte,\n         startDateLte,\n         state,\ndiff --git a/airflow/ui/openapi-gen/requests/schemas.gen.ts b/airflow/ui/openapi-gen/requests/schemas.gen.ts\nindex bb1f1a998f0ac..cdd063506696d 100644\n--- a/airflow/ui/openapi-gen/requests/schemas.gen.ts\n+++ b/airflow/ui/openapi-gen/requests/schemas.gen.ts\n@@ -2418,6 +2418,30 @@ export const $DAGRunsBatchBody = {\n       ],\n       title: \"States\",\n     },\n+    run_after_gte: {\n+      anyOf: [\n+        {\n+          type: \"string\",\n+          format: \"date-time\",\n+        },\n+        {\n+          type: \"null\",\n+        },\n+      ],\n+      title: \"Run After Gte\",\n+    },\n+    run_after_lte: {\n+      anyOf: [\n+        {\n+          type: \"string\",\n+          format: \"date-time\",\n+        },\n+        {\n+          type: \"null\",\n+        },\n+      ],\n+      title: \"Run After Lte\",\n+    },\n     logical_date_gte: {\n       anyOf: [\n         {\ndiff --git a/airflow/ui/openapi-gen/requests/services.gen.ts b/airflow/ui/openapi-gen/requests/services.gen.ts\nindex 995e95e2ea358..a56ebe886582e 100644\n--- a/airflow/ui/openapi-gen/requests/services.gen.ts\n+++ b/airflow/ui/openapi-gen/requests/services.gen.ts\n@@ -1371,6 +1371,8 @@ export class DagRunService {\n    * @param data.dagId\n    * @param data.limit\n    * @param data.offset\n+   * @param data.runAfterGte\n+   * @param data.runAfterLte\n    * @param data.logicalDateGte\n    * @param data.logicalDateLte\n    * @param data.startDateGte\n@@ -1394,6 +1396,8 @@ export class DagRunService {\n       query: {\n         limit: data.limit,\n         offset: data.offset,\n+        run_after_gte: data.runAfterGte,\n+        run_after_lte: data.runAfterLte,\n         logical_date_gte: data.logicalDateGte,\n         logical_date_lte: data.logicalDateLte,\n         start_date_gte: data.startDateGte,\ndiff --git a/airflow/ui/openapi-gen/requests/types.gen.ts b/airflow/ui/openapi-gen/requests/types.gen.ts\nindex 54e74a7198dbf..ff6cb20c7512b 100644\n--- a/airflow/ui/openapi-gen/requests/types.gen.ts\n+++ b/airflow/ui/openapi-gen/requests/types.gen.ts\n@@ -628,6 +628,8 @@ export type DAGRunsBatchBody = {\n   page_limit?: number;\n   dag_ids?: Array<string> | null;\n   states?: Array<DagRunState | null> | null;\n+  run_after_gte?: string | null;\n+  run_after_lte?: string | null;\n   logical_date_gte?: string | null;\n   logical_date_lte?: string | null;\n   start_date_gte?: string | null;\n@@ -1884,6 +1886,8 @@ export type GetDagRunsData = {\n   logicalDateLte?: string | null;\n   offset?: number;\n   orderBy?: string;\n+  runAfterGte?: string | null;\n+  runAfterLte?: string | null;\n   startDateGte?: string | null;\n   startDateLte?: string | null;\n   state?: Array<string>;\ndiff --git a/airflow/ui/src/components/DagRunInfo.tsx b/airflow/ui/src/components/DagRunInfo.tsx\nindex 55739b4f98d12..80742a3868747 100644\n--- a/airflow/ui/src/components/DagRunInfo.tsx\n+++ b/airflow/ui/src/components/DagRunInfo.tsx\n@@ -25,59 +25,44 @@ import Time from \"src/components/Time\";\n import { Tooltip } from \"src/components/ui\";\n \n type Props = {\n-  readonly dataIntervalEnd?: string | null;\n-  readonly dataIntervalStart?: string | null;\n   readonly endDate?: string | null;\n-  readonly nextDagrunCreateAfter?: string | null;\n+  readonly logicalDate?: string | null;\n+  readonly runAfter: string;\n   readonly startDate?: string | null;\n   readonly state?: DAGRunResponse[\"state\"];\n };\n \n-const DagRunInfo = ({\n-  dataIntervalEnd,\n-  dataIntervalStart,\n-  endDate,\n-  nextDagrunCreateAfter,\n-  startDate,\n-  state,\n-}: Props) =>\n-  Boolean(dataIntervalStart) && Boolean(dataIntervalEnd) ? (\n-    <Tooltip\n-      content={\n-        <VStack align=\"left\" gap={0}>\n-          {state === undefined ? undefined : <Text>State: {state}</Text>}\n-          {Boolean(nextDagrunCreateAfter) ? (\n-            <Text>\n-              Run After: <Time datetime={nextDagrunCreateAfter} />\n-            </Text>\n-          ) : undefined}\n-          {Boolean(startDate) ? (\n-            <Text>\n-              Start Date: <Time datetime={startDate} />\n-            </Text>\n-          ) : undefined}\n-          {Boolean(endDate) ? (\n-            <Text>\n-              End Date: <Time datetime={endDate} />\n-            </Text>\n-          ) : undefined}\n-          {Boolean(startDate) ? (\n-            <Text>Duration: {dayjs.duration(dayjs(endDate).diff(startDate)).asSeconds()}s</Text>\n-          ) : undefined}\n+const DagRunInfo = ({ endDate, logicalDate, runAfter, startDate, state }: Props) => (\n+  <Tooltip\n+    content={\n+      <VStack align=\"left\" gap={0}>\n+        {state === undefined ? undefined : <Text>State: {state}</Text>}\n+        {Boolean(logicalDate) ? (\n           <Text>\n-            Data Interval Start: <Time datetime={dataIntervalStart} />\n+            Logical Date: <Time datetime={logicalDate} />\n           </Text>\n+        ) : undefined}\n+        {Boolean(startDate) ? (\n           <Text>\n-            Data Interval End: <Time datetime={dataIntervalEnd} />\n+            Start Date: <Time datetime={startDate} />\n           </Text>\n-        </VStack>\n-      }\n-    >\n-      <Box>\n-        <Time datetime={dataIntervalStart} mr={2} showTooltip={false} />\n-        {state === undefined ? undefined : <StateBadge state={state} />}\n-      </Box>\n-    </Tooltip>\n-  ) : undefined;\n+        ) : undefined}\n+        {Boolean(endDate) ? (\n+          <Text>\n+            End Date: <Time datetime={endDate} />\n+          </Text>\n+        ) : undefined}\n+        {Boolean(startDate) ? (\n+          <Text>Duration: {dayjs.duration(dayjs(endDate).diff(startDate)).asSeconds()}s</Text>\n+        ) : undefined}\n+      </VStack>\n+    }\n+  >\n+    <Box>\n+      <Time datetime={runAfter} mr={2} showTooltip={false} />\n+      {state === undefined ? undefined : <StateBadge state={state} />}\n+    </Box>\n+  </Tooltip>\n+);\n \n export default DagRunInfo;\ndiff --git a/airflow/ui/src/pages/Dag/Header.tsx b/airflow/ui/src/pages/Dag/Header.tsx\nindex 618bc8a4f665a..525df81ba769b 100644\n--- a/airflow/ui/src/pages/Dag/Header.tsx\n+++ b/airflow/ui/src/pages/Dag/Header.tsx\n@@ -93,20 +93,19 @@ export const Header = ({\n           <Stat label=\"Latest Run\">\n             {Boolean(latestRun) && latestRun !== undefined ? (\n               <DagRunInfo\n-                dataIntervalEnd={latestRun.data_interval_end}\n-                dataIntervalStart={latestRun.data_interval_start}\n                 endDate={latestRun.end_date}\n+                logicalDate={latestRun.logical_date}\n+                runAfter={latestRun.run_after}\n                 startDate={latestRun.start_date}\n                 state={latestRun.state}\n               />\n             ) : undefined}\n           </Stat>\n           <Stat label=\"Next Run\">\n-            {Boolean(dagWithRuns?.next_dagrun) ? (\n+            {Boolean(dagWithRuns?.next_dagrun_create_after) ? (\n               <DagRunInfo\n-                dataIntervalEnd={dagWithRuns?.next_dagrun_data_interval_end}\n-                dataIntervalStart={dagWithRuns?.next_dagrun_data_interval_start}\n-                nextDagrunCreateAfter={dagWithRuns?.next_dagrun_create_after}\n+                logicalDate={dagWithRuns?.next_dagrun}\n+                runAfter={dagWithRuns?.next_dagrun_create_after as string}\n               />\n             ) : undefined}\n           </Stat>\ndiff --git a/airflow/ui/src/pages/Dag/Overview/Overview.tsx b/airflow/ui/src/pages/Dag/Overview/Overview.tsx\nindex 76275f146284b..3e6e213196b93 100644\n--- a/airflow/ui/src/pages/Dag/Overview/Overview.tsx\n+++ b/airflow/ui/src/pages/Dag/Overview/Overview.tsx\n@@ -45,15 +45,15 @@ export const Overview = () => {\n \n   const { data: failedRuns, isLoading: isLoadingFailedRuns } = useDagRunServiceGetDagRuns({\n     dagId: dagId ?? \"\",\n-    logicalDateGte: startDate,\n-    logicalDateLte: endDate,\n+    runAfterGte: startDate,\n+    runAfterLte: endDate,\n     state: [\"failed\"],\n   });\n \n   const { data: runs, isLoading: isLoadingRuns } = useDagRunServiceGetDagRuns({\n     dagId: dagId ?? \"\",\n     limit: 14,\n-    orderBy: \"-logical_date\",\n+    orderBy: \"-run_after\",\n   });\n \n   return (\n@@ -88,7 +88,7 @@ export const Overview = () => {\n           count={failedRuns?.total_entries ?? 0}\n           endDate={endDate}\n           events={(failedRuns?.dag_runs ?? []).map((dr) => ({\n-            timestamp: dr.start_date ?? dr.logical_date ?? \"\",\n+            timestamp: dr.run_after,\n           }))}\n           isLoading={isLoadingFailedRuns}\n           label=\"Failed Run\"\ndiff --git a/airflow/ui/src/pages/DagRuns.tsx b/airflow/ui/src/pages/DagRuns.tsx\nindex de13ddb604717..a98df1c70eabb 100644\n--- a/airflow/ui/src/pages/DagRuns.tsx\n+++ b/airflow/ui/src/pages/DagRuns.tsx\n@@ -53,16 +53,15 @@ const runColumns = (dagId?: string): Array<ColumnDef<DAGRunResponse>> => [\n         },\n       ]),\n   {\n-    accessorKey: \"run_id\",\n+    accessorKey: \"run_after\",\n     cell: ({ row: { original } }: DagRunRow) => (\n       <Link asChild color=\"fg.info\" fontWeight=\"bold\">\n         <RouterLink to={`/dags/${original.dag_id}/runs/${original.dag_run_id}`}>\n-          {original.dag_run_id}\n+          <Time datetime={original.run_after} />\n         </RouterLink>\n       </Link>\n     ),\n-    enableSorting: false,\n-    header: \"Run ID\",\n+    header: \"Run After\",\n   },\n   {\n     accessorKey: \"state\",\n@@ -123,7 +122,7 @@ export const DagRuns = () => {\n   const { setTableURLState, tableURLState } = useTableURLState();\n   const { pagination, sorting } = tableURLState;\n   const [sort] = sorting;\n-  const orderBy = sort ? `${sort.desc ? \"-\" : \"\"}${sort.id}` : \"-logical_date\";\n+  const orderBy = sort ? `${sort.desc ? \"-\" : \"\"}${sort.id}` : \"-run_after\";\n \n   const filteredState = searchParams.get(STATE_PARAM);\n \ndiff --git a/airflow/ui/src/pages/DagsList/DagCard.tsx b/airflow/ui/src/pages/DagsList/DagCard.tsx\nindex d99845cdb4b0f..f926bab5abd39 100644\n--- a/airflow/ui/src/pages/DagsList/DagCard.tsx\n+++ b/airflow/ui/src/pages/DagsList/DagCard.tsx\n@@ -65,9 +65,9 @@ export const DagCard = ({ dag }: Props) => {\n             <Link asChild color=\"fg.info\">\n               <RouterLink to={`/dags/${latestRun.dag_id}/runs/${latestRun.dag_run_id}`}>\n                 <DagRunInfo\n-                  dataIntervalEnd={latestRun.data_interval_end}\n-                  dataIntervalStart={latestRun.data_interval_start}\n                   endDate={latestRun.end_date}\n+                  logicalDate={latestRun.logical_date}\n+                  runAfter={latestRun.run_after}\n                   startDate={latestRun.start_date}\n                   state={latestRun.state}\n                 />\n@@ -77,12 +77,8 @@ export const DagCard = ({ dag }: Props) => {\n           ) : undefined}\n         </Stat>\n         <Stat label=\"Next Run\">\n-          {Boolean(dag.next_dagrun) ? (\n-            <DagRunInfo\n-              dataIntervalEnd={dag.next_dagrun_data_interval_end}\n-              dataIntervalStart={dag.next_dagrun_data_interval_start}\n-              nextDagrunCreateAfter={dag.next_dagrun_create_after}\n-            />\n+          {Boolean(dag.next_dagrun_create_after) ? (\n+            <DagRunInfo logicalDate={dag.next_dagrun} runAfter={dag.next_dagrun_create_after as string} />\n           ) : undefined}\n         </Stat>\n         <RecentRuns latestRuns={dag.latest_dag_runs} />\ndiff --git a/airflow/ui/src/pages/DagsList/DagsList.tsx b/airflow/ui/src/pages/DagsList/DagsList.tsx\nindex 31b5eb04a4670..ac71234f3071a 100644\n--- a/airflow/ui/src/pages/DagsList/DagsList.tsx\n+++ b/airflow/ui/src/pages/DagsList/DagsList.tsx\n@@ -87,11 +87,10 @@ const columns: Array<ColumnDef<DAGWithLatestDagRunsResponse>> = [\n   {\n     accessorKey: \"next_dagrun\",\n     cell: ({ row: { original } }) =>\n-      Boolean(original.next_dagrun) ? (\n+      Boolean(original.next_dagrun_create_after) ? (\n         <DagRunInfo\n-          dataIntervalEnd={original.next_dagrun_data_interval_end}\n-          dataIntervalStart={original.next_dagrun_data_interval_start}\n-          nextDagrunCreateAfter={original.next_dagrun_create_after}\n+          logicalDate={original.next_dagrun}\n+          runAfter={original.next_dagrun_create_after as string}\n         />\n       ) : undefined,\n     header: \"Next Dag Run\",\n@@ -101,9 +100,9 @@ const columns: Array<ColumnDef<DAGWithLatestDagRunsResponse>> = [\n     cell: ({ row: { original } }) =>\n       original.latest_dag_runs[0] ? (\n         <DagRunInfo\n-          dataIntervalEnd={original.latest_dag_runs[0].data_interval_end}\n-          dataIntervalStart={original.latest_dag_runs[0].data_interval_start}\n           endDate={original.latest_dag_runs[0].end_date}\n+          logicalDate={original.latest_dag_runs[0].logical_date}\n+          runAfter={original.latest_dag_runs[0].run_after}\n           startDate={original.latest_dag_runs[0].start_date}\n           state={original.latest_dag_runs[0].state}\n         />\ndiff --git a/airflow/ui/src/pages/DagsList/RecentRuns.tsx b/airflow/ui/src/pages/DagsList/RecentRuns.tsx\nindex 4b80355123024..045a85d45fcb0 100644\n--- a/airflow/ui/src/pages/DagsList/RecentRuns.tsx\n+++ b/airflow/ui/src/pages/DagsList/RecentRuns.tsx\n@@ -56,8 +56,18 @@ export const RecentRuns = ({\n             <Box>\n               <Text>State: {run.state}</Text>\n               <Text>\n-                Start Date: <Time datetime={run.start_date} />\n+                Run After: <Time datetime={run.run_after} />\n               </Text>\n+              {run.start_date === null ? undefined : (\n+                <Text>\n+                  Start Date: <Time datetime={run.start_date} />\n+                </Text>\n+              )}\n+              {run.end_date === null ? undefined : (\n+                <Text>\n+                  End Date: <Time datetime={run.end_date} />\n+                </Text>\n+              )}\n               <Text>Duration: {run.duration.toFixed(2)}s</Text>\n             </Box>\n           }\n", "test_patch": "diff --git a/tests/api_fastapi/core_api/routes/public/test_dag_run.py b/tests/api_fastapi/core_api/routes/public/test_dag_run.py\nindex 99a2ae83acce0..df4dc708d94d1 100644\n--- a/tests/api_fastapi/core_api/routes/public/test_dag_run.py\n+++ b/tests/api_fastapi/core_api/routes/public/test_dag_run.py\n@@ -66,6 +66,8 @@\n START_DATE1 = datetime(2024, 1, 15, 0, 0, tzinfo=timezone.utc)\n LOGICAL_DATE1 = datetime(2024, 2, 16, 0, 0, tzinfo=timezone.utc)\n LOGICAL_DATE2 = datetime(2024, 2, 20, 0, 0, tzinfo=timezone.utc)\n+RUN_AFTER1 = datetime(2024, 2, 16, 0, 0, tzinfo=timezone.utc)\n+RUN_AFTER2 = datetime(2024, 2, 20, 0, 0, tzinfo=timezone.utc)\n START_DATE2 = datetime(2024, 4, 15, 0, 0, tzinfo=timezone.utc)\n LOGICAL_DATE3 = datetime(2024, 5, 16, 0, 0, tzinfo=timezone.utc)\n LOGICAL_DATE4 = datetime(2024, 5, 25, 0, 0, tzinfo=timezone.utc)\n@@ -397,6 +399,14 @@ def test_bad_limit_and_offset(self, test_client, query_params, expected_detail):\n                 },\n                 [DAG1_RUN1_ID, DAG1_RUN2_ID],\n             ),\n+            (\n+                DAG1_ID,\n+                {\n+                    \"run_after_gte\": RUN_AFTER1.isoformat(),\n+                    \"run_after_lte\": RUN_AFTER2.isoformat(),\n+                },\n+                [DAG1_RUN1_ID, DAG1_RUN2_ID],\n+            ),\n             (\n                 DAG2_ID,\n                 {\n@@ -436,11 +446,27 @@ def test_bad_filters(self, test_client):\n             \"logical_date_gte\": \"invalid\",\n             \"start_date_gte\": \"invalid\",\n             \"end_date_gte\": \"invalid\",\n+            \"run_after_gte\": \"invalid\",\n             \"logical_date_lte\": \"invalid\",\n             \"start_date_lte\": \"invalid\",\n             \"end_date_lte\": \"invalid\",\n+            \"run_after_lte\": \"invalid\",\n         }\n         expected_detail = [\n+            {\n+                \"type\": \"datetime_from_date_parsing\",\n+                \"loc\": [\"query\", \"run_after_gte\"],\n+                \"msg\": \"Input should be a valid datetime or date, input is too short\",\n+                \"input\": \"invalid\",\n+                \"ctx\": {\"error\": \"input is too short\"},\n+            },\n+            {\n+                \"type\": \"datetime_from_date_parsing\",\n+                \"loc\": [\"query\", \"run_after_lte\"],\n+                \"msg\": \"Input should be a valid datetime or date, input is too short\",\n+                \"input\": \"invalid\",\n+                \"ctx\": {\"error\": \"input is too short\"},\n+            },\n             {\n                 \"type\": \"datetime_from_date_parsing\",\n                 \"loc\": [\"query\", \"logical_date_gte\"],\n@@ -577,6 +603,7 @@ def test_invalid_order_by_raises_400(self, test_client):\n                 \"state\", [DAG1_RUN2_ID, DAG1_RUN1_ID, DAG2_RUN1_ID, DAG2_RUN2_ID], id=\"order_by_state\"\n             ),\n             pytest.param(\"dag_id\", DAG_RUNS_LIST, id=\"order_by_dag_id\"),\n+            pytest.param(\"run_after\", DAG_RUNS_LIST, id=\"order_by_run_after\"),\n             pytest.param(\"logical_date\", DAG_RUNS_LIST, id=\"order_by_logical_date\"),\n             pytest.param(\"dag_run_id\", DAG_RUNS_LIST, id=\"order_by_dag_run_id\"),\n             pytest.param(\"start_date\", DAG_RUNS_LIST, id=\"order_by_start_date\"),\ndiff --git a/tests/api_fastapi/core_api/routes/ui/test_dags.py b/tests/api_fastapi/core_api/routes/ui/test_dags.py\nindex 5e7cee8096cf0..fc6d509356972 100644\n--- a/tests/api_fastapi/core_api/routes/ui/test_dags.py\n+++ b/tests/api_fastapi/core_api/routes/ui/test_dags.py\n@@ -53,6 +53,7 @@ def setup_dag_runs(self, session=None) -> None:\n                     run_type=DagRunType.MANUAL,\n                     start_date=start_date,\n                     logical_date=start_date,\n+                    run_after=start_date,\n                     state=(DagRunState.FAILED if i % 2 == 0 else DagRunState.SUCCESS),\n                     triggered_by=DagRunTriggeredByType.TEST,\n                 )\n@@ -90,16 +91,16 @@ def test_recent_dag_runs(self, test_client, query_params, expected_ids, expected\n             \"dag_run_id\",\n             \"dag_id\",\n             \"state\",\n-            \"logical_date\",\n+            \"run_after\",\n         ]\n         for recent_dag_runs in body[\"dags\"]:\n             dag_runs = recent_dag_runs[\"latest_dag_runs\"]\n             # check date ordering\n-            previous_logical_date = None\n+            previous_run_after = None\n             for dag_run in dag_runs:\n                 # validate the response\n                 for key in required_dag_run_key:\n                     assert key in dag_run\n-                if previous_logical_date:\n-                    assert previous_logical_date > dag_run[\"logical_date\"]\n-                previous_logical_date = dag_run[\"logical_date\"]\n+                if previous_run_after:\n+                    assert previous_run_after > dag_run[\"run_after\"]\n+                previous_run_after = dag_run[\"run_after\"]\n", "problem_statement": "AIP-84 Make dag runs list sortable by run_after\nWe added `run_after` to the DagRunResponse object. But we didn't make the dag runs list to be sortable by `run_after`\n", "hints_text": "Hi @bbovenzi, I can work on this issue, could you assign it to me? Thanks!", "created_at": "2025-02-13T22:10:51Z"}
