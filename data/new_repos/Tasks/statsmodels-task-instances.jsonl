{"repo": "statsmodels/statsmodels", "pull_number": 9487, "instance_id": "statsmodels__statsmodels-9487", "issue_numbers": ["9175"], "base_commit": "8600926f2f22e58779a667d82047a90318b20431", "patch": "diff --git a/statsmodels/sandbox/stats/multicomp.py b/statsmodels/sandbox/stats/multicomp.py\nindex ea0cef0825b..f35c2688447 100644\n--- a/statsmodels/sandbox/stats/multicomp.py\n+++ b/statsmodels/sandbox/stats/multicomp.py\n@@ -71,6 +71,7 @@\n import numpy as np\n from numpy.testing import assert_almost_equal, assert_equal\n from scipy import interpolate, stats\n+import pandas as pd\n \n from statsmodels.graphics import utils\n from statsmodels.iolib.table import SimpleTable\n@@ -646,6 +647,9 @@ def __init__(\n         reject2=None,\n         variance=None,\n         pvalues=None,\n+        alpha=None,\n+        group_t=None,\n+        group_c=None,\n     ):\n         self._multicomp = mc_object\n         self._results_table = results_table\n@@ -658,11 +662,24 @@ def __init__(\n         self.reject2 = reject2\n         self.variance = variance\n         self.pvalues = pvalues\n+        self.alpha = alpha\n+        self.group_t = group_t\n+        self.group_c = group_c\n         # Taken out of _multicomp for ease of access for unknowledgeable users\n         self.data = self._multicomp.data\n         self.groups = self._multicomp.groups\n         self.groupsunique = self._multicomp.groupsunique\n \n+        if np.size(df_total) > 1:  # or should it be np.isscalar\n+            # assume we have Games-Howell, unequal var case\n+            self._qcrit_hsd = None\n+        else:\n+            self._qcrit_hsd = q_crit\n+\n+        nobs_group = self._multicomp.groupstats.groupnobs\n+        self.df_total_hsd = np.sum(nobs_group - 1)\n+\n+\n     def __str__(self):\n         return str(self._results_table)\n \n@@ -670,10 +687,60 @@ def summary(self):\n         \"\"\"Summary table that can be printed\"\"\"\n         return self._results_table\n \n+    def summary_frame(self):\n+        \"\"\"Summary DataFrame\n+\n+        The group columns are labeled as \"group_t\" and \"group_c\" with mean\n+        difference defined as treatment minus control.\n+        This should be less confusing than numeric labels group1 and group2.\n+\n+        Returns\n+        -------\n+        pandas.DataFrame\n+\n+        Notes\n+        -----\n+        The number of columns will likely increase in a future version of\n+        statsmodels. Do not use numeric indices for the DataFrame in order\n+        to be robust to the addition of columns.\n+        \"\"\"\n+        frame = pd.DataFrame({\n+            \"group_t\": self.group_t,\n+            \"group_c\": self.group_c,\n+            \"meandiff\": self.meandiffs,\n+            \"p-adj\": self.pvalues,\n+            \"lower\": self.confint[:, 0],\n+            \"upper\": self.confint[:, 1],\n+            \"reject\": self.reject,\n+            })\n+        return frame\n+\n+    def _get_q_crit(self, hsd=True, alpha=None):\n+        n_means = len(self.groupsunique)\n+\n+        if alpha is None:\n+            alpha = self.alpha\n+            use_attr = True\n+\n+        if hsd is True:\n+            if use_attr and self._qcrit_hsd is not None:\n+                q_crit = self._qcrit_hsd\n+            else:  # compute it\n+                q_crit = get_tukeyQcrit2(n_means, self.df_total_hsd, alpha=alpha)\n+            if use_attr:\n+                self._qcrit_hsd = q_crit\n+        else:\n+            raise NotImplementedError(\"not yet\")\n+\n+        return q_crit\n+\n     def _simultaneous_ci(self):\n         \"\"\"Compute simultaneous confidence intervals for comparison of means.\"\"\"\n+\n+        q_crit_hsd = self._get_q_crit(hsd=True)\n+\n         self.halfwidths = simultaneous_ci(\n-            self.q_crit,\n+            q_crit_hsd,\n             self.variance,\n             self._multicomp.groupstats.groupnobs,\n             self._multicomp.pairindices,\n@@ -720,6 +787,16 @@ def plot_simultaneous(\n         confidence intervals, any two pairs can be compared for significance\n         by looking for overlap.\n \n+        The derivation in Hochberg and Tamhane is under the equal variance\n+        assumption. We use the same computation in the case of unequal\n+        variances, however, with replacement of the common pooled variance\n+        by the unequal estimates of the whithin group variances.\n+        This provides a plot that looks more informative and plausible in the\n+        case where there are large differences in variances. In the equal\n+        sample size and equal variance case, the confidence intervals computed\n+        by the two methods, equal and unequal variance, are very close to\n+        each other in larger samples.\n+\n         References\n         ----------\n         .. [*] Hochberg, Y., and A. C. Tamhane. Multiple Comparison Procedures.\n@@ -1042,7 +1119,7 @@ def allpairtest(self, testfunc, alpha=0.05, method=\"bonf\", pvalidx=1):\n             resarr,\n         )\n \n-    def tukeyhsd(self, alpha=0.05):\n+    def tukeyhsd(self, alpha=0.05, use_var='equal'):\n         \"\"\"\n         Tukey's range test to compare means of all pairs of groups\n \n@@ -1050,12 +1127,25 @@ def tukeyhsd(self, alpha=0.05):\n         ----------\n         alpha : float, optional\n             Value of FWER at which to calculate HSD.\n+        use_var : {\"unequal\", \"equal\"}\n+            If ``use_var`` is \"equal\", then the Tukey-hsd pvalues are returned.\n+            Tukey-hsd assumes that (within) variances are the same across groups.\n+            If ``use_var`` is \"unequal\", then the Games-Howell pvalues are\n+            returned. This uses Welch's t-test for unequal variances with\n+            Satterthwait's corrected degrees of freedom for each pairwise\n+            comparison.\n \n         Returns\n         -------\n         results : TukeyHSDResults instance\n             A results class containing relevant data and some post-hoc\n             calculations\n+\n+        Notes\n+        -----\n+\n+        .. versionadded:: 0.15\n+   `       The `use_var` keyword and option for Games-Howell test.\n         \"\"\"\n         self.groupstats = GroupsStats(\n             np.column_stack([self.data, self.groupintlab]), useranks=False\n@@ -1063,9 +1153,13 @@ def tukeyhsd(self, alpha=0.05):\n \n         gmeans = self.groupstats.groupmean\n         gnobs = self.groupstats.groupnobs\n-        # var_ = self.groupstats.groupvarwithin()\n-        # #possibly an error in varcorrection in this case\n-        var_ = np.var(self.groupstats.groupdemean(), ddof=len(gmeans))\n+        if use_var == 'unequal':\n+            var_ = self.groupstats.groupvarwithin()\n+        elif use_var == 'equal':\n+            var_ = np.var(self.groupstats.groupdemean(), ddof=len(gmeans))\n+        else:\n+            raise ValueError('use_var should be \"unequal\" or \"equal\"')\n+\n         # res contains: 0:(idx1, idx2), 1:reject, 2:meandiffs, 3: std_pairs,\n         # 4:confint, 5:q_crit, 6:df_total, 7:reject2, 8: pvals\n         res = tukeyhsd(gmeans, gnobs, var_, df=None, alpha=alpha, q_crit=None)\n@@ -1096,18 +1190,21 @@ def tukeyhsd(self, alpha=0.05):\n         )\n \n         return TukeyHSDResults(\n-            self,\n+            self,  # mc_object, attached as _multicomp\n             results_table,\n-            res[5],\n-            res[1],\n-            res[2],\n-            res[3],\n-            res[4],\n-            res[6],\n-            res[7],\n-            var_,\n-            res[8],\n-        )\n+            res[5],  # q_crit, positional\n+            reject=res[1],\n+            meandiffs=res[2],\n+            std_pairs=res[3],\n+            confint=res[4],\n+            df_total=res[6],\n+            reject2=res[7],\n+            variance=var_,\n+            pvalues=res[8],\n+            alpha=alpha,\n+            group_t=self.groupsunique[res[0][1]],\n+            group_c=self.groupsunique[res[0][0]],\n+            )\n \n \n def rankdata(x):\n@@ -1326,7 +1423,6 @@ def varcorrection_pairs_unequal(var_all, nobs_all, df_all):\n     error, MSE. To obtain the correction factor for the standard deviation,\n     square root needs to be taken.\n \n-    TODO: something looks wrong with dfjoint, is formula from SPSS\n     \"\"\"\n     # TODO: test and replace with broadcasting\n     v1, v2 = np.meshgrid(var_all, var_all)\n@@ -1334,8 +1430,7 @@ def varcorrection_pairs_unequal(var_all, nobs_all, df_all):\n     df1, df2 = np.meshgrid(df_all, df_all)\n \n     varjoint = v1 / n1 + v2 / n2\n-\n-    dfjoint = varjoint**2 / (df1 * (v1 / n1) ** 2 + df2 * (v2 / n2) ** 2)\n+    dfjoint = varjoint**2 / ((v1 / n1) ** 2 / df1 + (v2 / n2) ** 2 / df2)\n \n     return varjoint, dfjoint\n \n@@ -1368,6 +1463,7 @@ def tukeyhsd(mean_all, nobs_all, var_all, df=None, alpha=0.05, q_crit=None):\n     else:\n         df_total = np.sum(df)\n \n+    df_pairs_ = None\n     if (np.size(nobs_all) == 1) and (np.size(var_all) == 1):\n         # balanced sample sizes and homogenous variance\n         var_pairs = 1.0 * var_all / nobs_all * np.ones((n_means, n_means))\n@@ -1376,8 +1472,8 @@ def tukeyhsd(mean_all, nobs_all, var_all, df=None, alpha=0.05, q_crit=None):\n         # unequal sample sizes and homogenous variance\n         var_pairs = var_all * varcorrection_pairs_unbalanced(nobs_all, srange=True)\n     elif np.size(var_all) > 1:\n-        var_pairs, df_sum = varcorrection_pairs_unequal(nobs_all, var_all, df)\n-        var_pairs /= 2.0\n+        var_pairs, df_pairs_ = varcorrection_pairs_unequal(var_all, nobs_all, df)\n+        var_pairs /= 2.\n         # check division by two for studentized range\n \n     else:\n@@ -1391,10 +1487,13 @@ def tukeyhsd(mean_all, nobs_all, var_all, df=None, alpha=0.05, q_crit=None):\n     idx1, idx2 = np.triu_indices(n_means, 1)\n     meandiffs = meandiffs_[idx1, idx2]\n     std_pairs = std_pairs_[idx1, idx2]\n+    if df_pairs_ is not None:\n+        df_total = df_pairs_[idx1, idx2]\n \n     st_range = np.abs(meandiffs) / std_pairs  # studentized range statistic\n \n-    max(df_total, 5)  # TODO: smallest df in table\n+    # df_total_ = np.maximum(df_total, 5)  # TODO: smallest df in table\n+\n     if q_crit is None:\n         q_crit = get_tukeyQcrit2(n_means, df_total, alpha=alpha)\n \n@@ -1513,10 +1612,9 @@ def distance_st_range(mean_all, nobs_all, var_all, df=None, triu=False):\n         # unequal sample sizes and homogenous variance\n         var_pairs = var_all * varcorrection_pairs_unbalanced(nobs_all, srange=True)\n     elif np.size(var_all) > 1:\n-        var_pairs, df_sum = varcorrection_pairs_unequal(nobs_all, var_all, df)\n-        var_pairs /= 2.0\n+        var_pairs, df_sum = varcorrection_pairs_unequal(var_all, nobs_all, df)\n+        var_pairs /= 2.\n         # check division by two for studentized range\n-\n     else:\n         raise ValueError(\"not supposed to be here\")\n \n@@ -1592,7 +1690,10 @@ def contrast_diff_mean(nm):\n \n \n def tukey_pvalues(std_range, nm, df):\n+    \"\"\"compute tukey p-values by numerical integration of multivariate-t distribution\n+    \"\"\"\n     # corrected but very slow with warnings about integration\n+    # need to increase maxiter or similar\n     # nm = len(std_range)\n     contr = contrast_allpairs(nm)\n     corr = np.dot(contr, contr.T) / 2.0\n@@ -1601,7 +1702,11 @@ def tukey_pvalues(std_range, nm, df):\n \n \n def multicontrast_pvalues(tstat, tcorr, df=None, dist=\"t\", alternative=\"two-sided\"):\n-    \"\"\"pvalues for simultaneous tests\"\"\"\n+    \"\"\"pvalues for simultaneous tests\n+\n+    currently only for t distribution, normal distribution not added yet\n+    alternative is ignored\n+    \"\"\"\n     from statsmodels.sandbox.distributions.multivariate import mvstdtprob\n \n     if (df is None) and (dist == \"t\"):\ndiff --git a/statsmodels/stats/multicomp.py b/statsmodels/stats/multicomp.py\nindex 79ba99c1ecf..40c731a928f 100644\n--- a/statsmodels/stats/multicomp.py\n+++ b/statsmodels/stats/multicomp.py\n@@ -10,9 +10,9 @@\n __all__ = ['tukeyhsd', 'MultiComparison']\n \n \n-def pairwise_tukeyhsd(endog, groups, alpha=0.05):\n+def pairwise_tukeyhsd(endog, groups, alpha=0.05, use_var='equal'):\n     \"\"\"\n-    Calculate all pairwise comparisons with TukeyHSD confidence intervals\n+    Calculate all pairwise comparisons with TukeyHSD or Games-Howell.\n \n     Parameters\n     ----------\n@@ -22,6 +22,13 @@ def pairwise_tukeyhsd(endog, groups, alpha=0.05):\n         array with groups, can be string or integers\n     alpha : float\n         significance level for the test\n+    use_var : {\"unequal\", \"equal\"}\n+        If ``use_var`` is \"equal\", then the Tukey-hsd pvalues are returned.\n+        Tukey-hsd assumes that (within) variances are the same across groups.\n+        If ``use_var`` is \"unequal\", then the Games-Howell pvalues are\n+        returned. This uses Welch's t-test for unequal variances with\n+        Satterthwaite's corrected degrees of freedom for each pairwise\n+        comparison.\n \n     Returns\n     -------\n@@ -31,7 +38,17 @@ def pairwise_tukeyhsd(endog, groups, alpha=0.05):\n \n     Notes\n     -----\n-    This is just a wrapper around tukeyhsd method of MultiComparison\n+    This is just a wrapper around tukeyhsd method of MultiComparison.\n+    Tukey-hsd is not robust to heteroscedasticity, i.e. variance differ across\n+    groups, especially if group sizes also vary. In those cases, the actual\n+    size (rejection rate under the Null hypothesis) might be far from the\n+    nominal size of the test.\n+    The Games-Howell method uses pairwise t-tests that are robust to differences\n+    in variances and approximately maintains size unless samples are very\n+    small.\n+\n+    .. versionadded:: 0.15\n+   `   The `use_var` keyword and option for Games-Howell test.\n \n     See Also\n     --------\n@@ -40,4 +57,5 @@ def pairwise_tukeyhsd(endog, groups, alpha=0.05):\n     statsmodels.sandbox.stats.multicomp.TukeyHSDResults\n     \"\"\"\n \n-    return MultiComparison(endog, groups).tukeyhsd(alpha=alpha)\n+    return MultiComparison(endog, groups).tukeyhsd(alpha=alpha,\n+                                                   use_var=use_var)\n", "test_patch": "diff --git a/statsmodels/stats/tests/test_pairwise.py b/statsmodels/stats/tests/test_pairwise.py\nindex 5d34b7a8d11..c9a84ead9fe 100644\n--- a/statsmodels/stats/tests/test_pairwise.py\n+++ b/statsmodels/stats/tests/test_pairwise.py\n@@ -120,6 +120,14 @@\n 1 - 3\\t-0.260\\t-3.909\\t3.389\\t-\n '''\n \n+# result in R: library(rstatix)\n+# games_howell_test(df, StressReduction ~ Treatment, conf.level = 0.99)\n+ss2_unequal = '''\\\n+1\\tStressReduction\\tmedical\\tmental\\t1.8888888888888888\\t0.7123347940930316\\t3.0654429836847461\\t0.000196\\t***\n+2\\tStressReduction\\tmedical\\tphysical\\t0.8888888888888888\\t-0.8105797509636128\\t2.5883575287413905\\t0.206000\\tns\n+3\\tStressReduction\\tmental\\tphysical\\t-1.0000000000000000\\t-2.6647460755237473\\t0.6647460755237473\\t0.127000\\tns\n+'''\n+\n cylinders = np.array([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4, 4,\n                     4, 4, 4, 4, 6, 8, 8, 8, 8, 4, 4, 4, 4, 8, 8, 8, 8, 6, 6, 6, 6, 4, 4, 4, 4, 6, 6,\n                     6, 6, 4, 4, 4, 4, 4, 8, 4, 6, 6, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n@@ -138,6 +146,7 @@\n ss2 = asbytes(ss2)\n ss3 = asbytes(ss3)\n ss5 = asbytes(ss5)\n+ss2_unequal = asbytes(ss2_unequal)\n \n dta = pd.read_csv(BytesIO(ss), sep=r'\\s+', header=None, engine='python')\n dta.columns = \"Rust\", \"Brand\", \"Replication\"\n@@ -151,7 +160,10 @@\n for col in ('pair', 'sig'):\n     dta5[col] = dta5[col].map(lambda v: v.encode('utf-8'))\n sas_ = dta5.iloc[[1, 3, 2]]\n-\n+games_howell_r_result = pd.read_csv(BytesIO(ss2_unequal), sep=r'\\t', header=None, engine='python')\n+games_howell_r_result.columns = ['idx', 'y', 'group1', 'group2', 'meandiff', 'lower', 'upper', 'pvalue', 'sig']\n+for col in ('y', 'group1', 'group2', 'sig'):\n+    games_howell_r_result[col] = games_howell_r_result[col].map(lambda v: v.encode('utf-8'))\n \n def get_thsd(mci, alpha=0.05):\n     var_ = np.var(mci.groupstats.groupdemean(), ddof=len(mci.groupsunique))\n@@ -172,7 +184,10 @@ class CheckTuckeyHSDMixin:\n     @classmethod\n     def setup_class_(cls):\n         cls.mc = MultiComparison(cls.endog, cls.groups)\n-        cls.res = cls.mc.tukeyhsd(alpha=cls.alpha)\n+        if hasattr(cls, 'use_var'):\n+            cls.res = cls.mc.tukeyhsd(alpha=cls.alpha, use_var=cls.use_var)\n+        else:\n+            cls.res = cls.mc.tukeyhsd(alpha=cls.alpha)\n \n     def test_multicomptukey(self):\n         assert_almost_equal(self.res.meandiffs, self.meandiff2, decimal=14)\n@@ -180,12 +195,18 @@ def test_multicomptukey(self):\n         assert_equal(self.res.reject, self.reject2)\n \n     def test_group_tukey(self):\n+        if hasattr(self, 'use_var') and self.use_var == 'unequal':\n+            # in unequal variance case, we feed groupvarwithin, no need to test total variance\n+            return\n         res_t = get_thsd(self.mc, alpha=self.alpha)\n         assert_almost_equal(res_t[4], self.confint2, decimal=2)\n \n     def test_shortcut_function(self):\n         #check wrapper function\n-        res = pairwise_tukeyhsd(self.endog, self.groups, alpha=self.alpha)\n+        if hasattr(self, 'use_var'):\n+            res = pairwise_tukeyhsd(self.endog, self.groups, alpha=self.alpha, use_var=self.use_var)\n+        else:\n+            res = pairwise_tukeyhsd(self.endog, self.groups, alpha=self.alpha)\n         assert_almost_equal(res.confint, self.res.confint, decimal=14)\n \n     @pytest.mark.smoke\n@@ -244,6 +265,15 @@ def test_table_names_custom_group_order(self):\n             second_group = t[i][1].data\n             assert_((first_group, second_group) == expected_order[i - 1])\n \n+        frame = res.summary_frame()\n+        assert_equal(frame[\"p-adj\"], res.pvalues)\n+        assert_equal(frame[\"meandiff\"], res.meandiffs)\n+        # Why are we working with binary strings, old time numpy?\n+        group_t = [b\"medical\", b\"mental\", b\"mental\"]\n+        group_c = [b\"physical\", b\"physical\", b\"medical\"]\n+        assert frame[\"group_t\"].to_list() == group_t\n+        assert frame[\"group_c\"].to_list() == group_c\n+\n \n class TestTuckeyHSD2Pandas(TestTuckeyHSD2):\n \n@@ -323,6 +353,23 @@ def setup_class(cls):\n         cls.reject2 = pvals < 0.01\n \n \n+class TestTukeyHSD2sUnequal(CheckTuckeyHSDMixin):\n+\n+    @classmethod\n+    def setup_class(cls):\n+        # Games-Howell test\n+        cls.endog = dta2['StressReduction'][3:29]\n+        cls.groups = dta2['Treatment'][3:29]\n+        cls.alpha = 0.01\n+        cls.use_var = 'unequal'\n+        cls.setup_class_()\n+\n+        #from R: library(rstatix)\n+        cls.meandiff2 = games_howell_r_result['meandiff']\n+        cls.confint2 = games_howell_r_result[['lower', 'upper']].astype(float).values.reshape((3, 2))\n+        cls.reject2 = games_howell_r_result['sig'] == asbytes('***')\n+\n+\n class TestTuckeyHSD3(CheckTuckeyHSDMixin):\n \n     @classmethod\n@@ -365,3 +412,18 @@ def setup_class(cls):\n \n     def test_hochberg_intervals(self):\n         assert_almost_equal(self.res.halfwidths, self.halfwidth2, 4)\n+\n+\n+@pytest.mark.smoke\n+@pytest.mark.matplotlib\n+def test_plot(close_figures):\n+    # SMOKE test\n+    cylinders_adj = cylinders.astype(float)\n+    # avoid zero division, zero within variance in France and Sweden\n+    cylinders_adj[[10, 28]] += 0.05\n+    alpha = 0.05\n+    mc = MultiComparison(cylinders_adj, cyl_labels)\n+    resth = mc.tukeyhsd(alpha=alpha, use_var=\"equal\")\n+    resgh = mc.tukeyhsd(alpha=alpha, use_var=\"unequal\")\n+    resth.plot_simultaneous()\n+    resgh.plot_simultaneous()\n", "problem_statement": "BUG: Fix unequal varcorrection in tukeyhsd\n- [x] tests added / passed. \r\n- [x] code/documentation is well formatted.  \r\n- [x] properly formatted commit message. See \r\n      [NumPy's guide](https://docs.scipy.org/doc/numpy-1.15.1/dev/gitwash/development_workflow.html#writing-the-commit-message). \r\n\r\n<details>\r\n\r\nlike tests in try_tukey_hsd.py\r\nWith the first dataset, results should be the same, as below.\r\n\r\n![image](https://github.com/statsmodels/statsmodels/assets/56634448/9b070938-dac8-4e8a-ac5e-eef711c00477)\r\n\r\n\r\n</details>\r\n\n", "hints_text": "", "created_at": "2025-01-21T04:20:19Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9471, "instance_id": "statsmodels__statsmodels-9471", "issue_numbers": ["9037"], "base_commit": "91d84c294de2b507d6a5778b6bf2e77ad9b574ed", "patch": "diff --git a/statsmodels/discrete/conditional_models.py b/statsmodels/discrete/conditional_models.py\nindex 99c6ea49366..7171742ba9f 100644\n--- a/statsmodels/discrete/conditional_models.py\n+++ b/statsmodels/discrete/conditional_models.py\n@@ -2,15 +2,20 @@\n Conditional logistic, Poisson, and multinomial logit regression\n \"\"\"\n \n+import collections\n+import itertools\n+import warnings\n+\n import numpy as np\n+\n import statsmodels.base.model as base\n-import statsmodels.regression.linear_model as lm\n import statsmodels.base.wrapper as wrap\n-from statsmodels.discrete.discrete_model import (MultinomialResults,\n-      MultinomialResultsWrapper)\n-import collections\n-import warnings\n-import itertools\n+from statsmodels.discrete.discrete_model import (\n+    MultinomialResults,\n+    MultinomialResultsWrapper,\n+)\n+from statsmodels.formula.formulatools import advance_eval_env\n+import statsmodels.regression.linear_model as lm\n \n \n class _ConditionalModel(base.LikelihoodModel):\n@@ -208,7 +213,7 @@ def from_formula(cls,\n \n         if \"0+\" not in formula.replace(\" \", \"\"):\n             warnings.warn(\"Conditional models should not include an intercept\")\n-\n+        advance_eval_env(kwargs)\n         model = super().from_formula(\n             formula, data=data, groups=groups, *args, **kwargs)\n \ndiff --git a/statsmodels/duration/hazard_regression.py b/statsmodels/duration/hazard_regression.py\nindex d00d2ee1c17..78e4d8c2dc6 100644\n--- a/statsmodels/duration/hazard_regression.py\n+++ b/statsmodels/duration/hazard_regression.py\n@@ -14,13 +14,14 @@\n hazards model.\n http://www.mwsug.org/proceedings/2006/stats/MWSUG-2006-SD08.pdf\n \"\"\"\n+from statsmodels.compat.pandas import Appender\n+\n import numpy as np\n \n from statsmodels.base import model\n import statsmodels.base.model as base\n+from statsmodels.formula.formulatools import advance_eval_env\n from statsmodels.tools.decorators import cache_readonly\n-from statsmodels.compat.pandas import Appender\n-\n \n _predict_docstring = \"\"\"\n     Returns predicted values from the proportional hazards\n@@ -423,7 +424,7 @@ def from_formula(cls, formula, data, status=None, entry=None,\n             if term in (\"0\", \"1\"):\n                 import warnings\n                 warnings.warn(\"PHReg formulas should not include any '0' or '1' terms\")\n-\n+        advance_eval_env(kwargs)\n         mod = super().from_formula(formula, data,\n                     status=status, entry=entry, strata=strata,\n                     offset=offset, subset=subset, ties=ties,\ndiff --git a/statsmodels/formula/formulatools.py b/statsmodels/formula/formulatools.py\nindex 7d710222ba5..13dba3ebb31 100644\n--- a/statsmodels/formula/formulatools.py\n+++ b/statsmodels/formula/formulatools.py\n@@ -5,6 +5,8 @@\n # if users want to pass in a different formula framework, they can\n # add their handler here. how to do it interactively?\n \n+__all__ = [\"handle_formula_data\", \"formula_handler\", \"advance_eval_env\"]\n+\n # this is a mutable object, so editing it should show up in the below\n formula_handler = {}\n \n@@ -77,3 +79,21 @@ def make_hypotheses_matrices(model_results, test_formula):\n     exog_names = model_results.model.exog_names\n     lc = mgr.get_linear_constraints(test_formula, exog_names)\n     return lc\n+\n+\n+def advance_eval_env(kwargs):\n+    \"\"\"\n+    Adjusts the keyword arguments for from_formula to account for the patsy\n+    eval environment being passed down once on the stack. Adjustments are\n+    made in place.\n+    Parameters\n+    ----------\n+    kwargs : dict\n+        The dictionary of keyword arguments passed to `from_formula`.\n+    \"\"\"\n+\n+    eval_env = kwargs.get(\"eval_env\", None)\n+    if eval_env is None:\n+        kwargs[\"eval_env\"] = 2\n+    elif eval_env == -1:\n+        kwargs[\"eval_env\"] = FormulaManager().get_empty_eval_env()\ndiff --git a/statsmodels/genmod/generalized_estimating_equations.py b/statsmodels/genmod/generalized_estimating_equations.py\nindex 2a5eb85bdd7..d16e4d9b8c4 100644\n--- a/statsmodels/genmod/generalized_estimating_equations.py\n+++ b/statsmodels/genmod/generalized_estimating_equations.py\n@@ -46,6 +46,7 @@\n     margeff_cov_with_se,\n )\n from statsmodels.formula._manager import FormulaManager\n+from statsmodels.formula.formulatools import advance_eval_env\n from statsmodels.genmod import cov_struct as cov_structs, families\n from statsmodels.genmod.families.links import Link\n import statsmodels.genmod.families.varfuncs as varfuncs\n@@ -762,6 +763,7 @@ def from_formula(cls, formula, groups, data, subset=None,\n             family = kwargs[\"family\"]\n             del kwargs[\"family\"]\n \n+        advance_eval_env(kwargs)\n         model = super().from_formula(formula, data=data, subset=subset,\n                                      groups=groups, time=time,\n                                      offset=offset,\ndiff --git a/statsmodels/genmod/qif.py b/statsmodels/genmod/qif.py\nindex 0ec5ab3c813..2aa5250de2c 100644\n--- a/statsmodels/genmod/qif.py\n+++ b/statsmodels/genmod/qif.py\n@@ -1,12 +1,14 @@\n-import numpy as np\n from collections import defaultdict\n+\n+import numpy as np\n+\n import statsmodels.base.model as base\n+import statsmodels.base.wrapper as wrap\n+from statsmodels.formula.formulatools import advance_eval_env\n from statsmodels.genmod import families\n+from statsmodels.genmod.families import links, varfuncs\n from statsmodels.genmod.generalized_linear_model import GLM\n-from statsmodels.genmod.families import links\n-from statsmodels.genmod.families import varfuncs\n import statsmodels.regression.linear_model as lm\n-import statsmodels.base.wrapper as wrap\n from statsmodels.tools.decorators import cache_readonly\n \n \n@@ -329,7 +331,7 @@ def from_formula(cls, formula, groups, data, subset=None,\n \n         if isinstance(groups, str):\n             groups = data[groups]\n-\n+        advance_eval_env(kwargs)\n         model = super().from_formula(\n                    formula, data=data, subset=subset,\n                    groups=groups, *args, **kwargs)\ndiff --git a/statsmodels/miscmodels/ordinal_model.py b/statsmodels/miscmodels/ordinal_model.py\nindex 6d19f2b3d89..c12e5b12a54 100644\n--- a/statsmodels/miscmodels/ordinal_model.py\n+++ b/statsmodels/miscmodels/ordinal_model.py\n@@ -21,6 +21,7 @@\n     Model,\n )\n import statsmodels.base.wrapper as wrap\n+from statsmodels.formula.formulatools import advance_eval_env\n # for results wrapper:\n import statsmodels.regression.linear_model as lm\n from statsmodels.tools.decorators import cache_readonly\n@@ -251,7 +252,7 @@ def from_formula(cls, formula, data, subset=None, drop_cols=None,\n \n         endog_name = formula.split(\"~\")[0].strip()\n         original_endog = data[endog_name]\n-\n+        advance_eval_env(kwargs)\n         model = super().from_formula(\n             formula, data=data, drop_cols=[\"Intercept\"], *args, **kwargs)\n \ndiff --git a/statsmodels/othermod/betareg.py b/statsmodels/othermod/betareg.py\nindex 32af9d05a65..367d6ff8aa6 100644\n--- a/statsmodels/othermod/betareg.py\n+++ b/statsmodels/othermod/betareg.py\n@@ -22,6 +22,7 @@\n )\n import statsmodels.base.wrapper as wrap\n from statsmodels.formula._manager import FormulaManager\n+from statsmodels.formula.formulatools import advance_eval_env\n from statsmodels.genmod import families\n import statsmodels.regression.linear_model as lm\n from statsmodels.tools.decorators import cache_readonly\n@@ -151,7 +152,7 @@ def from_formula(cls, formula, data, exog_precision_formula=None,\n             else:\n                 Z = mgr.get_matrices(exog_precision_formula, data, pandas=False)\n             kwargs['exog_precision'] = Z\n-\n+        advance_eval_env(kwargs)\n         return super().from_formula(formula, data, *args,\n                                     **kwargs)\n \ndiff --git a/statsmodels/regression/mixed_linear_model.py b/statsmodels/regression/mixed_linear_model.py\nindex a9b79b2432f..5086402516d 100644\n--- a/statsmodels/regression/mixed_linear_model.py\n+++ b/statsmodels/regression/mixed_linear_model.py\n@@ -152,6 +152,7 @@\n from statsmodels.base._penalties import Penalty\n import statsmodels.base.model as base\n from statsmodels.formula._manager import FormulaManager\n+from statsmodels.formula.formulatools import advance_eval_env\n from statsmodels.tools import data as data_tools\n from statsmodels.tools.decorators import cache_readonly\n from statsmodels.tools.sm_exceptions import ConvergenceWarning\n@@ -1020,7 +1021,6 @@ def from_formula(cls, formula, data, re_formula=None, vc_formula=None,\n             vcf = sorted(vc_formula.keys())\n             mgr = FormulaManager()\n             for vc_name in vcf:\n-                # TODO: patsy migration\n                 model_spec = mgr.get_spec(vc_formula[vc_name])\n                 vc_names.append(vc_name)\n                 evc_mats, evc_colnames = [], []\n@@ -1044,6 +1044,7 @@ def from_formula(cls, formula, data, re_formula=None, vc_formula=None,\n         kwargs[\"exog_re\"] = exog_re\n         kwargs[\"exog_vc\"] = exog_vc\n         kwargs[\"groups\"] = groups\n+        advance_eval_env(kwargs)\n         mod = super().from_formula(\n             formula, data, *args, **kwargs)\n \n", "test_patch": "diff --git a/statsmodels/discrete/tests/test_conditional.py b/statsmodels/discrete/tests/test_conditional.py\nindex 20ea9139485..9497bab39d0 100644\n--- a/statsmodels/discrete/tests/test_conditional.py\n+++ b/statsmodels/discrete/tests/test_conditional.py\n@@ -40,6 +40,31 @@ def test_logit_1d():\n     assert_allclose(result.bse, np.r_[1.295155], rtol=1e-5)\n \n \n+def test_logit_formula():\n+    \"\"\"Test that ConditionalLogit uses the right environment for formulas.\"\"\"\n+\n+    def times_two(x):\n+        return 2 * x\n+\n+    groups = np.repeat([0, 1], 50)\n+    exog = np.linspace(-2, 2, len(groups))\n+\n+    error = np.linspace(-1, 1, len(groups)) # Needed for within-group variance\n+    logit_link = 1 / (1 + np.exp(exog + groups)) + error\n+    endog = (logit_link > 0.5).astype(int)\n+\n+    data = pd.DataFrame({\"exog\": exog, \"groups\": groups, \"endog\": endog})\n+\n+    result_direct = ConditionalLogit(endog, times_two(exog), groups=groups).fit()\n+\n+    result_formula = ConditionalLogit.from_formula(\n+        \"endog ~ 0 + times_two(exog)\", groups=\"groups\", data=data\n+    ).fit()\n+\n+    assert_allclose(result_direct.params, result_formula.params)\n+    assert_allclose(result_direct.bse, result_formula.bse)\n+\n+\n def test_logit_2d():\n \n     y = np.r_[0, 1, 0, 1, 0, 1, 0, 1, 1, 1]\ndiff --git a/statsmodels/duration/tests/test_phreg.py b/statsmodels/duration/tests/test_phreg.py\nindex 85ab6ab968a..98b4c0890fa 100644\n--- a/statsmodels/duration/tests/test_phreg.py\n+++ b/statsmodels/duration/tests/test_phreg.py\n@@ -160,6 +160,26 @@ def test_formula(self):\n         assert_allclose(rslt1.bse, rslt2.bse)\n         assert_allclose(rslt1.bse, rslt3.bse)\n \n+    def test_formula_environment(self):\n+        \"\"\"Test that PHReg uses the right environment for formulas.\"\"\"\n+\n+        def times_two(x):\n+            return 2 * x\n+\n+        rng = np.random.default_rng(0)\n+\n+        exog = rng.uniform(size=100)\n+        endog = np.exp(exog) * -np.log(rng.uniform(size=len(exog)))\n+        data = pd.DataFrame({\"endog\": endog, \"exog\": exog})\n+\n+        result_direct = PHReg(endog, times_two(exog)).fit()\n+\n+        result_formula = PHReg.from_formula(\"endog ~ times_two(exog)\", data=data).fit()\n+\n+        assert_allclose(result_direct.params, result_formula.params)\n+        assert_allclose(result_direct.bse, result_formula.bse)\n+\n+\n     def test_formula_cat_interactions(self):\n \n         time = np.r_[1, 2, 3, 4, 5, 6, 7, 8, 9]\ndiff --git a/statsmodels/genmod/tests/test_gee.py b/statsmodels/genmod/tests/test_gee.py\nindex 1965335879c..8ddc9151590 100644\n--- a/statsmodels/genmod/tests/test_gee.py\n+++ b/statsmodels/genmod/tests/test_gee.py\n@@ -1245,6 +1245,46 @@ def test_formulas(self):\n \n         check_wrapper(rslt2)\n \n+    def test_formula_environment(self):\n+        \"\"\"Test that GEE uses the right environment for formulas.\"\"\"\n+\n+        n = 100\n+        rng = np.random.default_rng(34234)\n+        X1 = rng.normal(size=n)\n+        Y = X1 + rng.normal(size=n)\n+        Time = rng.uniform(size=n)\n+        groups = np.kron(lrange(20), np.ones(5))\n+\n+        data = pd.DataFrame({\"Y\": Y, \"X1\": X1, \"Time\": Time, \"groups\": groups})\n+\n+        va = cov_struct.Autoregressive(grid=False)\n+        family = families.Gaussian()\n+\n+        def times_two(x):\n+            return 2 * x\n+\n+        mat = np.concatenate((np.ones((n, 1)), times_two(X1[:, None])), axis=1)\n+        result_direct = gee.GEE(\n+            Y, mat, groups, time=Time, family=family, cov_struct=va\n+        ).fit()\n+        assert result_direct is not None\n+\n+        result_formula = gee.GEE.from_formula(\n+            \"Y ~ times_two(X1)\",\n+            groups,\n+            data,\n+            time=Time,\n+            family=family,\n+            cov_struct=va,\n+        ).fit()\n+        assert result_formula is not None\n+\n+        assert_almost_equal(\n+            result_direct.params,\n+            result_formula.params,\n+            decimal=8,\n+        )\n+\n     def test_compare_logit(self):\n \n         vs = cov_struct.Independence()\ndiff --git a/statsmodels/genmod/tests/test_qif.py b/statsmodels/genmod/tests/test_qif.py\nindex 6e247b6c459..c0b663f08d6 100644\n--- a/statsmodels/genmod/tests/test_qif.py\n+++ b/statsmodels/genmod/tests/test_qif.py\n@@ -111,3 +111,37 @@ def test_formula(cov_struct):\n     if not isinstance(cov_struct, QIFIndependence):\n         _ = result2.bic\n         _ = result2.aic\n+\n+\n+def test_formula_environment():\n+    \"\"\"Test that QIF uses the right environment for formulas.\"\"\"\n+\n+    rng = np.random.default_rng(3423)\n+\n+    x1 = rng.normal(size=100)\n+    y = x1 + rng.normal(size=100)\n+    groups = np.kron(np.arange(25), np.ones(4))\n+\n+    def times_two(x):\n+        return 2 * x\n+\n+    cov_struct = QIFIndependence()\n+\n+    result_direct = QIF(\n+        y,\n+        times_two(x1).reshape(-1, 1),\n+        groups=groups,\n+        cov_struct=cov_struct\n+    ).fit()\n+\n+    df = pd.DataFrame({\"y\": y, \"x1\": x1, \"groups\": groups})\n+\n+    result_formula = QIF.from_formula(\n+        \"y ~ 0 + times_two(x1)\",\n+        groups=\"groups\",\n+        cov_struct=cov_struct,\n+        data=df\n+    ).fit()\n+\n+    assert_allclose(result_direct.params, result_formula.params)\n+    assert_allclose(result_direct.bse, result_formula.bse)\ndiff --git a/statsmodels/miscmodels/tests/test_ordinal_model.py b/statsmodels/miscmodels/tests/test_ordinal_model.py\nindex 090b6927959..cffe09a9d13 100644\n--- a/statsmodels/miscmodels/tests/test_ordinal_model.py\n+++ b/statsmodels/miscmodels/tests/test_ordinal_model.py\n@@ -305,6 +305,25 @@ def test_formula_categorical(self):\n                     distr=\"probit\",\n                 )\n \n+    def test_formula_eval_env(self):\n+        def times_two(x):\n+            return 2 * x\n+\n+        resp = self.resp\n+        data = ds.df\n+\n+        formula = \"apply ~ times_two(pared) + public + gpa - 1\"\n+        modf2 = OrderedModel.from_formula(formula,\n+                                          data, distr='probit')\n+        resf2 = modf2.fit(method='bfgs', disp=False)\n+\n+        # Transform original params to reflext rescale\n+        trans_params = resp.params.copy()\n+        trans_params[\"pared\"] = trans_params[\"pared\"] / 2\n+        # Loose check that transformation worked\n+        assert_allclose(resf2.params, trans_params , atol=1e-2)\n+        assert \"times_two(pared)\" in resf2.model.exog_names\n+\n     def test_offset(self):\n \n         resp = self.resp\ndiff --git a/statsmodels/othermod/tests/test_beta.py b/statsmodels/othermod/tests/test_beta.py\nindex 825fa9d36ed..13c9a5722b1 100644\n--- a/statsmodels/othermod/tests/test_beta.py\n+++ b/statsmodels/othermod/tests/test_beta.py\n@@ -74,6 +74,12 @@ def setup_class(cls):\n         model = \"I(food/income) ~ income + persons\"\n         cls.income_fit = BetaModel.from_formula(model, income).fit()\n \n+        def times_two(x):\n+            return 2 * x\n+\n+        model = \"I(food/income) ~ times_two(income) + persons\"\n+        cls.income_fit_eval_env = BetaModel.from_formula(model, income).fit()\n+\n         model = cls.model = \"methylation ~ gender + CpG\"\n         mgr = FormulaManager()\n         Z = cls.Z = mgr.get_matrices(\"~ age\", methylation, pandas=False)\n@@ -161,6 +167,15 @@ def test_results_other(self):\n         assert_allclose(rslt.resid, resid, rtol=1e-12)\n         assert_allclose(rslt.resid_pearson, resid / np.sqrt(var), rtol=1e-12)\n \n+    def test_eval_env(self):\n+        assert \"times_two(income)\" in self.income_fit_eval_env.params.index\n+        # Loose check that the eval env scaler worked\n+        assert_allclose(\n+            self.income_fit.params[\"income\"],\n+            2 * self.income_fit_eval_env.params[\"times_two(income)\"],\n+            rtol=1e-02\n+        )\n+\n \n class TestBetaMeth():\n \ndiff --git a/statsmodels/regression/tests/test_lme.py b/statsmodels/regression/tests/test_lme.py\nindex 838b4e41559..b46f3a6e9cb 100644\n--- a/statsmodels/regression/tests/test_lme.py\n+++ b/statsmodels/regression/tests/test_lme.py\n@@ -325,6 +325,21 @@ def test_vcomp_2(self):\n             data=df)\n         result1 = model1.fit()\n \n+        def times_two(x):\n+            return 2 * x\n+        model1_env = MixedLM.from_formula(\n+            \"y ~ times_two(x1) + x2\",\n+            groups=groups,\n+            re_formula=\"0+z1+z2\",\n+            vc_formula=vcf,\n+            data=df)\n+        result1_env = model1_env.fit()\n+        # Loose check that the evan env has worked\n+        assert \"times_two(x1)\" in result1_env.model.exog_names\n+        assert_allclose(\n+            result1.params[\"x1\"], 2*result1_env.params[\"times_two(x1)\"], rtol=1e-3\n+        )\n+\n         # Compare to R\n         assert_allclose(\n             result1.fe_params, [0.16527, 0.99911, 0.96217], rtol=1e-4)\n", "problem_statement": "BUG: Cox Model from formula doesn't grab the correct environment\n#### Describe the bug\r\n\r\nConstructing a proportional hazard model from a formula with `smf.phreg` (aka `PHReg.from_formula`) doesn't use the proper environment.\r\n\r\nSpecifically, `PHReg` overrides the `from_formula` class method but doesn't adjust or set the `eval_env` keyword. It calls `Model.from_formula` to parse the formula, but `Model.from_formula` doesn't know that it was called indirectly and therefore underestimates its depth by one. In the default case, `Model.from_formula` pulls the environment from where it was called, but this is `hazard_regression.py` rather than the user's environment (where `PHReg.from_formula` was called). User-defined symbols aren't found, though internal ones like `np` are available.\r\n\r\nThis problem should also show up for all the other subclass implementations of `from_formula`s (e.g., `GEE`, `QIF`, `OrderedModel`).\r\n\r\n#### Code Sample, a copy-pastable example if possible\r\n\r\n\r\n```python\r\nimport pandas as pd\r\nimport statsmodels.formula.api as smf\r\n\r\ndata = pd.DataFrame(\r\n\t[\r\n\t\t{\"y\": 2, \"x\": 2},\r\n\t\t{\"y\": 2, \"x\": 4},\r\n\t\t{\"y\": 4, \"x\": 6},\r\n\t\t{\"y\": 4, \"x\": 8},\r\n\t]\r\n)\r\n\r\n# Works\r\nsmf.phreg(\"y ~ x\", data=data).fit()\r\n\r\ndef plus_one(x):\r\n\treturn x + 1\r\n\r\n# Works\r\nsmf.ols(\"y ~ plus_one(x)\", data=data).fit()\r\n\r\n# PatsyError from NameError: name 'plus_one' is not defined\r\nsmf.phreg(\"y ~ plus_one(x)\", data=data).fit()\r\n```\r\n\r\n#### Expected Output\r\n\r\nA clear and concise description of what you expected to happen.\r\n\r\n#### Output of ``import statsmodels.api as sm; sm.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\nPython: 3.11.5.final.0\r\nOS: Darwin\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\n\r\nstatsmodels\r\n===========\r\n\r\nInstalled: 0.14.0\r\n\r\nRequired Dependencies\r\n=====================\r\n\r\ncython: Not installed\r\nnumpy: 1.26.1\r\nscipy: 1.11.3\r\npandas: 2.1.1\r\n    dateutil: 2.8.2\r\npatsy: 0.5.3\r\n\r\nOptional Dependencies\r\n=====================\r\n\r\nmatplotlib: Not installed\r\ncvxopt: Not installed\r\njoblib: Not installed\r\n\r\nDeveloper Tools\r\n================\r\n\r\nIPython: Not installed\r\n    jinja2: Not installed\r\nsphinx: Not installed\r\n    pygments: Not installed\r\npytest: Not installed\r\nvirtualenv: Not installed\r\n\r\n</details>\r\n\n", "hints_text": "", "created_at": "2025-01-07T11:36:24Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9468, "instance_id": "statsmodels__statsmodels-9468", "issue_numbers": ["9302"], "base_commit": "831e26ca5dfb087658500f08236a30b99b3f4501", "patch": "diff --git a/statsmodels/tsa/vector_ar/svar_model.py b/statsmodels/tsa/vector_ar/svar_model.py\nindex 6af60aa92ee..02375d8e1d6 100644\n--- a/statsmodels/tsa/vector_ar/svar_model.py\n+++ b/statsmodels/tsa/vector_ar/svar_model.py\n@@ -78,12 +78,14 @@ def __init__(self, endog, svar_type, dates=None,\n             A = np.identity(self.neqs)\n             self.A_mask = A_mask = np.zeros(A.shape, dtype=bool)\n         else:\n+            A = A.astype(\"U\")\n             A_mask = np.logical_or(A == 'E', A == 'e')\n             self.A_mask = A_mask\n         if B is None:\n             B = np.identity(self.neqs)\n             self.B_mask = B_mask = np.zeros(B.shape, dtype=bool)\n         else:\n+            B = B.astype(\"U\")\n             B_mask = np.logical_or(B == 'E', B == 'e')\n             self.B_mask = B_mask\n \n@@ -308,13 +310,22 @@ def score(self, AB_mask):\n         Return numerical gradient\n         \"\"\"\n         loglike = self.loglike\n-        return approx_fprime(AB_mask, loglike, epsilon=1e-8)\n+        if AB_mask.ndim > 1:\n+            AB_mask = AB_mask.ravel()\n+        grad = approx_fprime(AB_mask, loglike, epsilon=1e-8)\n+\n+        # workaround shape of grad if only one parameter #9302\n+        if AB_mask.size == 1 and grad.ndim == 2:\n+            grad = grad.ravel()\n+        return grad\n \n     def hessian(self, AB_mask):\n         \"\"\"\n         Returns numerical hessian.\n         \"\"\"\n         loglike = self.loglike\n+        if AB_mask.ndim > 1:\n+            AB_mask = AB_mask.ravel()\n         return approx_hess(AB_mask, loglike)\n \n     def _solve_AB(self, start_params, maxiter, override=False, solver='bfgs'):\n@@ -355,10 +366,16 @@ def _solve_AB(self, start_params, maxiter, override=False, solver='bfgs'):\n         else: #TODO: change to a warning?\n             print(\"Order/rank conditions have not been checked\")\n \n+        if solver == \"bfgs\":\n+            kwargs = {\"gtol\": 1e-5}\n+        else:\n+            kwargs = {}\n         retvals = super().fit(start_params=start_params,\n                               method=solver, maxiter=maxiter,\n-                              gtol=1e-20, disp=False).params\n+                              disp=False, **kwargs).params\n \n+        if retvals.ndim > 1:\n+            retvals = retvals.ravel()\n         A[A_mask] = retvals[:A_len]\n         B[B_mask] = retvals[A_len:]\n \n", "test_patch": "diff --git a/statsmodels/tsa/vector_ar/tests/test_svar.py b/statsmodels/tsa/vector_ar/tests/test_svar.py\nindex 58f35dce782..b53adeb14b4 100644\n--- a/statsmodels/tsa/vector_ar/tests/test_svar.py\n+++ b/statsmodels/tsa/vector_ar/tests/test_svar.py\n@@ -74,3 +74,32 @@ def test_irf(self):\n         # Windows precision limits require non-zero atol\n         atol = 1e-6 if PLATFORM_WIN else 1e-8\n         assert_allclose(errband1, errband2, rtol=1e-8, atol=atol)\n+\n+\n+def test_oneparam():\n+    # regression test, one parameter in A, B, issue #9302\n+    np.random.seed(873562)\n+    lags = 2\n+    nobs = 200\n+    y = np.random.randn(nobs, 3)\n+    y[1:] += 0.5 * y[:-1]\n+    A = np.asarray([[1, \"E\"], [0, 1.]])\n+    # A_guess = np.asarray([[1, 0.2], [0, 1.]])\n+    B = np.eye(2, dtype=object)\n+\n+    k=2\n+    model = SVAR(y[:, :k], svar_type=\"AB\", A=A, B=B)\n+    model.k_exog_user = 0\n+    results = model.fit(maxlags=lags, solver=\"bfgs\")  # \"newton\")\n+    results.k_exog_user = 0\n+    results.summary()\n+\n+    # regression number\n+    assert_allclose(results.A[0, 1], -0.075818, atol=1e-5)\n+\n+    results = model.fit(maxlags=lags, solver=\"newton\")\n+    results.k_exog_user = 0\n+    results.summary()\n+\n+    # regression number\n+    assert_allclose(results.A[0, 1], -0.075818, atol=1e-5)\n", "problem_statement": "Bug when trying to estimate SVAR because of changes in numpy\nI am trying to estimate a two equation SVAR model using statsmodels but I am facing an issue. For reference, I am using the following code where 'subset' is just a pandas dataframe with two columns (the two series for the variables of the system) and a time series index in datetime format. \r\n\r\n```\r\nlags = 20\r\n   \r\nA = np.array([[1, 'E'], [0, 1]])  \r\n   \r\nA_guess = np.asarray([0.0002])\r\n\r\nmodel = SVAR(subset, svar_type='A', A=A)\r\n\r\nresults = model.fit(A_guess = A_guess, maxlags=20, maxiter = 10000000, maxfun=1000000, solver='bfgs', trend=\"n\")\r\n```\r\n\r\nRunning the code I get the following error\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nFile /Users/test/Desktop/anders_project/code/sql_server_retrieval.py:27\r\n     24     model = SVAR(subset, svar_type='A', A=A)\r\n     26     # Fit the model\r\n---> 27     results = model.fit(maxlags=20, maxiter = 10000000, maxfun=1000000, solver='bfgs', trend=\"n\")\r\n     28     var_results[ticker] = results\r\n     31 # # %% (C)(R) VAR model estimation -> apparently I cannot estimate without intercept so need to find an alternative; also, there seem to be data issues so i need to clean data/remove outliers first\r\n     32\r\n     33 # from statsmodels.tsa.vector_ar.var_model import VAR\r\n   (...)\r\n     66 #     print(f\"Results for {ticker}:\")\r\n     67 #     result.summary()\r\n\r\nFile /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/vector_ar/svar_model.py:180, in SVAR.fit(self, A_guess, B_guess, maxlags, method, ic, trend, verbose, s_method, solver, override, maxiter, maxfun)\r\n    177 # initialize starting parameters\r\n    178 start_params = self._get_init_params(A_guess, B_guess)\r\n--> 180 return self._estimate_svar(start_params, lags, trend=trend,\r\n    181                            solver=solver, override=override,\r\n    182                            maxiter=maxiter, maxfun=maxfun)\r\n\r\nFile /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/vector_ar/svar_model.py:248, in SVAR._estimate_svar(self, start_params, lags, maxiter, maxfun, trend, solver, override)\r\n    245 omega = sse / df_resid\r\n    246 self.sigma_u = omega\r\n--> 248 A, B = self._solve_AB(start_params, override=override,\r\n...\r\n--> 279     A[A_mask] = params[:A_len]\r\n    280 if B is not None:\r\n    281     B[B_mask] = params[A_len:A_len+B_len]\r\n\r\nTypeError: NumPy boolean array indexing assignment requires a 0 or 1-dimensional input, input has 2 dimensions\r\n```\r\n\r\nI talked to josefpktd in the Google group and he had a quick look at the issue. He found that this most likely is a bug as numpy got more strict with shape mismatch in masked assignments which seems to cause the issue. He told me to report the issue here which I am doing with this report. He is a link [link](https://groups.google.com/g/pystatsmodels/c/uRzZMF-OLP8) to what he said exactly for reference.\r\n\r\n\n", "hints_text": "see also another example in #9436 that breaks because no parameters are to be estimated in A, B\nI managed to get it to work\r\n\r\nmask work fine with numpy if dtype of A and B is \"U\"\r\n\r\nhowever, params is 3dim, and I have not figured out why\r\nfixing the symptoms instead of source:\r\n\r\nadd this to several methods\r\n```\r\n        if params.ndim > 1:\r\n            params = params.ravel()\r\n```\r\n\r\n\r\nresult for similar example\r\nsummary requires patching k_exog_user\r\n\r\nHowever, it looks like we don't have A, B parameters in summary and no inference, cov_params for them\r\n\r\n```\r\nresults.A, results.B\r\n(array([[1.        , 0.03613134],\r\n        [0.        , 1.        ]]),\r\n array([[1., 0.],\r\n        [0., 1.]]))\r\n```\r\n\r\n\r\n```\r\nk=2\r\nmodel = SVAR(y[:, :k], svar_type=\"AB\", A=A, B=B)\r\nmodel.k_exog_user = 0\r\nresults = model.fit(maxlags=lags)\r\nresults.k_exog_user = 0\r\nresults.summary()\r\n  Summary of Regression Results   \r\n==================================\r\nModel:                        SVAR\r\nMethod:                        OLS\r\nDate:           Sun, 24, Nov, 2024\r\nTime:                     14:24:18\r\n--------------------------------------------------------------------\r\nNo. of Equations:         2.00000    BIC:                  0.0998087\r\nNobs:                     198.000    HQIC:               0.000955839\r\nLog likelihood:          -545.339    FPE:                   0.935903\r\nAIC:                   -0.0662654    Det(Omega_mle):        0.890367\r\n--------------------------------------------------------------------\r\nResults for equation y1\r\n========================================================================\r\n           coefficient       std. error           t-stat            prob\r\n------------------------------------------------------------------------\r\nconst        -0.049756         0.070477           -0.706           0.480\r\nL1.y1         0.355000         0.071535            4.963           0.000\r\nL1.y2         0.076060         0.064452            1.180           0.238\r\nL2.y1        -0.081373         0.071915           -1.132           0.258\r\nL2.y2        -0.068970         0.064102           -1.076           0.282\r\n========================================================================\r\n\r\nResults for equation y2\r\n========================================================================\r\n           coefficient       std. error           t-stat            prob\r\n------------------------------------------------------------------------\r\nconst        -0.223188         0.074249           -3.006           0.003\r\nL1.y1         0.156949         0.075363            2.083           0.037\r\nL1.y2         0.575030         0.067901            8.469           0.000\r\nL2.y1        -0.086858         0.075764           -1.146           0.252\r\nL2.y2        -0.332960         0.067532           -4.930           0.000\r\n========================================================================\r\n\r\nCorrelation matrix of residuals\r\n            y1        y2\r\ny1    1.000000 -0.038065\r\ny2   -0.038065  1.000000\r\n```\nWhat are the params in SVARResults?\r\n\r\nskimming the code it looks like those are just the var parameters\r\ndefault svar_ma_rep  uses p = Ainv * B\r\n\r\ni.e. I guess reduced form lag representation should pre-multiply var system by Ainv.\r\n\r\n\nThere is something wrong with \"bfgs\".\r\n\r\nDigging in with pdb, it looks like extra dimension to `params` are added during bfgs optimization.\r\nI have no idea yet why and where (statsmodels or scipy?)\r\n\"newton\" also fails. So there could be a problem in `score` or `hessian`, which both use numdiff.\r\n(But, AFAIR, both bfgs and lbfgs use score only.)\r\n\r\n\"nm\" and \"lbfgs\" seems to work fine  (I only partially removed my workaround `ravel`.)\r\n\r\n\r\n**update**\r\nSVAR,score return 2dim gradient.\r\nIf I ravel it to return 1dim gradient, then bfgs works. \"newdon\" also works now with 1dim score.\r\nSo, it could be that \"bfgs\" gets messed up by 2dim gradient, while \"lbfgs\" does not.\r\n\r\nMaybe something changed in numdiff approx_fprime in this case.\r\nIIRC, I added vectorization if there is only one param.\r\n\r\npossible change in #8780\r\n\r\ncomments for problem and change with 1 param starts around here\r\nhttps://github.com/statsmodels/statsmodels/pull/8780#issuecomment-1505709618\r\n\r\n\nconclusion:\r\n\r\nit looks like only two changes are needed:\r\n\r\n- force dtype of A and B to be \"U\" (to force elementwise comparison in numpy)\r\n- change score to return 1dim \r\n\r\n", "created_at": "2025-01-05T21:27:18Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9461, "instance_id": "statsmodels__statsmodels-9461", "issue_numbers": ["9460"], "base_commit": "ddeaa63e9f9d608a63899b2b7c39cb20c1392248", "patch": "diff --git a/statsmodels/tsa/seasonal.py b/statsmodels/tsa/seasonal.py\nindex 636336b8b8b..8dc358fcb6e 100644\n--- a/statsmodels/tsa/seasonal.py\n+++ b/statsmodels/tsa/seasonal.py\n@@ -1,13 +1,14 @@\n \"\"\"\n Seasonal Decomposition by Moving Averages\n \"\"\"\n+\n import numpy as np\n import pandas as pd\n from pandas.core.nanops import nanmean as pd_nanmean\n \n from statsmodels.tools.validation import PandasWrapper, array_like\n-from statsmodels.tsa.stl._stl import STL\n from statsmodels.tsa.filters.filtertools import convolution_filter\n+from statsmodels.tsa.stl._stl import STL\n from statsmodels.tsa.stl.mstl import MSTL\n from statsmodels.tsa.tsatools import freq_to_period\n \n@@ -25,17 +26,11 @@ def _extrapolate_trend(trend, npoints):\n     Replace nan values on trend's end-points with least-squares extrapolated\n     values with regression considering npoints closest defined points.\n     \"\"\"\n-    front = next(\n-        i for i, vals in enumerate(trend) if not np.any(np.isnan(vals))\n-    )\n+    front = next(i for i, vals in enumerate(trend) if not np.any(np.isnan(vals)))\n     back = (\n         trend.shape[0]\n         - 1\n-        - next(\n-            i\n-            for i, vals in enumerate(trend[::-1])\n-            if not np.any(np.isnan(vals))\n-        )\n+        - next(i for i, vals in enumerate(trend[::-1]) if not np.any(np.isnan(vals)))\n     )\n     front_last = min(front + npoints, back)\n     back_first = max(front, back - npoints)\n@@ -145,7 +140,14 @@ def seasonal_decompose(\n     pfreq = period\n     pw = PandasWrapper(x)\n     if period is None:\n-        pfreq = getattr(getattr(x, \"index\", None), \"inferred_freq\", None)\n+        if isinstance(x, (pd.Series, pd.DataFrame)):\n+            index = x.index\n+            if isinstance(index, pd.PeriodIndex):\n+                pfreq = index.freq\n+            else:\n+                pfreq = getattr(index, \"freq\", None) or getattr(\n+                    index, \"inferred_freq\", None\n+                )\n \n     x = array_like(x, \"x\", maxdim=2)\n     nobs = len(x)\n@@ -245,9 +247,7 @@ def __init__(self, observed, seasonal, trend, resid, weights=None):\n         if weights is None:\n             weights = np.ones_like(observed)\n             if isinstance(observed, pd.Series):\n-                weights = pd.Series(\n-                    weights, index=observed.index, name=\"weights\"\n-                )\n+                weights = pd.Series(weights, index=observed.index, name=\"weights\")\n         self._weights = weights\n         self._resid = resid\n         self._observed = observed\n@@ -325,14 +325,10 @@ def plot(\n         elif self.seasonal.ndim > 1:\n             if isinstance(self.seasonal, pd.DataFrame):\n                 for col in self.seasonal.columns:\n-                    series += (\n-                        [(self.seasonal[col], \"seasonal\")] if seasonal else []\n-                    )\n+                    series += [(self.seasonal[col], \"seasonal\")] if seasonal else []\n             else:\n                 for i in range(self.seasonal.shape[1]):\n-                    series += (\n-                        [(self.seasonal[:, i], \"seasonal\")] if seasonal else []\n-                    )\n+                    series += [(self.seasonal[:, i], \"seasonal\")] if seasonal else []\n \n         series += [(self.resid, \"residual\")] if resid else []\n         series += [(self.weights, \"weights\")] if weights else []\n", "test_patch": "diff --git a/statsmodels/tsa/tests/test_seasonal.py b/statsmodels/tsa/tests/test_seasonal.py\nindex 51c441bc457..08b4f1e1e28 100644\n--- a/statsmodels/tsa/tests/test_seasonal.py\n+++ b/statsmodels/tsa/tests/test_seasonal.py\n@@ -13,50 +13,257 @@\n from statsmodels.tsa.seasonal import seasonal_decompose\n \n # Verification values for tests\n-SEASONAL = [62.46, 86.17, -88.38, -60.25, 62.46, 86.17, -88.38,\n-            -60.25, 62.46, 86.17, -88.38, -60.25, 62.46, 86.17,\n-            -88.38, -60.25, 62.46, 86.17, -88.38, -60.25,\n-            62.46, 86.17, -88.38, -60.25, 62.46, 86.17, -88.38,\n-            -60.25, 62.46, 86.17, -88.38, -60.25]\n-TREND = [np.nan, np.nan, 159.12, 204.00, 221.25, 245.12, 319.75,\n-         451.50, 561.12, 619.25, 615.62, 548.00, 462.12, 381.12,\n-         316.62, 264.00, 228.38, 210.75, 188.38, 199.00, 207.12,\n-         191.00, 166.88, 72.00, -9.25, -33.12, -36.75, 36.25,\n-         103.00, 131.62, np.nan, np.nan]\n-RANDOM = [np.nan, np.nan, 78.254, 70.254, -36.710, -94.299, -6.371,\n-          -62.246, 105.415, 103.576, 2.754, 1.254, 15.415, -10.299,\n-          -33.246, -27.746, 46.165, -57.924, 28.004, -36.746,\n-          -37.585, 151.826, -75.496, 86.254, -10.210, -194.049,\n-          48.129, 11.004, -40.460, 143.201, np.nan, np.nan]\n-\n-MULT_SEASONAL = [1.0815, 1.5538, 0.6716, 0.6931, 1.0815, 1.5538, 0.6716,\n-                 0.6931, 1.0815, 1.5538, 0.6716, 0.6931, 1.0815, 1.5538,\n-                 0.6716, 0.6931, 1.0815, 1.5538, 0.6716, 0.6931, 1.0815,\n-                 1.5538, 0.6716, 0.6931, 1.0815, 1.5538, 0.6716, 0.6931,\n-                 1.0815, 1.5538, 0.6716, 0.6931]\n-MULT_TREND = [np.nan, np.nan, 171.62, 204.00, 221.25, 245.12, 319.75,\n-              451.50, 561.12, 619.25, 615.62, 548.00, 462.12, 381.12,\n-              316.62, 264.00, 228.38, 210.75, 188.38, 199.00, 207.12,\n-              191.00, 166.88, 107.25, 80.50, 79.12, 78.75, 116.50,\n-              140.00, 157.38, np.nan, np.nan]\n-MULT_RANDOM = [np.nan, np.nan, 1.29263, 1.51360, 1.03223, 0.62226,\n-               1.04771, 1.05139, 1.20124, 0.84080, 1.28182, 1.28752,\n-               1.08043, 0.77172, 0.91697, 0.96191, 1.36441, 0.72986,\n-               1.01171, 0.73956, 1.03566, 1.44556, 0.02677, 1.31843,\n-               0.49390, 1.14688, 1.45582, 0.16101, 0.82555, 1.47633,\n-               np.nan, np.nan]\n+SEASONAL = [\n+    62.46,\n+    86.17,\n+    -88.38,\n+    -60.25,\n+    62.46,\n+    86.17,\n+    -88.38,\n+    -60.25,\n+    62.46,\n+    86.17,\n+    -88.38,\n+    -60.25,\n+    62.46,\n+    86.17,\n+    -88.38,\n+    -60.25,\n+    62.46,\n+    86.17,\n+    -88.38,\n+    -60.25,\n+    62.46,\n+    86.17,\n+    -88.38,\n+    -60.25,\n+    62.46,\n+    86.17,\n+    -88.38,\n+    -60.25,\n+    62.46,\n+    86.17,\n+    -88.38,\n+    -60.25,\n+]\n+TREND = [\n+    np.nan,\n+    np.nan,\n+    159.12,\n+    204.00,\n+    221.25,\n+    245.12,\n+    319.75,\n+    451.50,\n+    561.12,\n+    619.25,\n+    615.62,\n+    548.00,\n+    462.12,\n+    381.12,\n+    316.62,\n+    264.00,\n+    228.38,\n+    210.75,\n+    188.38,\n+    199.00,\n+    207.12,\n+    191.00,\n+    166.88,\n+    72.00,\n+    -9.25,\n+    -33.12,\n+    -36.75,\n+    36.25,\n+    103.00,\n+    131.62,\n+    np.nan,\n+    np.nan,\n+]\n+RANDOM = [\n+    np.nan,\n+    np.nan,\n+    78.254,\n+    70.254,\n+    -36.710,\n+    -94.299,\n+    -6.371,\n+    -62.246,\n+    105.415,\n+    103.576,\n+    2.754,\n+    1.254,\n+    15.415,\n+    -10.299,\n+    -33.246,\n+    -27.746,\n+    46.165,\n+    -57.924,\n+    28.004,\n+    -36.746,\n+    -37.585,\n+    151.826,\n+    -75.496,\n+    86.254,\n+    -10.210,\n+    -194.049,\n+    48.129,\n+    11.004,\n+    -40.460,\n+    143.201,\n+    np.nan,\n+    np.nan,\n+]\n+\n+MULT_SEASONAL = [\n+    1.0815,\n+    1.5538,\n+    0.6716,\n+    0.6931,\n+    1.0815,\n+    1.5538,\n+    0.6716,\n+    0.6931,\n+    1.0815,\n+    1.5538,\n+    0.6716,\n+    0.6931,\n+    1.0815,\n+    1.5538,\n+    0.6716,\n+    0.6931,\n+    1.0815,\n+    1.5538,\n+    0.6716,\n+    0.6931,\n+    1.0815,\n+    1.5538,\n+    0.6716,\n+    0.6931,\n+    1.0815,\n+    1.5538,\n+    0.6716,\n+    0.6931,\n+    1.0815,\n+    1.5538,\n+    0.6716,\n+    0.6931,\n+]\n+MULT_TREND = [\n+    np.nan,\n+    np.nan,\n+    171.62,\n+    204.00,\n+    221.25,\n+    245.12,\n+    319.75,\n+    451.50,\n+    561.12,\n+    619.25,\n+    615.62,\n+    548.00,\n+    462.12,\n+    381.12,\n+    316.62,\n+    264.00,\n+    228.38,\n+    210.75,\n+    188.38,\n+    199.00,\n+    207.12,\n+    191.00,\n+    166.88,\n+    107.25,\n+    80.50,\n+    79.12,\n+    78.75,\n+    116.50,\n+    140.00,\n+    157.38,\n+    np.nan,\n+    np.nan,\n+]\n+MULT_RANDOM = [\n+    np.nan,\n+    np.nan,\n+    1.29263,\n+    1.51360,\n+    1.03223,\n+    0.62226,\n+    1.04771,\n+    1.05139,\n+    1.20124,\n+    0.84080,\n+    1.28182,\n+    1.28752,\n+    1.08043,\n+    0.77172,\n+    0.91697,\n+    0.96191,\n+    1.36441,\n+    0.72986,\n+    1.01171,\n+    0.73956,\n+    1.03566,\n+    1.44556,\n+    0.02677,\n+    1.31843,\n+    0.49390,\n+    1.14688,\n+    1.45582,\n+    0.16101,\n+    0.82555,\n+    1.47633,\n+    np.nan,\n+    np.nan,\n+]\n \n \n class TestDecompose:\n     @classmethod\n     def setup_class(cls):\n         # even\n-        data = [-50, 175, 149, 214, 247, 237, 225, 329, 729, 809,\n-                530, 489, 540, 457, 195, 176, 337, 239, 128, 102,\n-                232, 429, 3, 98, 43, -141, -77, -13, 125, 361, -45, 184]\n-        cls.data = pd.DataFrame(data, pd.date_range(start='1/1/1951',\n-                                                    periods=len(data),\n-                                                    freq=QUARTER_END))\n+        data = [\n+            -50,\n+            175,\n+            149,\n+            214,\n+            247,\n+            237,\n+            225,\n+            329,\n+            729,\n+            809,\n+            530,\n+            489,\n+            540,\n+            457,\n+            195,\n+            176,\n+            337,\n+            239,\n+            128,\n+            102,\n+            232,\n+            429,\n+            3,\n+            98,\n+            43,\n+            -141,\n+            -77,\n+            -13,\n+            125,\n+            361,\n+            -45,\n+            184,\n+        ]\n+        index = pd.date_range(start=\"1/1/1951\", periods=len(data), freq=QUARTER_END)\n+        df = pd.DataFrame(data, index=index)\n+        cls.data = df\n+        df = df.copy()\n+        df.index = pd.period_range(start=\"1/1/1951\", periods=len(data), freq=\"Q\")\n+        cls.data_period_index = df\n \n     def test_ndarray(self):\n         res_add = seasonal_decompose(self.data.values, period=4)\n@@ -64,7 +271,7 @@ def test_ndarray(self):\n         assert_almost_equal(res_add.trend, TREND, 2)\n         assert_almost_equal(res_add.resid, RANDOM, 3)\n \n-        res_mult = seasonal_decompose(np.abs(self.data.values), 'm', period=4)\n+        res_mult = seasonal_decompose(np.abs(self.data.values), \"m\", period=4)\n \n         assert_almost_equal(res_mult.seasonal, MULT_SEASONAL, 4)\n         assert_almost_equal(res_mult.trend, MULT_TREND, 2)\n@@ -72,21 +279,105 @@ def test_ndarray(self):\n \n         # test odd\n         res_add = seasonal_decompose(self.data.values[:-1], period=4)\n-        seasonal = [68.18, 69.02, -82.66, -54.54, 68.18, 69.02, -82.66,\n-                    -54.54, 68.18, 69.02, -82.66, -54.54, 68.18, 69.02,\n-                    -82.66, -54.54, 68.18, 69.02, -82.66, -54.54, 68.18,\n-                    69.02, -82.66, -54.54, 68.18, 69.02, -82.66, -54.54,\n-                    68.18, 69.02, -82.66]\n-        trend = [np.nan, np.nan, 159.12, 204.00, 221.25, 245.12, 319.75,\n-                 451.50, 561.12, 619.25, 615.62, 548.00, 462.12, 381.12,\n-                 316.62, 264.00, 228.38, 210.75, 188.38, 199.00, 207.12,\n-                 191.00, 166.88, 72.00, -9.25, -33.12, -36.75, 36.25,\n-                 103.00, np.nan, np.nan]\n-        random = [np.nan, np.nan, 72.538, 64.538, -42.426, -77.150,\n-                  -12.087, -67.962, 99.699, 120.725, -2.962, -4.462,\n-                  9.699, 6.850, -38.962, -33.462, 40.449, -40.775, 22.288,\n-                  -42.462, -43.301, 168.975, -81.212, 80.538, -15.926,\n-                  -176.900, 42.413, 5.288, -46.176, np.nan, np.nan]\n+        seasonal = [\n+            68.18,\n+            69.02,\n+            -82.66,\n+            -54.54,\n+            68.18,\n+            69.02,\n+            -82.66,\n+            -54.54,\n+            68.18,\n+            69.02,\n+            -82.66,\n+            -54.54,\n+            68.18,\n+            69.02,\n+            -82.66,\n+            -54.54,\n+            68.18,\n+            69.02,\n+            -82.66,\n+            -54.54,\n+            68.18,\n+            69.02,\n+            -82.66,\n+            -54.54,\n+            68.18,\n+            69.02,\n+            -82.66,\n+            -54.54,\n+            68.18,\n+            69.02,\n+            -82.66,\n+        ]\n+        trend = [\n+            np.nan,\n+            np.nan,\n+            159.12,\n+            204.00,\n+            221.25,\n+            245.12,\n+            319.75,\n+            451.50,\n+            561.12,\n+            619.25,\n+            615.62,\n+            548.00,\n+            462.12,\n+            381.12,\n+            316.62,\n+            264.00,\n+            228.38,\n+            210.75,\n+            188.38,\n+            199.00,\n+            207.12,\n+            191.00,\n+            166.88,\n+            72.00,\n+            -9.25,\n+            -33.12,\n+            -36.75,\n+            36.25,\n+            103.00,\n+            np.nan,\n+            np.nan,\n+        ]\n+        random = [\n+            np.nan,\n+            np.nan,\n+            72.538,\n+            64.538,\n+            -42.426,\n+            -77.150,\n+            -12.087,\n+            -67.962,\n+            99.699,\n+            120.725,\n+            -2.962,\n+            -4.462,\n+            9.699,\n+            6.850,\n+            -38.962,\n+            -33.462,\n+            40.449,\n+            -40.775,\n+            22.288,\n+            -42.462,\n+            -43.301,\n+            168.975,\n+            -81.212,\n+            80.538,\n+            -15.926,\n+            -176.900,\n+            42.413,\n+            5.288,\n+            -46.176,\n+            np.nan,\n+            np.nan,\n+        ]\n         assert_almost_equal(res_add.seasonal, seasonal, 2)\n         assert_almost_equal(res_add.trend, trend, 2)\n         assert_almost_equal(res_add.resid, random, 3)\n@@ -95,36 +386,36 @@ def test_pandas(self):\n         res_add = seasonal_decompose(self.data, period=4)\n         freq_override_data = self.data.copy()\n         freq_override_data.index = pd.date_range(\n-            start='1/1/1951', periods=len(freq_override_data), freq=YEAR_END)\n+            start=\"1/1/1951\", periods=len(freq_override_data), freq=YEAR_END\n+        )\n         res_add_override = seasonal_decompose(freq_override_data, period=4)\n \n         assert_almost_equal(res_add.seasonal.values.squeeze(), SEASONAL, 2)\n         assert_almost_equal(res_add.trend.values.squeeze(), TREND, 2)\n         assert_almost_equal(res_add.resid.values.squeeze(), RANDOM, 3)\n-        assert_almost_equal(res_add_override.seasonal.values.squeeze(),\n-                            SEASONAL, 2)\n-        assert_almost_equal(res_add_override.trend.values.squeeze(),\n-                            TREND, 2)\n-        assert_almost_equal(res_add_override.resid.values.squeeze(),\n-                            RANDOM, 3)\n-        assert_equal(res_add.seasonal.index.values.squeeze(),\n-                     self.data.index.values)\n-\n-        res_mult = seasonal_decompose(np.abs(self.data), 'm', period=4)\n-        res_mult_override = seasonal_decompose(np.abs(freq_override_data), 'm',\n-                                               period=4)\n-        assert_almost_equal(res_mult.seasonal.values.squeeze(), MULT_SEASONAL,\n-                            4)\n+        assert_almost_equal(res_add_override.seasonal.values.squeeze(), SEASONAL, 2)\n+        assert_almost_equal(res_add_override.trend.values.squeeze(), TREND, 2)\n+        assert_almost_equal(res_add_override.resid.values.squeeze(), RANDOM, 3)\n+        assert_equal(res_add.seasonal.index.values.squeeze(), self.data.index.values)\n+\n+        res_mult = seasonal_decompose(np.abs(self.data), \"m\", period=4)\n+        res_mult_override = seasonal_decompose(\n+            np.abs(freq_override_data), \"m\", period=4\n+        )\n+        assert_almost_equal(res_mult.seasonal.values.squeeze(), MULT_SEASONAL, 4)\n         assert_almost_equal(res_mult.trend.values.squeeze(), MULT_TREND, 2)\n         assert_almost_equal(res_mult.resid.values.squeeze(), MULT_RANDOM, 4)\n-        assert_almost_equal(res_mult_override.seasonal.values.squeeze(),\n-                            MULT_SEASONAL, 4)\n-        assert_almost_equal(res_mult_override.trend.values.squeeze(),\n-                            MULT_TREND, 2)\n-        assert_almost_equal(res_mult_override.resid.values.squeeze(),\n-                            MULT_RANDOM, 4)\n-        assert_equal(res_mult.seasonal.index.values.squeeze(),\n-                     self.data.index.values)\n+        assert_almost_equal(\n+            res_mult_override.seasonal.values.squeeze(), MULT_SEASONAL, 4\n+        )\n+        assert_almost_equal(res_mult_override.trend.values.squeeze(), MULT_TREND, 2)\n+        assert_almost_equal(res_mult_override.resid.values.squeeze(), MULT_RANDOM, 4)\n+        assert_equal(res_mult.seasonal.index.values.squeeze(), self.data.index.values)\n+\n+        res_mult_pi = seasonal_decompose(np.abs(self.data_period_index), \"m\", period=4)\n+        assert_almost_equal(\n+            res_mult.seasonal.values.squeeze(), res_mult_pi.seasonal.values.squeeze(), 4\n+        )\n \n     def test_pandas_nofreq(self, reset_randomstate):\n         # issue #3503\n@@ -135,95 +426,361 @@ def test_pandas_nofreq(self, reset_randomstate):\n \n         atol = 1e-8\n         rtol = 1e-10\n-        assert_allclose(res.seasonal.values.squeeze(), res_np.seasonal,\n-                        atol=atol, rtol=rtol)\n-        assert_allclose(res.trend.values.squeeze(), res_np.trend,\n-                        atol=atol, rtol=rtol)\n-        assert_allclose(res.resid.values.squeeze(), res_np.resid,\n-                        atol=atol, rtol=rtol)\n+        assert_allclose(\n+            res.seasonal.values.squeeze(), res_np.seasonal, atol=atol, rtol=rtol\n+        )\n+        assert_allclose(res.trend.values.squeeze(), res_np.trend, atol=atol, rtol=rtol)\n+        assert_allclose(res.resid.values.squeeze(), res_np.resid, atol=atol, rtol=rtol)\n \n     def test_filt(self):\n-        filt = np.array([1 / 8., 1 / 4., 1. / 4, 1 / 4., 1 / 8.])\n+        filt = np.array([1 / 8.0, 1 / 4.0, 1.0 / 4, 1 / 4.0, 1 / 8.0])\n         res_add = seasonal_decompose(self.data.values, filt=filt, period=4)\n         assert_almost_equal(res_add.seasonal, SEASONAL, 2)\n         assert_almost_equal(res_add.trend, TREND, 2)\n         assert_almost_equal(res_add.resid, RANDOM, 3)\n \n     def test_one_sided_moving_average_in_stl_decompose(self):\n-        res_add = seasonal_decompose(self.data.values, period=4,\n-                                     two_sided=False)\n-\n-        seasonal = np.array([76.76, 90.03, -114.4, -52.4, 76.76, 90.03, -114.4,\n-                             -52.4, 76.76, 90.03, -114.4, -52.4, 76.76, 90.03,\n-                             -114.4, -52.4, 76.76, 90.03, -114.4, -52.4, 76.76,\n-                             90.03, -114.4, -52.4, 76.76, 90.03, -114.4, -52.4,\n-                             76.76, 90.03, -114.4, -52.4])\n-\n-        trend = np.array([np.nan, np.nan, np.nan, np.nan, 159.12, 204., 221.25,\n-                          245.12, 319.75, 451.5, 561.12, 619.25, 615.62, 548.,\n-                          462.12, 381.12, 316.62, 264., 228.38, 210.75, 188.38,\n-                          199., 207.12, 191., 166.88, 72., -9.25, -33.12,\n-                          -36.75, 36.25, 103., 131.62])\n-\n-        resid = np.array([np.nan, np.nan, np.nan, np.nan, 11.112, -57.031,\n-                          118.147, 136.272, 332.487, 267.469, 83.272, -77.853,\n-                          -152.388, -181.031, -152.728, -152.728, -56.388,\n-                          -115.031, 14.022, -56.353, -33.138, 139.969, -89.728,\n-                          -40.603, -200.638, -303.031, 46.647, 72.522, 84.987,\n-                          234.719, -33.603, 104.772])\n+        res_add = seasonal_decompose(self.data.values, period=4, two_sided=False)\n+\n+        seasonal = np.array(\n+            [\n+                76.76,\n+                90.03,\n+                -114.4,\n+                -52.4,\n+                76.76,\n+                90.03,\n+                -114.4,\n+                -52.4,\n+                76.76,\n+                90.03,\n+                -114.4,\n+                -52.4,\n+                76.76,\n+                90.03,\n+                -114.4,\n+                -52.4,\n+                76.76,\n+                90.03,\n+                -114.4,\n+                -52.4,\n+                76.76,\n+                90.03,\n+                -114.4,\n+                -52.4,\n+                76.76,\n+                90.03,\n+                -114.4,\n+                -52.4,\n+                76.76,\n+                90.03,\n+                -114.4,\n+                -52.4,\n+            ]\n+        )\n+\n+        trend = np.array(\n+            [\n+                np.nan,\n+                np.nan,\n+                np.nan,\n+                np.nan,\n+                159.12,\n+                204.0,\n+                221.25,\n+                245.12,\n+                319.75,\n+                451.5,\n+                561.12,\n+                619.25,\n+                615.62,\n+                548.0,\n+                462.12,\n+                381.12,\n+                316.62,\n+                264.0,\n+                228.38,\n+                210.75,\n+                188.38,\n+                199.0,\n+                207.12,\n+                191.0,\n+                166.88,\n+                72.0,\n+                -9.25,\n+                -33.12,\n+                -36.75,\n+                36.25,\n+                103.0,\n+                131.62,\n+            ]\n+        )\n+\n+        resid = np.array(\n+            [\n+                np.nan,\n+                np.nan,\n+                np.nan,\n+                np.nan,\n+                11.112,\n+                -57.031,\n+                118.147,\n+                136.272,\n+                332.487,\n+                267.469,\n+                83.272,\n+                -77.853,\n+                -152.388,\n+                -181.031,\n+                -152.728,\n+                -152.728,\n+                -56.388,\n+                -115.031,\n+                14.022,\n+                -56.353,\n+                -33.138,\n+                139.969,\n+                -89.728,\n+                -40.603,\n+                -200.638,\n+                -303.031,\n+                46.647,\n+                72.522,\n+                84.987,\n+                234.719,\n+                -33.603,\n+                104.772,\n+            ]\n+        )\n \n         assert_almost_equal(res_add.seasonal, seasonal, 2)\n         assert_almost_equal(res_add.trend, trend, 2)\n         assert_almost_equal(res_add.resid, resid, 3)\n \n-        res_mult = seasonal_decompose(np.abs(self.data.values), 'm', period=4,\n-                                      two_sided=False)\n-\n-        seasonal = np.array([1.1985, 1.5449, 0.5811, 0.6755, 1.1985, 1.5449,\n-                             0.5811, 0.6755, 1.1985, 1.5449, 0.5811, 0.6755,\n-                             1.1985, 1.5449, 0.5811, 0.6755, 1.1985, 1.5449,\n-                             0.5811, 0.6755, 1.1985, 1.5449, 0.5811, 0.6755,\n-                             1.1985, 1.5449, 0.5811, 0.6755, 1.1985, 1.5449,\n-                             0.5811, 0.6755])\n-\n-        trend = np.array([np.nan, np.nan, np.nan, np.nan, 171.625, 204.,\n-                          221.25, 245.125, 319.75, 451.5, 561.125, 619.25,\n-                          615.625, 548., 462.125, 381.125, 316.625, 264.,\n-                          228.375, 210.75, 188.375, 199., 207.125, 191.,\n-                          166.875, 107.25, 80.5, 79.125, 78.75, 116.5,\n-                          140., 157.375])\n-\n-        resid = np.array([np.nan, np.nan, np.nan, np.nan, 1.2008, 0.752, 1.75,\n-                          1.987, 1.9023, 1.1598, 1.6253, 1.169, 0.7319, 0.5398,\n-                          0.7261, 0.6837, 0.888, 0.586, 0.9645, 0.7165, 1.0276,\n-                          1.3954, 0.0249, 0.7596, 0.215, 0.851, 1.646, 0.2432,\n-                          1.3244, 2.0058, 0.5531, 1.7309])\n+        res_mult = seasonal_decompose(\n+            np.abs(self.data.values), \"m\", period=4, two_sided=False\n+        )\n+\n+        seasonal = np.array(\n+            [\n+                1.1985,\n+                1.5449,\n+                0.5811,\n+                0.6755,\n+                1.1985,\n+                1.5449,\n+                0.5811,\n+                0.6755,\n+                1.1985,\n+                1.5449,\n+                0.5811,\n+                0.6755,\n+                1.1985,\n+                1.5449,\n+                0.5811,\n+                0.6755,\n+                1.1985,\n+                1.5449,\n+                0.5811,\n+                0.6755,\n+                1.1985,\n+                1.5449,\n+                0.5811,\n+                0.6755,\n+                1.1985,\n+                1.5449,\n+                0.5811,\n+                0.6755,\n+                1.1985,\n+                1.5449,\n+                0.5811,\n+                0.6755,\n+            ]\n+        )\n+\n+        trend = np.array(\n+            [\n+                np.nan,\n+                np.nan,\n+                np.nan,\n+                np.nan,\n+                171.625,\n+                204.0,\n+                221.25,\n+                245.125,\n+                319.75,\n+                451.5,\n+                561.125,\n+                619.25,\n+                615.625,\n+                548.0,\n+                462.125,\n+                381.125,\n+                316.625,\n+                264.0,\n+                228.375,\n+                210.75,\n+                188.375,\n+                199.0,\n+                207.125,\n+                191.0,\n+                166.875,\n+                107.25,\n+                80.5,\n+                79.125,\n+                78.75,\n+                116.5,\n+                140.0,\n+                157.375,\n+            ]\n+        )\n+\n+        resid = np.array(\n+            [\n+                np.nan,\n+                np.nan,\n+                np.nan,\n+                np.nan,\n+                1.2008,\n+                0.752,\n+                1.75,\n+                1.987,\n+                1.9023,\n+                1.1598,\n+                1.6253,\n+                1.169,\n+                0.7319,\n+                0.5398,\n+                0.7261,\n+                0.6837,\n+                0.888,\n+                0.586,\n+                0.9645,\n+                0.7165,\n+                1.0276,\n+                1.3954,\n+                0.0249,\n+                0.7596,\n+                0.215,\n+                0.851,\n+                1.646,\n+                0.2432,\n+                1.3244,\n+                2.0058,\n+                0.5531,\n+                1.7309,\n+            ]\n+        )\n \n         assert_almost_equal(res_mult.seasonal, seasonal, 4)\n         assert_almost_equal(res_mult.trend, trend, 2)\n         assert_almost_equal(res_mult.resid, resid, 4)\n \n         # test odd\n-        res_add = seasonal_decompose(self.data.values[:-1], period=4,\n-                                     two_sided=False)\n-        seasonal = np.array([81.21, 94.48, -109.95, -65.74, 81.21, 94.48,\n-                             -109.95, -65.74, 81.21, 94.48, -109.95, -65.74,\n-                             81.21, 94.48, -109.95, -65.74, 81.21, 94.48,\n-                             -109.95, -65.74, 81.21, 94.48, -109.95, -65.74,\n-                             81.21, 94.48, -109.95, -65.74, 81.21, 94.48,\n-                             -109.95])\n-\n-        trend = [np.nan, np.nan, np.nan, np.nan, 159.12, 204., 221.25,\n-                 245.12, 319.75, 451.5, 561.12, 619.25, 615.62, 548.,\n-                 462.12, 381.12, 316.62, 264., 228.38, 210.75, 188.38,\n-                 199., 207.12, 191., 166.88, 72., -9.25, -33.12,\n-                 -36.75, 36.25, 103.]\n-\n-        random = [np.nan, np.nan, np.nan, np.nan, 6.663, -61.48,\n-                  113.699, 149.618, 328.038, 263.02, 78.824, -64.507,\n-                  -156.837, -185.48, -157.176, -139.382, -60.837, -119.48,\n-                  9.574, -43.007, -37.587, 135.52, -94.176, -27.257,\n-                  -205.087, -307.48, 42.199, 85.868, 80.538, 230.27, -38.051]\n+        res_add = seasonal_decompose(self.data.values[:-1], period=4, two_sided=False)\n+        seasonal = np.array(\n+            [\n+                81.21,\n+                94.48,\n+                -109.95,\n+                -65.74,\n+                81.21,\n+                94.48,\n+                -109.95,\n+                -65.74,\n+                81.21,\n+                94.48,\n+                -109.95,\n+                -65.74,\n+                81.21,\n+                94.48,\n+                -109.95,\n+                -65.74,\n+                81.21,\n+                94.48,\n+                -109.95,\n+                -65.74,\n+                81.21,\n+                94.48,\n+                -109.95,\n+                -65.74,\n+                81.21,\n+                94.48,\n+                -109.95,\n+                -65.74,\n+                81.21,\n+                94.48,\n+                -109.95,\n+            ]\n+        )\n+\n+        trend = [\n+            np.nan,\n+            np.nan,\n+            np.nan,\n+            np.nan,\n+            159.12,\n+            204.0,\n+            221.25,\n+            245.12,\n+            319.75,\n+            451.5,\n+            561.12,\n+            619.25,\n+            615.62,\n+            548.0,\n+            462.12,\n+            381.12,\n+            316.62,\n+            264.0,\n+            228.38,\n+            210.75,\n+            188.38,\n+            199.0,\n+            207.12,\n+            191.0,\n+            166.88,\n+            72.0,\n+            -9.25,\n+            -33.12,\n+            -36.75,\n+            36.25,\n+            103.0,\n+        ]\n+\n+        random = [\n+            np.nan,\n+            np.nan,\n+            np.nan,\n+            np.nan,\n+            6.663,\n+            -61.48,\n+            113.699,\n+            149.618,\n+            328.038,\n+            263.02,\n+            78.824,\n+            -64.507,\n+            -156.837,\n+            -185.48,\n+            -157.176,\n+            -139.382,\n+            -60.837,\n+            -119.48,\n+            9.574,\n+            -43.007,\n+            -37.587,\n+            135.52,\n+            -94.176,\n+            -27.257,\n+            -205.087,\n+            -307.48,\n+            42.199,\n+            85.868,\n+            80.538,\n+            230.27,\n+            -38.051,\n+        ]\n \n         assert_almost_equal(res_add.seasonal, seasonal, 2)\n         assert_almost_equal(res_add.trend, trend, 2)\n@@ -245,12 +802,10 @@ def test_interpolate_trend(self):\n         trend = seasonal_decompose(x, period=freq, extrapolate_trend=5).trend\n         assert_almost_equal(trend, x)\n \n-        trend = seasonal_decompose(x, period=freq,\n-                                   extrapolate_trend='freq').trend\n+        trend = seasonal_decompose(x, period=freq, extrapolate_trend=\"freq\").trend\n         assert_almost_equal(trend, x)\n \n-        trend = seasonal_decompose(x[:, None], period=freq,\n-                                   extrapolate_trend=5).trend\n+        trend = seasonal_decompose(x[:, None], period=freq, extrapolate_trend=5).trend\n         assert_almost_equal(trend, x)\n \n         # 2d case\n@@ -258,31 +813,29 @@ def test_interpolate_trend(self):\n         trend = seasonal_decompose(x, period=freq, extrapolate_trend=1).trend\n         assert_almost_equal(trend, x)\n \n-        trend = seasonal_decompose(x, period=freq,\n-                                   extrapolate_trend='freq').trend\n+        trend = seasonal_decompose(x, period=freq, extrapolate_trend=\"freq\").trend\n         assert_almost_equal(trend, x)\n \n     def test_raises(self):\n         assert_raises(ValueError, seasonal_decompose, self.data.values)\n-        assert_raises(ValueError, seasonal_decompose, self.data, 'm',\n-                      period=4)\n+        assert_raises(ValueError, seasonal_decompose, self.data, \"m\", period=4)\n         x = self.data.astype(float).copy()\n         x.iloc[2] = np.nan\n         assert_raises(ValueError, seasonal_decompose, x)\n \n \n def test_seasonal_decompose_too_short(reset_randomstate):\n-    dates = pd.date_range('2000-01-31', periods=4, freq=QUARTER_END)\n+    dates = pd.date_range(\"2000-01-31\", periods=4, freq=QUARTER_END)\n     y = np.sin(np.arange(4) / 4 * 2 * np.pi)\n     y += np.random.standard_normal(y.size)\n-    y = pd.Series(y, name='y', index=dates)\n+    y = pd.Series(y, name=\"y\", index=dates)\n     with pytest.raises(ValueError):\n         seasonal_decompose(y)\n \n-    dates = pd.date_range('2000-01-31', periods=12, freq=MONTH_END)\n+    dates = pd.date_range(\"2000-01-31\", periods=12, freq=MONTH_END)\n     y = np.sin(np.arange(12) / 12 * 2 * np.pi)\n     y += np.random.standard_normal(y.size)\n-    y = pd.Series(y, name='y', index=dates)\n+    y = pd.Series(y, name=\"y\", index=dates)\n     with pytest.raises(ValueError):\n         seasonal_decompose(y)\n     with pytest.raises(ValueError):\n@@ -291,22 +844,88 @@ def test_seasonal_decompose_too_short(reset_randomstate):\n \n @pytest.mark.smoke\n def test_seasonal_decompose_smoke():\n-    x = np.array([-50, 175, 149, 214, 247, 237, 225, 329, 729, 809,\n-                  530, 489, 540, 457, 195, 176, 337, 239, 128, 102,\n-                  232, 429, 3, 98, 43, -141, -77, -13, 125, 361, -45, 184])\n+    x = np.array(\n+        [\n+            -50,\n+            175,\n+            149,\n+            214,\n+            247,\n+            237,\n+            225,\n+            329,\n+            729,\n+            809,\n+            530,\n+            489,\n+            540,\n+            457,\n+            195,\n+            176,\n+            337,\n+            239,\n+            128,\n+            102,\n+            232,\n+            429,\n+            3,\n+            98,\n+            43,\n+            -141,\n+            -77,\n+            -13,\n+            125,\n+            361,\n+            -45,\n+            184,\n+        ]\n+    )\n     seasonal_decompose(x, period=4)\n \n-    data = pd.DataFrame(x, pd.date_range(start='1/1/1951',\n-                                         periods=len(x),\n-                                         freq=QUARTER_END))\n+    data = pd.DataFrame(\n+        x, pd.date_range(start=\"1/1/1951\", periods=len(x), freq=QUARTER_END)\n+    )\n \n     seasonal_decompose(data)\n \n \n def test_seasonal_decompose_multiple():\n-    x = np.array([-50, 175, 149, 214, 247, 237, 225, 329, 729, 809,\n-                  530, 489, 540, 457, 195, 176, 337, 239, 128, 102,\n-                  232, 429, 3, 98, 43, -141, -77, -13, 125, 361, -45, 184])\n+    x = np.array(\n+        [\n+            -50,\n+            175,\n+            149,\n+            214,\n+            247,\n+            237,\n+            225,\n+            329,\n+            729,\n+            809,\n+            530,\n+            489,\n+            540,\n+            457,\n+            195,\n+            176,\n+            337,\n+            239,\n+            128,\n+            102,\n+            232,\n+            429,\n+            3,\n+            98,\n+            43,\n+            -141,\n+            -77,\n+            -13,\n+            125,\n+            361,\n+            -45,\n+            184,\n+        ]\n+    )\n     x = np.c_[x, x]\n     res = seasonal_decompose(x, period=4)\n     assert_allclose(res.trend[:, 0], res.trend[:, 1])\n@@ -322,17 +941,47 @@ def test_seasonal_decompose_multiple():\n def test_seasonal_decompose_plot(\n     model, freq, two_sided, extrapolate_trend, close_figures\n ):\n-    x = np.array([-50, 175, 149, 214, 247, 237, 225, 329, 729, 809,\n-                  530, 489, 540, 457, 195, 176, 337, 239, 128, 102,\n-                  232, 429, 3, 98, 43, -141, -77, -13, 125, 361, -45, 184])\n+    x = np.array(\n+        [\n+            -50,\n+            175,\n+            149,\n+            214,\n+            247,\n+            237,\n+            225,\n+            329,\n+            729,\n+            809,\n+            530,\n+            489,\n+            540,\n+            457,\n+            195,\n+            176,\n+            337,\n+            239,\n+            128,\n+            102,\n+            232,\n+            429,\n+            3,\n+            98,\n+            43,\n+            -141,\n+            -77,\n+            -13,\n+            125,\n+            361,\n+            -45,\n+            184,\n+        ]\n+    )\n     x -= x.min() + 1\n     x2 = np.r_[x[12:], x[:12]]\n     x = np.c_[x, x2]\n     res = seasonal_decompose(\n-        x,\n-        period=freq,\n-        two_sided=two_sided,\n-        extrapolate_trend=extrapolate_trend\n+        x, period=freq, two_sided=two_sided, extrapolate_trend=extrapolate_trend\n     )\n     fig = res.plot()\n \n", "problem_statement": "Seasonal decomposition fails on PeriodIndex\n#### Describe the bug\r\n\r\n`statsmodels.tsa.seasonal.seasonal_decompose` fails on a series with a fixed-frequency PeriodIndex.\r\n\r\nConfirmed on `main`.\r\n\r\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\n>>> import pandas as pd\r\n>>> from statsmodels.tsa.seasonal import seasonal_decompose\r\n>>> series = pd.Series(range(10), index=pd.period_range(start=\"2024-01-01\", periods=10))\r\n>>> print(type(series.index))\r\n<class 'pandas.core.indexes.period.PeriodIndex'>\r\n>>> print(series.index.freq)\r\n<Day>\r\n>>> seasonal_decompose(series)\r\nValueError: You must specify a period or x must be a pandas object with a PeriodIndex or a DatetimeIndex with a freq not set to None\r\n```\r\n\r\n#### Expected Output\r\n\r\nBased on the error message, the function should accept this kind of series.\r\n\r\n#### Output of ``import statsmodels.api as sm; sm.show_versions()``\r\n\r\n<details>\r\n\r\n```\r\nINSTALLED VERSIONS\r\n------------------\r\nPython: 3.12.2.final.0\r\nOS: Linux 5.15.167.4-microsoft-standard-WSL2 #1 SMP Tue Nov 5 00:21:55 UTC 2024 x86_64\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\n\r\nstatsmodels\r\n===========\r\n\r\nInstalled: 0.15.0.dev575+gddeaa63e9 (/home/alex/statsmodels_test/.venv/lib/python3.12/site-packages/statsmodels)\r\n\r\nRequired Dependencies\r\n=====================\r\n\r\ncython: Not installed\r\nnumpy: 2.2.0 (/home/alex/statsmodels_test/.venv/lib/python3.12/site-packages/numpy)\r\nscipy: 1.14.1 (/home/alex/statsmodels_test/.venv/lib/python3.12/site-packages/scipy)\r\npandas: 2.2.3 (/home/alex/statsmodels_test/.venv/lib/python3.12/site-packages/pandas)\r\n    dateutil: 2.9.0.post0 (/home/alex/statsmodels_test/.venv/lib/python3.12/site-packages/dateutil)\r\npatsy: 1.0.1 (/home/alex/statsmodels_test/.venv/lib/python3.12/site-packages/patsy)\r\n\r\nOptional Dependencies\r\n=====================\r\n\r\nmatplotlib: Not installed\r\ncvxopt: Not installed\r\njoblib: Not installed\r\n\r\nDeveloper Tools\r\n================\r\n\r\nIPython: Not installed\r\n    jinja2: Not installed\r\nsphinx: Not installed\r\n    pygments: Not installed\r\npytest: Not installed\r\nvirtualenv: Not installed\r\n```\r\n</details>\n", "hints_text": "", "created_at": "2024-12-17T18:43:18Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9457, "instance_id": "statsmodels__statsmodels-9457", "issue_numbers": ["9455"], "base_commit": "61201b7b55618133c104414fec2e322f72799d4e", "patch": "diff --git a/statsmodels/tsa/x13.py b/statsmodels/tsa/x13.py\nindex 2b0651e6561..009a4fd5256 100644\n--- a/statsmodels/tsa/x13.py\n+++ b/statsmodels/tsa/x13.py\n@@ -7,42 +7,45 @@\n Many of the functions are called x12. However, they are also intended to work\n for x13. If this is not the case, it's a bug.\n \"\"\"\n+\n from statsmodels.compat.pandas import deprecate_kwarg\n \n import os\n+import re\n import subprocess\n import tempfile\n-import re\n from warnings import warn\n \n import pandas as pd\n \n+from statsmodels.tools.sm_exceptions import (\n+    IOWarning,\n+    X13Error,\n+    X13NotFoundError,\n+    X13Warning,\n+)\n from statsmodels.tools.tools import Bunch\n-from statsmodels.tools.sm_exceptions import (X13NotFoundError,\n-                                             IOWarning, X13Error,\n-                                             X13Warning)\n \n __all__ = [\"x13_arima_select_order\", \"x13_arima_analysis\"]\n \n-_binary_names = ('x13as.exe', 'x13as', 'x12a.exe', 'x12a',\n-                 'x13as_ascii', 'x13as_html')\n+_binary_names = (\"x13as.exe\", \"x13as\", \"x12a.exe\", \"x12a\", \"x13as_ascii\", \"x13as_html\")\n \n \n class _freq_to_period:\n     def __getitem__(self, key):\n-        if key.startswith('M'):\n+        if key.startswith(\"M\"):\n             return 12\n-        elif key.startswith('Q'):\n+        elif key.startswith(\"Q\"):\n             return 4\n-        elif key.startswith('W'):\n+        elif key.startswith(\"W\"):\n             return 52\n \n \n _freq_to_period = _freq_to_period()\n \n-_period_to_freq = {12: 'M', 4: 'Q'}\n-_log_to_x12 = {True: 'log', False: 'none', None: 'auto'}\n-_bool_to_yes_no = lambda x: 'yes' if x else 'no'  # noqa:E731\n+_period_to_freq = {12: \"M\", 4: \"Q\"}\n+_log_to_x12 = {True: \"log\", False: \"none\", None: \"auto\"}\n+_bool_to_yes_no = lambda x: \"yes\" if x else \"no\"  # noqa:E731\n \n \n def _find_x12(x12path=None, prefer_x13=True):\n@@ -72,8 +75,7 @@ def _find_x12(x12path=None, prefer_x13=True):\n     for binary in _binary_names:\n         x12 = os.path.join(x12path, binary)\n         try:\n-            subprocess.check_call(x12, stdout=subprocess.PIPE,\n-                                  stderr=subprocess.PIPE)\n+            subprocess.check_call(x12, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n             return x12\n         except OSError:\n             pass\n@@ -85,9 +87,11 @@ def _find_x12(x12path=None, prefer_x13=True):\n def _check_x12(x12path=None):\n     x12path = _find_x12(x12path)\n     if not x12path:\n-        raise X13NotFoundError(\"x12a and x13as not found on path. Give the \"\n-                               \"path, put them on PATH, or set the \"\n-                               \"X12PATH or X13PATH environmental variable.\")\n+        raise X13NotFoundError(\n+            \"x12a and x13as not found on path. Give the \"\n+            \"path, put them on PATH, or set the \"\n+            \"X12PATH or X13PATH environmental variable.\"\n+        )\n     return x12path\n \n \n@@ -111,7 +115,6 @@ def clean(x):\n \n \n def run_spec(x12path, specpath, outname=None, meta=False, datameta=False):\n-\n     if meta and datameta:\n         raise ValueError(\"Cannot specify both meta and datameta.\")\n     if meta:\n@@ -124,8 +127,7 @@ def run_spec(x12path, specpath, outname=None, meta=False, datameta=False):\n     if outname:\n         args += [outname]\n \n-    return subprocess.Popen(args, stdout=subprocess.PIPE,\n-                            stderr=subprocess.STDOUT)\n+    return subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n \n \n def _make_automdl_options(maxorder, maxdiff, diff):\n@@ -149,6 +151,7 @@ def _make_var_names(exog):\n         var_names = \" \".join(var_names)\n     except TypeError:  # cannot have names that are numbers, pandas default\n         from statsmodels.base.data import _make_exog_names\n+\n         if exog.ndim == 1:\n             var_names = \"x1\"\n         else:\n@@ -166,8 +169,8 @@ def _make_regression_options(trading, exog):\n     if exog is not None:\n         var_names = _make_var_names(exog)\n         reg_spec += f\"    user = ({var_names})\\n\"\n-        reg_spec += \"    data = ({})\\n\".format(\"\\n\".join(\n-            map(str, exog.values.ravel().tolist()))\n+        reg_spec += \"    data = ({})\\n\".format(\n+            \"\\n\".join(map(str, exog.values.ravel().tolist()))\n         )\n \n     reg_spec += \"}\\n\"  # close out regression spec\n@@ -183,10 +186,10 @@ def _make_forecast_options(forecast_periods):\n \n \n def _check_errors(errors):\n-    errors = errors[errors.find(\"spc:\")+4:].strip()\n-    if errors and 'ERROR' in errors:\n+    errors = errors[errors.find(\"spc:\") + 4 :].strip()\n+    if errors and \"ERROR\" in errors:\n         raise X13Error(errors)\n-    elif errors and 'WARNING' in errors:\n+    elif errors and \"WARNING\" in errors:\n         warn(errors, X13Warning)\n \n \n@@ -196,9 +199,10 @@ def _convert_out_to_series(x, dates, name):\n     x-13arima-seats output.\n     \"\"\"\n     from io import StringIO\n+\n     from pandas import read_csv\n-    out = read_csv(StringIO(x), skiprows=2,\n-                   header=None, sep='\\t', engine='python')\n+\n+    out = read_csv(StringIO(x), skiprows=2, header=None, sep=\"\\t\", engine=\"python\")\n     return out.set_index(dates).rename(columns={1: name})[name]\n \n \n@@ -219,8 +223,7 @@ def create_spec(self, **kwargs):\n         {options}\n         }}\n         \"\"\"\n-        return spec.format(name=self.spec_name,\n-                           options=self.options)\n+        return spec.format(name=self.spec_name, options=self.options)\n \n     def set_options(self, **kwargs):\n         options = \"\"\n@@ -261,32 +264,56 @@ class SeriesSpec(Spec):\n     saveprecision\n     trimzero\n     \"\"\"\n-    def __init__(self, data, name='Unnamed Series', appendbcst=False,\n-                 appendfcst=False,\n-                 comptype=None, compwt=1, decimals=0, modelspan=(),\n-                 period=12, precision=0, to_print=[], to_save=[], span=(),\n-                 start=(1, 1), title='', series_type=None, divpower=None,\n-                 missingcode=-99999, missingval=1000000000):\n \n-        appendbcst, appendfcst = map(_bool_to_yes_no, [appendbcst,\n-                                                       appendfcst,\n-                                                       ])\n+    def __init__(\n+        self,\n+        data,\n+        name=\"Unnamed Series\",\n+        appendbcst=False,\n+        appendfcst=False,\n+        comptype=None,\n+        compwt=1,\n+        decimals=0,\n+        modelspan=(),\n+        period=12,\n+        precision=0,\n+        to_print=[],\n+        to_save=[],\n+        span=(),\n+        start=(1, 1),\n+        title=\"\",\n+        series_type=None,\n+        divpower=None,\n+        missingcode=-99999,\n+        missingval=1000000000,\n+    ):\n+        appendbcst, appendfcst = map(\n+            _bool_to_yes_no,\n+            [\n+                appendbcst,\n+                appendfcst,\n+            ],\n+        )\n \n-        series_name = f\"\\\"{name[:64]}\\\"\"  # trim to 64 characters\n-        title = f\"\\\"{title[:79]}\\\"\"  # trim to 79 characters\n-        self.set_options(data=data, appendbcst=appendbcst,\n-                         appendfcst=appendfcst, period=period, start=start,\n-                         title=title, name=series_name,\n-                         )\n+        series_name = f'\"{name[:64]}\"'  # trim to 64 characters\n+        title = f'\"{title[:79]}\"'  # trim to 79 characters\n+        self.set_options(\n+            data=data,\n+            appendbcst=appendbcst,\n+            appendfcst=appendfcst,\n+            period=period,\n+            start=start,\n+            title=title,\n+            name=series_name,\n+        )\n \n \n def pandas_to_series_spec(x):\n     # from statsmodels.tools.data import _check_period_index\n     # check_period_index(x)\n-    if hasattr(x, 'columns'):  # convert to series\n+    if hasattr(x, \"columns\"):  # convert to series\n         if len(x.columns) > 1:\n-            raise ValueError(\"Does not handle DataFrame with more than one \"\n-                             \"column\")\n+            raise ValueError(\"Does not handle DataFrame with more than one \" \"column\")\n         x = x[x.columns[0]]\n \n     data = \"({})\".format(\"\\n\".join(map(str, x.values.tolist())))\n@@ -298,6 +325,7 @@ def pandas_to_series_spec(x):\n         period = _freq_to_period[x.index.freqstr]\n     except (AttributeError, ValueError):\n         from pandas.tseries.api import infer_freq\n+\n         period = _freq_to_period[infer_freq(x.index)]\n     start_date = x.index[0]\n     if period == 12:\n@@ -305,31 +333,42 @@ def pandas_to_series_spec(x):\n     elif period == 4:\n         year, stperiod = start_date.year, start_date.quarter\n     else:  # pragma: no cover\n-        raise ValueError(\"Only monthly and quarterly periods are supported.\"\n-                         \" Please report or send a pull request if you want \"\n-                         \"this extended.\")\n+        raise ValueError(\n+            \"Only monthly and quarterly periods are supported.\"\n+            \" Please report or send a pull request if you want \"\n+            \"this extended.\"\n+        )\n \n-    if hasattr(x, 'name'):\n+    if hasattr(x, \"name\"):\n         name = x.name or \"Unnamed Series\"\n     else:\n-        name = 'Unnamed Series'\n+        name = \"Unnamed Series\"\n     series_spec = SeriesSpec(\n-        data=data,\n-        name=name,\n-        period=period,\n-        title=name,\n-        start=f\"{year}.{stperiod}\"\n+        data=data, name=name, period=period, title=name, start=f\"{year}.{stperiod}\"\n     )\n     return series_spec\n \n \n-@deprecate_kwarg('forecast_years', 'forecast_periods')\n-def x13_arima_analysis(endog, maxorder=(2, 1), maxdiff=(2, 1), diff=None,\n-                       exog=None, log=None, outlier=True, trading=False,\n-                       forecast_periods=None, retspec=False,\n-                       speconly=False, start=None, freq=None,\n-                       print_stdout=False, x12path=None, prefer_x13=True,\n-                       tempdir=None):\n+@deprecate_kwarg(\"forecast_years\", \"forecast_periods\")\n+def x13_arima_analysis(\n+    endog,\n+    maxorder=(2, 1),\n+    maxdiff=(2, 1),\n+    diff=None,\n+    exog=None,\n+    log=None,\n+    outlier=True,\n+    trading=False,\n+    forecast_periods=None,\n+    retspec=False,\n+    speconly=False,\n+    start=None,\n+    freq=None,\n+    print_stdout=False,\n+    x12path=None,\n+    prefer_x13=True,\n+    tempdir=None,\n+):\n     \"\"\"\n     Perform x13-arima analysis for monthly or quarterly data.\n \n@@ -425,11 +464,12 @@ def x13_arima_analysis(endog, maxorder=(2, 1), maxdiff=(2, 1), diff=None,\n \n     if not isinstance(endog, (pd.DataFrame, pd.Series)):\n         if start is None or freq is None:\n-            raise ValueError(\"start and freq cannot be none if endog is not \"\n-                             \"a pandas object\")\n-        endog = pd.Series(endog, index=pd.DatetimeIndex(start=start,\n-                                                        periods=len(endog),\n-                                                        freq=freq))\n+            raise ValueError(\n+                \"start and freq cannot be none if endog is not \" \"a pandas object\"\n+            )\n+        idx = pd.date_range(start=start, periods=len(endog), freq=freq)\n+        endog = pd.Series(endog, index=idx)\n+\n     spec_obj = pandas_to_series_spec(endog)\n     spec = spec_obj.create_spec()\n     spec += f\"transform{{function={_log_to_x12[log]}}}\\n\"\n@@ -444,12 +484,10 @@ def x13_arima_analysis(endog, maxorder=(2, 1), maxdiff=(2, 1), diff=None,\n         return spec\n     # write it to a tempfile\n     # TODO: make this more robust - give the user some control?\n-    ftempin = tempfile.NamedTemporaryFile(delete=False,\n-                                          suffix='.spc',\n-                                          dir=tempdir)\n+    ftempin = tempfile.NamedTemporaryFile(delete=False, suffix=\".spc\", dir=tempdir)\n     ftempout = tempfile.NamedTemporaryFile(delete=False, dir=tempdir)\n     try:\n-        ftempin.write(spec.encode('utf8'))\n+        ftempin.write(spec.encode(\"utf8\"))\n         ftempin.close()\n         ftempout.close()\n         # call x12 arima\n@@ -459,14 +497,14 @@ def x13_arima_analysis(endog, maxorder=(2, 1), maxdiff=(2, 1), diff=None,\n         if print_stdout:\n             print(p.stdout.read())\n         # check for errors\n-        errors = _open_and_read(ftempout.name + '.err')\n+        errors = _open_and_read(ftempout.name + \".err\")\n         _check_errors(errors)\n \n         # read in results\n-        results = _open_and_read(ftempout.name + '.out')\n-        seasadj = _open_and_read(ftempout.name + '.d11')\n-        trend = _open_and_read(ftempout.name + '.d12')\n-        irregular = _open_and_read(ftempout.name + '.d13')\n+        results = _open_and_read(ftempout.name + \".out\")\n+        seasadj = _open_and_read(ftempout.name + \".d11\")\n+        trend = _open_and_read(ftempout.name + \".d12\")\n+        irregular = _open_and_read(ftempout.name + \".d13\")\n     finally:\n         try:  # sometimes this gives a permission denied error?\n             #   not sure why. no process should have these open\n@@ -474,36 +512,56 @@ def x13_arima_analysis(endog, maxorder=(2, 1), maxdiff=(2, 1), diff=None,\n             os.remove(ftempout.name)\n         except OSError:\n             if os.path.exists(ftempin.name):\n-                warn(f\"Failed to delete resource {ftempin.name}\",\n-                     IOWarning)\n+                warn(f\"Failed to delete resource {ftempin.name}\", IOWarning)\n             if os.path.exists(ftempout.name):\n-                warn(f\"Failed to delete resource {ftempout.name}\",\n-                     IOWarning)\n+                warn(f\"Failed to delete resource {ftempout.name}\", IOWarning)\n \n-    seasadj = _convert_out_to_series(seasadj, endog.index, 'seasadj')\n-    trend = _convert_out_to_series(trend, endog.index, 'trend')\n-    irregular = _convert_out_to_series(irregular, endog.index, 'irregular')\n+    seasadj = _convert_out_to_series(seasadj, endog.index, \"seasadj\")\n+    trend = _convert_out_to_series(trend, endog.index, \"trend\")\n+    irregular = _convert_out_to_series(irregular, endog.index, \"irregular\")\n \n     # NOTE: there is not likely anything in stdout that's not in results\n     #       so may be safe to just suppress and remove it\n     if not retspec:\n-        res = X13ArimaAnalysisResult(observed=endog, results=results,\n-                                     seasadj=seasadj, trend=trend,\n-                                     irregular=irregular, stdout=stdout)\n+        res = X13ArimaAnalysisResult(\n+            observed=endog,\n+            results=results,\n+            seasadj=seasadj,\n+            trend=trend,\n+            irregular=irregular,\n+            stdout=stdout,\n+        )\n     else:\n-        res = X13ArimaAnalysisResult(observed=endog, results=results,\n-                                     seasadj=seasadj, trend=trend,\n-                                     irregular=irregular, stdout=stdout,\n-                                     spec=spec)\n+        res = X13ArimaAnalysisResult(\n+            observed=endog,\n+            results=results,\n+            seasadj=seasadj,\n+            trend=trend,\n+            irregular=irregular,\n+            stdout=stdout,\n+            spec=spec,\n+        )\n     return res\n \n \n-@deprecate_kwarg('forecast_years', 'forecast_periods')\n-def x13_arima_select_order(endog, maxorder=(2, 1), maxdiff=(2, 1), diff=None,\n-                           exog=None, log=None, outlier=True, trading=False,\n-                           forecast_periods=None,\n-                           start=None, freq=None, print_stdout=False,\n-                           x12path=None, prefer_x13=True, tempdir=None):\n+@deprecate_kwarg(\"forecast_years\", \"forecast_periods\")\n+def x13_arima_select_order(\n+    endog,\n+    maxorder=(2, 1),\n+    maxdiff=(2, 1),\n+    diff=None,\n+    exog=None,\n+    log=None,\n+    outlier=True,\n+    trading=False,\n+    forecast_periods=None,\n+    start=None,\n+    freq=None,\n+    print_stdout=False,\n+    x12path=None,\n+    prefer_x13=True,\n+    tempdir=None,\n+):\n     \"\"\"\n     Perform automatic seasonal ARIMA order identification using x12/x13 ARIMA.\n \n@@ -585,14 +643,24 @@ def x13_arima_select_order(endog, maxorder=(2, 1), maxdiff=(2, 1), diff=None,\n     directory, invoking X12/X13 in a subprocess, and reading the output back\n     in.\n     \"\"\"\n-    results = x13_arima_analysis(endog, x12path=x12path, exog=exog, log=log,\n-                                 outlier=outlier, trading=trading,\n-                                 forecast_periods=forecast_periods,\n-                                 maxorder=maxorder, maxdiff=maxdiff, diff=diff,\n-                                 start=start, freq=freq, prefer_x13=prefer_x13,\n-                                 tempdir=tempdir)\n-    model = re.search(\"(?<=Final automatic model choice : ).*\",\n-                      results.results)\n+    results = x13_arima_analysis(\n+        endog,\n+        x12path=x12path,\n+        exog=exog,\n+        log=log,\n+        outlier=outlier,\n+        trading=trading,\n+        forecast_periods=forecast_periods,\n+        maxorder=maxorder,\n+        maxdiff=maxdiff,\n+        diff=diff,\n+        start=start,\n+        freq=freq,\n+        prefer_x13=prefer_x13,\n+        tempdir=tempdir,\n+        print_stdout=print_stdout,\n+    )\n+    model = re.search(\"(?<=Final automatic model choice : ).*\", results.results)\n     order = model.group()\n     if re.search(\"Mean is not significant\", results.results):\n         include_mean = False\n@@ -601,8 +669,13 @@ def x13_arima_select_order(endog, maxorder=(2, 1), maxdiff=(2, 1), diff=None,\n     else:\n         include_mean = False\n     order, sorder = _clean_order(order)\n-    res = Bunch(order=order, sorder=sorder, include_mean=include_mean,\n-                results=results.results, stdout=results.stdout)\n+    res = Bunch(\n+        order=order,\n+        sorder=sorder,\n+        include_mean=include_mean,\n+        results=results.results,\n+        stdout=results.stdout,\n+    )\n     return res\n \n \n@@ -613,16 +686,17 @@ def __init__(self, **kwargs):\n \n     def plot(self):\n         from statsmodels.graphics.utils import _import_mpl\n+\n         plt = _import_mpl()\n         fig, axes = plt.subplots(4, 1, sharex=True)\n         self.observed.plot(ax=axes[0], legend=False)\n-        axes[0].set_ylabel('Observed')\n+        axes[0].set_ylabel(\"Observed\")\n         self.seasadj.plot(ax=axes[1], legend=False)\n-        axes[1].set_ylabel('Seas. Adjusted')\n+        axes[1].set_ylabel(\"Seas. Adjusted\")\n         self.trend.plot(ax=axes[2], legend=False)\n-        axes[2].set_ylabel('Trend')\n+        axes[2].set_ylabel(\"Trend\")\n         self.irregular.plot(ax=axes[3], legend=False)\n-        axes[3].set_ylabel('Irregular')\n+        axes[3].set_ylabel(\"Irregular\")\n \n         fig.tight_layout()\n         return fig\n", "test_patch": "diff --git a/statsmodels/tsa/tests/test_x13.py b/statsmodels/tsa/tests/test_x13.py\nindex 357b7881c88..9b280c3c2b6 100644\n--- a/statsmodels/tsa/tests/test_x13.py\n+++ b/statsmodels/tsa/tests/test_x13.py\n@@ -1,5 +1,6 @@\n from statsmodels.compat.pandas import MONTH_END\n \n+import numpy as np\n import pandas as pd\n import pytest\n \n@@ -12,30 +13,38 @@\n \n x13path = _find_x12()\n \n-pytestmark = pytest.mark.skipif(x13path is False,\n-                                reason='X13/X12 not available')\n-\n dta = macrodata.load_pandas().data\n-index = pd.period_range(start='1959Q1', end='2009Q3', freq='Q')\n+index = pd.period_range(start=\"1959Q1\", end=\"2009Q3\", freq=\"Q\")\n dta.index = index\n quarterly_data = dta.dropna()\n \n dta = co2.load_pandas().data\n-dta['co2'] = dta.co2.interpolate()\n+dta[\"co2\"] = dta.co2.interpolate()\n monthly_data = dta.resample(MONTH_END)\n # change in pandas 0.18 resample is deferred object\n if not isinstance(monthly_data, (pd.DataFrame, pd.Series)):\n     monthly_data = monthly_data.mean()\n \n-monthly_start_data = dta.resample('MS')\n+monthly_start_data = dta.resample(\"MS\")\n if not isinstance(monthly_start_data, (pd.DataFrame, pd.Series)):\n     monthly_start_data = monthly_start_data.mean()\n \n-data = (monthly_data, monthly_start_data, monthly_data.co2,\n-        monthly_start_data.co2, quarterly_data.realgdp,\n-        quarterly_data[['realgdp']])\n-ids = ('monthly', 'monthly_start', 'monthly_co2', 'monthly_start_co2',\n-       'series', 'dataframe')\n+data = (\n+    monthly_data,\n+    monthly_start_data,\n+    monthly_data.co2,\n+    monthly_start_data.co2,\n+    quarterly_data.realgdp,\n+    quarterly_data[[\"realgdp\"]],\n+)\n+ids = (\n+    \"monthly\",\n+    \"monthly_start\",\n+    \"monthly_co2\",\n+    \"monthly_start_co2\",\n+    \"series\",\n+    \"dataframe\",\n+)\n \n \n @pytest.fixture(params=data, ids=ids)\n@@ -43,8 +52,23 @@ def dataset(request):\n     return request.param\n \n \n-def test_x13_arima_select_order(dataset):\n-    res = x13_arima_select_order(dataset)\n+@pytest.mark.parametrize(\"use_numpy\", [True, False])\n+def test_x13_arima_select_order(dataset, use_numpy):\n+    if use_numpy:\n+        index = dataset.index\n+        dataset = np.squeeze(np.asarray(dataset))\n+        start = index[0]\n+        if isinstance(index, pd.DatetimeIndex):\n+            freq = index.inferred_freq\n+        elif isinstance(index, pd.PeriodIndex):\n+            start = start.to_timestamp()\n+            freq = index.freq\n+        else:\n+            raise NotImplementedError()\n+        assert freq is not None\n+    else:\n+        freq = start = None\n+    res = x13_arima_select_order(dataset, start=start, freq=freq)\n     assert isinstance(res.order, tuple)\n     assert isinstance(res.sorder, tuple)\n \n@@ -53,3 +77,8 @@ def test_x13_arima_select_order(dataset):\n def test_x13_arima_plot(dataset):\n     res = x13_arima_analysis(dataset)\n     res.plot()\n+\n+\n+def test_x13_arima_plot_no_pandas(dataset):\n+    res = x13_arima_analysis(dataset)\n+    res.plot()\n", "problem_statement": "X13 makes invalid call to pd.DatetimeIndex\nhttps://github.com/statsmodels/statsmodels/blob/main/statsmodels/tsa/x13.py:430 calls `pd.DatetimeIndex` with the `start` argument, which has been deprecated. My understanding is that users are now supposed to use `pd.date_range` to accomplish something similar. \n", "hints_text": "", "created_at": "2024-12-16T09:46:56Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9413, "instance_id": "statsmodels__statsmodels-9413", "issue_numbers": ["9412"], "base_commit": "0838f111df35d73fdd921ed3007099b56928ce4f", "patch": "diff --git a/statsmodels/tsa/vector_ar/var_model.py b/statsmodels/tsa/vector_ar/var_model.py\nindex 9adb66784e2..648a47bbf72 100644\n--- a/statsmodels/tsa/vector_ar/var_model.py\n+++ b/statsmodels/tsa/vector_ar/var_model.py\n@@ -5,6 +5,7 @@\n ----------\n L\u00fctkepohl (2005) New Introduction to Multiple Time Series Analysis\n \"\"\"\n+\n from __future__ import annotations\n \n from statsmodels.compat.python import lrange\n@@ -226,12 +227,13 @@ def forecast(y, coefs, trend_coefs, steps, exog=None):\n     -----\n     L\u00fctkepohl p. 37\n     \"\"\"\n-    p = len(coefs)\n-    k = len(coefs[0])\n+    coefs = np.asarray(coefs)\n+    if coefs.ndim != 3:\n+        raise ValueError(\"coefs must be an array with 3 dimensions\")\n+    p, k = coefs.shape[:2]\n     if y.shape[0] < p:\n         raise ValueError(\n-            f\"y must by have at least order ({p}) observations. \"\n-            f\"Got {y.shape[0]}.\"\n+            f\"y must by have at least order ({p}) observations. \" f\"Got {y.shape[0]}.\"\n         )\n     # initial value\n     forcs = np.zeros((steps, k))\n@@ -286,9 +288,7 @@ def _forecast_vars(steps, ma_coefs, sig_u):\n     return covs[:, inds, inds]\n \n \n-def forecast_interval(\n-    y, coefs, trend_coefs, sig_u, steps=5, alpha=0.05, exog=1\n-):\n+def forecast_interval(y, coefs, trend_coefs, sig_u, steps=5, alpha=0.05, exog=1):\n     assert 0 < alpha < 1\n     q = util.norm_signif_level(alpha)\n \n@@ -362,9 +362,7 @@ def _reordered(self, order):\n             params_new_inc[0, i] = params[0, i]\n             endog_lagged_new[:, 0] = endog_lagged[:, 0]\n         for j in range(k_ar):\n-            params_new_inc[i + j * num_end + k, :] = self.params[\n-                c + j * num_end + k, :\n-            ]\n+            params_new_inc[i + j * num_end + k, :] = self.params[c + j * num_end + k, :]\n             endog_lagged_new[:, i + j * num_end + k] = endog_lagged[\n                 :, c + j * num_end + k\n             ]\n@@ -444,8 +442,8 @@ def test_normality(results, signif=0.05):\n     Pinv = np.linalg.inv(np.linalg.cholesky(sig))\n \n     w = np.dot(Pinv, resid_c.T)\n-    b1 = (w ** 3).sum(1)[:, None] / results.nobs\n-    b2 = (w ** 4).sum(1)[:, None] / results.nobs - 3\n+    b1 = (w**3).sum(1)[:, None] / results.nobs\n+    b2 = (w**4).sum(1)[:, None] / results.nobs - 3\n \n     lam_skew = results.nobs * np.dot(b1.T, b1) / 6\n     lam_kurt = results.nobs * np.dot(b2.T, b2) / 24\n@@ -544,9 +542,7 @@ class VAR(TimeSeriesModel):\n \n     y = deprecated_alias(\"y\", \"endog\", remove_version=\"0.11.0\")\n \n-    def __init__(\n-        self, endog, exog=None, dates=None, freq=None, missing=\"none\"\n-    ):\n+    def __init__(self, endog, exog=None, dates=None, freq=None, missing=\"none\"):\n         super().__init__(endog, exog, dates, freq, missing=missing)\n         if self.endog.ndim == 1:\n             raise ValueError(\"Only gave one variable to VAR\")\n@@ -658,8 +654,7 @@ def fit(\n             selections = self.select_order(maxlags=maxlags)\n             if not hasattr(selections, ic):\n                 raise ValueError(\n-                    \"%s not recognized, must be among %s\"\n-                    % (ic, sorted(selections))\n+                    \"%s not recognized, must be among %s\" % (ic, sorted(selections))\n                 )\n             lags = getattr(selections, ic)\n             if verbose:\n@@ -680,13 +675,9 @@ def fit(\n             if orig_exog_names:\n                 x_names_to_add = orig_exog_names\n             else:\n-                x_names_to_add = [\n-                    (\"exog%d\" % i) for i in range(self.exog.shape[1])\n-                ]\n+                x_names_to_add = [(\"exog%d\" % i) for i in range(self.exog.shape[1])]\n             self.data.xnames = (\n-                self.data.xnames[:k_trend]\n-                + x_names_to_add\n-                + self.data.xnames[k_trend:]\n+                self.data.xnames[:k_trend] + x_names_to_add + self.data.xnames[k_trend:]\n             )\n         self.data.cov_names = pd.MultiIndex.from_product(\n             (self.data.xnames, self.data.ynames)\n@@ -716,9 +707,7 @@ def _estimate_var(self, lags, offset=0, trend=\"c\"):\n         if exog is not None:\n             # TODO: currently only deterministic terms supported (exoglags==0)\n             # and since exoglags==0, x will be an array of size 0.\n-            x = util.get_var_endog(\n-                exog[-nobs:], 0, trend=\"n\", has_constant=\"raise\"\n-            )\n+            x = util.get_var_endog(exog[-nobs:], 0, trend=\"n\", has_constant=\"raise\")\n             x_inst = exog[-nobs:]\n             x = np.column_stack((x, x_inst))\n             del x_inst  # free memory\n@@ -823,16 +812,12 @@ def select_order(self, maxlags=None, trend=\"c\"):\n             for k, v in result.info_criteria.items():\n                 ics[k].append(v)\n \n-        selected_orders = {\n-            k: np.array(v).argmin() + p_min for k, v in ics.items()\n-        }\n+        selected_orders = {k: np.array(v).argmin() + p_min for k, v in ics.items()}\n \n         return LagOrderResults(ics, selected_orders, vecm=False)\n \n     @classmethod\n-    def from_formula(\n-        cls, formula, data, subset=None, drop_cols=None, *args, **kwargs\n-    ):\n+    def from_formula(cls, formula, data, subset=None, drop_cols=None, *args, **kwargs):\n         \"\"\"\n         Not implemented. Formulas are not supported for VAR models.\n         \"\"\"\n@@ -860,9 +845,7 @@ class VARProcess:\n         trend.\n     \"\"\"\n \n-    def __init__(\n-        self, coefs, coefs_exog, sigma_u, names=None, _params_info=None\n-    ):\n+    def __init__(self, coefs, coefs_exog, sigma_u, names=None, _params_info=None):\n         self.k_ar = len(coefs)\n         self.neqs = coefs.shape[1]\n         self.coefs = coefs\n@@ -920,7 +903,9 @@ def is_stable(self, verbose=False):\n         \"\"\"\n         return is_stable(self.coefs, verbose=verbose)\n \n-    def simulate_var(self, steps=None, offset=None, seed=None, initial_values=None, nsimulations=None):\n+    def simulate_var(\n+        self, steps=None, offset=None, seed=None, initial_values=None, nsimulations=None\n+    ):\n         \"\"\"\n         simulate the VAR(p) process for the desired number of steps\n \n@@ -963,9 +948,7 @@ def simulate_var(self, steps=None, offset=None, seed=None, initial_values=None,\n                 # if more than intercept\n                 # endog_lagged contains all regressors, trend, exog_user\n                 # and lagged endog, trimmed initial observations\n-                offset = self.endog_lagged[:, : self.k_exog].dot(\n-                    self.coefs_exog.T\n-                )\n+                offset = self.endog_lagged[:, : self.k_exog].dot(self.coefs_exog.T)\n                 steps_ = self.endog_lagged.shape[0]\n             else:\n                 offset = self.intercept\n@@ -992,7 +975,7 @@ def simulate_var(self, steps=None, offset=None, seed=None, initial_values=None,\n             steps=steps,\n             seed=seed,\n             initial_values=initial_values,\n-            nsimulations=nsimulations\n+            nsimulations=nsimulations,\n         )\n         return y\n \n@@ -1111,9 +1094,7 @@ def acorr(self, nlags=None):\n \n     def plot_acorr(self, nlags=10, linewidth=8):\n         \"\"\"Plot theoretical autocorrelation function\"\"\"\n-        fig = plotting.plot_full_acorr(\n-            self.acorr(nlags=nlags), linewidth=linewidth\n-        )\n+        fig = plotting.plot_full_acorr(self.acorr(nlags=nlags), linewidth=linewidth)\n         return fig\n \n     def forecast(self, y, steps, exog_future=None):\n@@ -1135,18 +1116,14 @@ def forecast(self, y, steps, exog_future=None):\n         \"\"\"\n         if self.exog is None and exog_future is not None:\n             raise ValueError(\n-                \"No exog in model, so no exog_future supported \"\n-                \"in forecast method.\"\n+                \"No exog in model, so no exog_future supported \" \"in forecast method.\"\n             )\n         if self.exog is not None and exog_future is None:\n             raise ValueError(\n-                \"Please provide an exog_future argument to \"\n-                \"the forecast method.\"\n+                \"Please provide an exog_future argument to \" \"the forecast method.\"\n             )\n \n-        exog_future = array_like(\n-            exog_future, \"exog_future\", optional=True, ndim=2\n-        )\n+        exog_future = array_like(exog_future, \"exog_future\", optional=True, ndim=2)\n         if exog_future is not None:\n             if exog_future.shape[0] != steps:\n                 err_msg = f\"\"\"\\\n@@ -1159,13 +1136,11 @@ def forecast(self, y, steps, exog_future=None):\n         exogs = []\n         if self.trend.startswith(\"c\"):  # constant term\n             exogs.append(np.ones(steps))\n-        exog_lin_trend = np.arange(\n-            self.n_totobs + 1, self.n_totobs + 1 + steps\n-        )\n+        exog_lin_trend = np.arange(self.n_totobs + 1, self.n_totobs + 1 + steps)\n         if \"t\" in self.trend:\n             exogs.append(exog_lin_trend)\n         if \"tt\" in self.trend:\n-            exogs.append(exog_lin_trend ** 2)\n+            exogs.append(exog_lin_trend**2)\n         if exog_future is not None:\n             exogs.append(exog_future)\n \n@@ -1384,9 +1359,7 @@ def __init__(\n \n     def plot(self):\n         \"\"\"Plot input time series\"\"\"\n-        return plotting.plot_mts(\n-            self.endog, names=self.names, index=self.dates\n-        )\n+        return plotting.plot_mts(self.endog, names=self.names, index=self.dates)\n \n     @property\n     def df_model(self):\n@@ -1662,7 +1635,7 @@ def forecast_cov(self, steps=1, method=\"mse\"):\n                 warnings.warn(\n                     \"forecast cov takes parameter uncertainty into\" \"account\",\n                     OutputWarning,\n-                    stacklevel = 2,\n+                    stacklevel=2,\n                 )\n         else:\n             raise ValueError(\"method has to be either 'mse' or 'auto'\")\n@@ -1766,9 +1739,7 @@ def irf_resim(\n \n         def fill_coll(sim):\n             ret = VAR(sim, exog=self.exog).fit(maxlags=k_ar, trend=self.trend)\n-            ret = (\n-                ret.orth_ma_rep(maxn=steps) if orth else ret.ma_rep(maxn=steps)\n-            )\n+            ret = ret.orth_ma_rep(maxn=steps) if orth else ret.ma_rep(maxn=steps)\n             return ret.cumsum(axis=0) if cum else ret\n \n         for i in range(repl):\n@@ -1989,13 +1960,13 @@ def test_causality(self, caused, causing=None, kind=\"f\", signif=0.05):\n         num_det_terms = self.k_exog\n \n         # Make restriction matrix\n-        C = np.zeros((num_restr, k * num_det_terms + k ** 2 * p), dtype=float)\n+        C = np.zeros((num_restr, k * num_det_terms + k**2 * p), dtype=float)\n         cols_det = k * num_det_terms\n         row = 0\n         for j in range(p):\n             for ing_ind in causing_ind:\n                 for ed_ind in caused_ind:\n-                    C[row, cols_det + ed_ind + k * ing_ind + k ** 2 * j] = 1\n+                    C[row, cols_det + ed_ind + k * ing_ind + k**2 * j] = 1\n                     row += 1\n \n         # L\u00fctkepohl 3.6.5\n@@ -2111,7 +2082,7 @@ def test_inst_causality(self, causing, signif=0.05):\n         caused = [self.names[c] for c in caused_ind]\n \n         # Note: JMulTi seems to be using k_ar+1 instead of k_ar\n-        k, t, p = self.neqs, self.nobs, self.k_ar\n+        k, t = self.neqs, self.nobs\n \n         num_restr = len(causing) * len(caused)  # called N in L\u00fctkepohl\n \n@@ -2198,8 +2169,8 @@ def test_whiteness(self, nlags=10, signif=0.05, adjusted=False):\n             if adjusted:\n                 to_add /= self.nobs - t\n             statistic += to_add\n-        statistic *= self.nobs ** 2 if adjusted else self.nobs\n-        df = self.neqs ** 2 * (nlags - self.k_ar)\n+        statistic *= self.nobs**2 if adjusted else self.nobs\n+        df = self.neqs**2 * (nlags - self.k_ar)\n         dist = stats.chi2(df)\n         pvalue = dist.sf(statistic)\n         crit_value = dist.ppf(1 - signif)\n@@ -2284,7 +2255,7 @@ def info_criteria(self):\n         nobs = self.nobs\n         neqs = self.neqs\n         lag_order = self.k_ar\n-        free_params = lag_order * neqs ** 2 + neqs * self.k_exog\n+        free_params = lag_order * neqs**2 + neqs * self.k_exog\n         if self.df_resid:\n             ld = logdet_symm(self.sigma_u_mle)\n         else:\n@@ -2355,13 +2326,9 @@ class VARResultsWrapper(wrap.ResultsWrapper):\n         \"sigma_u_mle\": \"cov_eq\",\n         \"stderr\": \"columns_eq\",\n     }\n-    _wrap_attrs = wrap.union_dicts(\n-        TimeSeriesResultsWrapper._wrap_attrs, _attrs\n-    )\n+    _wrap_attrs = wrap.union_dicts(TimeSeriesResultsWrapper._wrap_attrs, _attrs)\n     _methods = {\"conf_int\": \"multivariate_confint\"}\n-    _wrap_methods = wrap.union_dicts(\n-        TimeSeriesResultsWrapper._wrap_methods, _methods\n-    )\n+    _wrap_methods = wrap.union_dicts(TimeSeriesResultsWrapper._wrap_methods, _methods)\n \n \n wrap.populate_wrapper(VARResultsWrapper, VARResults)  # noqa:E305\n", "test_patch": "diff --git a/statsmodels/tsa/vector_ar/tests/test_var.py b/statsmodels/tsa/vector_ar/tests/test_var.py\nindex e370279679f..38ac4e21cd8 100644\n--- a/statsmodels/tsa/vector_ar/tests/test_var.py\n+++ b/statsmodels/tsa/vector_ar/tests/test_var.py\n@@ -1,6 +1,7 @@\n \"\"\"\n Test VAR Model\n \"\"\"\n+\n from statsmodels.compat.pandas import QUARTER_END, assert_index_equal\n from statsmodels.compat.python import lrange\n \n@@ -19,7 +20,7 @@\n from statsmodels.tools.sm_exceptions import ValueWarning\n from statsmodels.tsa.base.datetools import dates_from_str\n import statsmodels.tsa.vector_ar.util as util\n-from statsmodels.tsa.vector_ar.var_model import VAR, var_acf\n+from statsmodels.tsa.vector_ar.var_model import VAR, forecast, var_acf\n \n DECIMAL_12 = 12\n DECIMAL_6 = 6\n@@ -142,12 +143,8 @@ def __init__(self):\n         data = var_results.__dict__\n \n         self.names = data[\"coefs\"].dtype.names\n-        self.params = data[\"coefs\"].view(\n-            (float, len(self.names)), type=np.ndarray\n-        )\n-        self.stderr = data[\"stderr\"].view(\n-            (float, len(self.names)), type=np.ndarray\n-        )\n+        self.params = data[\"coefs\"].view((float, len(self.names)), type=np.ndarray)\n+        self.stderr = data[\"stderr\"].view((float, len(self.names)), type=np.ndarray)\n \n         self.irf = data[\"irf\"].item()\n         self.orth_irf = data[\"orthirf\"].item()\n@@ -223,9 +220,7 @@ def test_plot_cum_effects(self, close_figures):\n     @pytest.mark.matplotlib\n     def test_plot_figsizes(self):\n         assert_equal(self.irf.plot().get_size_inches(), (10, 10))\n-        assert_equal(\n-            self.irf.plot(figsize=(14, 10)).get_size_inches(), (14, 10)\n-        )\n+        assert_equal(self.irf.plot(figsize=(14, 10)).get_size_inches(), (14, 10))\n \n         assert_equal(self.irf.plot_cum_effects().get_size_inches(), (10, 10))\n         assert_equal(\n@@ -251,16 +246,11 @@ def test_fevd_repr(self):\n     def test_fevd_summary(self):\n         self.fevd.summary()\n \n-    @pytest.mark.xfail(\n-        reason=\"FEVD.cov() is not implemented\",\n-        raises=NotImplementedError,\n-        strict=True,\n-    )\n     def test_fevd_cov(self):\n         # test does not crash\n         # not implemented\n-        covs = self.fevd.cov()\n-        raise NotImplementedError\n+        with pytest.raises(NotImplementedError):\n+            self.fevd.cov()\n \n \n class TestVARResults(CheckIRF, CheckFEVD):\n@@ -285,7 +275,7 @@ def test_constructor(self):\n         # make sure this works with no names\n         ndarr = self.data.view((float, 3), type=np.ndarray)\n         model = VAR(ndarr)\n-        res = model.fit(self.p)\n+        model.fit(self.p)\n \n     def test_names(self):\n         assert_equal(self.model.endog_names, self.ref.names)\n@@ -309,8 +299,8 @@ def test_get_eq_index(self):\n     @pytest.mark.smoke\n     def test_repr(self):\n         # just want this to work\n-        foo = str(self.res)\n-        bar = repr(self.res)\n+        str(self.res)\n+        repr(self.res)\n \n     def test_params(self):\n         assert_almost_equal(self.res.params, self.ref.params, DECIMAL_3)\n@@ -335,6 +325,7 @@ def test_pvalues(self):\n     @pytest.mark.smoke\n     def test_summary(self):\n         summ = self.res.summary()\n+        assert \"Summary of \" in str(summ)\n \n     def test_detsig(self):\n         assert_almost_equal(self.res.detomega, self.ref.detomega)\n@@ -355,7 +346,8 @@ def test_lagorder_select(self):\n         ics = [\"aic\", \"fpe\", \"hqic\", \"bic\"]\n \n         for ic in ics:\n-            res = self.model.fit(maxlags=10, ic=ic, verbose=True)\n+            # Smoke test\n+            self.model.fit(maxlags=10, ic=ic, verbose=True)\n \n         with pytest.raises(Exception):\n             self.model.fit(ic=\"foo\")\n@@ -407,7 +399,9 @@ def test_causality_no_lags(self):\n     @pytest.mark.smoke\n     def test_select_order(self):\n         result = self.model.fit(10, ic=\"aic\", verbose=True)\n+        assert isinstance(result.params, np.ndarray)\n         result = self.model.fit(10, ic=\"fpe\", verbose=True)\n+        assert isinstance(result.params, np.ndarray)\n \n         # bug\n         model = VAR(self.model.endog)\n@@ -448,6 +442,7 @@ def test_acf_2_lags(self):\n     @pytest.mark.smoke\n     def test_acorr(self):\n         acorrs = self.res.acorr(10)\n+        assert acorrs.shape == (11, 3, 3)\n \n     @pytest.mark.smoke\n     def test_forecast(self):\n@@ -622,20 +617,17 @@ def test_approx_mse(self):\n     def test_irf_stderr(self):\n         irf_stderr = self.irf.stderr(orth=False)\n         for i in range(1, 1 + len(self.lut.irf_stderr)):\n-            assert_almost_equal(\n-                np.round(irf_stderr[i], 3), self.lut.irf_stderr[i - 1]\n-            )\n+            assert_almost_equal(np.round(irf_stderr[i], 3), self.lut.irf_stderr[i - 1])\n \n     def test_cum_irf_stderr(self):\n         stderr = self.irf.cum_effect_stderr(orth=False)\n         for i in range(1, 1 + len(self.lut.cum_irf_stderr)):\n-            assert_almost_equal(\n-                np.round(stderr[i], 3), self.lut.cum_irf_stderr[i - 1]\n-            )\n+            assert_almost_equal(np.round(stderr[i], 3), self.lut.cum_irf_stderr[i - 1])\n \n     def test_lr_effect_stderr(self):\n         stderr = self.irf.lr_effect_stderr(orth=False)\n         orth_stderr = self.irf.lr_effect_stderr(orth=True)\n+        assert orth_stderr.shape == stderr.shape\n         assert_almost_equal(np.round(stderr, 3), self.lut.lr_stderr)\n \n \n@@ -679,11 +671,14 @@ def test_var_trend():\n     model = VAR(data)\n     results = model.fit(4)  # , trend = 'c')\n     irf = results.irf(10)\n+    assert irf.irfs.shape == (11, 3, 3)\n \n     data_nc = data - data.mean(0)\n     model_nc = VAR(data_nc)\n-    results_nc = model_nc.fit(4, trend=\"n\")\n+    # Fit once with a trend\n+    model_nc.fit(4, trend=\"n\")\n     with pytest.raises(ValueError):\n+        # Attempt to change the trend\n         model.fit(4, trend=\"t\")\n \n \n@@ -746,15 +741,13 @@ def test_process(self, close_figures):\n         y_sim_init_2 = res0.simulate_var(seed=987128, initial_values=data[-1])\n         assert_allclose(y_sim_init[:k_ar], data[-k_ar:])\n         assert_allclose(y_sim_init_2[0], data[-1])\n-        assert_allclose(y_sim_init_2[k_ar-1], data[-1])\n+        assert_allclose(y_sim_init_2[k_ar - 1], data[-1])\n \n         y_sim_init_3 = resl1.simulate_var(seed=987128, initial_values=data[-1])\n         assert_allclose(y_sim_init_3[0], data[-1])\n \n         n_sim = 900\n-        ysimz = res0.simulate_var(\n-            steps=n_sim, offset=np.zeros((n_sim, 3)), seed=987128\n-        )\n+        ysimz = res0.simulate_var(steps=n_sim, offset=np.zeros((n_sim, 3)), seed=987128)\n         zero3 = np.zeros(3)\n         assert_allclose(ysimz.mean(0), zero3, atol=0.4)\n         # initialization does not use long run intercept, see #4542\n@@ -767,7 +760,8 @@ def test_process(self, close_figures):\n         assert_equal(res0.k_exog, 1)\n         assert_equal(res0.k_ar, 2)\n \n-        irf = res0.irf()\n+        # Smoke test\n+        res0.irf()\n \n     @pytest.mark.matplotlib\n     def test_process_plotting(self, close_figures):\n@@ -843,9 +837,7 @@ def test_exog(self):\n         # TODO: intercept differs by 4e-3, others are < 1e-12\n         assert_allclose(res_lin_trend.params, res_lin_trend1.params, rtol=5e-3)\n         assert_allclose(res_lin_trend.params, res_lin_trend2.params, rtol=5e-3)\n-        assert_allclose(\n-            res_lin_trend1.params, res_lin_trend2.params, rtol=1e-10\n-        )\n+        assert_allclose(res_lin_trend1.params, res_lin_trend2.params, rtol=1e-10)\n \n         y1 = res_lin_trend.simulate_var(seed=987128)\n         y2 = res_lin_trend1.simulate_var(seed=987128)\n@@ -857,18 +849,12 @@ def test_exog(self):\n         h = 10\n         fc1 = res_lin_trend.forecast(res_lin_trend.endog[-2:], h)\n         exf = np.arange(len(data), len(data) + h)\n-        fc2 = res_lin_trend1.forecast(\n-            res_lin_trend1.endog[-2:], h, exog_future=exf\n-        )\n+        fc2 = res_lin_trend1.forecast(res_lin_trend1.endog[-2:], h, exog_future=exf)\n         with pytest.raises(ValueError, match=\"exog_future only has\"):\n             wrong_exf = np.arange(len(data), len(data) + h // 2)\n-            res_lin_trend1.forecast(\n-                res_lin_trend1.endog[-2:], h, exog_future=wrong_exf\n-            )\n+            res_lin_trend1.forecast(res_lin_trend1.endog[-2:], h, exog_future=wrong_exf)\n         exf2 = exf[:, None] ** [0, 1]\n-        fc3 = res_lin_trend2.forecast(\n-            res_lin_trend2.endog[-2:], h, exog_future=exf2\n-        )\n+        fc3 = res_lin_trend2.forecast(res_lin_trend2.endog[-2:], h, exog_future=exf2)\n         assert_allclose(fc2, fc1, rtol=1e-12, atol=1e-12)\n         assert_allclose(fc3, fc1, rtol=1e-12, atol=1e-12)\n         assert_allclose(fc3, fc2, rtol=1e-12, atol=1e-12)\n@@ -900,8 +886,8 @@ def test_multiple_simulations(self):\n         sim2_init = res0.simulate_var(\n             seed=987128, steps=10, initial_values=init, nsimulations=2\n         )\n-        assert_allclose(sim2_init[0,:k_ar], init)\n-        assert_allclose(sim2_init[1,:k_ar], init)\n+        assert_allclose(sim2_init[0, :k_ar], init)\n+        assert_allclose(sim2_init[1, :k_ar], init)\n \n \n def test_var_cov_params_pandas(bivariate_var_data):\n@@ -919,9 +905,7 @@ def test_var_cov_params_pandas(bivariate_var_data):\n def test_summaries_exog(reset_randomstate):\n     y = np.random.standard_normal((500, 6))\n     df = pd.DataFrame(y)\n-    cols = [f\"endog_{i}\" for i in range(2)] + [\n-        f\"exog_{i}\" for i in range(4)\n-    ]\n+    cols = [f\"endog_{i}\" for i in range(2)] + [f\"exog_{i}\" for i in range(4)]\n     df.columns = cols\n     df.index = pd.date_range(\"1-1-1950\", periods=500, freq=\"MS\")\n     endog = df.iloc[:, :2]\n@@ -978,9 +962,7 @@ def test_correct_nobs():\n     # make a VAR model\n     model = VAR(endog=data, exog=data_exog)\n     results = model.fit(maxlags=1)\n-    irf = results.irf_resim(\n-        orth=False, repl=100, steps=10, seed=1, burn=100, cum=False\n-    )\n+    irf = results.irf_resim(orth=False, repl=100, steps=10, seed=1, burn=100, cum=False)\n     assert irf.shape == (100, 11, 3, 3)\n \n \n@@ -991,7 +973,26 @@ def test_irf_err_bands():\n     model = VAR(data)\n     results = model.fit(maxlags=2)\n     irf = results.irf()\n-    bands_sz1 = irf.err_band_sz1()\n-    bands_sz2 = irf.err_band_sz2()\n-    bands_sz3 = irf.err_band_sz3()\n-    bands_mc = irf.errband_mc()\n+    # Smoke tests only\n+    irf.err_band_sz1()\n+    irf.err_band_sz2()\n+    irf.err_band_sz3()\n+    irf.errband_mc()\n+\n+\n+def test_0_lag(reset_randomstate):\n+    # GH 9412\n+    y = np.random.rand(300, 2)\n+    results = VAR(y).fit(maxlags=1, ic=\"aic\", trend=\"c\")\n+    assert results.params.shape == (1, 2)\n+    fcasts = results.forecast(y, steps=5)\n+    assert_allclose(fcasts, np.ones((5, 1)) * results.params)\n+\n+\n+def test_forecast_wrong_shape_params(reset_randomstate):\n+    # GH 9412\n+    y = np.random.rand(300, 2)\n+    mod = VAR(y)\n+    results = mod.fit(maxlags=1, ic=\"aic\", trend=\"c\")\n+    with pytest.raises(ValueError):\n+        forecast(y, results.params, results.params, steps=5)\n", "problem_statement": "Cannot forecast with VAR when lags is zero.\n#### Describe the bug\r\n\r\nFitting and forecasting with a VAR model throws an error when the information criterion determines that the best number of lags is zero (e.g. for uniform random data).\r\n\r\n#### Code Sample, a copy-pastable example if possible\r\n\r\n\r\n```python\r\nimport numpy as np\r\nfrom statsmodels.tsa.api import VAR\r\n\r\nY = np.random.rand(300, 2)\r\nresults = VAR(Y).fit(maxlags=1, ic='aic', trend=\"c\")\r\nresults.forecast(Y, steps=5)\r\n```\r\n**Error**\r\n<details>\r\n\r\n        IndexError\r\n        Traceback (most recent call last)\r\n        [<ipython-input-81-0d77b71b9e4c>](https://localhost:8080/#) in <cell line: 6>()\r\n              4 Y = np.random.rand(300, 2)\r\n              5 results = VAR(Y).fit(maxlags=1, ic='aic', trend=\"c\")\r\n        ----> 6 results.forecast(Y, steps=5)\r\n        \r\n        [/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/vector_ar/var_model.py](https://localhost:8080/#) in forecast(self, y, steps, exog_future)\r\n           1174         else:\r\n           1175             exog_future = np.column_stack(exogs)\r\n        -> 1176         return forecast(y, self.coefs, trend_coefs, steps, exog_future)\r\n           1177 \r\n           1178     # TODO: use `mse` module-level function?\r\n        \r\n        [/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/vector_ar/var_model.py](https://localhost:8080/#) in forecast(y, coefs, trend_coefs, steps, exog)\r\n            228     \"\"\"\r\n            229     p = len(coefs)\r\n        --> 230     k = len(coefs[0])\r\n            231     if y.shape[0] < p:\r\n            232         raise ValueError(\r\n        \r\n        IndexError: index 0 is out of bounds for axis 0 with size 0\r\n\r\n</details>\r\n\r\n#### Expected Output\r\n\r\nI expected it to forecast a constant value. I think there is a problem when the VarResults initializer constructs `results.coefs` because when lags=0 it will be an empty array. This is fine for statistical summary but I don't think the forecaster knows how to handle the constant prediction case.\r\n\r\n#### Output of ``import statsmodels.api as sm; sm.show_versions()``\r\n\r\n<details>\r\n\r\n[paste the output of ``import statsmodels.api as sm; sm.show_versions()`` here below this line]\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\nPython: 3.10.12.final.0\r\nOS: Linux 6.1.85+ #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024 x86_64\r\nbyteorder: little\r\nLC_ALL: en_US.UTF-8\r\nLANG: en_US.UTF-8\r\n\r\nstatsmodels\r\n===========\r\n\r\nInstalled: 0.14.4 (/usr/local/lib/python3.10/dist-packages/statsmodels)\r\n\r\nRequired Dependencies\r\n=====================\r\n\r\ncython: 3.0.11 (/usr/local/lib/python3.10/dist-packages/Cython)\r\nnumpy: 1.26.4 (/usr/local/lib/python3.10/dist-packages/numpy)\r\nscipy: 1.13.1 (/usr/local/lib/python3.10/dist-packages/scipy)\r\npandas: 2.2.2 (/usr/local/lib/python3.10/dist-packages/pandas)\r\n    dateutil: 2.8.2 (/usr/local/lib/python3.10/dist-packages/dateutil)\r\npatsy: 0.5.6 (/usr/local/lib/python3.10/dist-packages/patsy)\r\n\r\nOptional Dependencies\r\n=====================\r\n\r\nmatplotlib: 3.7.1 (/usr/local/lib/python3.10/dist-packages/matplotlib)\r\n    backend: module://matplotlib_inline.backend_inline \r\ncvxopt: 1.3.2 (/usr/local/lib/python3.10/dist-packages/cvxopt)\r\njoblib: 1.4.2 (/usr/local/lib/python3.10/dist-packages/joblib)\r\n\r\nDeveloper Tools\r\n================\r\n\r\nIPython: 7.34.0 (/usr/local/lib/python3.10/dist-packages/IPython)\r\n    jinja2: 3.1.4 (/usr/local/lib/python3.10/dist-packages/jinja2)\r\nsphinx: 5.0.2 (/usr/local/lib/python3.10/dist-packages/sphinx)\r\n    pygments: 2.18.0 (/usr/local/lib/python3.10/dist-packages/pygments)\r\npytest: 7.4.4 (/usr/local/lib/python3.10/dist-packages/pytest)\r\nvirtualenv: Not installed\r\n\r\n</details>\r\n\n", "hints_text": "", "created_at": "2024-10-28T18:24:41Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9407, "instance_id": "statsmodels__statsmodels-9407", "issue_numbers": ["9206"], "base_commit": "f29be609729882446846a930bec1afbdc78a0d2b", "patch": "diff --git a/statsmodels/base/data.py b/statsmodels/base/data.py\nindex 61cada0b63f..8cbf5eb6e35 100644\n--- a/statsmodels/base/data.py\n+++ b/statsmodels/base/data.py\n@@ -2,6 +2,7 @@\n Base tools for handling various kinds of data structures, attaching metadata to\n results, and doing data cleaning\n \"\"\"\n+\n from __future__ import annotations\n \n from statsmodels.compat.python import lmap\n@@ -9,7 +10,7 @@\n from functools import reduce\n \n import numpy as np\n-from pandas import DataFrame, Series, isnull, MultiIndex\n+from pandas import DataFrame, MultiIndex, Series, isnull\n \n import statsmodels.tools.data as data_util\n from statsmodels.tools.decorators import cache_readonly, cache_writable\n@@ -26,8 +27,8 @@ def _asarray_2d_null_rows(x):\n     Makes sure input is an array and is 2d. Makes sure output is 2d. True\n     indicates a null in the rows of 2d x.\n     \"\"\"\n-    #Have to have the asarrays because isnull does not account for array_like\n-    #input\n+    # Have to have the asarrays because isnull does not account for array_like\n+    # input\n     x = np.asarray(x)\n     if x.ndim == 1:\n         x = x[:, None]\n@@ -45,9 +46,11 @@ def _nan_rows(*arrs):\n \n     def _nan_row_maybe_two_inputs(x, y):\n         # check for dtype bc dataframe has dtypes\n-        x_is_boolean_array = hasattr(x, 'dtype') and x.dtype == bool and x\n-        return np.logical_or(_asarray_2d_null_rows(x),\n-                             (x_is_boolean_array | _asarray_2d_null_rows(y)))\n+        x_is_boolean_array = hasattr(x, \"dtype\") and x.dtype == bool and x\n+        return np.logical_or(\n+            _asarray_2d_null_rows(x), (x_is_boolean_array | _asarray_2d_null_rows(y))\n+        )\n+\n     return reduce(_nan_row_maybe_two_inputs, arrs).squeeze()\n \n \n@@ -56,27 +59,26 @@ class ModelData:\n     Class responsible for handling input data and extracting metadata into the\n     appropriate form\n     \"\"\"\n+\n     _param_names = None\n     _cov_names = None\n \n-    def __init__(self, endog, exog=None, missing='none', hasconst=None,\n-                 **kwargs):\n+    def __init__(self, endog, exog=None, missing=\"none\", hasconst=None, **kwargs):\n         if data_util._is_recarray(endog) or data_util._is_recarray(exog):\n             from statsmodels.tools.sm_exceptions import recarray_exception\n+\n             raise NotImplementedError(recarray_exception)\n-        if 'design_info' in kwargs:\n-            self.design_info = kwargs.pop('design_info')\n-        if 'formula' in kwargs:\n-            self.formula = kwargs.pop('formula')\n-        if missing != 'none':\n-            arrays, nan_idx = self.handle_missing(endog, exog, missing,\n-                                                  **kwargs)\n+        if \"design_info\" in kwargs:\n+            self.design_info = kwargs.pop(\"design_info\")\n+        if \"formula\" in kwargs:\n+            self.formula = kwargs.pop(\"formula\")\n+        if missing != \"none\":\n+            arrays, nan_idx = self.handle_missing(endog, exog, missing, **kwargs)\n             self.missing_row_idx = nan_idx\n             self.__dict__.update(arrays)  # attach all the data arrays\n             self.orig_endog = self.endog\n             self.orig_exog = self.exog\n-            self.endog, self.exog = self._convert_endog_exog(self.endog,\n-                                                             self.exog)\n+            self.endog, self.exog = self._convert_endog_exog(self.endog, self.exog)\n         else:\n             self.__dict__.update(kwargs)  # attach the extra arrays anyway\n             self.orig_endog = endog\n@@ -91,6 +93,7 @@ def __init__(self, endog, exog=None, missing='none', hasconst=None,\n \n     def __getstate__(self):\n         from copy import copy\n+\n         d = copy(self.__dict__)\n         if \"design_info\" in d:\n             del d[\"design_info\"]\n@@ -100,20 +103,22 @@ def __getstate__(self):\n     def __setstate__(self, d):\n         if \"restore_design_info\" in d:\n             # NOTE: there may be a more performant way to do this\n-            from patsy import dmatrices, PatsyError\n+            from patsy import PatsyError, dmatrices\n+\n             exc = []\n             try:\n-                data = d['frame']\n+                data = d[\"frame\"]\n             except KeyError:\n-                data = d['orig_endog'].join(d['orig_exog'])\n+                data = d[\"orig_endog\"].join(d[\"orig_exog\"])\n \n             for depth in [2, 3, 1, 0, 4]:  # sequence is a guess where to likely find it\n                 try:\n-                    _, design = dmatrices(d['formula'], data, eval_env=depth,\n-                                          return_type='dataframe')\n+                    _, design = dmatrices(\n+                        d[\"formula\"], data, eval_env=depth, return_type=\"dataframe\"\n+                    )\n                     break\n                 except (NameError, PatsyError) as e:\n-                    exc.append(e)   # why do I need a reference from outside except block\n+                    exc.append(e)  # why do I need a reference from outside except block\n                     pass\n             else:\n                 raise exc[-1]\n@@ -131,7 +136,7 @@ def _handle_constant(self, hasconst):\n             check_implicit = False\n             exog_max = np.max(self.exog, axis=0)\n             if not np.isfinite(exog_max).all():\n-                raise MissingDataError('exog contains inf or nans')\n+                raise MissingDataError(\"exog contains inf or nans\")\n             exog_min = np.min(self.exog, axis=0)\n             const_idx = np.where(exog_max == exog_min)[0].squeeze()\n             self.k_constant = const_idx.size\n@@ -155,7 +160,7 @@ def _handle_constant(self, hasconst):\n                     values.append(value)\n                 else:\n                     # we did not break, no column of ones\n-                    pos = (np.array(values) != 0)\n+                    pos = np.array(values) != 0\n                     if pos.any():\n                         # take the first nonzero column\n                         self.k_constant = 1\n@@ -173,7 +178,8 @@ def _handle_constant(self, hasconst):\n                 # look for implicit constant\n                 # Compute rank of augmented matrix\n                 augmented_exog = np.column_stack(\n-                            (np.ones(self.exog.shape[0]), self.exog))\n+                    (np.ones(self.exog.shape[0]), self.exog)\n+                )\n                 rank_augm = np.linalg.matrix_rank(augmented_exog)\n                 rank_orig = np.linalg.matrix_rank(self.exog)\n                 self.k_constant = int(rank_orig == rank_augm)\n@@ -200,21 +206,21 @@ def handle_missing(cls, endog, exog, missing, **kwargs):\n         none_array_names = []\n \n         # patsy's already dropped NaNs in y/X\n-        missing_idx = kwargs.pop('missing_idx', None)\n+        missing_idx = kwargs.pop(\"missing_idx\", None)\n \n         if missing_idx is not None:\n             # y, X already handled by patsy. add back in later.\n             combined = ()\n             combined_names = []\n             if exog is None:\n-                none_array_names += ['exog']\n+                none_array_names += [\"exog\"]\n         elif exog is not None:\n             combined = (endog, exog)\n-            combined_names = ['endog', 'exog']\n+            combined_names = [\"endog\", \"exog\"]\n         else:\n             combined = (endog,)\n-            combined_names = ['endog']\n-            none_array_names += ['exog']\n+            combined_names = [\"endog\"]\n+            none_array_names += [\"exog\"]\n \n         # deal with other arrays\n         combined_2d = ()\n@@ -237,8 +243,9 @@ def handle_missing(cls, endog, exog, missing, **kwargs):\n                     combined_2d += (np.asarray(value_array),)\n                     combined_2d_names += [key]\n                 else:\n-                    raise ValueError(\"Arrays with more than 2 dimensions \"\n-                                     \"are not yet handled\")\n+                    raise ValueError(\n+                        \"Arrays with more than 2 dimensions \" \"are not yet handled\"\n+                    )\n \n         if missing_idx is not None:\n             nan_mask = missing_idx\n@@ -246,16 +253,20 @@ def handle_missing(cls, endog, exog, missing, **kwargs):\n             if combined:  # there were extra arrays not handled by patsy\n                 combined_nans = _nan_rows(*combined)\n                 if combined_nans.shape[0] != nan_mask.shape[0]:\n-                    raise ValueError(\"Shape mismatch between endog/exog \"\n-                                     \"and extra arrays given to model.\")\n+                    raise ValueError(\n+                        \"Shape mismatch between endog/exog \"\n+                        \"and extra arrays given to model.\"\n+                    )\n                 # for going back and updated endog/exog\n                 updated_row_mask = combined_nans[~nan_mask]\n                 nan_mask |= combined_nans  # for updating extra arrays only\n             if combined_2d:\n                 combined_2d_nans = _nan_rows(combined_2d)\n                 if combined_2d_nans.shape[0] != nan_mask.shape[0]:\n-                    raise ValueError(\"Shape mismatch between endog/exog \"\n-                                     \"and extra 2d arrays given to model.\")\n+                    raise ValueError(\n+                        \"Shape mismatch between endog/exog \"\n+                        \"and extra 2d arrays given to model.\"\n+                    )\n                 if updated_row_mask is not None:\n                     updated_row_mask |= combined_2d_nans[~nan_mask]\n                 else:\n@@ -272,20 +283,19 @@ def handle_missing(cls, endog, exog, missing, **kwargs):\n             if combined_2d:\n                 combined.update(dict(zip(combined_2d_names, combined_2d)))\n             if none_array_names:\n-                combined.update({k: kwargs.get(k, None)\n-                                 for k in none_array_names})\n+                combined.update({k: kwargs.get(k, None) for k in none_array_names})\n \n             if missing_idx is not None:\n-                combined.update({'endog': endog})\n+                combined.update({\"endog\": endog})\n                 if exog is not None:\n-                    combined.update({'exog': exog})\n+                    combined.update({\"exog\": exog})\n \n             return combined, []\n \n-        elif missing == 'raise':\n+        elif missing == \"raise\":\n             raise MissingDataError(\"NaNs were encountered in the data\")\n \n-        elif missing == 'drop':\n+        elif missing == \"drop\":\n             nan_mask = ~nan_mask\n             drop_nans = lambda x: cls._drop_nans(x, nan_mask)\n             drop_nans_2d = lambda x: cls._drop_nans_2d(x, nan_mask)\n@@ -299,16 +309,16 @@ def handle_missing(cls, endog, exog, missing, **kwargs):\n                     if exog is not None:\n                         exog = cls._drop_nans(exog, updated_row_mask)\n \n-                combined.update({'endog': endog})\n+                combined.update({\"endog\": endog})\n                 if exog is not None:\n-                    combined.update({'exog': exog})\n+                    combined.update({\"exog\": exog})\n \n             if combined_2d:\n-                combined.update(dict(zip(combined_2d_names,\n-                                         lmap(drop_nans_2d, combined_2d))))\n+                combined.update(\n+                    dict(zip(combined_2d_names, lmap(drop_nans_2d, combined_2d)))\n+                )\n             if none_array_names:\n-                combined.update({k: kwargs.get(k, None)\n-                                 for k in none_array_names})\n+                combined.update({k: kwargs.get(k, None) for k in none_array_names})\n \n             return combined, np.where(~nan_mask)[0].tolist()\n         else:\n@@ -396,8 +406,7 @@ def _get_names(self, arr):\n         if isinstance(arr, DataFrame):\n             if isinstance(arr.columns, MultiIndex):\n                 # Flatten MultiIndexes into \"simple\" column names\n-                return ['_'.join(level for level in c if level)\n-                        for c in arr.columns]\n+                return [\"_\".join(level for level in c if level) for c in arr.columns]\n             else:\n                 return list(arr.columns)\n         elif isinstance(arr, Series):\n@@ -435,26 +444,26 @@ def _check_integrity(self):\n             if len(self.exog) != len(self.endog):\n                 raise ValueError(\"endog and exog matrices are different sizes\")\n \n-    def wrap_output(self, obj, how='columns', names=None):\n-        if how == 'columns':\n+    def wrap_output(self, obj, how=\"columns\", names=None):\n+        if how == \"columns\":\n             return self.attach_columns(obj)\n-        elif how == 'rows':\n+        elif how == \"rows\":\n             return self.attach_rows(obj)\n-        elif how == 'cov':\n+        elif how == \"cov\":\n             return self.attach_cov(obj)\n-        elif how == 'dates':\n+        elif how == \"dates\":\n             return self.attach_dates(obj)\n-        elif how == 'columns_eq':\n+        elif how == \"columns_eq\":\n             return self.attach_columns_eq(obj)\n-        elif how == 'cov_eq':\n+        elif how == \"cov_eq\":\n             return self.attach_cov_eq(obj)\n-        elif how == 'generic_columns':\n+        elif how == \"generic_columns\":\n             return self.attach_generic_columns(obj, names)\n-        elif how == 'generic_columns_2d':\n+        elif how == \"generic_columns_2d\":\n             return self.attach_generic_columns_2d(obj, names)\n-        elif how == 'ynames':\n+        elif how == \"ynames\":\n             return self.attach_ynames(obj)\n-        elif how == 'multivariate_confint':\n+        elif how == \"multivariate_confint\":\n             return self.attach_mv_confint(obj)\n         else:\n             return obj\n@@ -502,12 +511,14 @@ class PandasData(ModelData):\n     \"\"\"\n \n     def _convert_endog_exog(self, endog, exog=None):\n-        #TODO: remove this when we handle dtype systematically\n+        # TODO: remove this when we handle dtype systematically\n         endog = np.asarray(endog)\n-        exog = exog if exog is None else np.asarray(exog)\n-        if endog.dtype == object or exog is not None and exog.dtype == object:\n-            raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n-                             \"Check input data with np.asarray(data).\")\n+        exog = exog if exog is None else np.asarray(exog, dtype=float)\n+        if endog.dtype == object:\n+            raise ValueError(\n+                \"Pandas data cast to numpy dtype of object. \"\n+                \"Check input data with np.asarray(data).\"\n+            )\n         return super()._convert_endog_exog(endog, exog)\n \n     @classmethod\n@@ -527,9 +538,11 @@ def _drop_nans_2d(cls, x, nan_mask):\n     def _check_integrity(self):\n         endog, exog = self.orig_endog, self.orig_exog\n         # exog can be None and we could be upcasting one or the other\n-        if (exog is not None and\n-                (hasattr(endog, 'index') and hasattr(exog, 'index')) and\n-                not self.orig_endog.index.equals(self.orig_exog.index)):\n+        if (\n+            exog is not None\n+            and (hasattr(endog, \"index\") and hasattr(exog, \"index\"))\n+            and not self.orig_endog.index.equals(self.orig_exog.index)\n+        ):\n             raise ValueError(\"The indices for endog and exog are not aligned\")\n         super()._check_integrity()\n \n@@ -583,7 +596,7 @@ def attach_rows(self, result):\n         else:\n             out = DataFrame(result)\n             out.columns = self.ynames\n-        out.index = self.row_labels[-len(result):]\n+        out.index = self.row_labels[-len(result) :]\n         return out\n \n     def attach_dates(self, result):\n@@ -595,14 +608,14 @@ def attach_dates(self, result):\n         if squeezed.ndim < 2:\n             return Series(squeezed, index=self.predict_dates)\n         else:\n-            return DataFrame(np.asarray(result),\n-                             index=self.predict_dates,\n-                             columns=self.ynames)\n+            return DataFrame(\n+                np.asarray(result), index=self.predict_dates, columns=self.ynames\n+            )\n \n     def attach_mv_confint(self, result):\n-        return DataFrame(result.reshape((-1, 2)),\n-                         index=self.cov_names,\n-                         columns=['lower', 'upper'])\n+        return DataFrame(\n+            result.reshape((-1, 2)), index=self.cov_names, columns=[\"lower\", \"upper\"]\n+        )\n \n     def attach_ynames(self, result):\n         squeezed = result.squeeze()\n@@ -615,9 +628,9 @@ def attach_ynames(self, result):\n \n def _make_endog_names(endog):\n     if endog.ndim == 1 or endog.shape[1] == 1:\n-        ynames = ['y']\n+        ynames = [\"y\"]\n     else:  # for VAR\n-        ynames = ['y%d' % (i+1) for i in range(endog.shape[1])]\n+        ynames = [\"y%d\" % (i + 1) for i in range(endog.shape[1])]\n \n     return ynames\n \n@@ -628,17 +641,17 @@ def _make_exog_names(exog):\n         # assumes one constant in first or last position\n         # avoid exception if more than one constant\n         const_idx = exog_var.argmin()\n-        exog_names = ['x%d' % i for i in range(1, exog.shape[1])]\n-        exog_names.insert(const_idx, 'const')\n+        exog_names = [\"x%d\" % i for i in range(1, exog.shape[1])]\n+        exog_names.insert(const_idx, \"const\")\n     else:\n-        exog_names = ['x%d' % i for i in range(1, exog.shape[1]+1)]\n+        exog_names = [\"x%d\" % i for i in range(1, exog.shape[1] + 1)]\n \n     return exog_names\n \n \n-def handle_missing(endog, exog=None, missing='none', **kwargs):\n+def handle_missing(endog, exog=None, missing=\"none\", **kwargs):\n     klass = handle_data_class_factory(endog, exog)\n-    if missing == 'none':\n+    if missing == \"none\":\n         ret_dict = dict(endog=endog, exog=exog)\n         ret_dict.update(kwargs)\n         return ret_dict, None\n@@ -659,12 +672,13 @@ def handle_data_class_factory(endog, exog):\n     elif data_util._is_using_ndarray(endog, exog):\n         klass = ModelData\n     else:\n-        raise ValueError('unrecognized data structures: %s / %s' %\n-                         (type(endog), type(exog)))\n+        raise ValueError(\n+            \"unrecognized data structures: %s / %s\" % (type(endog), type(exog))\n+        )\n     return klass\n \n \n-def handle_data(endog, exog, missing='none', hasconst=None, **kwargs):\n+def handle_data(endog, exog, missing=\"none\", hasconst=None, **kwargs):\n     # deal with lists and tuples up-front\n     if isinstance(endog, (list, tuple)):\n         endog = np.asarray(endog)\n@@ -672,5 +686,4 @@ def handle_data(endog, exog, missing='none', hasconst=None, **kwargs):\n         exog = np.asarray(exog)\n \n     klass = handle_data_class_factory(endog, exog)\n-    return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n-                 **kwargs)\n+    return klass(endog, exog=exog, missing=missing, hasconst=hasconst, **kwargs)\n", "test_patch": "diff --git a/statsmodels/base/tests/test_data.py b/statsmodels/base/tests/test_data.py\nindex 870a971f46e..ea04a297a53 100644\n--- a/statsmodels/base/tests/test_data.py\n+++ b/statsmodels/base/tests/test_data.py\n@@ -1,21 +1,20 @@\n from statsmodels.compat.pandas import (\n-    assert_series_equal,\n     assert_frame_equal,\n+    assert_series_equal,\n     make_dataframe,\n )\n \n import numpy as np\n-from numpy.testing import assert_equal, assert_, assert_raises\n+from numpy.testing import assert_, assert_equal, assert_raises\n import pandas as pd\n import pytest\n \n from statsmodels.base import data as sm_data\n+from statsmodels.discrete.discrete_model import Logit\n from statsmodels.formula import handle_formula_data\n-from statsmodels.regression.linear_model import OLS\n-from statsmodels.genmod.generalized_linear_model import GLM\n from statsmodels.genmod import families\n-from statsmodels.discrete.discrete_model import Logit\n-\n+from statsmodels.genmod.generalized_linear_model import GLM\n+from statsmodels.regression.linear_model import OLS\n \n # FIXME: do not leave commented-out, enable or move/remove\n # class TestDates:\n@@ -28,6 +27,7 @@\n #        np.testing.assert_equal(data.wrap_output(self.dates_input, 'dates'),\n #                                self.dates_result)\n \n+\n class TestArrays:\n     @classmethod\n     def setup_class(cls):\n@@ -39,8 +39,8 @@ def setup_class(cls):\n         cls.col_result = cls.col_input = np.random.random(nvars)\n         cls.row_result = cls.row_input = np.random.random(nrows)\n         cls.cov_result = cls.cov_input = np.random.random((nvars, nvars))\n-        cls.xnames = ['const', 'x1', 'x2']\n-        cls.ynames = 'y'\n+        cls.xnames = [\"const\", \"x1\", \"x2\"]\n+        cls.ynames = \"y\"\n         cls.row_labels = None\n \n     def test_orig(self):\n@@ -55,12 +55,15 @@ def test_attach(self):\n         data = self.data\n         # this makes sure what the wrappers need work but not the wrapped\n         # results themselves\n-        np.testing.assert_equal(data.wrap_output(self.col_input, 'columns'),\n-                                self.col_result)\n-        np.testing.assert_equal(data.wrap_output(self.row_input, 'rows'),\n-                                self.row_result)\n-        np.testing.assert_equal(data.wrap_output(self.cov_input, 'cov'),\n-                                self.cov_result)\n+        np.testing.assert_equal(\n+            data.wrap_output(self.col_input, \"columns\"), self.col_result\n+        )\n+        np.testing.assert_equal(\n+            data.wrap_output(self.row_input, \"rows\"), self.row_result\n+        )\n+        np.testing.assert_equal(\n+            data.wrap_output(self.cov_input, \"cov\"), self.cov_result\n+        )\n \n     def test_names(self):\n         data = self.data\n@@ -95,8 +98,8 @@ def setup_class(cls):\n         exog = np.random.random(10)\n         cls.data = sm_data.handle_data(cls.endog, exog)\n         cls.exog = exog[:, None]\n-        cls.xnames = ['x1']\n-        cls.ynames = 'y'\n+        cls.xnames = [\"x1\"]\n+        cls.ynames = \"y\"\n \n     def test_orig(self):\n         np.testing.assert_equal(self.data.orig_endog, self.endog)\n@@ -106,26 +109,23 @@ def test_orig(self):\n class TestDataFrames(TestArrays):\n     @classmethod\n     def setup_class(cls):\n-        cls.endog = pd.DataFrame(np.random.random(10), columns=['y_1'])\n-        exog = pd.DataFrame(np.random.random((10, 2)),\n-                            columns=['x_1', 'x_2'])\n-        exog.insert(0, 'const', 1)\n+        cls.endog = pd.DataFrame(np.random.random(10), columns=[\"y_1\"])\n+        exog = pd.DataFrame(np.random.random((10, 2)), columns=[\"x_1\", \"x_2\"])\n+        exog.insert(0, \"const\", 1)\n         cls.exog = exog\n         cls.data = sm_data.handle_data(cls.endog, cls.exog)\n         nrows = 10\n         nvars = 3\n         cls.col_input = np.random.random(nvars)\n-        cls.col_result = pd.Series(cls.col_input,\n-                                   index=exog.columns)\n+        cls.col_result = pd.Series(cls.col_input, index=exog.columns)\n         cls.row_input = np.random.random(nrows)\n-        cls.row_result = pd.Series(cls.row_input,\n-                                   index=exog.index)\n+        cls.row_result = pd.Series(cls.row_input, index=exog.index)\n         cls.cov_input = np.random.random((nvars, nvars))\n-        cls.cov_result = pd.DataFrame(cls.cov_input,\n-                                      index=exog.columns,\n-                                      columns=exog.columns)\n-        cls.xnames = ['const', 'x_1', 'x_2']\n-        cls.ynames = 'y_1'\n+        cls.cov_result = pd.DataFrame(\n+            cls.cov_input, index=exog.columns, columns=exog.columns\n+        )\n+        cls.xnames = [\"const\", \"x_1\", \"x_2\"]\n+        cls.ynames = \"y_1\"\n         cls.row_labels = cls.exog.index\n \n     def test_orig(self):\n@@ -140,22 +140,21 @@ def test_attach(self):\n         data = self.data\n         # this makes sure what the wrappers need work but not the wrapped\n         # results themselves\n-        assert_series_equal(data.wrap_output(self.col_input, 'columns'),\n-                            self.col_result)\n-        assert_series_equal(data.wrap_output(self.row_input, 'rows'),\n-                            self.row_result)\n-        assert_frame_equal(data.wrap_output(self.cov_input, 'cov'),\n-                           self.cov_result)\n+        assert_series_equal(\n+            data.wrap_output(self.col_input, \"columns\"), self.col_result\n+        )\n+        assert_series_equal(data.wrap_output(self.row_input, \"rows\"), self.row_result)\n+        assert_frame_equal(data.wrap_output(self.cov_input, \"cov\"), self.cov_result)\n \n \n class TestDataFramesWithMultiIndex(TestDataFrames):\n     @classmethod\n     def setup_class(cls):\n-        cls.endog = pd.DataFrame(np.random.random(10), columns=['y_1'])\n-        mi = pd.MultiIndex.from_product([['x'], ['1', '2']])\n+        cls.endog = pd.DataFrame(np.random.random(10), columns=[\"y_1\"])\n+        mi = pd.MultiIndex.from_product([[\"x\"], [\"1\", \"2\"]])\n         exog = pd.DataFrame(np.random.random((10, 2)), columns=mi)\n-        exog_flattened_idx = pd.Index(['const', 'x_1', 'x_2'])\n-        exog.insert(0, 'const', 1)\n+        exog_flattened_idx = pd.Index([\"const\", \"x_1\", \"x_2\"])\n+        exog.insert(0, \"const\", 1)\n         cls.exog = exog\n         cls.data = sm_data.handle_data(cls.endog, cls.exog)\n         nrows = 10\n@@ -165,11 +164,11 @@ def setup_class(cls):\n         cls.row_input = np.random.random(nrows)\n         cls.row_result = pd.Series(cls.row_input, index=exog.index)\n         cls.cov_input = np.random.random((nvars, nvars))\n-        cls.cov_result = pd.DataFrame(cls.cov_input,\n-                                      index=exog_flattened_idx,\n-                                      columns=exog_flattened_idx)\n-        cls.xnames = ['const', 'x_1', 'x_2']\n-        cls.ynames = 'y_1'\n+        cls.cov_result = pd.DataFrame(\n+            cls.cov_input, index=exog_flattened_idx, columns=exog_flattened_idx\n+        )\n+        cls.xnames = [\"const\", \"x_1\", \"x_2\"]\n+        cls.ynames = \"y_1\"\n         cls.row_labels = cls.exog.index\n \n \n@@ -187,25 +186,22 @@ class TestListDataFrame(TestDataFrames):\n     def setup_class(cls):\n         cls.endog = np.random.random(10).tolist()\n \n-        exog = pd.DataFrame(np.random.random((10, 2)),\n-                            columns=['x_1', 'x_2'])\n-        exog.insert(0, 'const', 1)\n+        exog = pd.DataFrame(np.random.random((10, 2)), columns=[\"x_1\", \"x_2\"])\n+        exog.insert(0, \"const\", 1)\n         cls.exog = exog\n         cls.data = sm_data.handle_data(cls.endog, cls.exog)\n         nrows = 10\n         nvars = 3\n         cls.col_input = np.random.random(nvars)\n-        cls.col_result = pd.Series(cls.col_input,\n-                                   index=exog.columns)\n+        cls.col_result = pd.Series(cls.col_input, index=exog.columns)\n         cls.row_input = np.random.random(nrows)\n-        cls.row_result = pd.Series(cls.row_input,\n-                                   index=exog.index)\n+        cls.row_result = pd.Series(cls.row_input, index=exog.index)\n         cls.cov_input = np.random.random((nvars, nvars))\n-        cls.cov_result = pd.DataFrame(cls.cov_input,\n-                                      index=exog.columns,\n-                                      columns=exog.columns)\n-        cls.xnames = ['const', 'x_1', 'x_2']\n-        cls.ynames = 'y'\n+        cls.cov_result = pd.DataFrame(\n+            cls.cov_input, index=exog.columns, columns=exog.columns\n+        )\n+        cls.xnames = [\"const\", \"x_1\", \"x_2\"]\n+        cls.ynames = \"y\"\n         cls.row_labels = cls.exog.index\n \n     def test_endogexog(self):\n@@ -220,27 +216,24 @@ def test_orig(self):\n class TestDataFrameList(TestDataFrames):\n     @classmethod\n     def setup_class(cls):\n-        cls.endog = pd.DataFrame(np.random.random(10), columns=['y_1'])\n+        cls.endog = pd.DataFrame(np.random.random(10), columns=[\"y_1\"])\n \n-        exog = pd.DataFrame(np.random.random((10, 2)),\n-                            columns=['x1', 'x2'])\n-        exog.insert(0, 'const', 1)\n+        exog = pd.DataFrame(np.random.random((10, 2)), columns=[\"x1\", \"x2\"])\n+        exog.insert(0, \"const\", 1)\n         cls.exog = exog.values.tolist()\n         cls.data = sm_data.handle_data(cls.endog, cls.exog)\n         nrows = 10\n         nvars = 3\n         cls.col_input = np.random.random(nvars)\n-        cls.col_result = pd.Series(cls.col_input,\n-                                   index=exog.columns)\n+        cls.col_result = pd.Series(cls.col_input, index=exog.columns)\n         cls.row_input = np.random.random(nrows)\n-        cls.row_result = pd.Series(cls.row_input,\n-                                   index=exog.index)\n+        cls.row_result = pd.Series(cls.row_input, index=exog.index)\n         cls.cov_input = np.random.random((nvars, nvars))\n-        cls.cov_result = pd.DataFrame(cls.cov_input,\n-                                      index=exog.columns,\n-                                      columns=exog.columns)\n-        cls.xnames = ['const', 'x1', 'x2']\n-        cls.ynames = 'y_1'\n+        cls.cov_result = pd.DataFrame(\n+            cls.cov_input, index=exog.columns, columns=exog.columns\n+        )\n+        cls.xnames = [\"const\", \"x1\", \"x2\"]\n+        cls.ynames = \"y_1\"\n         cls.row_labels = cls.endog.index\n \n     def test_endogexog(self):\n@@ -257,25 +250,22 @@ class TestArrayDataFrame(TestDataFrames):\n     def setup_class(cls):\n         cls.endog = np.random.random(10)\n \n-        exog = pd.DataFrame(np.random.random((10, 2)),\n-                            columns=['x_1', 'x_2'])\n-        exog.insert(0, 'const', 1)\n+        exog = pd.DataFrame(np.random.random((10, 2)), columns=[\"x_1\", \"x_2\"])\n+        exog.insert(0, \"const\", 1)\n         cls.exog = exog\n         cls.data = sm_data.handle_data(cls.endog, exog)\n         nrows = 10\n         nvars = 3\n         cls.col_input = np.random.random(nvars)\n-        cls.col_result = pd.Series(cls.col_input,\n-                                   index=exog.columns)\n+        cls.col_result = pd.Series(cls.col_input, index=exog.columns)\n         cls.row_input = np.random.random(nrows)\n-        cls.row_result = pd.Series(cls.row_input,\n-                                   index=exog.index)\n+        cls.row_result = pd.Series(cls.row_input, index=exog.index)\n         cls.cov_input = np.random.random((nvars, nvars))\n-        cls.cov_result = pd.DataFrame(cls.cov_input,\n-                                      index=exog.columns,\n-                                      columns=exog.columns)\n-        cls.xnames = ['const', 'x_1', 'x_2']\n-        cls.ynames = 'y'\n+        cls.cov_result = pd.DataFrame(\n+            cls.cov_input, index=exog.columns, columns=exog.columns\n+        )\n+        cls.xnames = [\"const\", \"x_1\", \"x_2\"]\n+        cls.ynames = \"y\"\n         cls.row_labels = cls.exog.index\n \n     def test_endogexog(self):\n@@ -290,27 +280,26 @@ def test_orig(self):\n class TestDataFrameArray(TestDataFrames):\n     @classmethod\n     def setup_class(cls):\n-        cls.endog = pd.DataFrame(np.random.random(10), columns=['y_1'])\n+        cls.endog = pd.DataFrame(np.random.random(10), columns=[\"y_1\"])\n \n-        exog = pd.DataFrame(np.random.random((10, 2)),\n-                            columns=['x1', 'x2'])  # names mimic defaults\n-        exog.insert(0, 'const', 1)\n+        exog = pd.DataFrame(\n+            np.random.random((10, 2)), columns=[\"x1\", \"x2\"]\n+        )  # names mimic defaults\n+        exog.insert(0, \"const\", 1)\n         cls.exog = exog.values\n         cls.data = sm_data.handle_data(cls.endog, cls.exog)\n         nrows = 10\n         nvars = 3\n         cls.col_input = np.random.random(nvars)\n-        cls.col_result = pd.Series(cls.col_input,\n-                                   index=exog.columns)\n+        cls.col_result = pd.Series(cls.col_input, index=exog.columns)\n         cls.row_input = np.random.random(nrows)\n-        cls.row_result = pd.Series(cls.row_input,\n-                                   index=exog.index)\n+        cls.row_result = pd.Series(cls.row_input, index=exog.index)\n         cls.cov_input = np.random.random((nvars, nvars))\n-        cls.cov_result = pd.DataFrame(cls.cov_input,\n-                                      index=exog.columns,\n-                                      columns=exog.columns)\n-        cls.xnames = ['const', 'x1', 'x2']\n-        cls.ynames = 'y_1'\n+        cls.cov_result = pd.DataFrame(\n+            cls.cov_input, index=exog.columns, columns=exog.columns\n+        )\n+        cls.xnames = [\"const\", \"x1\", \"x2\"]\n+        cls.ynames = \"y_1\"\n         cls.row_labels = cls.endog.index\n \n     def test_endogexog(self):\n@@ -325,27 +314,24 @@ def test_orig(self):\n class TestSeriesDataFrame(TestDataFrames):\n     @classmethod\n     def setup_class(cls):\n-        cls.endog = pd.Series(np.random.random(10), name='y_1')\n+        cls.endog = pd.Series(np.random.random(10), name=\"y_1\")\n \n-        exog = pd.DataFrame(np.random.random((10, 2)),\n-                            columns=['x_1', 'x_2'])\n-        exog.insert(0, 'const', 1)\n+        exog = pd.DataFrame(np.random.random((10, 2)), columns=[\"x_1\", \"x_2\"])\n+        exog.insert(0, \"const\", 1)\n         cls.exog = exog\n         cls.data = sm_data.handle_data(cls.endog, cls.exog)\n         nrows = 10\n         nvars = 3\n         cls.col_input = np.random.random(nvars)\n-        cls.col_result = pd.Series(cls.col_input,\n-                                   index=exog.columns)\n+        cls.col_result = pd.Series(cls.col_input, index=exog.columns)\n         cls.row_input = np.random.random(nrows)\n-        cls.row_result = pd.Series(cls.row_input,\n-                                   index=exog.index)\n+        cls.row_result = pd.Series(cls.row_input, index=exog.index)\n         cls.cov_input = np.random.random((nvars, nvars))\n-        cls.cov_result = pd.DataFrame(cls.cov_input,\n-                                      index=exog.columns,\n-                                      columns=exog.columns)\n-        cls.xnames = ['const', 'x_1', 'x_2']\n-        cls.ynames = 'y_1'\n+        cls.cov_result = pd.DataFrame(\n+            cls.cov_input, index=exog.columns, columns=exog.columns\n+        )\n+        cls.xnames = [\"const\", \"x_1\", \"x_2\"]\n+        cls.ynames = \"y_1\"\n         cls.row_labels = cls.exog.index\n \n     def test_orig(self):\n@@ -356,25 +342,23 @@ def test_orig(self):\n class TestSeriesSeries(TestDataFrames):\n     @classmethod\n     def setup_class(cls):\n-        cls.endog = pd.Series(np.random.random(10), name='y_1')\n+        cls.endog = pd.Series(np.random.random(10), name=\"y_1\")\n \n-        exog = pd.Series(np.random.random(10), name='x_1')\n+        exog = pd.Series(np.random.random(10), name=\"x_1\")\n         cls.exog = exog\n         cls.data = sm_data.handle_data(cls.endog, cls.exog)\n         nrows = 10\n         nvars = 1\n         cls.col_input = np.random.random(nvars)\n-        cls.col_result = pd.Series(cls.col_input,\n-                                   index=[exog.name])\n+        cls.col_result = pd.Series(cls.col_input, index=[exog.name])\n         cls.row_input = np.random.random(nrows)\n-        cls.row_result = pd.Series(cls.row_input,\n-                                   index=exog.index)\n+        cls.row_result = pd.Series(cls.row_input, index=exog.index)\n         cls.cov_input = np.random.random((nvars, nvars))\n-        cls.cov_result = pd.DataFrame(cls.cov_input,\n-                                      index=[exog.name],\n-                                      columns=[exog.name])\n-        cls.xnames = ['x_1']\n-        cls.ynames = 'y_1'\n+        cls.cov_result = pd.DataFrame(\n+            cls.cov_input, index=[exog.name], columns=[exog.name]\n+        )\n+        cls.xnames = [\"x_1\"]\n+        cls.ynames = \"y_1\"\n         cls.row_labels = cls.exog.index\n \n     def test_orig(self):\n@@ -392,14 +376,14 @@ def test_alignment():\n \n     d = load_pandas().data\n     # growth rates\n-    gs_l_realinv = 400 * np.log(d['realinv']).diff().dropna()\n-    gs_l_realgdp = 400 * np.log(d['realgdp']).diff().dropna()\n-    lint = d['realint'][:-1]  # incorrect indexing for test purposes\n+    gs_l_realinv = 400 * np.log(d[\"realinv\"]).diff().dropna()\n+    gs_l_realgdp = 400 * np.log(d[\"realgdp\"]).diff().dropna()\n+    lint = d[\"realint\"][:-1]  # incorrect indexing for test purposes\n \n     endog = gs_l_realinv\n \n     # re-index because they will not conform to lint\n-    realgdp = gs_l_realgdp.reindex(lint.index, method='bfill')\n+    realgdp = gs_l_realgdp.reindex(lint.index, method=\"bfill\")\n     data = dict(const=np.ones_like(lint), lrealgdp=realgdp, lint=lint)\n     exog = pd.DataFrame(data)\n \n@@ -421,74 +405,77 @@ def setup_class(cls):\n         cls.cov_result = cls.cov_input = np.random.random((nvars, nvars))\n         cls.cov_eq_result = cls.cov_eq_input = np.random.random((neqs, neqs))\n         cls.col_eq_result = cls.col_eq_input = np.array((neqs, nvars))\n-        cls.xnames = ['const', 'x1', 'x2']\n-        cls.ynames = ['y1', 'y2', 'y3', 'y4']\n+        cls.xnames = [\"const\", \"x1\", \"x2\"]\n+        cls.ynames = [\"y1\", \"y2\", \"y3\", \"y4\"]\n         cls.row_labels = None\n \n     def test_attach(self):\n         data = self.data\n         # this makes sure what the wrappers need work but not the wrapped\n         # results themselves\n-        np.testing.assert_equal(data.wrap_output(self.col_input, 'columns'),\n-                                self.col_result)\n-        np.testing.assert_equal(data.wrap_output(self.row_input, 'rows'),\n-                                self.row_result)\n-        np.testing.assert_equal(data.wrap_output(self.cov_input, 'cov'),\n-                                self.cov_result)\n-        np.testing.assert_equal(data.wrap_output(self.cov_eq_input, 'cov_eq'),\n-                                self.cov_eq_result)\n-        np.testing.assert_equal(data.wrap_output(self.col_eq_input,\n-                                                 'columns_eq'),\n-                                self.col_eq_result)\n+        np.testing.assert_equal(\n+            data.wrap_output(self.col_input, \"columns\"), self.col_result\n+        )\n+        np.testing.assert_equal(\n+            data.wrap_output(self.row_input, \"rows\"), self.row_result\n+        )\n+        np.testing.assert_equal(\n+            data.wrap_output(self.cov_input, \"cov\"), self.cov_result\n+        )\n+        np.testing.assert_equal(\n+            data.wrap_output(self.cov_eq_input, \"cov_eq\"), self.cov_eq_result\n+        )\n+        np.testing.assert_equal(\n+            data.wrap_output(self.col_eq_input, \"columns_eq\"), self.col_eq_result\n+        )\n \n \n class TestMultipleEqsDataFrames(TestDataFrames):\n     @classmethod\n     def setup_class(cls):\n-        cls.endog = endog = pd.DataFrame(np.random.random((10, 4)),\n-                                         columns=['y_1', 'y_2', 'y_3', 'y_4'])\n-        exog = pd.DataFrame(np.random.random((10, 2)),\n-                            columns=['x_1', 'x_2'])\n-        exog.insert(0, 'const', 1)\n+        cls.endog = endog = pd.DataFrame(\n+            np.random.random((10, 4)), columns=[\"y_1\", \"y_2\", \"y_3\", \"y_4\"]\n+        )\n+        exog = pd.DataFrame(np.random.random((10, 2)), columns=[\"x_1\", \"x_2\"])\n+        exog.insert(0, \"const\", 1)\n         cls.exog = exog\n         cls.data = sm_data.handle_data(cls.endog, cls.exog)\n         nrows = 10\n         nvars = 3\n         neqs = 4\n         cls.col_input = np.random.random(nvars)\n-        cls.col_result = pd.Series(cls.col_input,\n-                                   index=exog.columns)\n+        cls.col_result = pd.Series(cls.col_input, index=exog.columns)\n         cls.row_input = np.random.random(nrows)\n-        cls.row_result = pd.Series(cls.row_input,\n-                                   index=exog.index)\n+        cls.row_result = pd.Series(cls.row_input, index=exog.index)\n         cls.cov_input = np.random.random((nvars, nvars))\n-        cls.cov_result = pd.DataFrame(cls.cov_input,\n-                                      index=exog.columns,\n-                                      columns=exog.columns)\n+        cls.cov_result = pd.DataFrame(\n+            cls.cov_input, index=exog.columns, columns=exog.columns\n+        )\n         cls.cov_eq_input = np.random.random((neqs, neqs))\n-        cls.cov_eq_result = pd.DataFrame(cls.cov_eq_input,\n-                                         index=endog.columns,\n-                                         columns=endog.columns)\n+        cls.cov_eq_result = pd.DataFrame(\n+            cls.cov_eq_input, index=endog.columns, columns=endog.columns\n+        )\n         cls.col_eq_input = np.random.random((nvars, neqs))\n-        cls.col_eq_result = pd.DataFrame(cls.col_eq_input,\n-                                         index=exog.columns,\n-                                         columns=endog.columns)\n-        cls.xnames = ['const', 'x_1', 'x_2']\n-        cls.ynames = ['y_1', 'y_2', 'y_3', 'y_4']\n+        cls.col_eq_result = pd.DataFrame(\n+            cls.col_eq_input, index=exog.columns, columns=endog.columns\n+        )\n+        cls.xnames = [\"const\", \"x_1\", \"x_2\"]\n+        cls.ynames = [\"y_1\", \"y_2\", \"y_3\", \"y_4\"]\n         cls.row_labels = cls.exog.index\n \n     def test_attach(self):\n         data = self.data\n-        assert_series_equal(data.wrap_output(self.col_input, 'columns'),\n-                            self.col_result)\n-        assert_series_equal(data.wrap_output(self.row_input, 'rows'),\n-                            self.row_result)\n-        assert_frame_equal(data.wrap_output(self.cov_input, 'cov'),\n-                           self.cov_result)\n-        assert_frame_equal(data.wrap_output(self.cov_eq_input, 'cov_eq'),\n-                           self.cov_eq_result)\n-        assert_frame_equal(data.wrap_output(self.col_eq_input, 'columns_eq'),\n-                           self.col_eq_result)\n+        assert_series_equal(\n+            data.wrap_output(self.col_input, \"columns\"), self.col_result\n+        )\n+        assert_series_equal(data.wrap_output(self.row_input, \"rows\"), self.row_result)\n+        assert_frame_equal(data.wrap_output(self.cov_input, \"cov\"), self.cov_result)\n+        assert_frame_equal(\n+            data.wrap_output(self.cov_eq_input, \"cov_eq\"), self.cov_eq_result\n+        )\n+        assert_frame_equal(\n+            data.wrap_output(self.col_eq_input, \"columns_eq\"), self.col_eq_result\n+        )\n \n \n class TestMissingArray:\n@@ -504,13 +491,12 @@ def setup_class(cls):\n     @pytest.mark.smoke\n     def test_raise_no_missing(self):\n         # GH#1700\n-        sm_data.handle_data(np.random.random(20), np.random.random((20, 2)),\n-                            'raise')\n+        sm_data.handle_data(np.random.random(20), np.random.random((20, 2)), \"raise\")\n \n     def test_raise(self):\n         with pytest.raises(Exception):\n             # TODO: be more specific about exception\n-            sm_data.handle_data(self.y, self.X, 'raise')\n+            sm_data.handle_data(self.y, self.X, \"raise\")\n \n     def test_drop(self):\n         y = self.y\n@@ -519,12 +505,12 @@ def test_drop(self):\n         idx = ~np.isnan(combined).any(axis=1)\n         y = y[idx]\n         X = X[idx]\n-        data = sm_data.handle_data(self.y, self.X, 'drop')\n+        data = sm_data.handle_data(self.y, self.X, \"drop\")\n         np.testing.assert_array_equal(data.endog, y)\n         np.testing.assert_array_equal(data.exog, X)\n \n     def test_none(self):\n-        data = sm_data.handle_data(self.y, self.X, 'none', hasconst=False)\n+        data = sm_data.handle_data(self.y, self.X, \"none\", hasconst=False)\n         np.testing.assert_array_equal(data.endog, self.y)\n         np.testing.assert_array_equal(data.exog, self.X)\n         assert data.k_constant == 0\n@@ -532,31 +518,31 @@ def test_none(self):\n     def test_endog_only_raise(self):\n         with pytest.raises(Exception):\n             # TODO: be more specific about exception\n-            sm_data.handle_data(self.y, None, 'raise')\n+            sm_data.handle_data(self.y, None, \"raise\")\n \n     def test_endog_only_drop(self):\n         y = self.y\n         y = y[~np.isnan(y)]\n-        data = sm_data.handle_data(self.y, None, 'drop')\n+        data = sm_data.handle_data(self.y, None, \"drop\")\n         np.testing.assert_array_equal(data.endog, y)\n \n     def test_mv_endog(self):\n         y = self.X\n         y = y[~np.isnan(y).any(axis=1)]\n-        data = sm_data.handle_data(self.X, None, 'drop')\n+        data = sm_data.handle_data(self.X, None, \"drop\")\n         np.testing.assert_array_equal(data.endog, y)\n \n     def test_extra_kwargs_2d(self):\n         sigma = np.random.random((25, 25))\n         sigma = sigma + sigma.T - np.diag(np.diag(sigma))\n-        data = sm_data.handle_data(self.y, self.X, 'drop', sigma=sigma)\n+        data = sm_data.handle_data(self.y, self.X, \"drop\", sigma=sigma)\n         idx = ~np.isnan(np.c_[self.y, self.X]).any(axis=1)\n         sigma = sigma[idx][:, idx]\n         np.testing.assert_array_equal(data.sigma, sigma)\n \n     def test_extra_kwargs_1d(self):\n         weights = np.random.random(25)\n-        data = sm_data.handle_data(self.y, self.X, 'drop', weights=weights)\n+        data = sm_data.handle_data(self.y, self.X, \"drop\", weights=weights)\n         idx = ~np.isnan(np.c_[self.y, self.X]).any(axis=1)\n         weights = weights[idx]\n         np.testing.assert_array_equal(data.weights, weights)\n@@ -576,14 +562,16 @@ def setup_class(cls):\n     @pytest.mark.smoke\n     def test_raise_no_missing(self):\n         # GH#1700\n-        sm_data.handle_data(pd.Series(np.random.random(20)),\n-                            pd.DataFrame(np.random.random((20, 2))),\n-                            'raise')\n+        sm_data.handle_data(\n+            pd.Series(np.random.random(20)),\n+            pd.DataFrame(np.random.random((20, 2))),\n+            \"raise\",\n+        )\n \n     def test_raise(self):\n         with pytest.raises(Exception):\n             # TODO: be more specific about exception\n-            sm_data.handle_data(self.y, self.X, 'raise')\n+            sm_data.handle_data(self.y, self.X, \"raise\")\n \n     def test_drop(self):\n         y = self.y\n@@ -592,14 +580,14 @@ def test_drop(self):\n         idx = ~np.isnan(combined).any(axis=1)\n         y = y.loc[idx]\n         X = X.loc[idx]\n-        data = sm_data.handle_data(self.y, self.X, 'drop')\n+        data = sm_data.handle_data(self.y, self.X, \"drop\")\n         np.testing.assert_array_equal(data.endog, y.values)\n         assert_series_equal(data.orig_endog, self.y.loc[idx])\n         np.testing.assert_array_equal(data.exog, X.values)\n         assert_frame_equal(data.orig_exog, self.X.loc[idx])\n \n     def test_none(self):\n-        data = sm_data.handle_data(self.y, self.X, 'none', hasconst=False)\n+        data = sm_data.handle_data(self.y, self.X, \"none\", hasconst=False)\n         np.testing.assert_array_equal(data.endog, self.y.values)\n         np.testing.assert_array_equal(data.exog, self.X.values)\n         assert data.k_constant == 0\n@@ -607,24 +595,48 @@ def test_none(self):\n     def test_endog_only_raise(self):\n         with pytest.raises(Exception):\n             # TODO: be more specific about exception\n-            sm_data.handle_data(self.y, None, 'raise')\n+            sm_data.handle_data(self.y, None, \"raise\")\n \n     def test_endog_only_drop(self):\n         y = self.y\n         y = y.dropna()\n-        data = sm_data.handle_data(self.y, None, 'drop')\n+        data = sm_data.handle_data(self.y, None, \"drop\")\n         np.testing.assert_array_equal(data.endog, y.values)\n \n     def test_mv_endog(self):\n         y = self.X\n         y = y.loc[~np.isnan(y.values).any(axis=1)]\n-        data = sm_data.handle_data(self.X, None, 'drop')\n+        data = sm_data.handle_data(self.X, None, \"drop\")\n         np.testing.assert_array_equal(data.endog, y.values)\n \n     def test_labels(self):\n-        labels = pd.Index([0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15,\n-                           16, 17, 18, 19, 20, 21, 22, 23, 24])\n-        data = sm_data.handle_data(self.y, self.X, 'drop')\n+        labels = pd.Index(\n+            [\n+                0,\n+                1,\n+                3,\n+                4,\n+                5,\n+                6,\n+                7,\n+                8,\n+                9,\n+                11,\n+                12,\n+                13,\n+                15,\n+                16,\n+                17,\n+                18,\n+                19,\n+                20,\n+                21,\n+                22,\n+                23,\n+                24,\n+            ]\n+        )\n+        data = sm_data.handle_data(self.y, self.X, \"drop\")\n         np.testing.assert_(data.row_labels.equals(labels))\n \n \n@@ -632,18 +644,19 @@ class TestConstant:\n     @classmethod\n     def setup_class(cls):\n         from statsmodels.datasets.longley import load_pandas\n+\n         cls.data = load_pandas()\n \n     def test_array_constant(self):\n         exog = self.data.exog.copy()\n-        exog['const'] = 1\n+        exog[\"const\"] = 1\n         data = sm_data.handle_data(self.data.endog.values, exog.values)\n         np.testing.assert_equal(data.k_constant, 1)\n         np.testing.assert_equal(data.const_idx, 6)\n \n     def test_pandas_constant(self):\n         exog = self.data.exog.copy()\n-        exog['const'] = 1\n+        exog[\"const\"] = 1\n         data = sm_data.handle_data(self.data.endog, exog)\n         np.testing.assert_equal(data.k_constant, 1)\n         np.testing.assert_equal(data.const_idx, 6)\n@@ -668,57 +681,57 @@ def test_pandas(self):\n         df = make_dataframe()\n         df.iloc[[2, 5, 10], [2, 3, 1]] = np.nan\n         y, X = df[df.columns[0]], df[df.columns[1:]]\n-        data, _ = sm_data.handle_missing(y, X, missing='drop')\n+        data, _ = sm_data.handle_missing(y, X, missing=\"drop\")\n \n         df = df.dropna()\n         y_exp, X_exp = df[df.columns[0]], df[df.columns[1:]]\n-        assert_frame_equal(data['exog'], X_exp)\n-        assert_series_equal(data['endog'], y_exp)\n+        assert_frame_equal(data[\"exog\"], X_exp)\n+        assert_series_equal(data[\"endog\"], y_exp)\n \n     def test_arrays(self):\n         arr = np.random.randn(20, 4)\n         arr[[2, 5, 10], [2, 3, 1]] = np.nan\n         y, X = arr[:, 0], arr[:, 1:]\n-        data, _ = sm_data.handle_missing(y, X, missing='drop')\n+        data, _ = sm_data.handle_missing(y, X, missing=\"drop\")\n \n         bools_mask = np.ones(20, dtype=bool)\n         bools_mask[[2, 5, 10]] = False\n         y_exp = arr[bools_mask, 0]\n         X_exp = arr[bools_mask, 1:]\n-        np.testing.assert_array_equal(data['endog'], y_exp)\n-        np.testing.assert_array_equal(data['exog'], X_exp)\n+        np.testing.assert_array_equal(data[\"endog\"], y_exp)\n+        np.testing.assert_array_equal(data[\"exog\"], X_exp)\n \n     def test_pandas_array(self):\n         df = make_dataframe()\n         df.iloc[[2, 5, 10], [2, 3, 1]] = np.nan\n         y, X = df[df.columns[0]], df[df.columns[1:]].values\n-        data, _ = sm_data.handle_missing(y, X, missing='drop')\n+        data, _ = sm_data.handle_missing(y, X, missing=\"drop\")\n \n         df = df.dropna()\n         y_exp, X_exp = df[df.columns[0]], df[df.columns[1:]].values\n-        np.testing.assert_array_equal(data['exog'], X_exp)\n-        assert_series_equal(data['endog'], y_exp)\n+        np.testing.assert_array_equal(data[\"exog\"], X_exp)\n+        assert_series_equal(data[\"endog\"], y_exp)\n \n     def test_array_pandas(self):\n         df = make_dataframe()\n         df.iloc[[2, 5, 10], [2, 3, 1]] = np.nan\n         y, X = df[df.columns[0]].values, df[df.columns[1:]]\n-        data, _ = sm_data.handle_missing(y, X, missing='drop')\n+        data, _ = sm_data.handle_missing(y, X, missing=\"drop\")\n \n         df = df.dropna()\n         y_exp, X_exp = df[df.columns[0]].values, df[df.columns[1:]]\n-        assert_frame_equal(data['exog'], X_exp)\n-        np.testing.assert_array_equal(data['endog'], y_exp)\n+        assert_frame_equal(data[\"exog\"], X_exp)\n+        np.testing.assert_array_equal(data[\"endog\"], y_exp)\n \n     def test_noop(self):\n         df = make_dataframe()\n         df.iloc[[2, 5, 10], [2, 3, 1]] = np.nan\n         y, X = df[df.columns[0]], df[df.columns[1:]]\n-        data, _ = sm_data.handle_missing(y, X, missing='none')\n+        data, _ = sm_data.handle_missing(y, X, missing=\"none\")\n \n         y_exp, X_exp = df[df.columns[0]], df[df.columns[1:]]\n-        assert_frame_equal(data['exog'], X_exp)\n-        assert_series_equal(data['endog'], y_exp)\n+        assert_frame_equal(data[\"exog\"], X_exp)\n+        assert_series_equal(data[\"endog\"], y_exp)\n \n \n class CheckHasConstant:\n@@ -734,7 +747,7 @@ def test_hasconst(self):\n                 assert_equal(mod.data.const_idx, result[1])\n \n             # extra check after fit, some models raise on singular\n-            fit_kwds = getattr(self, 'fit_kwds', {})\n+            fit_kwds = getattr(self, \"fit_kwds\", {})\n             try:\n                 res = mod.fit(**fit_kwds)\n             except np.linalg.LinAlgError:\n@@ -751,8 +764,7 @@ def setup_class(cls):\n         cls.y_bin = (cls.y_c > 0).astype(int)\n         x1 = np.column_stack((np.ones(20), np.zeros(20)))\n         result1 = (1, 0)\n-        x2 = np.column_stack((np.arange(20) < 10.5,\n-                              np.arange(20) > 10.5)).astype(float)\n+        x2 = np.column_stack((np.arange(20) < 10.5, np.arange(20) > 10.5)).astype(float)\n         result2 = (1, None)\n         x3 = np.column_stack((np.arange(20), np.zeros(20)))\n         result3 = (0, None)\n@@ -765,18 +777,27 @@ def setup_class(cls):\n         x5c = np.column_stack((np.arange(20), np.ones((20, 3)) * [0.5, 1, 1]))\n         result5c = (1, 2)\n         # implicit and zero column\n-        x6 = np.column_stack((np.arange(20) < 10.5,\n-                              np.arange(20) > 10.5,\n-                              np.zeros(20))).astype(float)\n+        x6 = np.column_stack(\n+            (np.arange(20) < 10.5, np.arange(20) > 10.5, np.zeros(20))\n+        ).astype(float)\n         result6 = (1, None)\n-        x7 = np.column_stack((np.arange(20) < 10.5,\n-                              np.arange(20) > 10.5,\n-                              np.zeros((20, 2)))).astype(float)\n+        x7 = np.column_stack(\n+            (np.arange(20) < 10.5, np.arange(20) > 10.5, np.zeros((20, 2)))\n+        ).astype(float)\n         result7 = (1, None)\n \n         cls.exogs = (x1, x2, x3, x4, x5, x5b, x5c, x6, x7)\n-        cls.results = (result1, result2, result3, result4, result5, result5b,\n-                       result5c, result6, result7)\n+        cls.results = (\n+            result1,\n+            result2,\n+            result3,\n+            result4,\n+            result5,\n+            result5b,\n+            result5c,\n+            result6,\n+            result7,\n+        )\n         cls._initialize()\n \n \n@@ -806,7 +827,7 @@ class TestHasConstantLogit(CheckHasConstant):\n     def _initialize(cls):\n         cls.mod = Logit\n         cls.y = cls.y_bin\n-        cls.fit_kwds = {'disp': False}\n+        cls.fit_kwds = {\"disp\": False}\n \n \n def test_dtype_object():\n@@ -814,12 +835,24 @@ def test_dtype_object():\n \n     X = np.random.random((40, 2))\n     df = pd.DataFrame(X)\n-    df[2] = np.random.randint(2, size=40).astype('object')\n-    df['constant'] = 1\n+    df[2] = np.random.randint(2, size=40).astype(\"object\")\n+    df[\"constant\"] = 1\n \n     y = pd.Series(np.random.randint(2, size=40))\n+    out = sm_data.handle_data(y, df)\n+    assert isinstance(out, sm_data.PandasData)\n+    assert_equal(out.endog, np.array(y))\n+    assert_equal(out.exog, np.array(df))\n+\n \n-    np.testing.assert_raises(ValueError, sm_data.handle_data, y, df)\n+def test_dtype_actual_object():\n+    X = np.random.random((40, 2))\n+    df = pd.DataFrame(X)\n+    df[2] = np.random.randint(2, size=40).astype(\"object\")\n+    df[\"constant\"] = \"A\"\n+    y = pd.Series(np.random.randint(2, size=40))\n+    with pytest.raises(ValueError):\n+        sm_data.handle_data(y, df)\n \n \n def test_formula_missing_extra_arrays():\n@@ -848,59 +881,62 @@ def test_formula_missing_extra_arrays():\n \n     weights_wrong_size = np.random.randn(12)\n \n-    data = {'y': y,\n-            'X': X,\n-            'y_missing': y_missing,\n-            'X_missing': X_missing,\n-            'weights': weights,\n-            'weights_missing': weights_missing}\n+    data = {\n+        \"y\": y,\n+        \"X\": X,\n+        \"y_missing\": y_missing,\n+        \"X_missing\": X_missing,\n+        \"weights\": weights,\n+        \"weights_missing\": weights_missing,\n+    }\n     data = pd.DataFrame.from_dict(data)\n-    data['constant'] = 1\n+    data[\"constant\"] = 1\n \n-    formula = 'y_missing ~ X_missing'\n+    formula = \"y_missing ~ X_missing\"\n \n-    ((endog, exog),\n-     missing_idx, design_info) = handle_formula_data(data, None, formula,\n-                                                     depth=2,\n-                                                     missing='drop')\n+    ((endog, exog), missing_idx, design_info) = handle_formula_data(\n+        data, None, formula, depth=2, missing=\"drop\"\n+    )\n \n-    kwargs = {'missing_idx': missing_idx, 'missing': 'drop',\n-              'weights': data['weights_missing']}\n+    kwargs = {\n+        \"missing_idx\": missing_idx,\n+        \"missing\": \"drop\",\n+        \"weights\": data[\"weights_missing\"],\n+    }\n \n     model_data = sm_data.handle_data(endog, exog, **kwargs)\n     data_nona = data.dropna()\n-    assert_equal(data_nona['y'].values, model_data.endog)\n-    assert_equal(data_nona[['constant', 'X']].values, model_data.exog)\n-    assert_equal(data_nona['weights'].values, model_data.weights)\n+    assert_equal(data_nona[\"y\"].values, model_data.endog)\n+    assert_equal(data_nona[[\"constant\", \"X\"]].values, model_data.exog)\n+    assert_equal(data_nona[\"weights\"].values, model_data.weights)\n \n-    tmp = handle_formula_data(data, None, formula, depth=2, missing='drop')\n+    tmp = handle_formula_data(data, None, formula, depth=2, missing=\"drop\")\n     (endog, exog), missing_idx, design_info = tmp\n     weights_2d = np.random.randn(10, 10)\n-    weights_2d[[8, 7], [7, 8]] = np.nan   # symmetric missing values\n-    kwargs.update({'weights': weights_2d,\n-                   'missing_idx': missing_idx})\n+    weights_2d[[8, 7], [7, 8]] = np.nan  # symmetric missing values\n+    kwargs.update({\"weights\": weights_2d, \"missing_idx\": missing_idx})\n \n     model_data2 = sm_data.handle_data(endog, exog, **kwargs)\n \n     good_idx = [0, 4, 6, 9]\n-    assert_equal(data.loc[good_idx, 'y'], model_data2.endog)\n-    assert_equal(data.loc[good_idx, ['constant', 'X']], model_data2.exog)\n+    assert_equal(data.loc[good_idx, \"y\"], model_data2.endog)\n+    assert_equal(data.loc[good_idx, [\"constant\", \"X\"]], model_data2.exog)\n     assert_equal(weights_2d[good_idx][:, good_idx], model_data2.weights)\n \n-    tmp = handle_formula_data(data, None, formula, depth=2, missing='drop')\n+    tmp = handle_formula_data(data, None, formula, depth=2, missing=\"drop\")\n     (endog, exog), missing_idx, design_info = tmp\n \n-    kwargs.update({'weights': weights_wrong_size,\n-                   'missing_idx': missing_idx})\n+    kwargs.update({\"weights\": weights_wrong_size, \"missing_idx\": missing_idx})\n     assert_raises(ValueError, sm_data.handle_data, endog, exog, **kwargs)\n \n \n def test_raise_nonfinite_exog():\n     # we raise now in the has constant check before hitting the linear algebra\n     from statsmodels.tools.sm_exceptions import MissingDataError\n-    x = np.arange(10)[:, None]**([0., 1.])\n+\n+    x = np.arange(10)[:, None] ** ([0.0, 1.0])\n     # random numbers for y\n-    y = np.array([-0.6, -0.1, 0., -0.7, -0.5, 0.5, 0.1, -0.8, -2., 1.1])\n+    y = np.array([-0.6, -0.1, 0.0, -0.7, -0.5, 0.5, 0.1, -0.8, -2.0, 1.1])\n \n     x[1, 1] = np.inf\n     assert_raises(MissingDataError, OLS, y, x)\n", "problem_statement": "more reliable casting of pandas data\n- [ ] quick fix to #9205 \r\n- [ ] tests added / passed. \r\n- [x] code/documentation is well formatted.  \r\n- [x] properly formatted commit message. See \r\n      [NumPy's guide](https://docs.scipy.org/doc/numpy-1.15.1/dev/gitwash/development_workflow.html#writing-the-commit-message). \r\n\r\nNote: Only one test fails, in a particular code path that avoids data casting.\r\n```python\r\n    def test_dtype_object():\r\n        # see GH#880\r\n    \r\n        X = np.random.random((40, 2))\r\n        df = pd.DataFrame(X)\r\n        df[2] = np.random.randint(2, size=40).astype('object')\r\n        df['constant'] = 1\r\n    \r\n        y = pd.Series(np.random.randint(2, size=40))\r\n    \r\n>       np.testing.assert_raises(ValueError, sm_data.handle_data, y, df)\r\n```\r\n\r\n<details>\r\n\r\n\r\n**Notes**:\r\n\r\n* It is essential that you add a test when making code changes. Tests are not \r\n  needed for doc changes.\r\n* When adding a new function, test values should usually be verified in another package (e.g., R/SAS/Stata).\r\n* When fixing a bug, you must add a test that would produce the bug in main and\r\n  then show that it is fixed with the new code.\r\n* New code additions must be well formatted. Changes should pass flake8. If on Linux or OSX, you can\r\n  verify you changes are well formatted by running \r\n  ```\r\n  git diff upstream/main -u -- \"*.py\" | flake8 --diff --isolated\r\n  ```\r\n  assuming `flake8` is installed. This command is also available on Windows \r\n  using the Windows System for Linux once `flake8` is installed in the \r\n  local Linux environment. While passing this test is not required, it is good practice and it help \r\n  improve code quality in `statsmodels`.\r\n* Docstring additions must render correctly, including escapes and LaTeX.\r\n\r\n</details>\r\n\n", "hints_text": "", "created_at": "2024-10-24T08:03:43Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9399, "instance_id": "statsmodels__statsmodels-9399", "issue_numbers": ["9039"], "base_commit": "aef2533d3d8e107fd9df0ea28b04ecacce6380b2", "patch": "diff --git a/docs/source/api.rst b/docs/source/api.rst\nindex a1578945579..65ddcf2dd34 100644\n--- a/docs/source/api.rst\n+++ b/docs/source/api.rst\n@@ -140,6 +140,7 @@ Statistics and Tests\n    ~statsmodels.tsa.stattools.ccovf\n    ~statsmodels.tsa.stattools.coint\n    ~statsmodels.tsa.stattools.kpss\n+   ~statsmodels.tsa.stattools.leybourne\n    ~statsmodels.tsa.stattools.pacf\n    ~statsmodels.tsa.stattools.pacf_ols\n    ~statsmodels.tsa.stattools.pacf_yw\ndiff --git a/docs/source/tsa.rst b/docs/source/tsa.rst\nindex a194ebaf54f..629bf62ba14 100644\n--- a/docs/source/tsa.rst\n+++ b/docs/source/tsa.rst\n@@ -74,6 +74,7 @@ Descriptive Statistics and Tests\n    stattools.ccf\n    stattools.adfuller\n    stattools.kpss\n+   stattools.leybourne\n    stattools.range_unit_root_test\n    stattools.zivot_andrews\n    stattools.coint\ndiff --git a/setup.cfg b/setup.cfg\nindex f8c35d66b99..b6a2ccdffc0 100644\n--- a/setup.cfg\n+++ b/setup.cfg\n@@ -322,3 +322,7 @@ force_grid_wrap=0\n combine_as_imports=True\n force_sort_within_sections=True\n force_to_top=True\n+\n+\n+[tool.ruff.lint]\n+typing-modules = [\"statsmodels.compat.python\"]\n\\ No newline at end of file\ndiff --git a/statsmodels/tsa/_leybourne.py b/statsmodels/tsa/_leybourne.py\nnew file mode 100644\nindex 00000000000..8723eddedde\n--- /dev/null\n+++ b/statsmodels/tsa/_leybourne.py\n@@ -0,0 +1,142 @@\n+# Critical values for the Leybourne unit root test\n+import numpy as np\n+\n+c = np.array(\n+    (\n+        (99.9999, 0.00819),\n+        (99.999, 0.01050),\n+        (99.99, 0.01298),\n+        (99.9, 0.01701),\n+        (99.8, 0.01880),\n+        (99.7, 0.02005),\n+        (99.6, 0.02102),\n+        (99.5, 0.02186),\n+        (99.4, 0.02258),\n+        (99.3, 0.02321),\n+        (99.2, 0.02382),\n+        (99.1, 0.02437),\n+        (99.0, 0.02488),\n+        (97.5, 0.03045),\n+        (95.0, 0.03662),\n+        (92.5, 0.04162),\n+        (90.0, 0.04608),\n+        (87.5, 0.05024),\n+        (85.0, 0.05429),\n+        (82.5, 0.05827),\n+        (80.0, 0.06222),\n+        (77.5, 0.06621),\n+        (75.0, 0.07026),\n+        (72.5, 0.07439),\n+        (70.0, 0.07859),\n+        (67.5, 0.08295),\n+        (65.0, 0.08747),\n+        (62.5, 0.09214),\n+        (60.0, 0.09703),\n+        (57.5, 0.10212),\n+        (55.0, 0.10750),\n+        (52.5, 0.11315),\n+        (50.0, 0.11907),\n+        (47.5, 0.12535),\n+        (45.0, 0.13208),\n+        (42.5, 0.13919),\n+        (40.0, 0.14679),\n+        (37.5, 0.15503),\n+        (35.0, 0.16403),\n+        (32.5, 0.17380),\n+        (30.0, 0.18443),\n+        (27.5, 0.19638),\n+        (25.0, 0.20943),\n+        (22.5, 0.22440),\n+        (20.0, 0.24132),\n+        (17.5, 0.26123),\n+        (15.0, 0.28438),\n+        (12.5, 0.31242),\n+        (10.0, 0.34699),\n+        (7.5, 0.39354),\n+        (5.0, 0.45995),\n+        (2.5, 0.58098),\n+        (1.0, 0.74573),\n+        (0.9, 0.76453),\n+        (0.8, 0.78572),\n+        (0.7, 0.81005),\n+        (0.6, 0.83863),\n+        (0.5, 0.87385),\n+        (0.4, 0.91076),\n+        (0.3, 0.96501),\n+        (0.2, 1.03657),\n+        (0.1, 1.16658),\n+        (0.01, 1.60211),\n+        (0.001, 2.03312),\n+        (0.0001, 2.57878),\n+    )\n+)\n+# constant+trend model\n+ct = np.array(\n+    (\n+        (99.9999, 0.00759),\n+        (99.999, 0.00870),\n+        (99.99, 0.01023),\n+        (99.9, 0.01272),\n+        (99.8, 0.01378),\n+        (99.7, 0.01454),\n+        (99.6, 0.01509),\n+        (99.5, 0.01559),\n+        (99.4, 0.01598),\n+        (99.3, 0.01637),\n+        (99.2, 0.01673),\n+        (99.1, 0.01704),\n+        (99.0, 0.01731),\n+        (97.5, 0.02029),\n+        (95.0, 0.02342),\n+        (92.5, 0.02584),\n+        (90.0, 0.02791),\n+        (87.5, 0.02980),\n+        (85.0, 0.03158),\n+        (82.5, 0.03327),\n+        (80.0, 0.03492),\n+        (77.5, 0.03653),\n+        (75.0, 0.03813),\n+        (72.5, 0.03973),\n+        (70.0, 0.04135),\n+        (67.5, 0.04298),\n+        (65.0, 0.04464),\n+        (62.5, 0.04631),\n+        (60.0, 0.04805),\n+        (57.5, 0.04981),\n+        (55.0, 0.05163),\n+        (52.5, 0.05351),\n+        (50.0, 0.05546),\n+        (47.5, 0.05753),\n+        (45.0, 0.05970),\n+        (42.5, 0.06195),\n+        (40.0, 0.06434),\n+        (37.5, 0.06689),\n+        (35.0, 0.06962),\n+        (32.5, 0.07252),\n+        (30.0, 0.07564),\n+        (27.5, 0.07902),\n+        (25.0, 0.08273),\n+        (22.5, 0.08685),\n+        (20.0, 0.09150),\n+        (17.5, 0.09672),\n+        (15.0, 0.10285),\n+        (12.5, 0.11013),\n+        (10.0, 0.11917),\n+        (7.5, 0.13104),\n+        (5.0, 0.14797),\n+        (2.5, 0.17775),\n+        (1.0, 0.21801),\n+        (0.9, 0.22282),\n+        (0.8, 0.22799),\n+        (0.7, 0.23387),\n+        (0.6, 0.24109),\n+        (0.5, 0.24928),\n+        (0.4, 0.25888),\n+        (0.3, 0.27173),\n+        (0.2, 0.28939),\n+        (0.1, 0.32200),\n+        (0.01, 0.43218),\n+        (0.001, 0.54708),\n+        (0.0001, 0.69538),\n+    )\n+)\ndiff --git a/statsmodels/tsa/api.py b/statsmodels/tsa/api.py\nindex a802379c6f0..aec556cae92 100644\n--- a/statsmodels/tsa/api.py\n+++ b/statsmodels/tsa/api.py\n@@ -48,6 +48,7 @@\n     \"kpss\",\n     \"lagmat\",\n     \"lagmat2ds\",\n+    \"leybourne\",\n     \"pacf\",\n     \"pacf_ols\",\n     \"pacf_yw\",\n@@ -95,6 +96,7 @@\n     ccovf,\n     coint,\n     kpss,\n+    leybourne,\n     pacf,\n     pacf_ols,\n     pacf_yw,\ndiff --git a/statsmodels/tsa/stattools.py b/statsmodels/tsa/stattools.py\nindex f9a840ad864..8e7a34b8ed7 100644\n--- a/statsmodels/tsa/stattools.py\n+++ b/statsmodels/tsa/stattools.py\n@@ -1,6 +1,7 @@\n \"\"\"\n Statistical tools for time series analysis\n \"\"\"\n+\n from __future__ import annotations\n \n from statsmodels.compat.numpy import lstsq\n@@ -37,6 +38,7 @@\n )\n from statsmodels.tsa._bds import bds\n from statsmodels.tsa._innovations import innovations_algo, innovations_filter\n+import statsmodels.tsa._leybourne\n from statsmodels.tsa.adfvalues import mackinnoncrit, mackinnonp\n from statsmodels.tsa.tsatools import add_trend, lagmat, lagmat2ds\n \n@@ -63,6 +65,7 @@\n     \"levinson_durbin\",\n     \"zivot_andrews\",\n     \"range_unit_root_test\",\n+    \"leybourne\",\n ]\n \n SQRTEPS = np.sqrt(np.finfo(np.double).eps)\n@@ -262,9 +265,7 @@ def adfuller(\n     \"\"\"\n     x = array_like(x, \"x\")\n     maxlag = int_like(maxlag, \"maxlag\", optional=True)\n-    regression = string_like(\n-        regression, \"regression\", options=(\"c\", \"ct\", \"ctt\", \"n\")\n-    )\n+    regression = string_like(regression, \"regression\", options=(\"c\", \"ct\", \"ctt\", \"n\"))\n     autolag = string_like(\n         autolag, \"autolag\", optional=True, options=(\"aic\", \"bic\", \"t-stat\")\n     )\n@@ -291,8 +292,7 @@ def adfuller(\n         maxlag = min(nobs // 2 - ntrend - 1, maxlag)\n         if maxlag < 0:\n             raise ValueError(\n-                \"sample size is too short to use selected \"\n-                \"regression component\"\n+                \"sample size is too short to use selected \" \"regression component\"\n             )\n     elif maxlag > nobs // 2 - ntrend - 1:\n         raise ValueError(\n@@ -323,9 +323,7 @@ def adfuller(\n         # aic and bic: smaller is better\n \n         if not regresults:\n-            icbest, bestlag = _autolag(\n-                OLS, xdshort, fullRHS, startlag, maxlag, autolag\n-            )\n+            icbest, bestlag = _autolag(OLS, xdshort, fullRHS, startlag, maxlag, autolag)\n         else:\n             icbest, bestlag, alres = _autolag(\n                 OLS,\n@@ -350,9 +348,7 @@ def adfuller(\n         usedlag = maxlag\n         icbest = None\n     if regression != \"n\":\n-        resols = OLS(\n-            xdshort, add_trend(xdall[:, : usedlag + 1], regression)\n-        ).fit()\n+        resols = OLS(xdshort, add_trend(xdall[:, : usedlag + 1], regression)).fit()\n     else:\n         resols = OLS(xdshort, xdall[:, : usedlag + 1]).fit()\n \n@@ -378,9 +374,7 @@ def adfuller(\n         resstore.adfstat = adfstat\n         resstore.critvalues = critvalues\n         resstore.nobs = nobs\n-        resstore.H0 = (\n-            \"The coefficient on the lagged level equals 1 - unit root\"\n-        )\n+        resstore.H0 = \"The coefficient on the lagged level equals 1 - unit root\"\n         resstore.HA = \"The coefficient on the lagged level < 1 - stationary\"\n         resstore.icbest = icbest\n         resstore._str = \"Augmented Dickey-Fuller Test Results\"\n@@ -495,9 +489,7 @@ def acovf(x, adjusted=False, demean=True, fft=True, missing=\"none\", nlag=None):\n                 divisor = np.empty(lag_len + 1, dtype=np.int64)\n                 divisor[0] = notmask_int.sum()\n                 for i in range(lag_len):\n-                    divisor[i + 1] = notmask_int[i + 1 :].dot(\n-                        notmask_int[: -(i + 1)]\n-                    )\n+                    divisor[i + 1] = notmask_int[i + 1 :].dot(notmask_int[: -(i + 1)])\n                 divisor[divisor == 0] = 1\n                 acov /= divisor\n             else:  # biased, missing data but npt \"drop\"\n@@ -565,9 +557,7 @@ def q_stat(x, nobs):\n     nobs = int_like(nobs, \"nobs\")\n \n     ret = (\n-        nobs\n-        * (nobs + 2)\n-        * np.cumsum((1.0 / (nobs - np.arange(1, len(x) + 1))) * x ** 2)\n+        nobs * (nobs + 2) * np.cumsum((1.0 / (nobs - np.arange(1, len(x) + 1))) * x**2)\n     )\n     chi2 = stats.chi2.sf(ret, np.arange(1, len(x) + 1))\n     return ret, chi2\n@@ -720,6 +710,7 @@ def acf(\n     else:\n         return acf, qstat, pvalue\n \n+\n def pacf_yw(\n     x: ArrayLike1D,\n     nlags: int | None = None,\n@@ -907,7 +898,7 @@ def pacf_ols(\n     nobs = x.shape[0]\n     if nlags is None:\n         nlags = max(min(int(10 * np.log10(nobs)), nobs // 2), 1)\n-    if nlags > nobs//2:\n+    if nlags > nobs // 2:\n         raise ValueError(f\"nlags must be smaller than nobs // 2 ({nobs//2})\")\n     pacf = np.empty(nlags + 1)\n     pacf[0] = 1.0\n@@ -1124,7 +1115,7 @@ def ccovf(x, y, adjusted=True, demean=True, fft=True):\n         d = n\n \n     method = \"fft\" if fft else \"direct\"\n-    return correlate(xo, yo, \"full\", method=method)[n - 1:] / d\n+    return correlate(xo, yo, \"full\", method=method)[n - 1 :] / d\n \n \n @deprecate_kwarg(\"unbiased\", \"adjusted\")\n@@ -1246,9 +1237,7 @@ def levinson_durbin(s, nlags=10, isacov=False):\n     phi[1, 1] = sxx_m[1] / sxx_m[0]\n     sig[1] = sxx_m[0] - phi[1, 1] * sxx_m[1]\n     for k in range(2, order + 1):\n-        phi[k, k] = (\n-            sxx_m[k] - np.dot(phi[1:k, k - 1], sxx_m[1:k][::-1])\n-        ) / sig[k - 1]\n+        phi[k, k] = (sxx_m[k] - np.dot(phi[1:k, k - 1], sxx_m[1:k][::-1])) / sig[k - 1]\n         for j in range(1, k):\n             phi[j, k] = phi[j, k - 1] - phi[k, k] * phi[k - j, k - 1]\n         sig[k] = sig[k - 1] * (1 - phi[k, k] ** 2)\n@@ -1291,8 +1280,7 @@ def levinson_durbin_pacf(pacf, nlags=None):\n \n     if pacf[0] != 1:\n         raise ValueError(\n-            \"The first entry of the pacf corresponds to lags 0 \"\n-            \"and so must be 1.\"\n+            \"The first entry of the pacf corresponds to lags 0 \" \"and so must be 1.\"\n         )\n     pacf = pacf[1:]\n     n = pacf.shape[0]\n@@ -1307,7 +1295,7 @@ def levinson_durbin_pacf(pacf, nlags=None):\n \n     acf = np.zeros(n + 1)\n     acf[1] = pacf[0]\n-    nu = np.cumprod(1 - pacf ** 2)\n+    nu = np.cumprod(1 - pacf**2)\n     arcoefs = pacf.copy()\n     for i in range(1, n):\n         prev = arcoefs[: -(n - i)].copy()\n@@ -1458,9 +1446,7 @@ def breakvar_heteroskedasticity_test(\n         test_statistic = 1.0 / test_statistic\n         p_value = pval_upper(test_statistic)\n     elif alternative in [\"2\", \"2-sided\", \"two-sided\"]:\n-        p_value = 2 * np.minimum(\n-            pval_lower(test_statistic), pval_upper(test_statistic)\n-        )\n+        p_value = 2 * np.minimum(pval_lower(test_statistic), pval_upper(test_statistic))\n     else:\n         raise ValueError(\"Invalid alternative.\")\n \n@@ -1570,8 +1556,7 @@ def grangercausalitytests(x, maxlag, addconst=True, verbose=None):\n         maxlag = lags.max()\n         if lags.min() <= 0 or lags.size == 0:\n             raise ValueError(\n-                \"maxlag must be a non-empty list containing only \"\n-                \"positive integers\"\n+                \"maxlag must be a non-empty list containing only \" \"positive integers\"\n             )\n \n     if x.shape[0] <= 3 * maxlag + int(addconst):\n@@ -1814,9 +1799,7 @@ def coint(\n     res_co = OLS(y0, xx).fit()\n \n     if res_co.rsquared < 1 - 100 * SQRTEPS:\n-        res_adf = adfuller(\n-            res_co.resid, maxlag=maxlag, autolag=autolag, regression=\"n\"\n-        )\n+        res_adf = adfuller(res_co.resid, maxlag=maxlag, autolag=autolag, regression=\"n\")\n     else:\n         warnings.warn(\n             \"y0 and y1 are (almost) perfectly colinear.\"\n@@ -1859,12 +1842,10 @@ def _safe_arma_fit(y, order, model_kw, trend, fit_kw, start_params=None):\n             start_params = [0.1] * sum(order)\n             if trend == \"c\":\n                 start_params = [0.1] + start_params\n-            return _safe_arma_fit(\n-                y, order, model_kw, trend, fit_kw, start_params\n-            )\n+            return _safe_arma_fit(y, order, model_kw, trend, fit_kw, start_params)\n         else:\n             return\n-    except:  # no idea what happened\n+    except Exception:  # no idea what happened\n         return\n \n \n@@ -1954,9 +1935,7 @@ def arma_order_select_ic(\n             for i, criteria in enumerate(ic):\n                 results[i, ar, ma] = getattr(mod, criteria)\n \n-    dfs = [\n-        pd.DataFrame(res, columns=ma_range, index=ar_range) for res in results\n-    ]\n+    dfs = [pd.DataFrame(res, columns=ma_range, index=ar_range) for res in results]\n \n     res = dict(zip(ic, dfs))\n \n@@ -2112,7 +2091,7 @@ def kpss(\n \n     pvals = [0.10, 0.05, 0.025, 0.01]\n \n-    eta = np.sum(resids.cumsum() ** 2) / (nobs ** 2)  # eq. 11, p. 165\n+    eta = np.sum(resids.cumsum() ** 2) / (nobs**2)  # eq. 11, p. 165\n     s_hat = _sigma_est_kpss(resids, nobs, nlags)\n \n     kpss_stat = eta / s_hat\n@@ -2158,7 +2137,7 @@ def _sigma_est_kpss(resids, nobs, lags):\n     Computes equation 10, p. 164 of Kwiatkowski et al. (1992). This is the\n     consistent estimator for the variance.\n     \"\"\"\n-    s_hat = np.sum(resids ** 2)\n+    s_hat = np.sum(resids**2)\n     for i in range(1, lags + 1):\n         resids_prod = np.dot(resids[i:], resids[: nobs - i])\n         s_hat += 2 * resids_prod * (1.0 - (i / (lags + 1.0)))\n@@ -2172,7 +2151,7 @@ def _kpss_autolag(resids, nobs):\n     (1994), and Schwert (1989). Assumes Bartlett / Newey-West kernel.\n     \"\"\"\n     covlags = int(np.power(nobs, 2.0 / 9.0))\n-    s0 = np.sum(resids ** 2) / nobs\n+    s0 = np.sum(resids**2) / nobs\n     s1 = 0\n     for i in range(1, covlags + 1):\n         resids_prod = np.dot(resids[i:], resids[: nobs - i])\n@@ -2244,9 +2223,7 @@ def range_unit_root_test(x, store=False):\n     # Table from [1] has been replicated using 200,000 samples\n     # Critical values for new n_obs values have been identified\n     pvals = [0.01, 0.025, 0.05, 0.10, 0.90, 0.95]\n-    n = np.array(\n-        [25, 50, 100, 150, 200, 250, 500, 1000, 2000, 3000, 4000, 5000]\n-    )\n+    n = np.array([25, 50, 100, 150, 200, 250, 500, 1000, 2000, 3000, 4000, 5000])\n     crit = np.array(\n         [\n             [0.6626, 0.8126, 0.9192, 1.0712, 2.4863, 2.7312],\n@@ -2562,9 +2539,7 @@ def _format_regression_data(self, series, nobs, const, trend, cols, lags):\n         exog[:, 0] = const\n         # lagged y and dy\n         exog[:, cols - 1] = series[lags : (nobs - 1)]\n-        exog[:, cols:] = lagmat(endog, lags, trim=\"none\")[\n-            lags : exog.shape[0] + lags\n-        ]\n+        exog[:, cols:] = lagmat(endog, lags, trim=\"none\")[lags : exog.shape[0] + lags]\n         return endog, exog\n \n     def _update_regression_exog(\n@@ -2667,9 +2642,7 @@ def run(self, x, trim=0.15, maxlag=None, regression=\"c\", autolag=\"AIC\"):\n         x = array_like(x, \"x\", dtype=np.double, ndim=1)\n         trim = float_like(trim, \"trim\")\n         maxlag = int_like(maxlag, \"maxlag\", optional=True)\n-        regression = string_like(\n-            regression, \"regression\", options=(\"c\", \"t\", \"ct\")\n-        )\n+        regression = string_like(regression, \"regression\", options=(\"c\", \"t\", \"ct\"))\n         autolag = string_like(\n             autolag, \"autolag\", options=(\"aic\", \"bic\", \"t-stat\"), optional=True\n         )\n@@ -2677,9 +2650,7 @@ def run(self, x, trim=0.15, maxlag=None, regression=\"c\", autolag=\"AIC\"):\n             raise ValueError(\"trim value must be a float in range [0, 1/3)\")\n         nobs = x.shape[0]\n         if autolag:\n-            adf_res = adfuller(\n-                x, maxlag=maxlag, regression=\"ct\", autolag=autolag\n-            )\n+            adf_res = adfuller(x, maxlag=maxlag, regression=\"ct\", autolag=autolag)\n             baselags = adf_res[2]\n         elif maxlag:\n             baselags = maxlag\n@@ -2726,9 +2697,7 @@ def run(self, x, trim=0.15, maxlag=None, regression=\"c\", autolag=\"AIC\"):\n                     )\n                 stats[bp] = o.tvalues[basecols - 1]\n             else:\n-                stats[bp] = self._quick_ols(endog[baselags:], exog)[\n-                    basecols - 1\n-                ]\n+                stats[bp] = self._quick_ols(endog[baselags:], exog)[basecols - 1]\n         # return best seen\n         zastat = np.min(stats)\n         bpidx = np.argmin(stats) - 1\n@@ -2737,9 +2706,7 @@ def run(self, x, trim=0.15, maxlag=None, regression=\"c\", autolag=\"AIC\"):\n         cvdict = crit[1]\n         return zastat, pval, cvdict, baselags, bpidx\n \n-    def __call__(\n-        self, x, trim=0.15, maxlag=None, regression=\"c\", autolag=\"AIC\"\n-    ):\n+    def __call__(self, x, trim=0.15, maxlag=None, regression=\"c\", autolag=\"AIC\"):\n         return self.run(\n             x, trim=trim, maxlag=maxlag, regression=regression, autolag=autolag\n         )\n@@ -2747,3 +2714,285 @@ def __call__(\n \n zivot_andrews = ZivotAndrewsUnitRoot()\n zivot_andrews.__doc__ = zivot_andrews.run.__doc__\n+\n+\n+class LeybourneMcCabeStationarity:\n+    \"\"\"\n+    Class wrapper for Leybourne-McCabe stationarity test\n+    \"\"\"\n+\n+    def __init__(self):\n+        \"\"\"\n+        Asymptotic critical values for the two different models specified\n+        for the Leybourne-McCabe stationarity test. Asymptotic CVs are the\n+        same as the asymptotic CVs for the KPSS stationarity test.\n+\n+        Notes\n+        -----\n+        The p-values are generated through Monte Carlo simulation using\n+        1,000,000 replications and 10,000 data points.\n+        \"\"\"\n+        self.__leybourne_critical_values = {\n+            # constant-only model\n+            \"c\": statsmodels.tsa._leybourne.c,\n+            # constant-trend model\n+            \"ct\": statsmodels.tsa._leybourne.ct,\n+        }\n+\n+    def __leybourne_crit(self, stat, model=\"c\"):\n+        \"\"\"\n+        Linear interpolation for Leybourne p-values and critical values\n+\n+        Parameters\n+        ----------\n+        stat : float\n+            The Leybourne-McCabe test statistic\n+        model : {'c','ct'}\n+            The model used when computing the test statistic. 'c' is default.\n+\n+        Returns\n+        -------\n+        pvalue : float\n+            The interpolated p-value\n+        cvdict : dict\n+            Critical values for the test statistic at the 1%, 5%, and 10%\n+            levels\n+\n+        Notes\n+        -----\n+        The p-values are linear interpolated from the quantiles of the\n+        simulated Leybourne-McCabe (KPSS) test statistic distribution\n+        \"\"\"\n+        table = self.__leybourne_critical_values[model]\n+        # reverse the order\n+        y = table[:, 0]\n+        x = table[:, 1]\n+        # LM cv table contains quantiles multiplied by 100\n+        pvalue = np.interp(stat, x, y) / 100.0\n+        cv = [1.0, 5.0, 10.0]\n+        crit_value = np.interp(cv, np.flip(y), np.flip(x))\n+        cvdict = {\"1%\": crit_value[0], \"5%\": crit_value[1], \"10%\": crit_value[2]}\n+        return pvalue, cvdict\n+\n+    def _tsls_arima(self, x, arlags, model):\n+        \"\"\"\n+        Two-stage least squares approach for estimating ARIMA(p, 1, 1)\n+        parameters as an alternative to MLE estimation in the case of\n+        solver non-convergence\n+\n+        Parameters\n+        ----------\n+        x : array_like\n+            data series\n+        arlags : int\n+            AR(p) order\n+        model : {'c','ct'}\n+            Constant and trend order to include in regression\n+            * 'c'  : constant only\n+            * 'ct' : constant and trend\n+\n+        Returns\n+        -------\n+        arparams : int\n+            AR(1) coefficient plus constant\n+        theta : int\n+            MA(1) coefficient\n+        olsfit.resid : ndarray\n+            residuals from second-stage regression\n+        \"\"\"\n+        endog = np.diff(x, axis=0)\n+        exog = lagmat(endog, arlags, trim=\"both\")\n+        # add constant if requested\n+        if model == \"ct\":\n+            exog = add_constant(exog)\n+        # remove extra terms from front of endog\n+        endog = endog[arlags:]\n+        if arlags > 0:\n+            resids = lagmat(OLS(endog, exog).fit().resid, 1, trim=\"forward\")\n+        else:\n+            resids = lagmat(-endog, 1, trim=\"forward\")\n+        # add negated residuals column to exog as MA(1) term\n+        exog = np.append(exog, -resids, axis=1)\n+        olsfit = OLS(endog, exog).fit()\n+        if model == \"ct\":\n+            arparams = olsfit.params[1 : (len(olsfit.params) - 1)]\n+        else:\n+            arparams = olsfit.params[0 : (len(olsfit.params) - 1)]\n+        theta = olsfit.params[len(olsfit.params) - 1]\n+        return arparams, theta, olsfit.resid\n+\n+    def _autolag(self, x):\n+        \"\"\"\n+        Empirical method for Leybourne-McCabe auto AR lag detection.\n+        Set number of AR lags equal to the first PACF falling within the\n+        95% confidence interval. Maximum nuber of AR lags is limited to\n+        the smaller of 10 or 1/2 series length. Minimum is zero lags.\n+\n+        Parameters\n+        ----------\n+        x : array_like\n+            data series\n+\n+        Returns\n+        -------\n+        arlags : int\n+            AR(p) order\n+        \"\"\"\n+        p = pacf(x, nlags=min(len(x) // 2, 10), method=\"ols\")\n+        ci = 1.960 / np.sqrt(len(x))\n+        arlags = max(\n+            0, ([n - 1 for n, i in enumerate(p) if abs(i) < ci] + [len(p) - 1])[0]\n+        )\n+        return arlags\n+\n+    def run(self, x, arlags=1, regression=\"c\", method=\"mle\", varest=\"var94\"):\n+        \"\"\"\n+        Leybourne-McCabe stationarity test\n+\n+        The Leybourne-McCabe test can be used to test for stationarity in a\n+        univariate process.\n+\n+        Parameters\n+        ----------\n+        x : array_like\n+            data series\n+        arlags : int\n+            number of autoregressive terms to include, default=None\n+        regression : {'c','ct'}\n+            Constant and trend order to include in regression\n+            * 'c'  : constant only (default)\n+            * 'ct' : constant and trend\n+        method : {'mle','ols'}\n+            Method used to estimate ARIMA(p, 1, 1) filter model\n+            * 'mle' : condition sum of squares maximum likelihood\n+            * 'ols' : two-stage least squares (default)\n+        varest : {'var94','var99'}\n+            Method used for residual variance estimation\n+            * 'var94' : method used in original Leybourne-McCabe paper (1994)\n+                        (default)\n+            * 'var99' : method used in follow-up paper (1999)\n+\n+        Returns\n+        -------\n+        lmstat : float\n+            test statistic\n+        pvalue : float\n+            based on MC-derived critical values\n+        arlags : int\n+            AR(p) order used to create the filtered series\n+        cvdict : dict\n+            critical values for the test statistic at the 1%, 5%, and 10%\n+            levels\n+\n+        Notes\n+        -----\n+        H0 = series is stationary\n+\n+        Basic process is to create a filtered series which removes the AR(p)\n+        effects from the series under test followed by an auxiliary regression\n+        similar to that of Kwiatkowski et al (1992). The AR(p) coefficients\n+        are obtained by estimating an ARIMA(p, 1, 1) model. Two methods are\n+        provided for ARIMA estimation: MLE and two-stage least squares.\n+\n+        Two methods are provided for residual variance estimation used in the\n+        calculation of the test statistic. The first method ('var94') is the\n+        mean of the squared residuals from the filtered regression. The second\n+        method ('var99') is the MA(1) coefficient times the mean of the squared\n+        residuals from the ARIMA(p, 1, 1) filtering model.\n+\n+        An empirical autolag procedure is provided. In this context, the number\n+        of lags is equal to the number of AR(p) terms used in the filtering\n+        step. The number of AR(p) terms is set equal to the to the first PACF\n+        falling within the 95% confidence interval. Maximum nuber of AR lags is\n+        limited to 1/2 series length.\n+\n+        References\n+        ----------\n+        Kwiatkowski, D., Phillips, P.C.B., Schmidt, P. & Shin, Y. (1992).\n+        Testing the null hypothesis of stationarity against the alternative of\n+        a unit root. Journal of Econometrics, 54: 159\u2013178.\n+\n+        Leybourne, S.J., & McCabe, B.P.M. (1994). A consistent test for a\n+        unit root. Journal of Business and Economic Statistics, 12: 157\u2013166.\n+\n+        Leybourne, S.J., & McCabe, B.P.M. (1999). Modified stationarity tests\n+        with data-dependent model-selection rules. Journal of Business and\n+        Economic Statistics, 17: 264-270.\n+\n+        Schwert, G W. (1987). Effects of model specification on tests for unit\n+        roots in macroeconomic data. Journal of Monetary Economics, 20: 73\u2013103.\n+        \"\"\"\n+        if regression not in [\"c\", \"ct\"]:\n+            raise ValueError(\"LM: regression option '%s' not understood\" % regression)\n+        if method not in [\"mle\", \"ols\"]:\n+            raise ValueError(\"LM: method option '%s' not understood\" % method)\n+        if varest not in [\"var94\", \"var99\"]:\n+            raise ValueError(\"LM: varest option '%s' not understood\" % varest)\n+        x = np.asarray(x)\n+        if x.ndim > 2 or (x.ndim == 2 and x.shape[1] != 1):\n+            raise ValueError(\n+                \"LM: x must be a 1d array or a 2d array with a single column\"\n+            )\n+        x = np.reshape(x, (-1, 1))\n+        # determine AR order if not specified\n+        if arlags is None:\n+            arlags = self._autolag(x)\n+        elif not isinstance(arlags, int) or arlags < 0 or arlags > int(len(x) / 2):\n+            raise ValueError(\n+                \"LM: arlags must be an integer in range [0..%s]\" % str(int(len(x) / 2))\n+            )\n+        # estimate the reduced ARIMA(p, 1, 1) model\n+        if method == \"mle\":\n+            if regression == \"ct\":\n+                reg = \"t\"\n+            else:\n+                reg = None\n+\n+            from statsmodels.tsa.arima.model import ARIMA\n+\n+            arima = ARIMA(\n+                x, order=(arlags, 1, 1), trend=reg, enforce_invertibility=False\n+            )\n+            arfit = arima.fit()\n+            resids = arfit.resid\n+            arcoeffs = []\n+            if arlags > 0:\n+                arcoeffs = arfit.arparams\n+            theta = arfit.maparams[0]\n+        else:\n+            arcoeffs, theta, resids = self._tsls_arima(x, arlags, model=regression)\n+        # variance estimator from (1999) LM paper\n+        var99 = abs(theta * np.sum(resids**2) / len(resids))\n+        # create the filtered series:\n+        #   z(t) = x(t) - arcoeffs[0]*x(t-1) - ... - arcoeffs[p-1]*x(t-p)\n+        z = np.full(len(x) - arlags, np.inf)\n+        for i in range(len(z)):\n+            z[i] = x[i + arlags, 0]\n+            for j in range(len(arcoeffs)):\n+                z[i] -= arcoeffs[j] * x[i + arlags - j - 1, 0]\n+        # regress the filtered series against a constant and\n+        # trend term (if requested)\n+        if regression == \"c\":\n+            resids = z - z.mean()\n+        else:\n+            resids = OLS(z, add_constant(np.arange(1, len(z) + 1))).fit().resid\n+        # variance estimator from (1994) LM paper\n+        var94 = np.sum(resids**2) / len(resids)\n+        # compute test statistic with specified variance estimator\n+        eta = np.sum(resids.cumsum() ** 2) / (len(resids) ** 2)\n+        if varest == \"var99\":\n+            lmstat = eta / var99\n+        else:\n+            lmstat = eta / var94\n+        # calculate pval\n+        lmpval, cvdict = self.__leybourne_crit(lmstat, regression)\n+        return lmstat, lmpval, arlags, cvdict\n+\n+    def __call__(self, x, arlags=None, regression=\"c\", method=\"ols\", varest=\"var94\"):\n+        return self.run(\n+            x, arlags=arlags, regression=regression, method=method, varest=varest\n+        )\n+\n+\n+leybourne = LeybourneMcCabeStationarity()\n+leybourne.__doc__ = leybourne.run.__doc__\n", "test_patch": "diff --git a/statsmodels/tsa/tests/results/BAA.csv b/statsmodels/tsa/tests/results/BAA.csv\nnew file mode 100644\nindex 00000000000..e08d00e752c\n--- /dev/null\n+++ b/statsmodels/tsa/tests/results/BAA.csv\n@@ -0,0 +1,469 @@\n+SCHWERTBAA\n+3.13\n+3.12\n+3.15\n+3.16\n+3.17\n+3.21\n+3.18\n+3.17\n+3.23\n+3.35\n+3.44\n+3.52\n+3.52\n+3.53\n+3.53\n+3.47\n+3.38\n+3.34\n+3.37\n+3.44\n+3.45\n+3.5\n+3.53\n+3.53\n+3.46\n+3.45\n+3.47\n+3.45\n+3.45\n+3.47\n+3.46\n+3.4\n+3.37\n+3.36\n+3.35\n+3.31\n+3.24\n+3.24\n+3.24\n+3.23\n+3.25\n+3.28\n+3.32\n+3.23\n+3.21\n+3.22\n+3.22\n+3.2\n+3.17\n+3.16\n+3.23\n+3.35\n+3.4\n+3.49\n+3.53\n+3.5\n+3.46\n+3.5\n+3.56\n+3.61\n+3.5\n+3.53\n+3.51\n+3.5\n+3.49\n+3.5\n+3.5\n+3.51\n+3.52\n+3.54\n+3.53\n+3.51\n+3.51\n+3.53\n+3.57\n+3.65\n+3.78\n+3.86\n+3.86\n+3.85\n+3.88\n+3.82\n+3.75\n+3.74\n+3.71\n+3.61\n+3.51\n+3.47\n+3.47\n+3.49\n+3.5\n+3.49\n+3.47\n+3.46\n+3.45\n+3.45\n+3.45\n+3.47\n+3.48\n+3.49\n+3.5\n+3.51\n+3.52\n+3.56\n+3.59\n+3.59\n+3.58\n+3.62\n+3.6\n+3.58\n+3.6\n+3.68\n+3.73\n+3.76\n+3.8\n+3.93\n+4.07\n+4.17\n+4.24\n+4.37\n+4.49\n+4.47\n+4.43\n+4.44\n+4.52\n+4.63\n+4.73\n+4.82\n+4.93\n+4.99\n+5.09\n+5.03\n+4.83\n+4.66\n+4.68\n+4.67\n+4.62\n+4.55\n+4.53\n+4.67\n+4.87\n+4.92\n+4.87\n+4.85\n+4.87\n+4.89\n+4.85\n+4.86\n+4.96\n+5.04\n+5.08\n+5.09\n+5.18\n+5.28\n+5.26\n+5.28\n+5.34\n+5.34\n+5.25\n+5.2\n+5.28\n+5.26\n+5.22\n+5.08\n+5.01\n+5.11\n+5.08\n+5.1\n+5.1\n+5.07\n+5.02\n+5.01\n+5.01\n+5.03\n+5.09\n+5.11\n+5.12\n+5.13\n+5.11\n+5.1\n+5.08\n+5.07\n+5.04\n+5.02\n+5\n+5.02\n+5.05\n+5.06\n+5.03\n+4.99\n+4.96\n+4.92\n+4.91\n+4.89\n+4.88\n+4.87\n+4.85\n+4.84\n+4.84\n+4.83\n+4.84\n+4.83\n+4.84\n+4.85\n+4.83\n+4.83\n+4.83\n+4.85\n+4.85\n+4.85\n+4.83\n+4.82\n+4.82\n+4.81\n+4.81\n+4.81\n+4.8\n+4.78\n+4.78\n+4.8\n+4.81\n+4.85\n+4.88\n+4.88\n+4.91\n+4.93\n+4.95\n+5.02\n+5.06\n+5.12\n+5.32\n+5.41\n+5.48\n+5.58\n+5.68\n+5.83\n+6.09\n+6.1\n+6.13\n+6.18\n+5.97\n+5.82\n+5.85\n+5.83\n+5.96\n+6.15\n+6.26\n+6.33\n+6.4\n+6.52\n+6.72\n+6.93\n+6.84\n+6.8\n+6.85\n+6.97\n+7.03\n+7.07\n+6.98\n+6.82\n+6.79\n+6.84\n+7.01\n+7.23\n+7.32\n+7.3\n+7.51\n+7.54\n+7.52\n+7.7\n+7.84\n+7.86\n+8.05\n+8.22\n+8.25\n+8.65\n+8.86\n+8.78\n+8.63\n+8.7\n+8.98\n+9.25\n+9.4\n+9.44\n+9.39\n+9.33\n+9.38\n+9.12\n+8.74\n+8.39\n+8.46\n+8.45\n+8.62\n+8.75\n+8.76\n+8.76\n+8.59\n+8.48\n+8.38\n+8.38\n+8.23\n+8.23\n+8.23\n+8.24\n+8.23\n+8.2\n+8.23\n+8.19\n+8.09\n+8.06\n+7.99\n+7.93\n+7.9\n+7.97\n+8.03\n+8.09\n+8.06\n+8.13\n+8.24\n+8.53\n+8.63\n+8.41\n+8.42\n+8.48\n+8.48\n+8.53\n+8.62\n+8.87\n+9.05\n+9.27\n+9.48\n+9.77\n+10.18\n+10.48\n+10.6\n+10.63\n+10.81\n+10.65\n+10.48\n+10.58\n+10.69\n+10.62\n+10.55\n+10.59\n+10.61\n+10.62\n+10.56\n+10.56\n+10.41\n+10.24\n+10.12\n+9.94\n+9.86\n+9.89\n+9.82\n+9.64\n+9.4\n+9.29\n+9.23\n+9.12\n+9.08\n+9.12\n+9.12\n+9.07\n+9.01\n+8.91\n+8.87\n+8.82\n+8.8\n+8.89\n+8.95\n+8.99\n+9.17\n+9.2\n+9.22\n+9.32\n+9.49\n+9.6\n+9.6\n+9.48\n+9.42\n+9.59\n+9.83\n+9.94\n+10.13\n+10.08\n+10.26\n+10.33\n+10.47\n+10.38\n+10.29\n+10.35\n+10.54\n+11.4\n+11.99\n+12.06\n+12.42\n+13.57\n+14.45\n+14.19\n+13.17\n+12.71\n+12.65\n+13.15\n+13.7\n+14.23\n+14.64\n+15.14\n+15.03\n+15.37\n+15.34\n+15.56\n+15.95\n+15.8\n+16.17\n+16.34\n+16.92\n+17.11\n+16.39\n+16.55\n+17.1\n+17.18\n+16.82\n+16.78\n+16.64\n+16.92\n+16.8\n+16.32\n+15.63\n+14.73\n+14.3\n+14.14\n+13.94\n+13.95\n+13.61\n+13.29\n+13.09\n+13.37\n+13.39\n+13.64\n+13.55\n+13.46\n+13.61\n+13.75\n+13.65\n+13.59\n+13.99\n+14.31\n+14.74\n+15.05\n+15.15\n+14.63\n+14.35\n+13.94\n+13.48\n+13.4\n+13.26\n+13.23\n+13.69\n+13.51\n+13.15\n+12.4\n+12.43\n+12.5\n+12.48\n+12.36\n+11.99\n+11.58\ndiff --git a/statsmodels/tsa/tests/results/DBAA.csv b/statsmodels/tsa/tests/results/DBAA.csv\nnew file mode 100644\nindex 00000000000..3b05813779a\n--- /dev/null\n+++ b/statsmodels/tsa/tests/results/DBAA.csv\n@@ -0,0 +1,468 @@\n+SCHWERTDBAA\n+-0.01\n+0.03\n+0.01\n+0.01\n+0.04\n+-0.03\n+-0.01\n+0.06\n+0.12\n+0.09\n+0.08\n+0\n+0.01\n+0\n+-0.06\n+-0.09\n+-0.04\n+0.03\n+0.07\n+0.01\n+0.05\n+0.03\n+0\n+-0.07\n+-0.01\n+0.02\n+-0.02\n+0\n+0.02\n+-0.01\n+-0.06\n+-0.03\n+-0.01\n+-0.01\n+-0.04\n+-0.07\n+0\n+0\n+-0.01\n+0.02\n+0.03\n+0.04\n+-0.09\n+-0.02\n+0.01\n+0\n+-0.02\n+-0.03\n+-0.01\n+0.07\n+0.12\n+0.05\n+0.09\n+0.04\n+-0.03\n+-0.04\n+0.04\n+0.06\n+0.05\n+-0.11\n+0.03\n+-0.02\n+-0.01\n+-0.01\n+0.01\n+0\n+0.01\n+0.01\n+0.02\n+-0.01\n+-0.02\n+0\n+0.02\n+0.04\n+0.08\n+0.13\n+0.08\n+0\n+-0.01\n+0.03\n+-0.06\n+-0.07\n+-0.01\n+-0.03\n+-0.1\n+-0.1\n+-0.04\n+0\n+0.02\n+0.01\n+-0.01\n+-0.02\n+-0.01\n+-0.01\n+0\n+0\n+0.02\n+0.01\n+0.01\n+0.01\n+0.01\n+0.01\n+0.04\n+0.03\n+0\n+-0.01\n+0.04\n+-0.02\n+-0.02\n+0.02\n+0.08\n+0.05\n+0.03\n+0.04\n+0.13\n+0.14\n+0.1\n+0.07\n+0.13\n+0.12\n+-0.02\n+-0.04\n+0.01\n+0.08\n+0.11\n+0.1\n+0.09\n+0.11\n+0.06\n+0.1\n+-0.06\n+-0.2\n+-0.17\n+0.02\n+-0.01\n+-0.05\n+-0.07\n+-0.02\n+0.14\n+0.2\n+0.05\n+-0.05\n+-0.02\n+0.02\n+0.02\n+-0.04\n+0.01\n+0.1\n+0.08\n+0.04\n+0.01\n+0.09\n+0.1\n+-0.02\n+0.02\n+0.06\n+0\n+-0.09\n+-0.05\n+0.08\n+-0.02\n+-0.04\n+-0.14\n+-0.07\n+0.1\n+-0.03\n+0.02\n+0\n+-0.03\n+-0.05\n+-0.01\n+0\n+0.02\n+0.06\n+0.02\n+0.01\n+0.01\n+-0.02\n+-0.01\n+-0.02\n+-0.01\n+-0.03\n+-0.02\n+-0.02\n+0.02\n+0.03\n+0.01\n+-0.03\n+-0.04\n+-0.03\n+-0.04\n+-0.01\n+-0.02\n+-0.01\n+-0.01\n+-0.02\n+-0.01\n+0\n+-0.01\n+0.01\n+-0.01\n+0.01\n+0.01\n+-0.02\n+0\n+0\n+0.02\n+0\n+0\n+-0.02\n+-0.01\n+0\n+-0.01\n+0\n+0\n+-0.01\n+-0.02\n+0\n+0.02\n+0.01\n+0.04\n+0.03\n+0\n+0.03\n+0.02\n+0.02\n+0.07\n+0.04\n+0.06\n+0.2\n+0.09\n+0.07\n+0.1\n+0.1\n+0.15\n+0.26\n+0.01\n+0.03\n+0.05\n+-0.21\n+-0.15\n+0.03\n+-0.02\n+0.13\n+0.19\n+0.11\n+0.07\n+0.07\n+0.12\n+0.2\n+0.21\n+-0.09\n+-0.04\n+0.05\n+0.12\n+0.06\n+0.04\n+-0.09\n+-0.16\n+-0.03\n+0.05\n+0.17\n+0.22\n+0.09\n+-0.02\n+0.21\n+0.03\n+-0.02\n+0.18\n+0.14\n+0.02\n+0.19\n+0.17\n+0.03\n+0.4\n+0.21\n+-0.08\n+-0.15\n+0.07\n+0.28\n+0.27\n+0.15\n+0.04\n+-0.05\n+-0.06\n+0.05\n+-0.26\n+-0.38\n+-0.35\n+0.07\n+-0.01\n+0.17\n+0.13\n+0.01\n+0\n+-0.17\n+-0.11\n+-0.1\n+0\n+-0.15\n+0\n+0\n+0.01\n+-0.01\n+-0.03\n+0.03\n+-0.04\n+-0.1\n+-0.03\n+-0.07\n+-0.06\n+-0.03\n+0.07\n+0.06\n+0.06\n+-0.03\n+0.07\n+0.11\n+0.29\n+0.1\n+-0.22\n+0.01\n+0.06\n+0\n+0.05\n+0.09\n+0.25\n+0.18\n+0.22\n+0.21\n+0.29\n+0.41\n+0.3\n+0.12\n+0.03\n+0.18\n+-0.16\n+-0.17\n+0.1\n+0.11\n+-0.07\n+-0.07\n+0.04\n+0.02\n+0.01\n+-0.06\n+0\n+-0.15\n+-0.17\n+-0.12\n+-0.18\n+-0.08\n+0.03\n+-0.07\n+-0.18\n+-0.24\n+-0.11\n+-0.06\n+-0.11\n+-0.04\n+0.04\n+0\n+-0.05\n+-0.06\n+-0.1\n+-0.04\n+-0.05\n+-0.02\n+0.09\n+0.06\n+0.04\n+0.18\n+0.03\n+0.02\n+0.1\n+0.17\n+0.11\n+0\n+-0.12\n+-0.06\n+0.17\n+0.24\n+0.11\n+0.19\n+-0.05\n+0.18\n+0.07\n+0.14\n+-0.09\n+-0.09\n+0.06\n+0.19\n+0.86\n+0.59\n+0.07\n+0.36\n+1.15\n+0.88\n+-0.26\n+-1.02\n+-0.46\n+-0.06\n+0.5\n+0.55\n+0.53\n+0.41\n+0.5\n+-0.11\n+0.34\n+-0.03\n+0.22\n+0.39\n+-0.15\n+0.37\n+0.17\n+0.58\n+0.19\n+-0.72\n+0.16\n+0.55\n+0.08\n+-0.36\n+-0.04\n+-0.14\n+0.28\n+-0.12\n+-0.48\n+-0.69\n+-0.9\n+-0.43\n+-0.16\n+-0.2\n+0.01\n+-0.34\n+-0.32\n+-0.2\n+0.28\n+0.02\n+0.25\n+-0.09\n+-0.09\n+0.15\n+0.14\n+-0.1\n+-0.06\n+0.4\n+0.32\n+0.43\n+0.31\n+0.1\n+-0.52\n+-0.28\n+-0.41\n+-0.46\n+-0.08\n+-0.14\n+-0.03\n+0.46\n+-0.18\n+-0.36\n+-0.75\n+0.03\n+0.07\n+-0.02\n+-0.12\n+-0.37\n+-0.41\ndiff --git a/statsmodels/tsa/tests/results/DSP500.csv b/statsmodels/tsa/tests/results/DSP500.csv\nnew file mode 100644\nindex 00000000000..abf70c92db4\n--- /dev/null\n+++ b/statsmodels/tsa/tests/results/DSP500.csv\n@@ -0,0 +1,468 @@\n+SCHWERTDSP500\n+-0.23\n+-0.26\n+-0.59\n+-0.13\n+0.76\n+0.55\n+-0.44\n+-0.21\n+0.32\n+-0.44\n+0.31\n+-0.61\n+-0.69\n+1.08\n+0.4\n+1.21\n+0.05\n+-0.89\n+0.12\n+-0.48\n+1.05\n+-1.79\n+0.45\n+0.02\n+-0.6\n+0.44\n+-0.32\n+-0.55\n+-0.03\n+0.88\n+0.18\n+0.36\n+0.46\n+0.02\n+0.7\n+0.29\n+0.17\n+0.07\n+0.78\n+0.71\n+-1.09\n+0.15\n+0.58\n+1.03\n+0.08\n+-0.02\n+0.9\n+1.25\n+0.14\n+-0.4\n+1.03\n+-0.91\n+-0.56\n+1.44\n+0.88\n+-0.02\n+-0.32\n+-0.06\n+0.89\n+0.37\n+-0.88\n+1.11\n+-1.05\n+0.54\n+1.1\n+0.44\n+-0.37\n+-0.49\n+-0.02\n+1.14\n+0.91\n+-0.19\n+-0.48\n+-0.61\n+-0.67\n+-0.08\n+-0.4\n+0.61\n+-1.43\n+0.03\n+1.19\n+0.22\n+0.05\n+1.27\n+0.07\n+0.79\n+1.32\n+0.93\n+0.02\n+1.67\n+-1.05\n+2.48\n+-0.63\n+2.56\n+1.74\n+0.65\n+0.13\n+-0.18\n+1.38\n+-0.05\n+3.12\n+2.49\n+-0.34\n+0.49\n+-1.33\n+3.17\n+-0.03\n+-1.66\n+1.52\n+3.14\n+-0.1\n+-3.18\n+1.77\n+2.42\n+-1.88\n+-2.16\n+0.23\n+-0.5\n+1.59\n+-1.95\n+-1.46\n+0.85\n+1.63\n+1.69\n+-0.06\n+0.54\n+-2.69\n+-2.8\n+-1.36\n+0.66\n+-1.73\n+1.71\n+-0.86\n+1.26\n+1.34\n+0.65\n+1.15\n+1.95\n+0.56\n+2.31\n+1.27\n+1.15\n+2.73\n+0.21\n+-0.01\n+0.03\n+2.15\n+1.09\n+-0.21\n+2.04\n+-0.91\n+-2.72\n+0.64\n+0.76\n+1.61\n+-4.28\n+0.51\n+-0.78\n+-0.97\n+1.46\n+1.09\n+-1.41\n+1.45\n+-3.44\n+-0.13\n+2.15\n+2.57\n+3.67\n+1.66\n+1.62\n+0.25\n+1.25\n+-1.92\n+2.12\n+1.31\n+-1.34\n+1.89\n+2.7\n+0.23\n+-2.71\n+1.12\n+-0.41\n+-4.31\n+-5.61\n+-4.88\n+3.48\n+0.89\n+-2.85\n+0.25\n+5.74\n+0.84\n+3.1\n+-1.91\n+2.28\n+3.23\n+1\n+-1.43\n+-0.24\n+3.37\n+-0.8\n+2.31\n+-0.78\n+1.79\n+2.02\n+0.76\n+1.18\n+0.48\n+0.91\n+1.32\n+1.49\n+-1.35\n+2.35\n+0.68\n+-0.44\n+0.33\n+2.81\n+-0.13\n+-1.27\n+2.95\n+-0.69\n+-4.3\n+1.13\n+1.92\n+2.79\n+2.46\n+-0.81\n+0.82\n+0.45\n+-1.66\n+-1.99\n+1.83\n+-4.93\n+-1.39\n+-1.14\n+-6.5\n+-0.54\n+3.64\n+0.25\n+-0.12\n+6.28\n+0.17\n+3.42\n+3.81\n+-4.93\n+1.56\n+4.11\n+-1.11\n+3.07\n+-2.81\n+0.1\n+2.47\n+-4.23\n+-2.88\n+0.84\n+7.39\n+1.09\n+0.9\n+-1.84\n+1.12\n+3.81\n+0.74\n+4.96\n+-4.51\n+-0.85\n+-4.88\n+3.38\n+2.18\n+-0.23\n+-5.75\n+-5.88\n+3.68\n+-2.39\n+4.12\n+-3.43\n+-1.75\n+-7.04\n+4.48\n+0.13\n+-8.11\n+-4.97\n+-3.83\n+5.33\n+3.47\n+2.69\n+-0.96\n+3.95\n+4.95\n+3.73\n+0.87\n+3.56\n+3.64\n+-4.32\n+0.07\n+-4.12\n+3.45\n+-0.69\n+-4.11\n+-0.24\n+8.1\n+1.85\n+2.63\n+0.63\n+0.47\n+1.86\n+-2.39\n+0.25\n+3.7\n+-0.54\n+1.03\n+5.09\n+1.38\n+-2.02\n+-4.35\n+-0.16\n+-4.55\n+-2.02\n+-0.69\n+3.96\n+-3.97\n+4.18\n+-0.14\n+-12.33\n+1.59\n+-0.98\n+-0.35\n+-2.24\n+-3.67\n+-3.03\n+-1.28\n+-6.69\n+-7.16\n+-8.61\n+10.36\n+-3.93\n+-1.41\n+8.42\n+4.61\n+1.77\n+3.94\n+3.85\n+4.04\n+-6.44\n+-1.87\n+-3.01\n+5.17\n+2.2\n+-1.05\n+10.67\n+-1.15\n+3.06\n+-1.13\n+-1.46\n+4.1\n+-0.84\n+-0.53\n+2.33\n+-2.34\n+-0.8\n+5.36\n+-5.43\n+-2.21\n+-1.4\n+0.02\n+-2.32\n+4.36\n+-1.63\n+-2.08\n+-0.24\n+-4.19\n+2.49\n+0.27\n+-5.85\n+-2.21\n+2.17\n+7.62\n+0.41\n+-1.71\n+5.15\n+2.61\n+-0.75\n+-9.39\n+1.55\n+1.41\n+3.82\n+-3.65\n+5.31\n+0.17\n+-2.68\n+3.83\n+0.9\n+5.51\n+0\n+-7.5\n+4.34\n+1.78\n+6.22\n+-0.5\n+-11.57\n+4.2\n+4.95\n+3\n+7.43\n+0.71\n+3.08\n+2.01\n+13.05\n+-4.76\n+-6.21\n+1.72\n+4.73\n+-3.19\n+-0.22\n+-1.38\n+-0.29\n+-8.13\n+-6.61\n+5.71\n+4.46\n+-3.8\n+-2.15\n+-7.29\n+-1.15\n+4.48\n+-4.56\n+-2.27\n+-2.52\n+12.42\n+0.91\n+13.29\n+4.83\n+2.1\n+4.66\n+2.76\n+4.9\n+11.46\n+-2.03\n+5.72\n+-5.55\n+1.84\n+1.67\n+-2.52\n+2.85\n+-1.47\n+-1.52\n+-6.35\n+2.12\n+0.87\n+-9.5\n+2.63\n+-2.52\n+16.02\n+-0.58\n+-0.01\n+-2.51\n+3.66\n+12.39\n+1.55\n+-0.52\n+-0.83\n+9.72\n+2.3\n+-0.93\n+-2.29\n+-6.55\n+7.74\n+12.35\n+9.11\ndiff --git a/statsmodels/tsa/tests/results/DUN.csv b/statsmodels/tsa/tests/results/DUN.csv\nnew file mode 100644\nindex 00000000000..2bf85f2b772\n--- /dev/null\n+++ b/statsmodels/tsa/tests/results/DUN.csv\n@@ -0,0 +1,456 @@\n+SCHWERTDUN\n+0.4\n+0.2\n+-0.1\n+-0.4\n+0.1\n+0\n+0.3\n+-0.1\n+-0.1\n+0.1\n+0.2\n+0.3\n+0.4\n+0.3\n+0.3\n+0.8\n+0.1\n+0.5\n+0.1\n+-0.2\n+1.3\n+-1.5\n+0.2\n+-0.1\n+-0.1\n+-0.1\n+-0.5\n+-0.3\n+-0.1\n+-0.4\n+-0.5\n+-0.1\n+-0.2\n+0\n+0.1\n+-0.6\n+-0.3\n+0\n+-0.3\n+-0.1\n+0.2\n+-0.1\n+0\n+0.2\n+0.2\n+0\n+-0.4\n+0.1\n+-0.1\n+-0.2\n+0\n+0.1\n+0\n+0.2\n+0.2\n+-0.3\n+-0.1\n+-0.2\n+-0.1\n+0.2\n+-0.3\n+0\n+0.1\n+-0.2\n+0\n+0.1\n+0.1\n+0.2\n+0.2\n+0.4\n+1\n+0.4\n+0.3\n+0.5\n+0.2\n+0\n+-0.3\n+0.2\n+0.2\n+0.1\n+-0.4\n+-0.4\n+-0.3\n+-0.1\n+-0.2\n+-0.1\n+0.1\n+-0.4\n+-0.1\n+-0.2\n+0.2\n+-0.1\n+0.2\n+-0.1\n+0\n+-0.2\n+-0.1\n+0.3\n+-0.2\n+0.3\n+0\n+0.1\n+-0.3\n+-0.2\n+0\n+0.4\n+-0.1\n+0\n+-0.3\n+-0.2\n+0.2\n+0.2\n+0.2\n+-0.1\n+-0.1\n+0.3\n+0.1\n+0.6\n+0.1\n+0.6\n+0.6\n+0.3\n+0.7\n+0\n+-0.1\n+0.2\n+-0.1\n+-0.3\n+-0.4\n+-0.5\n+0\n+-0.2\n+-0.1\n+-0.3\n+-0.4\n+-0.1\n+-0.1\n+0.1\n+0.1\n+0.3\n+0.2\n+0.1\n+-0.5\n+-0.1\n+-0.4\n+0.6\n+-0.2\n+-0.1\n+0.3\n+0.1\n+0.1\n+-0.1\n+0.6\n+0\n+0.5\n+0\n+0.3\n+0\n+0.1\n+0.1\n+-0.2\n+0.1\n+-0.4\n+0.1\n+-0.2\n+-0.4\n+-0.1\n+-0.2\n+-0.3\n+0.1\n+0\n+-0.1\n+0\n+-0.1\n+0.3\n+-0.1\n+-0.2\n+0.3\n+-0.2\n+0.2\n+0.2\n+-0.2\n+0\n+0.2\n+-0.3\n+0\n+-0.2\n+0.1\n+0\n+0.2\n+-0.2\n+0.1\n+-0.2\n+0\n+-0.1\n+-0.2\n+0.1\n+-0.3\n+0.1\n+0.1\n+0\n+-0.3\n+0.2\n+-0.1\n+0.2\n+-0.4\n+0.1\n+-0.2\n+0\n+-0.2\n+0\n+-0.1\n+-0.1\n+-0.1\n+-0.1\n+0\n+-0.2\n+0\n+0\n+0.1\n+-0.1\n+0\n+0\n+-0.1\n+0\n+-0.1\n+0.2\n+0.1\n+-0.1\n+0\n+0\n+0\n+0.1\n+-0.1\n+0\n+0\n+0.2\n+-0.1\n+-0.1\n+-0.1\n+0.1\n+-0.1\n+-0.2\n+0\n+0.2\n+0\n+-0.2\n+-0.1\n+0\n+0\n+0\n+0\n+0\n+0\n+0\n+0\n+0.1\n+0\n+0\n+0.2\n+0\n+-0.2\n+0\n+0.4\n+0.3\n+0.2\n+0.2\n+0.2\n+0.1\n+0.1\n+0.1\n+0.3\n+0.1\n+0.4\n+0.2\n+-0.2\n+0\n+0.1\n+-0.1\n+0\n+0\n+0.1\n+0.1\n+-0.1\n+-0.2\n+0.2\n+0\n+-0.2\n+-0.1\n+0.1\n+-0.1\n+0\n+0\n+-0.1\n+0\n+-0.1\n+0.1\n+-0.3\n+-0.1\n+-0.3\n+0.1\n+-0.1\n+0.1\n+-0.1\n+0\n+-0.1\n+0\n+0\n+-0.2\n+0.2\n+0.1\n+0.2\n+0.1\n+-0.1\n+0\n+0\n+0.3\n+0.1\n+0\n+0.4\n+0.1\n+0.6\n+0.6\n+0.9\n+0\n+0.5\n+0.2\n+0.2\n+-0.2\n+-0.2\n+-0.2\n+0\n+0\n+-0.1\n+-0.1\n+-0.3\n+-0.2\n+-0.1\n+0.1\n+-0.3\n+0.2\n+0.2\n+0\n+-0.2\n+0.1\n+0.1\n+0\n+-0.3\n+0.1\n+-0.2\n+-0.2\n+-0.2\n+0.2\n+-0.3\n+0.1\n+-0.2\n+0\n+0\n+-0.4\n+0\n+-0.1\n+0\n+-0.2\n+-0.1\n+-0.1\n+0.3\n+-0.3\n+0.1\n+-0.2\n+0.1\n+0.1\n+-0.1\n+0\n+-0.1\n+0\n+-0.2\n+0.1\n+0\n+0.3\n+-0.1\n+0.1\n+-0.1\n+0.1\n+0.3\n+0\n+0\n+0.6\n+0.6\n+0.1\n+0.2\n+-0.1\n+-0.2\n+0\n+0\n+-0.3\n+0.3\n+-0.1\n+0\n+-0.2\n+0.3\n+0\n+-0.3\n+0.2\n+0.2\n+0.3\n+0.4\n+0.2\n+0.1\n+0.3\n+0.1\n+0.3\n+0.1\n+0.2\n+0.2\n+0.1\n+0.2\n+0.3\n+0.3\n+0\n+-0.3\n+0\n+-0.1\n+-0.1\n+0\n+-0.1\n+-0.7\n+0.1\n+-0.3\n+-0.4\n+-0.3\n+-0.3\n+-0.2\n+-0.2\n+0\n+0\n+-0.3\n+-0.3\n+0.2\n+0.1\n+-0.1\n+-0.1\n+-0.1\n+0\n+0.2\n+-0.1\n+0\n+0\n+0\n+0\n+0\n+-0.2\n+0\n+0\n+-0.1\n+-0.1\ndiff --git a/statsmodels/tsa/tests/results/SP500.csv b/statsmodels/tsa/tests/results/SP500.csv\nnew file mode 100644\nindex 00000000000..aa6b9897193\n--- /dev/null\n+++ b/statsmodels/tsa/tests/results/SP500.csv\n@@ -0,0 +1,469 @@\n+SCHWERTSP500\n+15.66\n+15.43\n+15.17\n+14.58\n+14.45\n+15.21\n+15.76\n+15.32\n+15.11\n+15.43\n+14.99\n+15.3\n+14.69\n+14\n+15.08\n+15.48\n+16.69\n+16.74\n+15.85\n+15.97\n+15.49\n+16.54\n+14.75\n+15.2\n+15.22\n+14.62\n+15.06\n+14.74\n+14.19\n+14.16\n+15.04\n+15.22\n+15.58\n+16.04\n+16.06\n+16.76\n+17.05\n+17.22\n+17.29\n+18.07\n+18.78\n+17.69\n+17.84\n+18.42\n+19.45\n+19.53\n+19.51\n+20.41\n+21.66\n+21.8\n+21.4\n+22.43\n+21.52\n+20.96\n+22.4\n+23.28\n+23.26\n+22.94\n+22.88\n+23.77\n+24.14\n+23.26\n+24.37\n+23.32\n+23.86\n+24.96\n+25.4\n+25.03\n+24.54\n+24.52\n+25.66\n+26.57\n+26.38\n+25.9\n+25.29\n+24.62\n+24.54\n+24.14\n+24.75\n+23.32\n+23.35\n+24.54\n+24.76\n+24.81\n+26.08\n+26.15\n+26.94\n+28.26\n+29.19\n+29.21\n+30.88\n+29.83\n+32.31\n+31.68\n+34.24\n+35.98\n+36.63\n+36.76\n+36.58\n+37.96\n+37.91\n+41.03\n+43.52\n+43.18\n+43.67\n+42.34\n+45.51\n+45.48\n+43.82\n+45.34\n+48.48\n+48.38\n+45.2\n+46.97\n+49.39\n+47.51\n+45.35\n+45.58\n+45.08\n+46.67\n+44.72\n+43.26\n+44.11\n+45.74\n+47.43\n+47.37\n+47.91\n+45.22\n+42.42\n+41.06\n+41.72\n+39.99\n+41.7\n+40.84\n+42.1\n+43.44\n+44.09\n+45.24\n+47.19\n+47.75\n+50.06\n+51.33\n+52.48\n+55.21\n+55.42\n+55.41\n+55.44\n+57.59\n+58.68\n+58.47\n+60.51\n+59.6\n+56.88\n+57.52\n+58.28\n+59.89\n+55.61\n+56.12\n+55.34\n+54.37\n+55.83\n+56.92\n+55.51\n+56.96\n+53.52\n+53.39\n+55.54\n+58.11\n+61.78\n+63.44\n+65.06\n+65.31\n+66.56\n+64.64\n+66.76\n+68.07\n+66.73\n+68.62\n+71.32\n+71.55\n+68.84\n+69.96\n+69.55\n+65.24\n+59.63\n+54.75\n+58.23\n+59.12\n+56.27\n+56.52\n+62.26\n+63.1\n+66.2\n+64.29\n+66.57\n+69.8\n+70.8\n+69.37\n+69.13\n+72.5\n+71.7\n+74.01\n+73.23\n+75.02\n+77.04\n+77.8\n+78.98\n+79.46\n+80.37\n+81.69\n+83.18\n+81.83\n+84.18\n+84.86\n+84.42\n+84.75\n+87.56\n+87.43\n+86.16\n+89.11\n+88.42\n+84.12\n+85.25\n+87.17\n+89.96\n+92.42\n+91.61\n+92.43\n+92.88\n+91.22\n+89.23\n+91.06\n+86.13\n+84.74\n+83.6\n+77.1\n+76.56\n+80.2\n+80.45\n+80.33\n+86.61\n+86.78\n+90.2\n+94.01\n+89.08\n+90.64\n+94.75\n+93.64\n+96.71\n+93.9\n+94\n+96.47\n+92.24\n+89.36\n+90.2\n+97.59\n+98.68\n+99.58\n+97.74\n+98.86\n+102.67\n+103.41\n+108.37\n+103.86\n+103.01\n+98.13\n+101.51\n+103.69\n+103.46\n+97.71\n+91.83\n+95.51\n+93.12\n+97.24\n+93.81\n+92.06\n+85.02\n+89.5\n+89.63\n+81.52\n+76.55\n+72.72\n+78.05\n+81.52\n+84.21\n+83.25\n+87.2\n+92.15\n+95.88\n+96.75\n+100.31\n+103.95\n+99.63\n+99.7\n+95.58\n+99.03\n+98.34\n+94.23\n+93.99\n+102.09\n+103.94\n+106.57\n+107.2\n+107.67\n+109.53\n+107.14\n+107.39\n+111.09\n+110.55\n+111.58\n+116.67\n+118.05\n+116.03\n+111.68\n+111.52\n+106.97\n+104.95\n+104.26\n+108.22\n+104.25\n+108.43\n+108.29\n+95.96\n+97.55\n+96.57\n+96.22\n+93.98\n+90.31\n+87.28\n+86\n+79.31\n+72.15\n+63.54\n+73.9\n+69.97\n+68.56\n+76.98\n+81.59\n+83.36\n+87.3\n+91.15\n+95.19\n+88.75\n+86.88\n+83.87\n+89.04\n+91.24\n+90.19\n+100.86\n+99.71\n+102.77\n+101.64\n+100.18\n+104.28\n+103.44\n+102.91\n+105.24\n+102.9\n+102.1\n+107.46\n+102.03\n+99.82\n+98.42\n+98.44\n+96.12\n+100.48\n+98.85\n+96.77\n+96.53\n+92.34\n+94.83\n+95.1\n+89.25\n+87.04\n+89.21\n+96.83\n+97.24\n+95.53\n+100.68\n+103.29\n+102.54\n+93.15\n+94.7\n+96.11\n+99.93\n+96.28\n+101.59\n+101.76\n+99.08\n+102.91\n+103.81\n+109.32\n+109.32\n+101.82\n+106.16\n+107.94\n+114.16\n+113.66\n+102.09\n+106.29\n+111.24\n+114.24\n+121.67\n+122.38\n+125.46\n+127.47\n+140.52\n+135.76\n+129.55\n+131.27\n+136\n+132.81\n+132.59\n+131.21\n+130.92\n+122.79\n+116.18\n+121.89\n+126.35\n+122.55\n+120.4\n+113.11\n+111.96\n+116.44\n+111.88\n+109.61\n+107.09\n+119.51\n+120.42\n+133.71\n+138.54\n+140.64\n+145.3\n+148.06\n+152.96\n+164.42\n+162.39\n+168.11\n+162.56\n+164.4\n+166.07\n+163.55\n+166.4\n+164.93\n+163.41\n+157.06\n+159.18\n+160.05\n+150.55\n+153.18\n+150.66\n+166.68\n+166.1\n+166.09\n+163.58\n+167.24\n+179.63\n+181.18\n+180.66\n+179.83\n+189.55\n+191.85\n+190.92\n+188.63\n+182.08\n+189.82\n+202.17\n+211.28\ndiff --git a/statsmodels/tsa/tests/results/UN.csv b/statsmodels/tsa/tests/results/UN.csv\nnew file mode 100644\nindex 00000000000..72ec601dd7b\n--- /dev/null\n+++ b/statsmodels/tsa/tests/results/UN.csv\n@@ -0,0 +1,457 @@\n+SCHWERTUN\n+3.4\n+3.8\n+4\n+3.9\n+3.5\n+3.6\n+3.6\n+3.9\n+3.8\n+3.7\n+3.8\n+4\n+4.3\n+4.7\n+5\n+5.3\n+6.1\n+6.2\n+6.7\n+6.8\n+6.6\n+7.9\n+6.4\n+6.6\n+6.5\n+6.4\n+6.3\n+5.8\n+5.5\n+5.4\n+5\n+4.5\n+4.4\n+4.2\n+4.2\n+4.3\n+3.7\n+3.4\n+3.4\n+3.1\n+3\n+3.2\n+3.1\n+3.1\n+3.3\n+3.5\n+3.5\n+3.1\n+3.2\n+3.1\n+2.9\n+2.9\n+3\n+3\n+3.2\n+3.4\n+3.1\n+3\n+2.8\n+2.7\n+2.9\n+2.6\n+2.6\n+2.7\n+2.5\n+2.5\n+2.6\n+2.7\n+2.9\n+3.1\n+3.5\n+4.5\n+4.9\n+5.2\n+5.7\n+5.9\n+5.9\n+5.6\n+5.8\n+6\n+6.1\n+5.7\n+5.3\n+5\n+4.9\n+4.7\n+4.6\n+4.7\n+4.3\n+4.2\n+4\n+4.2\n+4.1\n+4.3\n+4.2\n+4.2\n+4\n+3.9\n+4.2\n+4\n+4.3\n+4.3\n+4.4\n+4.1\n+3.9\n+3.9\n+4.3\n+4.2\n+4.2\n+3.9\n+3.7\n+3.9\n+4.1\n+4.3\n+4.2\n+4.1\n+4.4\n+4.5\n+5.1\n+5.2\n+5.8\n+6.4\n+6.7\n+7.4\n+7.4\n+7.3\n+7.5\n+7.4\n+7.1\n+6.7\n+6.2\n+6.2\n+6\n+5.9\n+5.6\n+5.2\n+5.1\n+5\n+5.1\n+5.2\n+5.5\n+5.7\n+5.8\n+5.3\n+5.2\n+4.8\n+5.4\n+5.2\n+5.1\n+5.4\n+5.5\n+5.6\n+5.5\n+6.1\n+6.1\n+6.6\n+6.6\n+6.9\n+6.9\n+7\n+7.1\n+6.9\n+7\n+6.6\n+6.7\n+6.5\n+6.1\n+6\n+5.8\n+5.5\n+5.6\n+5.6\n+5.5\n+5.5\n+5.4\n+5.7\n+5.6\n+5.4\n+5.7\n+5.5\n+5.7\n+5.9\n+5.7\n+5.7\n+5.9\n+5.6\n+5.6\n+5.4\n+5.5\n+5.5\n+5.7\n+5.5\n+5.6\n+5.4\n+5.4\n+5.3\n+5.1\n+5.2\n+4.9\n+5\n+5.1\n+5.1\n+4.8\n+5\n+4.9\n+5.1\n+4.7\n+4.8\n+4.6\n+4.6\n+4.4\n+4.4\n+4.3\n+4.2\n+4.1\n+4\n+4\n+3.8\n+3.8\n+3.8\n+3.9\n+3.8\n+3.8\n+3.8\n+3.7\n+3.7\n+3.6\n+3.8\n+3.9\n+3.8\n+3.8\n+3.8\n+3.8\n+3.9\n+3.8\n+3.8\n+3.8\n+4\n+3.9\n+3.8\n+3.7\n+3.8\n+3.7\n+3.5\n+3.5\n+3.7\n+3.7\n+3.5\n+3.4\n+3.4\n+3.4\n+3.4\n+3.4\n+3.4\n+3.4\n+3.4\n+3.4\n+3.5\n+3.5\n+3.5\n+3.7\n+3.7\n+3.5\n+3.5\n+3.9\n+4.2\n+4.4\n+4.6\n+4.8\n+4.9\n+5\n+5.1\n+5.4\n+5.5\n+5.9\n+6.1\n+5.9\n+5.9\n+6\n+5.9\n+5.9\n+5.9\n+6\n+6.1\n+6\n+5.8\n+6\n+6\n+5.8\n+5.7\n+5.8\n+5.7\n+5.7\n+5.7\n+5.6\n+5.6\n+5.5\n+5.6\n+5.3\n+5.2\n+4.9\n+5\n+4.9\n+5\n+4.9\n+4.9\n+4.8\n+4.8\n+4.8\n+4.6\n+4.8\n+4.9\n+5.1\n+5.2\n+5.1\n+5.1\n+5.1\n+5.4\n+5.5\n+5.5\n+5.9\n+6\n+6.6\n+7.2\n+8.1\n+8.1\n+8.6\n+8.8\n+9\n+8.8\n+8.6\n+8.4\n+8.4\n+8.4\n+8.3\n+8.2\n+7.9\n+7.7\n+7.6\n+7.7\n+7.4\n+7.6\n+7.8\n+7.8\n+7.6\n+7.7\n+7.8\n+7.8\n+7.5\n+7.6\n+7.4\n+7.2\n+7\n+7.2\n+6.9\n+7\n+6.8\n+6.8\n+6.8\n+6.4\n+6.4\n+6.3\n+6.3\n+6.1\n+6\n+5.9\n+6.2\n+5.9\n+6\n+5.8\n+5.9\n+6\n+5.9\n+5.9\n+5.8\n+5.8\n+5.6\n+5.7\n+5.7\n+6\n+5.9\n+6\n+5.9\n+6\n+6.3\n+6.3\n+6.3\n+6.9\n+7.5\n+7.6\n+7.8\n+7.7\n+7.5\n+7.5\n+7.5\n+7.2\n+7.5\n+7.4\n+7.4\n+7.2\n+7.5\n+7.5\n+7.2\n+7.4\n+7.6\n+7.9\n+8.3\n+8.5\n+8.6\n+8.9\n+9\n+9.3\n+9.4\n+9.6\n+9.8\n+9.9\n+10.1\n+10.4\n+10.7\n+10.7\n+10.4\n+10.4\n+10.3\n+10.2\n+10.2\n+10.1\n+9.4\n+9.5\n+9.2\n+8.8\n+8.5\n+8.2\n+8\n+7.8\n+7.8\n+7.8\n+7.5\n+7.2\n+7.4\n+7.5\n+7.4\n+7.3\n+7.2\n+7.2\n+7.4\n+7.3\n+7.3\n+7.3\n+7.3\n+7.3\n+7.3\n+7.1\n+7.1\n+7.1\n+7\n+6.9\ndiff --git a/statsmodels/tsa/tests/test_stattools.py b/statsmodels/tsa/tests/test_stattools.py\nindex 064ddad0d76..7c3be873425 100644\n--- a/statsmodels/tsa/tests/test_stattools.py\n+++ b/statsmodels/tsa/tests/test_stattools.py\n@@ -1,7 +1,7 @@\n from statsmodels.compat.numpy import lstsq\n from statsmodels.compat.pandas import MONTH_END, YEAR_END, assert_index_equal\n from statsmodels.compat.platform import PLATFORM_WIN\n-from statsmodels.compat.python import lrange\n+from statsmodels.compat.python import PYTHON_IMPL_WASM, lrange\n \n import os\n import warnings\n@@ -20,7 +20,6 @@\n from scipy import stats\n from scipy.interpolate import interp1d\n \n-from statsmodels.compat.python import PYTHON_IMPL_WASM\n from statsmodels.datasets import macrodata, modechoice, nile, randhie, sunspots\n from statsmodels.tools.sm_exceptions import (\n     CollinearityWarning,\n@@ -29,6 +28,7 @@\n     MissingDataError,\n     ValueWarning,\n )\n+\n # Remove imports when range unit root test gets an R implementation\n from statsmodels.tools.validation import array_like, bool_like\n from statsmodels.tsa.arima_process import arma_acovf\n@@ -48,6 +48,7 @@\n     kpss,\n     levinson_durbin,\n     levinson_durbin_pacf,\n+    leybourne,\n     pacf,\n     pacf_burg,\n     pacf_ols,\n@@ -187,9 +188,7 @@ def setup_class(cls):\n         )\n \n     def test_store_str(self):\n-        assert_equal(\n-            self.store.__str__(), \"Augmented Dickey-Fuller Test Results\"\n-        )\n+        assert_equal(self.store.__str__(), \"Augmented Dickey-Fuller Test Results\")\n \n \n @pytest.mark.parametrize(\"x\", [np.full(8, 5.0)])\n@@ -297,9 +296,7 @@ def test_acf_drop(self):\n         assert_almost_equal(self.res_drop[0][1:41], self.acf, DECIMAL_8)\n \n     def test_acf_conservative(self):\n-        assert_almost_equal(\n-            self.res_conservative[0][1:41], self.acf, DECIMAL_8\n-        )\n+        assert_almost_equal(self.res_conservative[0][1:41], self.acf, DECIMAL_8)\n \n     def test_qstat_none(self):\n         # todo why is res1/qstat 1 short\n@@ -350,10 +347,7 @@ def test_yw(self):\n         pacfyw = pacf_yw(self.x, nlags=40, method=\"mle\")\n         assert_almost_equal(pacfyw[1:], self.pacfyw, DECIMAL_8)\n \n-    @pytest.mark.skipif(\n-        PYTHON_IMPL_WASM,\n-        reason=\"No fp exception support in WASM\"\n-    )\n+    @pytest.mark.skipif(PYTHON_IMPL_WASM, reason=\"No fp exception support in WASM\")\n     def test_yw_singular(self):\n         with pytest.warns(ValueWarning):\n             pacf(np.ones(30), nlags=6)\n@@ -387,7 +381,7 @@ class TestCCF:\n \n     @classmethod\n     def setup_class(cls):\n-        cls.ccf = cls.results['ccf']\n+        cls.ccf = cls.results[\"ccf\"]\n         cls.res1 = ccf(cls.x, cls.y, nlags=cls.nlags, adjusted=False, fft=False)\n \n     def test_ccf(self):\n@@ -395,7 +389,9 @@ def test_ccf(self):\n \n     def test_confint(self):\n         alpha = 0.05\n-        res2, confint = ccf(self.x, self.y, nlags=self.nlags, adjusted=False, fft=False, alpha=alpha)\n+        res2, confint = ccf(\n+            self.x, self.y, nlags=self.nlags, adjusted=False, fft=False, alpha=alpha\n+        )\n         assert_equal(res2, self.res1)\n         assert_almost_equal(res2 - confint[:, 0], confint[:, 1] - res2, DECIMAL_8)\n         alpha1 = stats.norm.cdf(confint[:, 1] - res2, scale=1.0 / np.sqrt(len(self.x)))\n@@ -408,7 +404,7 @@ class TestBreakvarHeteroskedasticityTest:\n     def test_1d_input(self):\n \n         input_residuals = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0]\n-        expected_statistic = (4.0 ** 2 + 5.0 ** 2) / (0.0 ** 2 + 1.0 ** 2)\n+        expected_statistic = (4.0**2 + 5.0**2) / (0.0**2 + 1.0**2)\n         # ~ F(2, 2), two-sided test\n         expected_pvalue = 2 * min(\n             self.f.cdf(expected_statistic, 2, 2),\n@@ -438,9 +434,8 @@ def test_2d_input_with_missing_values(self):\n         )\n         expected_statistic = np.array(\n             [\n-                (8.0 ** 2 + 7.0 ** 2 + 6.0 ** 2)\n-                / (0.0 ** 2 + 1.0 ** 2 + 2.0 ** 2),\n-                (8.0 ** 2 + 7.0 ** 2 + 6.0 ** 2) / (0.0 ** 2 + 2.0 ** 2),\n+                (8.0**2 + 7.0**2 + 6.0**2) / (0.0**2 + 1.0**2 + 2.0**2),\n+                (8.0**2 + 7.0**2 + 6.0**2) / (0.0**2 + 2.0**2),\n                 np.nan,\n             ]\n         )\n@@ -473,9 +468,7 @@ def test_2d_input_with_missing_values(self):\n             (0.5, 10, 2 * min(f.cdf(10, 3, 3), f.sf(10, 3, 3))),\n         ],\n     )\n-    def test_subset_length(\n-        self, subset_length, expected_statistic, expected_pvalue\n-    ):\n+    def test_subset_length(self, subset_length, expected_statistic, expected_pvalue):\n \n         input_residuals = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0]\n         actual_statistic, actual_pvalue = breakvar_heteroskedasticity_test(\n@@ -494,9 +487,7 @@ def test_subset_length(\n             (\"increasing\", 41, f.sf(41, 2, 2)),\n         ],\n     )\n-    def test_alternative(\n-        self, alternative, expected_statistic, expected_pvalue\n-    ):\n+    def test_alternative(self, alternative, expected_statistic, expected_pvalue):\n \n         input_residuals = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0]\n         actual_statistic, actual_pvalue = breakvar_heteroskedasticity_test(\n@@ -509,7 +500,7 @@ def test_alternative(\n     def test_use_chi2(self):\n \n         input_residuals = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0]\n-        expected_statistic = (4.0 ** 2 + 5.0 ** 2) / (0.0 ** 2 + 1.0 ** 2)\n+        expected_statistic = (4.0**2 + 5.0**2) / (0.0**2 + 1.0**2)\n         expected_pvalue = 2 * min(\n             self.chi2.cdf(2 * expected_statistic, 2),\n             self.chi2.sf(2 * expected_statistic, 2),\n@@ -547,9 +538,7 @@ class TestCoint_t(CheckCoint):\n     @classmethod\n     def setup_class(cls):\n         # cls.coint_t = coint(cls.y1, cls.y2, trend=\"c\")[0]\n-        cls.coint_t = coint(cls.y1, cls.y2, trend=\"c\", maxlag=0, autolag=None)[\n-            0\n-        ]\n+        cls.coint_t = coint(cls.y1, cls.y2, trend=\"c\", maxlag=0, autolag=None)[0]\n         cls.teststat = -1.8208817\n         cls.teststat = -1.830170986148\n \n@@ -657,9 +646,7 @@ def test_coint():\n     for trend in [\"c\", \"ct\", \"ctt\", \"n\"]:\n         res1 = {}\n         res1[0] = coint(y[:, 0], y[:, 1], trend=trend, maxlag=4, autolag=None)\n-        res1[1] = coint(\n-            y[:, 0], y[:, 1:3], trend=trend, maxlag=4, autolag=None\n-        )\n+        res1[1] = coint(y[:, 0], y[:, 1:3], trend=trend, maxlag=4, autolag=None)\n         res1[2] = coint(y[:, 0], y[:, 2:], trend=trend, maxlag=4, autolag=None)\n         res1[3] = coint(y[:, 0], y[:, 1:], trend=trend, maxlag=4, autolag=None)\n \n@@ -703,7 +690,7 @@ def test_coint_perfect_collinearity():\n     x = scale_e * np.random.randn(nobs, 2)\n     y = 1 + x.sum(axis=1) + 1e-7 * np.random.randn(nobs)\n     warnings.simplefilter(\"always\", CollinearityWarning)\n-    with warnings.catch_warnings(record=True) as w:\n+    with warnings.catch_warnings(record=True):\n         c = coint(y, x, trend=\"c\", maxlag=0, autolag=None)\n     assert_equal(c[1], 0.0)\n     assert_(np.isneginf(c[0]))\n@@ -722,9 +709,7 @@ def test_grangercausality(self):\n         with pytest.warns(FutureWarning, match=\"verbose is\"):\n             gr = grangercausalitytests(data[:, 1::-1], 2, verbose=False)\n         assert_almost_equal(r_result, gr[2][0][\"ssr_ftest\"], decimal=7)\n-        assert_almost_equal(\n-            gr[2][0][\"params_ftest\"], gr[2][0][\"ssr_ftest\"], decimal=7\n-        )\n+        assert_almost_equal(gr[2][0][\"params_ftest\"], gr[2][0][\"ssr_ftest\"], decimal=7)\n \n     def test_grangercausality_single(self):\n         mdata = macrodata.load_pandas().data\n@@ -737,12 +722,8 @@ def test_grangercausality_single(self):\n             gr2 = grangercausalitytests(data[:, 1::-1], [2], verbose=False)\n         assert 1 in gr\n         assert 1 not in gr2\n-        assert_almost_equal(\n-            gr[2][0][\"ssr_ftest\"], gr2[2][0][\"ssr_ftest\"], decimal=7\n-        )\n-        assert_almost_equal(\n-            gr[2][0][\"params_ftest\"], gr2[2][0][\"ssr_ftest\"], decimal=7\n-        )\n+        assert_almost_equal(gr[2][0][\"ssr_ftest\"], gr2[2][0][\"ssr_ftest\"], decimal=7)\n+        assert_almost_equal(gr[2][0][\"params_ftest\"], gr2[2][0][\"ssr_ftest\"], decimal=7)\n \n     def test_granger_fails_on_nobs_check(self, reset_randomstate):\n         # Test that if maxlag is too large, Granger Test raises a clear error.\n@@ -804,9 +785,7 @@ def test_fail_unclear_hypothesis(self):\n         with pytest.warns(InterpolationWarning):\n             kpss(self.x, \"CT\", nlags=\"legacy\")\n \n-        assert_raises(\n-            ValueError, kpss, self.x, \"unclear hypothesis\", nlags=\"legacy\"\n-        )\n+        assert_raises(ValueError, kpss, self.x, \"unclear hypothesis\", nlags=\"legacy\")\n \n     def test_teststat(self):\n         with pytest.warns(InterpolationWarning):\n@@ -861,9 +840,7 @@ def test_kpss_fails_on_nobs_check(self):\n         # clear error\n         # GH5925\n         nobs = len(self.x)\n-        msg = r\"lags \\({}\\) must be < number of observations \\({}\\)\".format(\n-            nobs, nobs\n-        )\n+        msg = r\"lags \\({}\\) must be < number of observations \\({}\\)\".format(nobs, nobs)\n         with pytest.raises(ValueError, match=msg):\n             kpss(self.x, \"c\", nlags=nobs)\n \n@@ -919,9 +896,7 @@ def simple_rur(self, x, store=False):\n         # Table from [1] has been replicated using 200,000 samples\n         # Critical values for new n_obs values have been identified\n         pvals = [0.01, 0.025, 0.05, 0.10, 0.90, 0.95]\n-        n = np.array(\n-            [25, 50, 100, 150, 200, 250, 500, 1000, 2000, 3000, 4000, 5000]\n-        )\n+        n = np.array([25, 50, 100, 150, 200, 250, 500, 1000, 2000, 3000, 4000, 5000])\n         crit = np.array(\n             [\n                 [0.6626, 0.8126, 0.9192, 1.0712, 2.4863, 2.7312],\n@@ -981,9 +956,7 @@ def simple_rur(self, x, store=False):\n             direction = \"larger\"\n \n         if direction:\n-            warnings.warn(\n-                warn_msg.format(direction=direction), InterpolationWarning\n-            )\n+            warnings.warn(warn_msg.format(direction=direction), InterpolationWarning)\n \n         crit_dict = {\n             \"10%\": inter_crit[0, 3],\n@@ -1173,15 +1146,13 @@ def test_arma_order_select_ic_failure():\n     with warnings.catch_warnings():\n         # catch a hessian inversion and convergence failure warning\n         warnings.simplefilter(\"ignore\")\n-        res = arma_order_select_ic(y)\n+        arma_order_select_ic(y)\n \n \n def test_acf_fft_dataframe():\n     # regression test #322\n \n-    result = acf(\n-        sunspots.load_pandas().data[[\"SUNACTIVITY\"]], fft=True, nlags=20\n-    )\n+    result = acf(sunspots.load_pandas().data[[\"SUNACTIVITY\"]], fft=True, nlags=20)\n     assert_equal(result.ndim, 1)\n \n \n@@ -1190,7 +1161,7 @@ def test_levinson_durbin_acov():\n     m = 20\n     acov = rho ** np.arange(200)\n     sigma2_eps, ar, pacf, _, _ = levinson_durbin(acov, m, isacov=True)\n-    assert_allclose(sigma2_eps, 1 - rho ** 2)\n+    assert_allclose(sigma2_eps, 1 - rho**2)\n     assert_allclose(ar, np.array([rho] + [0] * (m - 1)), atol=1e-8)\n     assert_allclose(pacf, np.array([1, rho] + [0] * (m - 1)), atol=1e-8)\n \n@@ -1200,9 +1171,7 @@ def test_levinson_durbin_acov():\n @pytest.mark.parametrize(\"demean\", [True, False])\n @pytest.mark.parametrize(\"adjusted\", [True, False])\n def test_acovf_nlags(acovf_data, adjusted, demean, fft, missing):\n-    full = acovf(\n-        acovf_data, adjusted=adjusted, demean=demean, fft=fft, missing=missing\n-    )\n+    full = acovf(acovf_data, adjusted=adjusted, demean=demean, fft=fft, missing=missing)\n     limited = acovf(\n         acovf_data,\n         adjusted=adjusted,\n@@ -1221,9 +1190,7 @@ def test_acovf_nlags(acovf_data, adjusted, demean, fft, missing):\n def test_acovf_nlags_missing(acovf_data, adjusted, demean, fft, missing):\n     acovf_data = acovf_data.copy()\n     acovf_data[1:3] = np.nan\n-    full = acovf(\n-        acovf_data, adjusted=adjusted, demean=demean, fft=fft, missing=missing\n-    )\n+    full = acovf(acovf_data, adjusted=adjusted, demean=demean, fft=fft, missing=missing)\n     limited = acovf(\n         acovf_data,\n         adjusted=adjusted,\n@@ -1301,7 +1268,7 @@ def test_pacf_burg():\n     ye = y - y.mean()\n     s2y = ye.dot(ye) / 10000\n     pacf[0] = 0\n-    sigma2_direct = s2y * np.cumprod(1 - pacf ** 2)\n+    sigma2_direct = s2y * np.cumprod(1 - pacf**2)\n     assert_allclose(sigma2, sigma2_direct, atol=1e-3)\n \n \n@@ -1314,7 +1281,7 @@ def test_pacf_burg_error():\n \n def test_innovations_algo_brockwell_davis():\n     ma = -0.9\n-    acovf = np.array([1 + ma ** 2, ma])\n+    acovf = np.array([1 + ma**2, ma])\n     theta, sigma2 = innovations_algo(acovf, nobs=4)\n     exp_theta = np.array([[0], [-0.4972], [-0.6606], [-0.7404]])\n     assert_allclose(theta, exp_theta, rtol=1e-4)\n@@ -1327,7 +1294,7 @@ def test_innovations_algo_brockwell_davis():\n \n def test_innovations_algo_rtol():\n     ma = np.array([-0.9, 0.5])\n-    acovf = np.array([1 + (ma ** 2).sum(), ma[0] + ma[1] * ma[0], ma[1]])\n+    acovf = np.array([1 + (ma**2).sum(), ma[0] + ma[1] * ma[0], ma[1]])\n     theta, sigma2 = innovations_algo(acovf, nobs=500)\n     theta_2, sigma2_2 = innovations_algo(acovf, nobs=500, rtol=1e-8)\n     assert_allclose(theta, theta_2)\n@@ -1336,7 +1303,7 @@ def test_innovations_algo_rtol():\n \n def test_innovations_errors():\n     ma = -0.9\n-    acovf = np.array([1 + ma ** 2, ma])\n+    acovf = np.array([1 + ma**2, ma])\n     with pytest.raises(TypeError):\n         innovations_algo(acovf, nobs=2.2)\n     with pytest.raises(ValueError):\n@@ -1349,7 +1316,7 @@ def test_innovations_errors():\n \n def test_innovations_filter_brockwell_davis(reset_randomstate):\n     ma = -0.9\n-    acovf = np.array([1 + ma ** 2, ma])\n+    acovf = np.array([1 + ma**2, ma])\n     theta, _ = innovations_algo(acovf, nobs=4)\n     e = np.random.randn(5)\n     endog = e[1:] + ma * e[:-1]\n@@ -1363,7 +1330,7 @@ def test_innovations_filter_brockwell_davis(reset_randomstate):\n \n def test_innovations_filter_pandas(reset_randomstate):\n     ma = np.array([-0.9, 0.5])\n-    acovf = np.array([1 + (ma ** 2).sum(), ma[0] + ma[1] * ma[0], ma[1]])\n+    acovf = np.array([1 + (ma**2).sum(), ma[0] + ma[1] * ma[0], ma[1]])\n     theta, _ = innovations_algo(acovf, nobs=10)\n     endog = np.random.randn(10)\n     endog_pd = pd.Series(endog, index=pd.date_range(\"2000-01-01\", periods=10))\n@@ -1375,7 +1342,7 @@ def test_innovations_filter_pandas(reset_randomstate):\n \n def test_innovations_filter_errors():\n     ma = -0.9\n-    acovf = np.array([1 + ma ** 2, ma])\n+    acovf = np.array([1 + ma**2, ma])\n     theta, _ = innovations_algo(acovf, nobs=4)\n     with pytest.raises(ValueError):\n         innovations_filter(np.empty((2, 2)), theta)\n@@ -1398,13 +1365,11 @@ def test_innovations_algo_filter_kalman_filter(reset_randomstate):\n     endog = np.random.normal(size=10)\n \n     # Innovations algorithm approach\n-    acovf = arma_acovf(\n-        np.r_[1, -ar_params], np.r_[1, ma_params], nobs=len(endog)\n-    )\n+    acovf = arma_acovf(np.r_[1, -ar_params], np.r_[1, ma_params], nobs=len(endog))\n \n     theta, v = innovations_algo(acovf)\n     u = innovations_filter(endog, theta)\n-    llf_obs = -0.5 * u ** 2 / (sigma2 * v) - 0.5 * np.log(2 * np.pi * v)\n+    llf_obs = -0.5 * u**2 / (sigma2 * v) - 0.5 * np.log(2 * np.pi * v)\n \n     # Kalman filter apparoach\n     mod = SARIMAX(endog, order=(len(ar_params), 0, len(ma_params)))\n@@ -1413,9 +1378,7 @@ def test_innovations_algo_filter_kalman_filter(reset_randomstate):\n     # Test that the two approaches are identical\n     atol = 1e-6 if PLATFORM_WIN else 0.0\n     assert_allclose(u, res.forecasts_error[0], rtol=1e-6, atol=atol)\n-    assert_allclose(\n-        theta[1:, 0], res.filter_results.kalman_gain[0, 0, :-1], atol=atol\n-    )\n+    assert_allclose(theta[1:, 0], res.filter_results.kalman_gain[0, 0, :-1], atol=atol)\n     assert_allclose(llf_obs, res.llf_obs, atol=atol)\n \n \n@@ -1472,12 +1435,8 @@ def test_autolag_case_sensitivity(self, autolag):\n \n     # following tests compare results to R package urca.ur.za (1.13-0)\n     def test_rgnp_case(self):\n-        res = zivot_andrews(\n-            self.fail_mdl, maxlag=8, regression=\"c\", autolag=None\n-        )\n-        assert_allclose(\n-            [res[0], res[1], res[4]], [-5.57615, 0.00312, 20], rtol=1e-3\n-        )\n+        res = zivot_andrews(self.fail_mdl, maxlag=8, regression=\"c\", autolag=None)\n+        assert_allclose([res[0], res[1], res[4]], [-5.57615, 0.00312, 20], rtol=1e-3)\n \n     def test_gnpdef_case(self):\n         mdlfile = os.path.join(self.run_dir, \"gnpdef.csv\")\n@@ -1589,8 +1548,9 @@ def test_granger_causality_verbose(gc_data):\n     with pytest.warns(FutureWarning, match=\"verbose\"):\n         grangercausalitytests(gc_data, 3, verbose=True)\n \n-@pytest.mark.parametrize(\"size\",[3,5,7,9])\n-def test_pacf_small_sample(size,reset_randomstate):\n+\n+@pytest.mark.parametrize(\"size\", [3, 5, 7, 9])\n+def test_pacf_small_sample(size, reset_randomstate):\n     y = np.random.standard_normal(size)\n     a = pacf(y)\n     assert isinstance(a, np.ndarray)\n@@ -1616,15 +1576,108 @@ def test_pacf_1_obs(reset_randomstate):\n \n def test_zivot_andrews_change_data(reset_randomstate):\n     # GH9307\n-    years = pd.date_range(start='1990-01-01', end='2023-12-31', freq='YS')\n+    years = pd.date_range(start=\"1990-01-01\", end=\"2023-12-31\", freq=\"YS\")\n     df = pd.DataFrame(index=years)\n-    df['variable1'] = np.where(df.index.year <= 2002, 10, 20)\n-    df['variable2'] = np.where(df.index.year <= 2002, 10, 20)\n+    df[\"variable1\"] = np.where(df.index.year <= 2002, 10, 20)\n+    df[\"variable2\"] = np.where(df.index.year <= 2002, 10, 20)\n     df.iloc[-1] = 30\n \n     # Zivot-Andrews test with data with type float64\n     df = df.astype(float)\n     df_original = df.copy()\n-    zivot_andrews(df['variable1'])\n-    zivot_andrews(df['variable1'], regression='c')\n+    zivot_andrews(df[\"variable1\"])\n+    zivot_andrews(df[\"variable1\"], regression=\"c\")\n     pd.testing.assert_frame_equal(df, df_original)\n+\n+\n+class TestLeybourneMcCabe:\n+    cur_dir = CURR_DIR\n+    run_dir = os.path.join(cur_dir, \"results\")\n+\n+    # failure mode tests\n+    def test_fail_inputs(self):\n+        # use results/BAA.csv file for testing failure modes\n+        fail_file = os.path.join(self.run_dir, \"BAA.csv\")\n+        fail_mdl = np.asarray(pd.read_csv(fail_file))\n+        with pytest.raises(ValueError):\n+            leybourne(fail_mdl, regression=\"nc\")\n+        with pytest.raises(ValueError):\n+            leybourne(fail_mdl, method=\"gls\")\n+        with pytest.raises(ValueError):\n+            leybourne(fail_mdl, varest=\"var98\")\n+        with pytest.raises(ValueError):\n+            leybourne([[1, 1], [2, 2]], regression=\"c\")\n+        with pytest.raises(ValueError):\n+            leybourne(fail_mdl, arlags=250)\n+        with pytest.raises(ValueError):\n+            leybourne(fail_mdl, arlags=\"error\")\n+\n+    # the following tests use data sets from Schwert (1987)\n+    # and were verified against Matlab 9.13\n+    def test_baa_results(self):\n+        mdl_file = os.path.join(self.run_dir, \"BAA.csv\")\n+        mdl = np.asarray(pd.read_csv(mdl_file))\n+        res = leybourne(mdl, regression=\"ct\", method=\"mle\")\n+        assert_allclose(res[0:3], [5.4438, 0.0000, 3], rtol=1e-4, atol=1e-4)\n+        res = leybourne(mdl, regression=\"ct\")\n+        assert_allclose(res[0:3], [5.4757, 0.0000, 3], rtol=1e-4, atol=1e-4)\n+\n+    def test_dbaa_results(self):\n+        mdl_file = os.path.join(self.run_dir, \"DBAA.csv\")\n+        mdl = np.asarray(pd.read_csv(mdl_file))\n+        res = leybourne(mdl, method=\"mle\")\n+        assert_allclose(res[0:3], [0.096534, 0.602535, 2], rtol=1e-4, atol=1e-4)\n+        res = leybourne(mdl, regression=\"ct\", method=\"mle\")\n+        assert_allclose(res[0:3], [0.047924, 0.601817, 2], rtol=1e-4, atol=1e-4)\n+\n+    def test_dsp500_results(self):\n+        mdl_file = os.path.join(self.run_dir, \"DSP500.csv\")\n+        mdl = np.asarray(pd.read_csv(mdl_file))\n+        res = leybourne(mdl, method=\"mle\")\n+        assert_allclose(res[0:3], [0.3118, 0.1256, 0], rtol=1e-4, atol=1e-4)\n+        res = leybourne(mdl, varest=\"var99\", method=\"mle\")\n+        assert_allclose(res[0:3], [0.306886, 0.129934, 0], rtol=1e-4, atol=1e-4)\n+\n+    def test_dun_results(self):\n+        mdl_file = os.path.join(self.run_dir, \"DUN.csv\")\n+        mdl = np.asarray(pd.read_csv(mdl_file))\n+        res = leybourne(mdl, regression=\"ct\", method=\"ols\")\n+        assert_allclose(res[0:3], [0.0938, 0.1890, 3], rtol=1e-4, atol=1e-4)\n+\n+    @pytest.mark.xfail(reason=\"Fails due to numerical issues\", strict=False)\n+    def test_dun_results_arima(self):\n+        mdl_file = os.path.join(self.run_dir, \"DUN.csv\")\n+        mdl = np.asarray(pd.read_csv(mdl_file))\n+        res = leybourne(mdl, regression=\"ct\")\n+        assert_allclose(res[0], 0.024083, rtol=1e-4, atol=1e-4)\n+        assert_allclose(res[1], 0.943151, rtol=1e-4, atol=1e-4)\n+        assert res[2] == 3\n+\n+    def test_sp500_results(self):\n+        mdl_file = os.path.join(self.run_dir, \"SP500.csv\")\n+        mdl = np.asarray(pd.read_csv(mdl_file))\n+        res = leybourne(mdl, arlags=4, regression=\"ct\", method=\"mle\")\n+        assert_allclose(res[0:2], [1.8761, 0.0000], rtol=1e-4, atol=1e-4)\n+        res = leybourne(mdl, arlags=4, regression=\"ct\")\n+        assert_allclose(res[0:2], [1.9053, 0.0000], rtol=1e-4, atol=1e-4)\n+\n+    def test_un_results(self):\n+        mdl_file = os.path.join(self.run_dir, \"UN.csv\")\n+        mdl = np.asarray(pd.read_csv(mdl_file))\n+        res = leybourne(mdl, method=\"ols\", varest=\"var99\")\n+        assert_allclose(res[0:3], [556.0444, 0.0000, 4], rtol=1e-4, atol=1e-4)\n+\n+    @pytest.mark.xfail(reason=\"Fails due to numerical issues\", strict=False)\n+    def test_un_results_arima(self):\n+        mdl_file = os.path.join(self.run_dir, \"UN.csv\")\n+        mdl = np.asarray(pd.read_csv(mdl_file))\n+        res = leybourne(mdl, varest=\"var99\")\n+        assert_allclose(res[0], 285.5181, rtol=1e-4, atol=1e-4)\n+        assert_allclose(res[1], 0.0000, rtol=1e-4, atol=1e-4)\n+        assert res[2] == 4\n+\n+    def test_lm_whitenoise(self):\n+        rg = np.random.RandomState(0)\n+        y = rg.standard_normal(250)\n+        res = leybourne(y, method=\"ols\", varest=\"var99\")\n+        assert res[2] == 0\n", "problem_statement": "Leybourne\n- [ ] closes #xxxx\r\n- [ ] tests added / passed. \r\n- [ ] code/documentation is well formatted.  \r\n- [ ] properly formatted commit message. See \r\n      [NumPy's guide](https://docs.scipy.org/doc/numpy-1.15.1/dev/gitwash/development_workflow.html#writing-the-commit-message). \r\n\r\n<details>\r\n\r\n\r\n**Notes**:\r\n\r\n* It is essential that you add a test when making code changes. Tests are not \r\n  needed for doc changes.\r\n* When adding a new function, test values should usually be verified in another package (e.g., R/SAS/Stata).\r\n* When fixing a bug, you must add a test that would produce the bug in main and\r\n  then show that it is fixed with the new code.\r\n* New code additions must be well formatted. Changes should pass flake8. If on Linux or OSX, you can\r\n  verify you changes are well formatted by running \r\n  ```\r\n  git diff upstream/main -u -- \"*.py\" | flake8 --diff --isolated\r\n  ```\r\n  assuming `flake8` is installed. This command is also available on Windows \r\n  using the Windows System for Linux once `flake8` is installed in the \r\n  local Linux environment. While passing this test is not required, it is good practice and it help \r\n  improve code quality in `statsmodels`.\r\n* Docstring additions must render correctly, including escapes and LaTeX.\r\n\r\n</details>\r\n\n", "hints_text": "", "created_at": "2024-10-17T14:32:13Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9398, "instance_id": "statsmodels__statsmodels-9398", "issue_numbers": ["9181"], "base_commit": "e6cb84a16f6f15a700e52dd09308faf30e01233b", "patch": "diff --git a/statsmodels/discrete/conditional_models.py b/statsmodels/discrete/conditional_models.py\nindex af519e36042..99c6ea49366 100644\n--- a/statsmodels/discrete/conditional_models.py\n+++ b/statsmodels/discrete/conditional_models.py\n@@ -122,7 +122,12 @@ def fit(self,\n             disp=disp,\n             skip_hessian=skip_hessian)\n \n-        crslt = ConditionalResults(self, rslt.params, rslt.cov_params(), 1)\n+        if skip_hessian:\n+            cov_params = None\n+        else:\n+            cov_params = rslt.cov_params()\n+\n+        crslt = ConditionalResults(self, rslt.params, cov_params, 1)\n         crslt.method = method\n         crslt.nobs = self.nobs\n         crslt.n_groups = self._n_groups\n@@ -232,8 +237,7 @@ class ConditionalLogit(_ConditionalModel):\n \n     def __init__(self, endog, exog, missing='none', **kwargs):\n \n-        super().__init__(\n-            endog, exog, missing=missing, **kwargs)\n+        super().__init__(endog, exog, missing=missing, **kwargs)\n \n         if np.any(np.unique(self.endog) != np.r_[0, 1]):\n             msg = \"endog must be coded as 0, 1\"\n", "test_patch": "diff --git a/statsmodels/discrete/tests/test_conditional.py b/statsmodels/discrete/tests/test_conditional.py\nindex 05fc26f4a8a..20ea9139485 100644\n--- a/statsmodels/discrete/tests/test_conditional.py\n+++ b/statsmodels/discrete/tests/test_conditional.py\n@@ -1,10 +1,14 @@\n import numpy as np\n-from statsmodels.discrete.conditional_models import (\n-      ConditionalLogit, ConditionalPoisson, ConditionalMNLogit)\n-from statsmodels.tools.numdiff import approx_fprime\n from numpy.testing import assert_allclose\n import pandas as pd\n \n+from statsmodels.discrete.conditional_models import (\n+    ConditionalLogit,\n+    ConditionalMNLogit,\n+    ConditionalPoisson,\n+)\n+from statsmodels.tools.numdiff import approx_fprime\n+\n \n def test_logit_1d():\n \n@@ -18,15 +22,15 @@ def test_logit_1d():\n \n     # Check the gradient for the denominator of the partial likelihood\n     for x in -1, 0, 1, 2:\n-        params = np.r_[x, ]\n+        params = np.r_[x,]\n         _, grad = model._denom_grad(0, params)\n         ngrad = approx_fprime(params, lambda x: model._denom(0, x)).squeeze()\n         assert_allclose(grad, ngrad)\n \n     # Check the gradient for the loglikelihood\n     for x in -1, 0, 1, 2:\n-        grad = approx_fprime(np.r_[x, ], model.loglike).squeeze()\n-        score = model.score(np.r_[x, ])\n+        grad = approx_fprime(np.r_[x,], model.loglike).squeeze()\n+        score = model.score(np.r_[x,])\n         assert_allclose(grad, score, rtol=1e-4)\n \n     result = model.fit()\n@@ -51,14 +55,14 @@ def test_logit_2d():\n \n     # Check the gradient for the denominator of the partial likelihood\n     for x in -1, 0, 1, 2:\n-        params = np.r_[x, -1.5*x]\n+        params = np.r_[x, -1.5 * x]\n         _, grad = model._denom_grad(0, params)\n         ngrad = approx_fprime(params, lambda x: model._denom(0, x))\n         assert_allclose(grad, ngrad, rtol=1e-5)\n \n     # Check the gradient for the loglikelihood\n     for x in -1, 0, 1, 2:\n-        params = np.r_[-0.5*x, 0.5*x]\n+        params = np.r_[-0.5 * x, 0.5 * x]\n         grad = approx_fprime(params, model.loglike)\n         score = model.score(params)\n         assert_allclose(grad, score, rtol=1e-4)\n@@ -93,10 +97,12 @@ def test_formula():\n         df = pd.DataFrame({\"y\": y, \"x1\": x1, \"x2\": x2, \"g\": g})\n         if j == 0:\n             model2 = ConditionalLogit.from_formula(\n-                        \"y ~ 0 + x1 + x2\", groups=\"g\", data=df)\n+                \"y ~ 0 + x1 + x2\", groups=\"g\", data=df\n+            )\n         else:\n             model2 = ConditionalPoisson.from_formula(\n-                        \"y ~ 0 + x1 + x2\", groups=\"g\", data=df)\n+                \"y ~ 0 + x1 + x2\", groups=\"g\", data=df\n+            )\n         result2 = model2.fit()\n \n         assert_allclose(result1.params, result2.params, rtol=1e-5)\n@@ -117,8 +123,8 @@ def test_poisson_1d():\n \n     # Check the gradient for the loglikelihood\n     for x in -1, 0, 1, 2:\n-        grad = approx_fprime(np.r_[x, ], model.loglike).squeeze()\n-        score = model.score(np.r_[x, ])\n+        grad = approx_fprime(np.r_[x,], model.loglike).squeeze()\n+        score = model.score(np.r_[x,])\n         assert_allclose(grad, score, rtol=1e-4)\n \n     result = model.fit()\n@@ -143,7 +149,7 @@ def test_poisson_2d():\n \n     # Check the gradient for the loglikelihood\n     for x in -1, 0, 1, 2:\n-        params = np.r_[-0.5*x, 0.5*x]\n+        params = np.r_[-0.5 * x, 0.5 * x]\n         grad = approx_fprime(params, model.loglike)\n         score = model.score(params)\n         assert_allclose(grad, score, rtol=1e-4)\n@@ -151,8 +157,8 @@ def test_poisson_2d():\n     result = model.fit()\n \n     # From Stata\n-    assert_allclose(result.params, np.r_[-.9478957, -.0134279], rtol=1e-3)\n-    assert_allclose(result.bse, np.r_[.3874942, .1686712], rtol=1e-5)\n+    assert_allclose(result.params, np.r_[-0.9478957, -0.0134279], rtol=1e-3)\n+    assert_allclose(result.bse, np.r_[0.3874942, 0.1686712], rtol=1e-5)\n \n     result.summary()\n \n@@ -190,8 +196,16 @@ def test_lasso_logistic():\n     assert_allclose(result2.params, np.r_[0, 0, 0.55235152, 0], rtol=1e-4)\n \n     # Test with formula\n-    df = pd.DataFrame({\"y\": y, \"x1\": x[:, 0], \"x2\": x[:, 1], \"x3\": x[:, 2],\n-                       \"x4\": x[:, 3], \"groups\": groups})\n+    df = pd.DataFrame(\n+        {\n+            \"y\": y,\n+            \"x1\": x[:, 0],\n+            \"x2\": x[:, 1],\n+            \"x3\": x[:, 2],\n+            \"x4\": x[:, 3],\n+            \"groups\": groups,\n+        }\n+    )\n     fml = \"y ~ 0 + x1 + x2 + x3 + x4\"\n     model3 = ConditionalLogit.from_formula(fml, groups=\"groups\", data=df)\n     result3 = model3.fit_regularized(L1_wt=1, alpha=0.05)\n@@ -231,8 +245,16 @@ def test_lasso_poisson():\n     assert_allclose(result2.params, np.r_[0, 0, 0.91697508, 0], rtol=1e-4)\n \n     # Test with formula\n-    df = pd.DataFrame({\"y\": y, \"x1\": x[:, 0], \"x2\": x[:, 1], \"x3\": x[:, 2],\n-                       \"x4\": x[:, 3], \"groups\": groups})\n+    df = pd.DataFrame(\n+        {\n+            \"y\": y,\n+            \"x1\": x[:, 0],\n+            \"x2\": x[:, 1],\n+            \"x3\": x[:, 2],\n+            \"x4\": x[:, 3],\n+            \"groups\": groups,\n+        }\n+    )\n     fml = \"y ~ 0 + x1 + x2 + x3 + x4\"\n     model3 = ConditionalPoisson.from_formula(fml, groups=\"groups\", data=df)\n     result3 = model3.fit_regularized(L1_wt=1, alpha=0.2)\n@@ -243,7 +265,7 @@ def gen_mnlogit(n):\n \n     np.random.seed(235)\n \n-    g = np.kron(np.ones(5), np.arange(n//5))\n+    g = np.kron(np.ones(5), np.arange(n // 5))\n     x1 = np.random.normal(size=n)\n     x2 = np.random.normal(size=n)\n     xm = np.concatenate((x1[:, None], x2[:, None]), axis=1)\n@@ -258,16 +280,14 @@ def gen_mnlogit(n):\n     y[u < cpr[:, 1]] = 1\n     y[u < cpr[:, 0]] = 0\n \n-    df = pd.DataFrame({\"y\": y, \"x1\": x1,\n-                       \"x2\": x2, \"g\": g})\n+    df = pd.DataFrame({\"y\": y, \"x1\": x1, \"x2\": x2, \"g\": g})\n     return df\n \n \n def test_conditional_mnlogit_grad():\n \n     df = gen_mnlogit(90)\n-    model = ConditionalMNLogit.from_formula(\n-                \"y ~ 0 + x1 + x2\", groups=\"g\", data=df)\n+    model = ConditionalMNLogit.from_formula(\"y ~ 0 + x1 + x2\", groups=\"g\", data=df)\n \n     # Compare the gradients to numeric gradients\n     for _ in range(5):\n@@ -280,45 +300,61 @@ def test_conditional_mnlogit_grad():\n def test_conditional_mnlogit_2d():\n \n     df = gen_mnlogit(90)\n-    model = ConditionalMNLogit.from_formula(\n-                \"y ~ 0 + x1 + x2\", groups=\"g\", data=df)\n+    model = ConditionalMNLogit.from_formula(\"y ~ 0 + x1 + x2\", groups=\"g\", data=df)\n     result = model.fit()\n \n     # Regression tests\n     assert_allclose(\n         result.params,\n-        np.asarray([[0.75592035, -1.58565494],\n-                    [1.82919869, -1.32594231]]),\n-        rtol=1e-5, atol=1e-5)\n+        np.asarray([[0.75592035, -1.58565494], [1.82919869, -1.32594231]]),\n+        rtol=1e-5,\n+        atol=1e-5,\n+    )\n     assert_allclose(\n         result.bse,\n-        np.asarray([[0.68099698, 0.70142727],\n-                    [0.65190315, 0.59653771]]),\n-        rtol=1e-5, atol=1e-5)\n+        np.asarray([[0.68099698, 0.70142727], [0.65190315, 0.59653771]]),\n+        rtol=1e-5,\n+        atol=1e-5,\n+    )\n \n \n def test_conditional_mnlogit_3d():\n \n     df = gen_mnlogit(90)\n     df[\"x3\"] = np.random.normal(size=df.shape[0])\n-    model = ConditionalMNLogit.from_formula(\n-                \"y ~ 0 + x1 + x2 + x3\", groups=\"g\", data=df)\n+    model = ConditionalMNLogit.from_formula(\"y ~ 0 + x1 + x2 + x3\", groups=\"g\", data=df)\n     result = model.fit()\n \n     # Regression tests\n     assert_allclose(\n         result.params,\n-        np.asarray([[ 0.729629, -1.633673],\n-                    [ 1.879019, -1.327163],\n-                    [-0.114124, -0.109378]]),\n-        atol=1e-5, rtol=1e-5)\n+        np.asarray(\n+            [[0.729629, -1.633673], [1.879019, -1.327163], [-0.114124, -0.109378]]\n+        ),\n+        atol=1e-5,\n+        rtol=1e-5,\n+    )\n \n     assert_allclose(\n         result.bse,\n-        np.asarray([[0.682965, 0.60472],\n-                    [0.672947, 0.42401],\n-                    [0.722631, 0.33663]]),\n-        atol=1e-5, rtol=1e-5)\n+        np.asarray([[0.682965, 0.60472], [0.672947, 0.42401], [0.722631, 0.33663]]),\n+        atol=1e-5,\n+        rtol=1e-5,\n+    )\n \n     # Smoke test\n     result.summary()\n+\n+\n+def test_skip_hessian():\n+    y = np.r_[0, 1, 0, 1, 0, 1, 0, 1, 1, 1]\n+    g = np.r_[0, 0, 0, 1, 1, 1, 2, 2, 2, 2]\n+\n+    x = np.r_[0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n+    x = x[:, None]\n+\n+    model = ConditionalLogit(y, x, groups=g)\n+    result_no_hess = model.fit(skip_hessian=True)\n+    result_hess = model.fit(skip_hessian=False)\n+    assert result_no_hess.normalized_cov_params is None\n+    assert isinstance(result_hess.normalized_cov_params, np.ndarray)\n", "problem_statement": "Skip_hessian `True` now works in ConditionalLogit\nThe `skip_hessian` option did not work in ConditionalLogit.fit() because the ConditionalResults function tried to retrieve cov_params() from LikelihoodModel.fit() results. \r\n\n", "hints_text": "", "created_at": "2024-10-17T11:57:28Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9396, "instance_id": "statsmodels__statsmodels-9396", "issue_numbers": ["9315"], "base_commit": "4fde69f6725c2bea27bcadb96863b26073348156", "patch": "diff --git a/statsmodels/genmod/generalized_linear_model.py b/statsmodels/genmod/generalized_linear_model.py\nindex 6cd29fd7691..3dfdd1d6cca 100644\n--- a/statsmodels/genmod/generalized_linear_model.py\n+++ b/statsmodels/genmod/generalized_linear_model.py\n@@ -2567,7 +2567,6 @@ def summary2(self, yname=None, xname=None, title=None, alpha=.05,\n         --------\n         statsmodels.iolib.summary2.Summary : class to hold summary results\n         \"\"\"\n-        self.method = 'IRLS'\n         from statsmodels.iolib import summary2\n         smry = summary2.Summary()\n         with warnings.catch_warnings():\n", "test_patch": "diff --git a/statsmodels/genmod/tests/test_glm.py b/statsmodels/genmod/tests/test_glm.py\nindex b3b6876a43d..dbd99690584 100644\n--- a/statsmodels/genmod/tests/test_glm.py\n+++ b/statsmodels/genmod/tests/test_glm.py\n@@ -1,7 +1,11 @@\n \"\"\"\n Test functions for models.GLM\n \"\"\"\n+\n+from statsmodels.compat.scipy import SP_LT_17\n+\n import os\n+import re\n import warnings\n \n import numpy as np\n@@ -19,7 +23,6 @@\n from scipy import stats\n \n import statsmodels.api as sm\n-from statsmodels.compat.scipy import SP_LT_17\n from statsmodels.datasets import cpunish, longley\n from statsmodels.discrete import discrete_model as discrete\n from statsmodels.genmod.generalized_linear_model import GLM, SET_USE_BIC_LLF\n@@ -47,6 +50,7 @@\n \n if pdf_output:\n     from matplotlib.backends.backend_pdf import PdfPages\n+\n     pdf = PdfPages(\"test_glm.pdf\")\n else:\n     pdf = None\n@@ -65,27 +69,36 @@ def teardown_module():\n @pytest.fixture(scope=\"module\")\n def iris():\n     cur_dir = os.path.dirname(os.path.abspath(__file__))\n-    return np.genfromtxt(os.path.join(cur_dir, 'results', 'iris.csv'),\n-                         delimiter=\",\", skip_header=1)\n+    return np.genfromtxt(\n+        os.path.join(cur_dir, \"results\", \"iris.csv\"),\n+        delimiter=\",\",\n+        skip_header=1,\n+    )\n \n \n class CheckModelResultsMixin:\n-    '''\n+    \"\"\"\n     res2 should be either the results from RModelWrap\n     or the results as defined in model_results_data\n-    '''\n+    \"\"\"\n \n     decimal_params = DECIMAL_4\n+\n     def test_params(self):\n-        assert_almost_equal(self.res1.params, self.res2.params,\n-                self.decimal_params)\n+        assert_almost_equal(self.res1.params, self.res2.params, self.decimal_params)\n \n     decimal_bse = DECIMAL_4\n+\n     def test_standard_errors(self):\n-        assert_allclose(self.res1.bse, self.res2.bse,\n-                        atol=10**(-self.decimal_bse), rtol=1e-5)\n+        assert_allclose(\n+            self.res1.bse,\n+            self.res2.bse,\n+            atol=10 ** (-self.decimal_bse),\n+            rtol=1e-5,\n+        )\n \n     decimal_resids = DECIMAL_4\n+\n     def test_residuals(self):\n         # fix incorrect numbers in resid_working results\n         # residuals for Poisson are also tested in test_glm_weights.py\n@@ -93,13 +106,19 @@ def test_residuals(self):\n \n         # new numpy would have copy method\n         resid2 = copy.copy(self.res2.resids)\n-        resid2[:, 2] *= self.res1.family.link.deriv(self.res1.mu)**2\n+        resid2[:, 2] *= self.res1.family.link.deriv(self.res1.mu) ** 2\n \n-        atol = 10**(-self.decimal_resids)\n+        atol = 10 ** (-self.decimal_resids)\n         resid_a = self.res1.resid_anscombe_unscaled\n-        resids = np.column_stack((self.res1.resid_pearson,\n-                self.res1.resid_deviance, self.res1.resid_working,\n-                resid_a, self.res1.resid_response))\n+        resids = np.column_stack(\n+            (\n+                self.res1.resid_pearson,\n+                self.res1.resid_deviance,\n+                self.res1.resid_working,\n+                resid_a,\n+                self.res1.resid_response,\n+            )\n+        )\n         assert_allclose(resids, resid2, rtol=1e-6, atol=atol)\n \n     decimal_aic_R = DECIMAL_4\n@@ -112,83 +131,108 @@ def test_aic_R(self):\n         else:\n             dof = 0\n         if isinstance(self.res1.model.family, (sm.families.NegativeBinomial)):\n-            llf = self.res1.model.family.loglike(self.res1.model.endog,\n-                                                 self.res1.mu,\n-                                                 self.res1.model.var_weights,\n-                                                 self.res1.model.freq_weights,\n-                                                 scale=1)\n-            aic = (-2*llf+2*(self.res1.df_model+1))\n+            llf = self.res1.model.family.loglike(\n+                self.res1.model.endog,\n+                self.res1.mu,\n+                self.res1.model.var_weights,\n+                self.res1.model.freq_weights,\n+                scale=1,\n+            )\n+            aic = -2 * llf + 2 * (self.res1.df_model + 1)\n         else:\n             aic = self.res1.aic\n-        assert_almost_equal(aic+dof, self.res2.aic_R,\n-                self.decimal_aic_R)\n+        assert_almost_equal(aic + dof, self.res2.aic_R, self.decimal_aic_R)\n \n     decimal_aic_Stata = DECIMAL_4\n+\n     def test_aic_Stata(self):\n         # Stata uses the below llf for aic definition for these families\n-        if isinstance(self.res1.model.family, (sm.families.Gamma,\n-                                               sm.families.InverseGaussian,\n-                                               sm.families.NegativeBinomial)):\n-            llf = self.res1.model.family.loglike(self.res1.model.endog,\n-                                                 self.res1.mu,\n-                                                 self.res1.model.var_weights,\n-                                                 self.res1.model.freq_weights,\n-                                                 scale=1)\n-            aic = (-2*llf+2*(self.res1.df_model+1))/self.res1.nobs\n+        if isinstance(\n+            self.res1.model.family,\n+            (\n+                sm.families.Gamma,\n+                sm.families.InverseGaussian,\n+                sm.families.NegativeBinomial,\n+            ),\n+        ):\n+            llf = self.res1.model.family.loglike(\n+                self.res1.model.endog,\n+                self.res1.mu,\n+                self.res1.model.var_weights,\n+                self.res1.model.freq_weights,\n+                scale=1,\n+            )\n+            aic = (-2 * llf + 2 * (self.res1.df_model + 1)) / self.res1.nobs\n         else:\n-            aic = self.res1.aic/self.res1.nobs\n+            aic = self.res1.aic / self.res1.nobs\n         assert_almost_equal(aic, self.res2.aic_Stata, self.decimal_aic_Stata)\n \n     decimal_deviance = DECIMAL_4\n+\n     def test_deviance(self):\n-        assert_almost_equal(self.res1.deviance, self.res2.deviance,\n-                self.decimal_deviance)\n+        assert_almost_equal(\n+            self.res1.deviance, self.res2.deviance, self.decimal_deviance\n+        )\n \n     decimal_scale = DECIMAL_4\n+\n     def test_scale(self):\n-        assert_almost_equal(self.res1.scale, self.res2.scale,\n-                self.decimal_scale)\n+        assert_almost_equal(self.res1.scale, self.res2.scale, self.decimal_scale)\n \n     decimal_loglike = DECIMAL_4\n+\n     def test_loglike(self):\n         # Stata uses the below llf for these families\n         # We differ with R for them\n-        if isinstance(self.res1.model.family, (sm.families.Gamma,\n-                                               sm.families.InverseGaussian,\n-                                               sm.families.NegativeBinomial)):\n-            llf = self.res1.model.family.loglike(self.res1.model.endog,\n-                                                 self.res1.mu,\n-                                                 self.res1.model.var_weights,\n-                                                 self.res1.model.freq_weights,\n-                                                 scale=1)\n+        if isinstance(\n+            self.res1.model.family,\n+            (\n+                sm.families.Gamma,\n+                sm.families.InverseGaussian,\n+                sm.families.NegativeBinomial,\n+            ),\n+        ):\n+            llf = self.res1.model.family.loglike(\n+                self.res1.model.endog,\n+                self.res1.mu,\n+                self.res1.model.var_weights,\n+                self.res1.model.freq_weights,\n+                scale=1,\n+            )\n         else:\n             llf = self.res1.llf\n         assert_almost_equal(llf, self.res2.llf, self.decimal_loglike)\n \n     decimal_null_deviance = DECIMAL_4\n+\n     def test_null_deviance(self):\n         with warnings.catch_warnings():\n             warnings.simplefilter(\"ignore\", DomainWarning)\n \n-            assert_almost_equal(self.res1.null_deviance,\n-                                self.res2.null_deviance,\n-                                self.decimal_null_deviance)\n+            assert_almost_equal(\n+                self.res1.null_deviance,\n+                self.res2.null_deviance,\n+                self.decimal_null_deviance,\n+            )\n \n     decimal_bic = DECIMAL_4\n+\n     def test_bic(self):\n         with warnings.catch_warnings():\n             warnings.simplefilter(\"ignore\")\n-            assert_almost_equal(self.res1.bic,\n-                                self.res2.bic_Stata,\n-                                self.decimal_bic)\n+            assert_almost_equal(self.res1.bic, self.res2.bic_Stata, self.decimal_bic)\n \n     def test_degrees(self):\n-        assert_equal(self.res1.model.df_resid,self.res2.df_resid)\n+        assert_equal(self.res1.model.df_resid, self.res2.df_resid)\n \n     decimal_fittedvalues = DECIMAL_4\n+\n     def test_fittedvalues(self):\n-        assert_almost_equal(self.res1.fittedvalues, self.res2.fittedvalues,\n-                self.decimal_fittedvalues)\n+        assert_almost_equal(\n+            self.res1.fittedvalues,\n+            self.res2.fittedvalues,\n+            self.decimal_fittedvalues,\n+        )\n \n     def test_tpvalues(self):\n         # test comparing tvalues and pvalues with normal implementation\n@@ -206,18 +250,28 @@ def test_tpvalues(self):\n         assert_almost_equal(self.res1.conf_int(), conf_int)\n \n     def test_pearson_chi2(self):\n-        if hasattr(self.res2, 'pearson_chi2'):\n-            assert_allclose(self.res1.pearson_chi2, self.res2.pearson_chi2,\n-                            atol=1e-6, rtol=1e-6)\n+        if hasattr(self.res2, \"pearson_chi2\"):\n+            assert_allclose(\n+                self.res1.pearson_chi2,\n+                self.res2.pearson_chi2,\n+                atol=1e-6,\n+                rtol=1e-6,\n+            )\n \n     def test_prsquared(self):\n-        if hasattr(self.res2, 'prsquared'):\n-            assert_allclose(self.res1.pseudo_rsquared(kind=\"mcf\"),\n-                            self.res2.prsquared, rtol=0.05)\n-\n-        if hasattr(self.res2, 'prsquared_cox_snell'):\n-            assert_allclose(float(self.res1.pseudo_rsquared(kind=\"cs\")),\n-                            self.res2.prsquared_cox_snell, rtol=0.05)\n+        if hasattr(self.res2, \"prsquared\"):\n+            assert_allclose(\n+                self.res1.pseudo_rsquared(kind=\"mcf\"),\n+                self.res2.prsquared,\n+                rtol=0.05,\n+            )\n+\n+        if hasattr(self.res2, \"prsquared_cox_snell\"):\n+            assert_allclose(\n+                float(self.res1.pseudo_rsquared(kind=\"cs\")),\n+                self.res2.prsquared_cox_snell,\n+                rtol=0.05,\n+            )\n \n     @pytest.mark.smoke\n     def test_summary(self):\n@@ -240,8 +294,7 @@ def test_get_distribution(self):\n         else:\n             res_scale = res1.scale\n \n-        distr = res1.model.family.get_distribution(res1.fittedvalues,\n-                                                   res_scale)\n+        distr = res1.model.family.get_distribution(res1.fittedvalues, res_scale)\n         var_endog = res1.model.family.variance(res1.fittedvalues) * res_scale\n         m, v = distr.stats()\n         assert_allclose(res1.fittedvalues, m, rtol=1e-13)\n@@ -304,7 +357,7 @@ def test_score_test(self):\n         assert_equal(df, 0)\n \n         # TODO: no verified numbers largely SMOKE test\n-        exog_extra = res1.model.exog[:,1]**2\n+        exog_extra = res1.model.exog[:, 1] ** 2\n         st, pv, df = res1.model.score_test(res1.params, exog_extra=exog_extra)\n         assert_array_less(0.1, st)\n         assert_array_less(0.1, pv)\n@@ -315,23 +368,29 @@ def test_get_prediction(self):\n         predd = self.resd.get_prediction()  # discrete class\n         assert_allclose(predd.predicted, pred1.predicted_mean, rtol=1e-11)\n         assert_allclose(predd.se, pred1.se_mean, rtol=1e-6)\n-        assert_allclose(predd.summary_frame().values,\n-                        pred1.summary_frame().values, rtol=1e-6)\n+        assert_allclose(\n+            predd.summary_frame().values,\n+            pred1.summary_frame().values,\n+            rtol=1e-6,\n+        )\n \n         pred1 = self.res1.get_prediction(which=\"mean\")  # GLM\n         predd = self.resd.get_prediction()  # discrete class\n         assert_allclose(predd.predicted, pred1.predicted, rtol=1e-11)\n         assert_allclose(predd.se, pred1.se, rtol=1e-6)\n-        assert_allclose(predd.summary_frame().values,\n-                        pred1.summary_frame().values, rtol=1e-6)\n+        assert_allclose(\n+            predd.summary_frame().values,\n+            pred1.summary_frame().values,\n+            rtol=1e-6,\n+        )\n \n \n class TestGlmGaussian(CheckModelResultsMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Test Gaussian family with canonical identity link\n-        '''\n+        \"\"\"\n         # Test Precisions\n         cls.decimal_resids = DECIMAL_3\n         cls.decimal_params = DECIMAL_2\n@@ -339,20 +398,23 @@ def setup_class(cls):\n         cls.decimal_bse = DECIMAL_3\n \n         from statsmodels.datasets.longley import load\n+\n         cls.data = load()\n         cls.data.endog = np.require(cls.data.endog, requirements=\"W\")\n         cls.data.exog = np.require(cls.data.exog, requirements=\"W\")\n         cls.data.exog = add_constant(cls.data.exog, prepend=False)\n-        cls.res1 = GLM(cls.data.endog, cls.data.exog,\n-                        family=sm.families.Gaussian()).fit()\n+        cls.res1 = GLM(\n+            cls.data.endog, cls.data.exog, family=sm.families.Gaussian()\n+        ).fit()\n         from .results.results_glm import Longley\n-        cls.res2 = Longley()\n \n+        cls.res2 = Longley()\n \n     def test_compare_OLS(self):\n         res1 = self.res1\n         # OLS does not define score_obs\n         from statsmodels.regression.linear_model import OLS\n+\n         resd = OLS(self.data.endog, self.data.exog).fit(use_t=False)\n         self.resd = resd  # attach to access from the outside\n \n@@ -367,7 +429,7 @@ def test_compare_OLS(self):\n         assert_allclose(score_obs1, score_obsd, rtol=1e-8)\n \n         hess_obs1 = res1.model.hessian(res1.params, scale=None)\n-        hess_obsd = -1. / resd.scale * resd.model.exog.T.dot(resd.model.exog)\n+        hess_obsd = -1.0 / resd.scale * resd.model.exog.T.dot(resd.model.exog)\n         # low precision because of badly scaled exog\n         assert_allclose(hess_obs1, hess_obsd, rtol=1e-8)\n \n@@ -375,15 +437,22 @@ def test_compare_OLS(self):\n         predd = resd.get_prediction()  # discrete class\n         assert_allclose(predd.predicted, pred1.predicted_mean, rtol=1e-11)\n         assert_allclose(predd.se, pred1.se_mean, rtol=1e-6)\n-        assert_allclose(predd.summary_frame().values[:, :4],\n-                        pred1.summary_frame().values, rtol=1e-6)\n+        assert_allclose(\n+            predd.summary_frame().values[:, :4],\n+            pred1.summary_frame().values,\n+            rtol=1e-6,\n+        )\n \n         pred1 = self.res1.get_prediction(which=\"mean\")  # GLM\n         predd = self.resd.get_prediction()  # discrete class\n         assert_allclose(predd.predicted, pred1.predicted, rtol=1e-11)\n         assert_allclose(predd.se, pred1.se, rtol=1e-6)\n-        assert_allclose(predd.summary_frame().values[:, :4],\n-                        pred1.summary_frame().values, rtol=1e-6)\n+        assert_allclose(\n+            predd.summary_frame().values[:, :4],\n+            pred1.summary_frame().values,\n+            rtol=1e-6,\n+        )\n+\n \n # FIXME: enable or delete\n #    def setup_method(self):\n@@ -398,9 +467,9 @@ def test_compare_OLS(self):\n class TestGlmGaussianGradient(TestGlmGaussian):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Test Gaussian family with canonical identity link\n-        '''\n+        \"\"\"\n         # Test Precisions\n         cls.decimal_resids = DECIMAL_3\n         cls.decimal_params = DECIMAL_2\n@@ -408,13 +477,16 @@ def setup_class(cls):\n         cls.decimal_bse = DECIMAL_2\n \n         from statsmodels.datasets.longley import load\n+\n         cls.data = load()\n         cls.data.endog = np.require(cls.data.endog, requirements=\"W\")\n         cls.data.exog = np.require(cls.data.exog, requirements=\"W\")\n         cls.data.exog = add_constant(cls.data.exog, prepend=False)\n-        cls.res1 = GLM(cls.data.endog, cls.data.exog,\n-                       family=sm.families.Gaussian()).fit(method='newton')\n+        cls.res1 = GLM(\n+            cls.data.endog, cls.data.exog, family=sm.families.Gaussian()\n+        ).fit(method=\"newton\")\n         from .results.results_glm import Longley\n+\n         cls.res2 = Longley()\n \n \n@@ -430,17 +502,23 @@ def setup_class(cls):\n         nobs = 100\n         x = np.arange(nobs)\n         np.random.seed(54321)\n-#        y = 1.0 - .02*x - .001*x**2 + 0.001 * np.random.randn(nobs)\n-        cls.X = np.c_[np.ones((nobs,1)),x,x**2]\n-        cls.lny = np.exp(-(-1.0 + 0.02*x + 0.0001*x**2)) +\\\n-                        0.001 * np.random.randn(nobs)\n-\n-        GaussLog_Model = GLM(cls.lny, cls.X,\n-                             family=sm.families.Gaussian(sm.families.links.Log()))\n+        #        y = 1.0 - .02*x - .001*x**2 + 0.001 * np.random.randn(nobs)\n+        cls.X = np.c_[np.ones((nobs, 1)), x, x**2]\n+        cls.lny = np.exp(\n+            -(-1.0 + 0.02 * x + 0.0001 * x**2)\n+        ) + 0.001 * np.random.randn(nobs)\n+\n+        GaussLog_Model = GLM(\n+            cls.lny,\n+            cls.X,\n+            family=sm.families.Gaussian(sm.families.links.Log()),\n+        )\n         cls.res1 = GaussLog_Model.fit()\n         from .results.results_glm import GaussianLog\n+\n         cls.res2 = GaussianLog()\n \n+\n # FIXME: enable or delete\n #    def setup(cls):\n #        if skipR:\n@@ -449,6 +527,7 @@ def setup_class(cls):\n #        GaussLog_Res_R = RModel(cls.lny, cls.X, r.glm, family=GaussLogLink)\n #        cls.res2 = GaussLog_Res_R\n \n+\n class TestGaussianInverse(CheckModelResultsMixin):\n     @classmethod\n     def setup_class(cls):\n@@ -463,15 +542,22 @@ def setup_class(cls):\n         x = np.arange(nobs)\n         np.random.seed(54321)\n         y = 1.0 + 2.0 * x + x**2 + 0.1 * np.random.randn(nobs)\n-        cls.X = np.c_[np.ones((nobs,1)),x,x**2]\n-        cls.y_inv = (1. + .02*x + .001*x**2)**-1 + .001 * np.random.randn(nobs)\n-        InverseLink_Model = GLM(cls.y_inv, cls.X,\n-                family=sm.families.Gaussian(sm.families.links.InversePower()))\n+        cls.X = np.c_[np.ones((nobs, 1)), x, x**2]\n+        cls.y_inv = (1.0 + 0.02 * x + 0.001 * x**2) ** -1 + 0.001 * np.random.randn(\n+            nobs\n+        )\n+        InverseLink_Model = GLM(\n+            cls.y_inv,\n+            cls.X,\n+            family=sm.families.Gaussian(sm.families.links.InversePower()),\n+        )\n         InverseLink_Res = InverseLink_Model.fit()\n         cls.res1 = InverseLink_Res\n         from .results.results_glm import GaussianInverse\n+\n         cls.res2 = GaussianInverse()\n \n+\n # FIXME: enable or delete\n #    def setup(cls):\n #        if skipR:\n@@ -480,24 +566,25 @@ def setup_class(cls):\n #        InverseLink_Res_R = RModel(cls.y_inv, cls.X, r.glm, family=InverseLink)\n #        cls.res2 = InverseLink_Res_R\n \n+\n class TestGlmBinomial(CheckModelResultsMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Test Binomial family with canonical logit link using star98 dataset.\n-        '''\n+        \"\"\"\n         cls.decimal_resids = DECIMAL_1\n         cls.decimal_bic = DECIMAL_2\n \n         from statsmodels.datasets.star98 import load\n \n         from .results.results_glm import Star98\n+\n         data = load()\n         data.endog = np.require(data.endog, requirements=\"W\")\n         data.exog = np.require(data.exog, requirements=\"W\")\n         data.exog = add_constant(data.exog, prepend=False)\n-        cls.res1 = GLM(data.endog, data.exog,\n-                       family=sm.families.Binomial()).fit()\n+        cls.res1 = GLM(data.endog, data.exog, family=sm.families.Binomial()).fit()\n         # NOTE: if you want to replicate with RModel\n         # res2 = RModel(data.endog[:,0]/trials, data.exog, r.glm,\n         #        family=r.binomial, weights=trials)\n@@ -506,6 +593,7 @@ def setup_class(cls):\n \n     def test_endog_dtype(self):\n         from statsmodels.datasets.star98 import load\n+\n         data = load()\n         data.exog = add_constant(data.exog, prepend=False)\n         endog = data.endog.astype(int)\n@@ -519,7 +607,7 @@ def test_invalid_endog(self, reset_randomstate):\n         # GH2733 inspired check\n         endog = np.random.randint(0, 100, size=(1000, 3))\n         exog = np.random.standard_normal((1000, 2))\n-        with pytest.raises(ValueError, match='endog has more than 2 columns'):\n+        with pytest.raises(ValueError, match=\"endog has more than 2 columns\"):\n             GLM(endog, exog, family=sm.families.Binomial())\n \n     def test_invalid_endog_formula(self, reset_randomstate):\n@@ -529,9 +617,8 @@ def test_invalid_endog_formula(self, reset_randomstate):\n         endog = np.random.randint(0, 3, size=n).astype(str)\n         # formula interface\n         data = pd.DataFrame({\"y\": endog, \"x1\": exog[:, 0], \"x2\": exog[:, 1]})\n-        with pytest.raises(ValueError, match='array with multiple columns'):\n-            sm.GLM.from_formula(\"y ~ x1 + x2\", data,\n-                                family=sm.families.Binomial())\n+        with pytest.raises(ValueError, match=\"array with multiple columns\"):\n+            sm.GLM.from_formula(\"y ~ x1 + x2\", data, family=sm.families.Binomial())\n \n     def test_get_distribution_binom_count(self):\n         # test for binomial counts with n_trials > 1\n@@ -540,16 +627,14 @@ def test_get_distribution_binom_count(self):\n \n         mu_prob = res1.fittedvalues\n         n = res1.model.n_trials\n-        distr = res1.model.family.get_distribution(mu_prob, res_scale,\n-                                                   n_trials=n)\n+        distr = res1.model.family.get_distribution(mu_prob, res_scale, n_trials=n)\n         var_endog = res1.model.family.variance(mu_prob) * res_scale\n         m, v = distr.stats()\n         assert_allclose(mu_prob * n, m, rtol=1e-13)\n         assert_allclose(var_endog * n, v, rtol=1e-13)\n \n         # check model method\n-        distr2 = res1.model.get_distribution(res1.params, res_scale,\n-                                             n_trials=n)\n+        distr2 = res1.model.get_distribution(res1.params, res_scale, n_trials=n)\n         for k in distr2.kwds:\n             assert_allclose(distr.kwds[k], distr2.kwds[k], rtol=1e-13)\n \n@@ -585,9 +670,11 @@ class TestGlmBernoulli(CheckModelResultsMixin, CheckComparisonMixin):\n     @classmethod\n     def setup_class(cls):\n         from .results.results_glm import Lbw\n+\n         cls.res2 = Lbw()\n-        cls.res1 = GLM(cls.res2.endog, cls.res2.exog,\n-                       family=sm.families.Binomial()).fit()\n+        cls.res1 = GLM(\n+            cls.res2.endog, cls.res2.exog, family=sm.families.Binomial()\n+        ).fit()\n \n         modd = discrete.Logit(cls.res2.endog, cls.res2.exog)\n         cls.resd = modd.fit(start_params=cls.res1.params * 0.9, disp=False)\n@@ -595,23 +682,27 @@ def setup_class(cls):\n     def test_score_r(self):\n         res1 = self.res1\n         res2 = self.res2\n-        st, pv, df = res1.model.score_test(res1.params,\n-                                           exog_extra=res1.model.exog[:, 1]**2)\n+        st, pv, df = res1.model.score_test(\n+            res1.params, exog_extra=res1.model.exog[:, 1] ** 2\n+        )\n         st_res = 0.2837680293459376  # (-0.5326988167303712)**2\n         assert_allclose(st, st_res, rtol=1e-4)\n \n-        st, pv, df = res1.model.score_test(res1.params,\n-                                          exog_extra=res1.model.exog[:, 0]**2)\n+        st, pv, df = res1.model.score_test(\n+            res1.params, exog_extra=res1.model.exog[:, 0] ** 2\n+        )\n         st_res = 0.6713492821514992  # (-0.8193590679009413)**2\n         assert_allclose(st, st_res, rtol=1e-4)\n \n         select = list(range(9))\n         select.pop(7)\n \n-        res1b = GLM(res2.endog, res2.exog.iloc[:, select],\n-                    family=sm.families.Binomial()).fit()\n-        tres = res1b.model.score_test(res1b.params,\n-                                      exog_extra=res1.model.exog[:, -2])\n+        res1b = GLM(\n+            res2.endog,\n+            res2.exog.iloc[:, select],\n+            family=sm.families.Binomial(),\n+        ).fit()\n+        tres = res1b.model.score_test(res1b.params, exog_extra=res1.model.exog[:, -2])\n         tres = np.asarray(tres[:2]).ravel()\n         tres_r = (2.7864148487452, 0.0950667)\n         assert_allclose(tres, tres_r, rtol=1e-4)\n@@ -632,6 +723,7 @@ def test_score_r(self):\n         s**2\n         \"\"\"\n \n+\n # class TestGlmBernoulliIdentity(CheckModelResultsMixin):\n #    pass\n \n@@ -658,26 +750,26 @@ class TestGlmGamma(CheckModelResultsMixin):\n \n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests Gamma family with canonical inverse link (power -1)\n-        '''\n+        \"\"\"\n         # Test Precisions\n-        cls.decimal_aic_R = -1 #TODO: off by about 1, we are right with Stata\n+        cls.decimal_aic_R = -1  # TODO: off by about 1, we are right with Stata\n         cls.decimal_resids = DECIMAL_2\n \n         from statsmodels.datasets.scotland import load\n \n         from .results.results_glm import Scotvote\n+\n         data = load()\n         data.exog = add_constant(data.exog, prepend=False)\n         with warnings.catch_warnings():\n             warnings.simplefilter(\"ignore\")\n-            res1 = GLM(data.endog, data.exog,\n-                       family=sm.families.Gamma()).fit()\n+            res1 = GLM(data.endog, data.exog, family=sm.families.Gamma()).fit()\n         cls.res1 = res1\n-#        res2 = RModel(data.endog, data.exog, r.glm, family=r.Gamma)\n+        #        res2 = RModel(data.endog, data.exog, r.glm, family=r.Gamma)\n         res2 = Scotvote()\n-        res2.aic_R += 2 # R does not count degree of freedom for scale with gamma\n+        res2.aic_R += 2  # R does not count degree of freedom for scale with gamma\n         cls.res2 = res2\n \n \n@@ -690,11 +782,16 @@ def setup_class(cls):\n         cls.decimal_fittedvalues = DECIMAL_3\n \n         from .results.results_glm import CancerLog\n+\n         res2 = CancerLog()\n-        cls.res1 = GLM(res2.endog, res2.exog,\n-            family=sm.families.Gamma(link=sm.families.links.Log())).fit()\n+        cls.res1 = GLM(\n+            res2.endog,\n+            res2.exog,\n+            family=sm.families.Gamma(link=sm.families.links.Log()),\n+        ).fit()\n         cls.res2 = res2\n \n+\n # FIXME: enable or delete\n #    def setup(cls):\n #        if skipR:\n@@ -709,12 +806,13 @@ class TestGlmGammaIdentity(CheckModelResultsMixin):\n     @classmethod\n     def setup_class(cls):\n         # Test Precisions\n-        cls.decimal_resids = -100 #TODO Very off from Stata?\n+        cls.decimal_resids = -100  # TODO Very off from Stata?\n         cls.decimal_params = DECIMAL_2\n         cls.decimal_aic_R = DECIMAL_0\n         cls.decimal_loglike = DECIMAL_1\n \n         from .results.results_glm import CancerIdentity\n+\n         res2 = CancerIdentity()\n         with warnings.catch_warnings():\n             warnings.simplefilter(\"ignore\")\n@@ -722,6 +820,7 @@ def setup_class(cls):\n             cls.res1 = GLM(res2.endog, res2.exog, family=fam).fit()\n         cls.res2 = res2\n \n+\n # FIXME: enable or delete\n #    def setup(cls):\n #        if skipR:\n@@ -730,38 +829,42 @@ def setup_class(cls):\n #            family=r.Gamma(link=\"identity\"))\n #        cls.res2.null_deviance = 27.92207137420696 # from R, Rpy bug\n \n+\n class TestGlmPoisson(CheckModelResultsMixin, CheckComparisonMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests Poisson family with canonical log link.\n \n         Test results were obtained by R.\n-        '''\n+        \"\"\"\n         from .results.results_glm import Cpunish\n+\n         cls.data = cpunish.load()\n         cls.data.endog = np.require(cls.data.endog, requirements=\"W\")\n         cls.data.exog = np.require(cls.data.exog, requirements=\"W\")\n         cls.data.exog[:, 3] = np.log(cls.data.exog[:, 3])\n         cls.data.exog = add_constant(cls.data.exog, prepend=False)\n-        cls.res1 = GLM(cls.data.endog, cls.data.exog,\n-                       family=sm.families.Poisson()).fit()\n+        cls.res1 = GLM(\n+            cls.data.endog, cls.data.exog, family=sm.families.Poisson()\n+        ).fit()\n         cls.res2 = Cpunish()\n         # compare with discrete, start close to save time\n         modd = discrete.Poisson(cls.data.endog, cls.data.exog)\n         cls.resd = modd.fit(start_params=cls.res1.params * 0.9, disp=False)\n \n-#class TestGlmPoissonIdentity(CheckModelResultsMixin):\n+\n+# class TestGlmPoissonIdentity(CheckModelResultsMixin):\n #    pass\n \n-#class TestGlmPoissonPower(CheckModelResultsMixin):\n+# class TestGlmPoissonPower(CheckModelResultsMixin):\n #    pass\n \n \n class TestGlmInvgauss(CheckModelResultsMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests the Inverse Gaussian family in GLM.\n \n         Notes\n@@ -769,22 +872,21 @@ def setup_class(cls):\n         Used the rndivgx.ado file provided by Hardin and Hilbe to\n         generate the data.  Results are read from model_results, which\n         were obtained by running R_ig.s\n-        '''\n+        \"\"\"\n         # Test Precisions\n         cls.decimal_aic_R = DECIMAL_0\n         cls.decimal_loglike = DECIMAL_0\n \n         from .results.results_glm import InvGauss\n+\n         res2 = InvGauss()\n-        res1 = GLM(res2.endog, res2.exog,\n-                   family=sm.families.InverseGaussian()).fit()\n+        res1 = GLM(res2.endog, res2.exog, family=sm.families.InverseGaussian()).fit()\n         cls.res1 = res1\n         cls.res2 = res2\n \n     def test_get_distribution(self):\n         res1 = self.res1\n-        distr = res1.model.family.get_distribution(res1.fittedvalues,\n-                                                   res1.scale)\n+        distr = res1.model.family.get_distribution(res1.fittedvalues, res1.scale)\n         var_endog = res1.model.family.variance(res1.fittedvalues) * res1.scale\n         m, v = distr.stats()\n         assert_allclose(res1.fittedvalues, m, rtol=1e-13)\n@@ -795,16 +897,20 @@ class TestGlmInvgaussLog(CheckModelResultsMixin):\n     @classmethod\n     def setup_class(cls):\n         # Test Precisions\n-        cls.decimal_aic_R = -10 # Big difference vs R.\n+        cls.decimal_aic_R = -10  # Big difference vs R.\n         cls.decimal_resids = DECIMAL_3\n \n         from .results.results_glm import InvGaussLog\n+\n         res2 = InvGaussLog()\n-        cls.res1 = GLM(res2.endog, res2.exog,\n-            family=sm.families.InverseGaussian(\n-                link=sm.families.links.Log())).fit()\n+        cls.res1 = GLM(\n+            res2.endog,\n+            res2.exog,\n+            family=sm.families.InverseGaussian(link=sm.families.links.Log()),\n+        ).fit()\n         cls.res2 = res2\n \n+\n # FIXME: enable or delete\n #    def setup(cls):\n #        if skipR:\n@@ -819,20 +925,25 @@ class TestGlmInvgaussIdentity(CheckModelResultsMixin):\n     @classmethod\n     def setup_class(cls):\n         # Test Precisions\n-        cls.decimal_aic_R = -10 #TODO: Big difference vs R\n+        cls.decimal_aic_R = -10  # TODO: Big difference vs R\n         cls.decimal_fittedvalues = DECIMAL_3\n         cls.decimal_params = DECIMAL_3\n \n         from .results.results_glm import Medpar1\n+\n         data = Medpar1()\n         with warnings.catch_warnings():\n             warnings.simplefilter(\"ignore\")\n-            cls.res1 = GLM(data.endog, data.exog,\n-                            family=sm.families.InverseGaussian(\n-                                link=sm.families.links.Identity())).fit()\n+            cls.res1 = GLM(\n+                data.endog,\n+                data.exog,\n+                family=sm.families.InverseGaussian(link=sm.families.links.Identity()),\n+            ).fit()\n         from .results.results_glm import InvGaussIdentity\n+\n         cls.res2 = InvGaussIdentity()\n \n+\n # FIXME: enable or delete\n #    def setup(cls):\n #        if skipR:\n@@ -846,36 +957,38 @@ def setup_class(cls):\n class TestGlmNegbinomial(CheckModelResultsMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Test Negative Binomial family with log link\n-        '''\n+        \"\"\"\n         # Test Precision\n         cls.decimal_resid = DECIMAL_1\n         cls.decimal_params = DECIMAL_3\n-        cls.decimal_resids = -1 # 1 % mismatch at 0\n+        cls.decimal_resids = -1  # 1 % mismatch at 0\n         cls.decimal_fittedvalues = DECIMAL_1\n \n         from statsmodels.datasets.committee import load\n+\n         cls.data = load()\n         cls.data.endog = np.require(cls.data.endog, requirements=\"W\")\n         cls.data.exog = np.require(cls.data.exog, requirements=\"W\")\n-        cls.data.exog[:,2] = np.log(cls.data.exog[:,2])\n-        interaction = cls.data.exog[:,2]*cls.data.exog[:,1]\n-        cls.data.exog = np.column_stack((cls.data.exog,interaction))\n+        cls.data.exog[:, 2] = np.log(cls.data.exog[:, 2])\n+        interaction = cls.data.exog[:, 2] * cls.data.exog[:, 1]\n+        cls.data.exog = np.column_stack((cls.data.exog, interaction))\n         cls.data.exog = add_constant(cls.data.exog, prepend=False)\n         with warnings.catch_warnings():\n             warnings.simplefilter(\"ignore\", category=DomainWarning)\n             with pytest.warns(UserWarning):\n                 fam = sm.families.NegativeBinomial()\n \n-        cls.res1 = GLM(cls.data.endog, cls.data.exog,\n-                family=fam).fit(scale='x2')\n+        cls.res1 = GLM(cls.data.endog, cls.data.exog, family=fam).fit(scale=\"x2\")\n         from .results.results_glm import Committee\n+\n         res2 = Committee()\n-        res2.aic_R += 2 # They do not count a degree of freedom for the scale\n+        res2.aic_R += 2  # They do not count a degree of freedom for the scale\n         cls.res2 = res2\n         cls.has_edispersion = True\n \n+\n # FIXME: enable or delete\n #    def setup_method(self):\n #        if skipR:\n@@ -886,15 +999,15 @@ def setup_class(cls):\n #        self.res2.null_deviance = 27.8110469364343\n \n # FIXME: enable/xfail/skip or delete\n-#class TestGlmNegbinomial_log(CheckModelResultsMixin):\n+# class TestGlmNegbinomial_log(CheckModelResultsMixin):\n #    pass\n \n # FIXME: enable/xfail/skip or delete\n-#class TestGlmNegbinomial_power(CheckModelResultsMixin):\n+# class TestGlmNegbinomial_power(CheckModelResultsMixin):\n #    pass\n \n # FIXME: enable/xfail/skip or delete\n-#class TestGlmNegbinomial_nbinom(CheckModelResultsMixin):\n+# class TestGlmNegbinomial_nbinom(CheckModelResultsMixin):\n #    pass\n \n \n@@ -902,6 +1015,7 @@ class TestGlmPoissonOffset(CheckModelResultsMixin):\n     @classmethod\n     def setup_class(cls):\n         from .results.results_glm import Cpunish_offset\n+\n         cls.decimal_params = DECIMAL_4\n         cls.decimal_bse = DECIMAL_4\n         cls.decimal_aic_R = 3\n@@ -913,38 +1027,51 @@ def setup_class(cls):\n         exposure = [100] * len(data.endog)\n         cls.data = data\n         cls.exposure = exposure\n-        cls.res1 = GLM(data.endog, data.exog, family=sm.families.Poisson(),\n-                       exposure=exposure).fit()\n+        cls.res1 = GLM(\n+            data.endog,\n+            data.exog,\n+            family=sm.families.Poisson(),\n+            exposure=exposure,\n+        ).fit()\n         cls.res2 = Cpunish_offset()\n \n     def test_missing(self):\n         # make sure offset is dropped correctly\n         endog = self.data.endog.copy()\n-        endog[[2,4,6,8]] = np.nan\n-        mod = GLM(endog, self.data.exog, family=sm.families.Poisson(),\n-                    exposure=self.exposure, missing='drop')\n+        endog[[2, 4, 6, 8]] = np.nan\n+        mod = GLM(\n+            endog,\n+            self.data.exog,\n+            family=sm.families.Poisson(),\n+            exposure=self.exposure,\n+            missing=\"drop\",\n+        )\n         assert_equal(mod.exposure.shape[0], 13)\n \n     def test_offset_exposure(self):\n         # exposure=x and offset=log(x) should have the same effect\n         np.random.seed(382304)\n         endog = np.random.randint(0, 10, 100)\n-        exog = np.random.normal(size=(100,3))\n+        exog = np.random.normal(size=(100, 3))\n         exposure = np.random.uniform(1, 2, 100)\n         offset = np.random.uniform(1, 2, 100)\n-        mod1 = GLM(endog, exog, family=sm.families.Poisson(),\n-                   offset=offset, exposure=exposure).fit()\n+        mod1 = GLM(\n+            endog,\n+            exog,\n+            family=sm.families.Poisson(),\n+            offset=offset,\n+            exposure=exposure,\n+        ).fit()\n         offset2 = offset + np.log(exposure)\n-        mod2 = GLM(endog, exog, family=sm.families.Poisson(),\n-                   offset=offset2).fit()\n+        mod2 = GLM(endog, exog, family=sm.families.Poisson(), offset=offset2).fit()\n         assert_almost_equal(mod1.params, mod2.params)\n         assert_allclose(mod1.null, mod2.null, rtol=1e-10)\n \n         # test recreating model\n         mod1_ = mod1.model\n         kwds = mod1_._get_init_kwds()\n-        assert_allclose(kwds['exposure'], exposure, rtol=1e-14)\n-        assert_allclose(kwds['offset'], mod1_.offset, rtol=1e-14)\n+        assert_allclose(kwds[\"exposure\"], exposure, rtol=1e-14)\n+        assert_allclose(kwds[\"offset\"], mod1_.offset, rtol=1e-14)\n         mod3 = mod1_.__class__(mod1_.endog, mod1_.exog, **kwds)\n         assert_allclose(mod3.exposure, mod1_.exposure, rtol=1e-14)\n         assert_allclose(mod3.offset, mod1_.offset, rtol=1e-14)\n@@ -954,21 +1081,19 @@ def test_offset_exposure(self):\n         resr2 = mod2.model.fit_regularized()\n         assert_allclose(resr1.params, resr2.params, rtol=1e-10)\n \n-\n     def test_predict(self):\n         np.random.seed(382304)\n         endog = np.random.randint(0, 10, 100)\n-        exog = np.random.normal(size=(100,3))\n+        exog = np.random.normal(size=(100, 3))\n         exposure = np.random.uniform(1, 2, 100)\n-        mod1 = GLM(endog, exog, family=sm.families.Poisson(),\n-                   exposure=exposure).fit()\n-        exog1 = np.random.normal(size=(10,3))\n+        mod1 = GLM(endog, exog, family=sm.families.Poisson(), exposure=exposure).fit()\n+        exog1 = np.random.normal(size=(10, 3))\n         exposure1 = np.random.uniform(1, 2, 10)\n \n         # Doubling exposure time should double expected response\n         pred1 = mod1.predict(exog=exog1, exposure=exposure1)\n-        pred2 = mod1.predict(exog=exog1, exposure=2*exposure1)\n-        assert_almost_equal(pred2, 2*pred1)\n+        pred2 = mod1.predict(exog=exog1, exposure=2 * exposure1)\n+        assert_almost_equal(pred2, 2 * pred1)\n \n         # Check exposure defaults\n         pred3 = mod1.predict()\n@@ -979,8 +1104,7 @@ def test_predict(self):\n \n         # Check offset defaults\n         offset = np.random.uniform(1, 2, 100)\n-        mod2 = GLM(endog, exog, offset=offset,\n-                   family=sm.families.Poisson()).fit()\n+        mod2 = GLM(endog, exog, offset=offset, family=sm.families.Poisson()).fit()\n         pred1 = mod2.predict()\n         pred2 = mod2.predict(which=\"mean\", offset=offset)\n         pred3 = mod2.predict(exog=exog, which=\"mean\", offset=offset)\n@@ -993,13 +1117,12 @@ def test_predict(self):\n         with pytest.warns(FutureWarning):\n             # deprecation warning for linear keyword\n             pred1 = mod3.predict(exog=exog1, offset=offset, linear=True)\n-        pred2 = mod3.predict(exog=exog1, offset=2*offset, which=\"linear\")\n-        assert_almost_equal(pred2, pred1+offset)\n+        pred2 = mod3.predict(exog=exog1, offset=2 * offset, which=\"linear\")\n+        assert_almost_equal(pred2, pred1 + offset)\n \n         # Passing exposure as a pandas series should not effect output type\n         assert isinstance(\n-            mod1.predict(exog=exog1, exposure=pd.Series(exposure1)),\n-            np.ndarray\n+            mod1.predict(exog=exog1, exposure=pd.Series(exposure1)), np.ndarray\n         )\n \n \n@@ -1018,12 +1141,13 @@ def test_perfect_pred(iris):\n def test_score_test_ols():\n     # nicer example than Longley\n     from statsmodels.regression.linear_model import OLS\n+\n     np.random.seed(5)\n     nobs = 100\n     sige = 0.5\n     x = np.random.uniform(0, 1, size=(nobs, 5))\n     x[:, 0] = 1\n-    beta = 1. / np.arange(1., x.shape[1] + 1)\n+    beta = 1.0 / np.arange(1.0, x.shape[1] + 1)\n     y = x.dot(beta) + sige * np.random.randn(nobs)\n \n     res_ols = OLS(y, x).fit()\n@@ -1033,7 +1157,7 @@ def test_score_test_ols():\n     res_glm = GLM(y, x[:, :-2], family=sm.families.Gaussian()).fit()\n     co2 = res_glm.model.score_test(res_glm.params, exog_extra=x[:, -2:])\n     # difference in df_resid versus nobs in scale see #1786\n-    assert_allclose(co[0] * 97 / 100., co2[0], rtol=1e-13)\n+    assert_allclose(co[0] * 97 / 100.0, co2[0], rtol=1e-13)\n \n \n def test_attribute_writable_resettable():\n@@ -1042,7 +1166,7 @@ def test_attribute_writable_resettable():\n     endog, exog = data.endog, data.exog\n     glm_model = sm.GLM(endog, exog)\n     assert_equal(glm_model.family.link.power, 1.0)\n-    glm_model.family.link.power = 2.\n+    glm_model.family.link.power = 2.0\n     assert_equal(glm_model.family.link.power, 2.0)\n     glm_model2 = sm.GLM(endog, exog)\n     assert_equal(glm_model2.family.link.power, 1.0)\n@@ -1051,9 +1175,9 @@ def test_attribute_writable_resettable():\n class TestStartParams(CheckModelResultsMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Test Gaussian family with canonical identity link\n-        '''\n+        \"\"\"\n         # Test Precisions\n         cls.decimal_resids = DECIMAL_3\n         cls.decimal_params = DECIMAL_2\n@@ -1061,21 +1185,24 @@ def setup_class(cls):\n         cls.decimal_bse = DECIMAL_3\n \n         from statsmodels.datasets.longley import load\n+\n         cls.data = load()\n         cls.data.exog = add_constant(cls.data.exog, prepend=False)\n         params = sm.OLS(cls.data.endog, cls.data.exog).fit().params\n-        cls.res1 = GLM(cls.data.endog, cls.data.exog,\n-                        family=sm.families.Gaussian()).fit(start_params=params)\n+        cls.res1 = GLM(\n+            cls.data.endog, cls.data.exog, family=sm.families.Gaussian()\n+        ).fit(start_params=params)\n         from .results.results_glm import Longley\n+\n         cls.res2 = Longley()\n \n \n def test_glm_start_params():\n     # see 1604\n-    y2 = np.array('0 1 0 0 0 1'.split(), int)\n-    wt = np.array([50,1,50,1,5,10])\n+    y2 = np.array(\"0 1 0 0 0 1\".split(), int)\n+    wt = np.array([50, 1, 50, 1, 5, 10])\n     y2 = np.repeat(y2, wt)\n-    x2 = np.repeat([0,0,0.001,100,-1,-1], wt)\n+    x2 = np.repeat([0, 0, 0.001, 100, -1, -1], wt)\n     mod = sm.GLM(y2, sm.add_constant(x2), family=sm.families.Binomial())\n     res = mod.fit(start_params=[-4, -5])\n     np.testing.assert_almost_equal(res.params, [-4.60305022, -5.29634545], 6)\n@@ -1088,11 +1215,11 @@ def test_loglike_no_opt():\n     x = np.arange(10, dtype=np.float64)\n \n     def llf(params):\n-        lin_pred = params[0] + params[1]*x\n+        lin_pred = params[0] + params[1] * x\n         pr = 1 / (1 + np.exp(-lin_pred))\n-        return np.sum(y*np.log(pr) + (1-y)*np.log(1-pr))\n+        return np.sum(y * np.log(pr) + (1 - y) * np.log(1 - pr))\n \n-    for params in [0,0], [0,1], [0.5,0.5]:\n+    for params in [0, 0], [0, 1], [0.5, 0.5]:\n         mod = sm.GLM(y, sm.add_constant(x), family=sm.families.Binomial())\n         res = mod.fit(start_params=params, maxiter=0)\n         like = llf(params)\n@@ -1103,23 +1230,38 @@ def test_formula_missing_exposure():\n     # see 2083\n     import statsmodels.formula.api as smf\n \n-    d = {'Foo': [1, 2, 10, 149], 'Bar': [1, 2, 3, np.nan],\n-         'constant': [1] * 4, 'exposure': np.random.uniform(size=4),\n-         'x': [1, 3, 2, 1.5]}\n+    d = {\n+        \"Foo\": [1, 2, 10, 149],\n+        \"Bar\": [1, 2, 3, np.nan],\n+        \"constant\": [1] * 4,\n+        \"exposure\": np.random.uniform(size=4),\n+        \"x\": [1, 3, 2, 1.5],\n+    }\n     df = pd.DataFrame(d)\n \n     family = sm.families.Gaussian(link=sm.families.links.Log())\n \n-    mod = smf.glm(\"Foo ~ Bar\", data=df, exposure=df.exposure,\n-                  family=family)\n-    assert_(type(mod.exposure) is np.ndarray, msg='Exposure is not ndarray')\n+    mod = smf.glm(\"Foo ~ Bar\", data=df, exposure=df.exposure, family=family)\n+    assert_(type(mod.exposure) is np.ndarray, msg=\"Exposure is not ndarray\")\n \n     exposure = pd.Series(np.random.uniform(size=5))\n-    df.loc[3, 'Bar'] = 4   # nan not relevant for Valueerror for shape mismatch\n-    assert_raises(ValueError, smf.glm, \"Foo ~ Bar\", data=df,\n-                  exposure=exposure, family=family)\n-    assert_raises(ValueError, GLM, df.Foo, df[['constant', 'Bar']],\n-                  exposure=exposure, family=family)\n+    df.loc[3, \"Bar\"] = 4  # nan not relevant for Valueerror for shape mismatch\n+    assert_raises(\n+        ValueError,\n+        smf.glm,\n+        \"Foo ~ Bar\",\n+        data=df,\n+        exposure=exposure,\n+        family=family,\n+    )\n+    assert_raises(\n+        ValueError,\n+        GLM,\n+        df.Foo,\n+        df[[\"constant\", \"Bar\"]],\n+        exposure=exposure,\n+        family=family,\n+    )\n \n \n @pytest.mark.matplotlib\n@@ -1128,7 +1270,7 @@ def test_plots(close_figures):\n     np.random.seed(378)\n     n = 200\n     exog = np.random.normal(size=(n, 2))\n-    lin_pred = exog[:, 0] + exog[:, 1]**2\n+    lin_pred = exog[:, 0] + exog[:, 1] ** 2\n     prob = 1 / (1 + np.exp(-lin_pred))\n     endog = 1 * (np.random.uniform(size=n) < prob)\n \n@@ -1140,7 +1282,7 @@ def test_plots(close_figures):\n     from statsmodels.graphics.regressionplots import add_lowess\n \n     # array interface\n-    for j in 0,1:\n+    for j in 0, 1:\n         fig = result.plot_added_variable(j)\n         add_lowess(fig.axes[0], frac=0.5)\n         close_or_save(pdf, fig)\n@@ -1155,7 +1297,7 @@ def test_plots(close_figures):\n     data = pd.DataFrame({\"y\": endog, \"x1\": exog[:, 0], \"x2\": exog[:, 1]})\n     model = sm.GLM.from_formula(\"y ~ x1 + x2\", data, family=sm.families.Binomial())\n     result = model.fit()\n-    for j in 0,1:\n+    for j in 0, 1:\n         xname = [\"x1\", \"x2\"][j]\n         fig = result.plot_added_variable(xname)\n         add_lowess(fig.axes[0], frac=0.5)\n@@ -1167,6 +1309,7 @@ def test_plots(close_figures):\n         add_lowess(fig.axes[0], frac=0.5)\n         close_or_save(pdf, fig)\n \n+\n def gen_endog(lin_pred, family_class, link, binom_version=0):\n \n     np.random.seed(872)\n@@ -1177,11 +1320,13 @@ def gen_endog(lin_pred, family_class, link, binom_version=0):\n \n     if family_class == fam.Binomial:\n         if binom_version == 0:\n-            endog = 1*(np.random.uniform(size=len(lin_pred)) < mu)\n+            endog = 1 * (np.random.uniform(size=len(lin_pred)) < mu)\n         else:\n             endog = np.empty((len(lin_pred), 2))\n             n = 10\n-            endog[:, 0] = (np.random.uniform(size=(len(lin_pred), n)) < mu[:, None]).sum(1)\n+            endog[:, 0] = (\n+                np.random.uniform(size=(len(lin_pred), n)) < mu[:, None]\n+            ).sum(1)\n             endog[:, 1] = n - endog[:, 0]\n     elif family_class == fam.Poisson:\n         endog = np.random.poisson(mu)\n@@ -1191,9 +1336,11 @@ def gen_endog(lin_pred, family_class, link, binom_version=0):\n         endog = mu + 2 * np.random.normal(size=len(lin_pred))\n     elif family_class == fam.NegativeBinomial:\n         from scipy.stats.distributions import nbinom\n+\n         endog = nbinom.rvs(mu, 0.5)\n     elif family_class == fam.InverseGaussian:\n         from scipy.stats.distributions import invgauss\n+\n         endog = invgauss.rvs(mu, scale=20)\n     else:\n         raise ValueError\n@@ -1245,12 +1392,23 @@ def test_gradient_irls():\n \n     fam = sm.families\n     lnk = sm.families.links\n-    families = [(fam.Binomial, [lnk.Logit, lnk.Probit, lnk.CLogLog, lnk.Log, lnk.Cauchy]),\n-                (fam.Poisson, [lnk.Log, lnk.Identity, lnk.Sqrt]),\n-                (fam.Gamma, [lnk.Log, lnk.Identity, lnk.InversePower]),\n-                (fam.Gaussian, [lnk.Identity, lnk.Log, lnk.InversePower]),\n-                (fam.InverseGaussian, [lnk.Log, lnk.Identity, lnk.InversePower, lnk.InverseSquared]),\n-                (fam.NegativeBinomial, [lnk.Log, lnk.InversePower, lnk.InverseSquared, lnk.Identity])]\n+    families = [\n+        (\n+            fam.Binomial,\n+            [lnk.Logit, lnk.Probit, lnk.CLogLog, lnk.Log, lnk.Cauchy],\n+        ),\n+        (fam.Poisson, [lnk.Log, lnk.Identity, lnk.Sqrt]),\n+        (fam.Gamma, [lnk.Log, lnk.Identity, lnk.InversePower]),\n+        (fam.Gaussian, [lnk.Identity, lnk.Log, lnk.InversePower]),\n+        (\n+            fam.InverseGaussian,\n+            [lnk.Log, lnk.Identity, lnk.InversePower, lnk.InverseSquared],\n+        ),\n+        (\n+            fam.NegativeBinomial,\n+            [lnk.Log, lnk.InversePower, lnk.InverseSquared, lnk.Identity],\n+        ),\n+    ]\n \n     n = 100\n     p = 3\n@@ -1260,7 +1418,7 @@ def test_gradient_irls():\n     skip_one = False\n     for family_class, family_links in families:\n         for link in family_links:\n-            for binom_version in 0,1:\n+            for binom_version in 0, 1:\n \n                 if family_class != fam.Binomial and binom_version == 1:\n                     continue\n@@ -1272,23 +1430,41 @@ def test_gradient_irls():\n                 elif (family_class, link) == (fam.Poisson, lnk.Sqrt):\n                     lin_pred = 2 + exog.sum(1)\n                 elif (family_class, link) == (fam.InverseGaussian, lnk.Log):\n-                    #skip_zero = True\n+                    # skip_zero = True\n                     lin_pred = -1 + exog.sum(1)\n-                elif (family_class, link) == (fam.InverseGaussian, lnk.Identity):\n-                    lin_pred = 20 + 5*exog.sum(1)\n+                elif (family_class, link) == (\n+                    fam.InverseGaussian,\n+                    lnk.Identity,\n+                ):\n+                    lin_pred = 20 + 5 * exog.sum(1)\n                     lin_pred = np.clip(lin_pred, 1e-4, np.inf)\n-                elif (family_class, link) == (fam.InverseGaussian, lnk.InverseSquared):\n+                elif (family_class, link) == (\n+                    fam.InverseGaussian,\n+                    lnk.InverseSquared,\n+                ):\n                     lin_pred = 0.5 + exog.sum(1) / 5\n-                    continue # skip due to non-convergence\n-                elif (family_class, link) == (fam.InverseGaussian, lnk.InversePower):\n+                    continue  # skip due to non-convergence\n+                elif (family_class, link) == (\n+                    fam.InverseGaussian,\n+                    lnk.InversePower,\n+                ):\n                     lin_pred = 1 + exog.sum(1) / 5\n-                elif (family_class, link) == (fam.NegativeBinomial, lnk.Identity):\n-                    lin_pred = 20 + 5*exog.sum(1)\n+                elif (family_class, link) == (\n+                    fam.NegativeBinomial,\n+                    lnk.Identity,\n+                ):\n+                    lin_pred = 20 + 5 * exog.sum(1)\n                     lin_pred = np.clip(lin_pred, 1e-4, np.inf)\n-                elif (family_class, link) == (fam.NegativeBinomial, lnk.InverseSquared):\n+                elif (family_class, link) == (\n+                    fam.NegativeBinomial,\n+                    lnk.InverseSquared,\n+                ):\n                     lin_pred = 0.1 + np.random.uniform(size=exog.shape[0])\n-                    continue # skip due to non-convergence\n-                elif (family_class, link) == (fam.NegativeBinomial, lnk.InversePower):\n+                    continue  # skip due to non-convergence\n+                elif (family_class, link) == (\n+                    fam.NegativeBinomial,\n+                    lnk.InversePower,\n+                ):\n                     lin_pred = 1 + exog.sum(1) / 5\n \n                 elif (family_class, link) == (fam.Gaussian, lnk.InversePower):\n@@ -1307,32 +1483,50 @@ def test_gradient_irls():\n                     mod_irls = sm.GLM(endog, exog, family=family_class(link=link()))\n                 rslt_irls = mod_irls.fit(method=\"IRLS\")\n \n-                if (family_class, link) not in [(fam.Poisson, lnk.Sqrt),\n-                                                (fam.Gamma, lnk.InversePower),\n-                                                (fam.InverseGaussian, lnk.Identity)\n-                                                ]:\n+                if (family_class, link) not in [\n+                    (fam.Poisson, lnk.Sqrt),\n+                    (fam.Gamma, lnk.InversePower),\n+                    (fam.InverseGaussian, lnk.Identity),\n+                ]:\n                     check_score_hessian(rslt_irls)\n \n                 # Try with and without starting values.\n-                for max_start_irls, start_params in (0, rslt_irls.params), (3, None):\n+                for max_start_irls, start_params in (0, rslt_irls.params), (\n+                    3,\n+                    None,\n+                ):\n                     # TODO: skip convergence failures for now\n                     if max_start_irls > 0 and skip_one:\n                         continue\n                     with warnings.catch_warnings():\n                         warnings.simplefilter(\"ignore\")\n-                        mod_gradient = sm.GLM(endog, exog, family=family_class(link=link()))\n-                    rslt_gradient = mod_gradient.fit(max_start_irls=max_start_irls,\n-                                                     start_params=start_params,\n-                                                     method=\"newton\", maxiter=300)\n+                        mod_gradient = sm.GLM(\n+                            endog, exog, family=family_class(link=link())\n+                        )\n+                    rslt_gradient = mod_gradient.fit(\n+                        max_start_irls=max_start_irls,\n+                        start_params=start_params,\n+                        method=\"newton\",\n+                        maxiter=300,\n+                    )\n \n-                    assert_allclose(rslt_gradient.params,\n-                                    rslt_irls.params, rtol=1e-6, atol=5e-5)\n+                    assert_allclose(\n+                        rslt_gradient.params,\n+                        rslt_irls.params,\n+                        rtol=1e-6,\n+                        atol=5e-5,\n+                    )\n \n-                    assert_allclose(rslt_gradient.llf, rslt_irls.llf,\n-                                    rtol=1e-6, atol=1e-6)\n+                    assert_allclose(\n+                        rslt_gradient.llf, rslt_irls.llf, rtol=1e-6, atol=1e-6\n+                    )\n \n-                    assert_allclose(rslt_gradient.scale, rslt_irls.scale,\n-                                    rtol=1e-6, atol=1e-6)\n+                    assert_allclose(\n+                        rslt_gradient.scale,\n+                        rslt_irls.scale,\n+                        rtol=1e-6,\n+                        atol=1e-6,\n+                    )\n \n                     # Get the standard errors using expected information.\n                     gradient_bse = rslt_gradient.bse\n@@ -1340,13 +1534,20 @@ def test_gradient_irls():\n                     gradient_bse = np.sqrt(-np.diag(np.linalg.inv(ehess)))\n                     assert_allclose(gradient_bse, rslt_irls.bse, rtol=1e-6, atol=5e-5)\n                     # rslt_irls.bse corresponds to observed=True\n-                    assert_allclose(rslt_gradient.bse, rslt_irls.bse, rtol=0.2, atol=5e-5)\n+                    assert_allclose(\n+                        rslt_gradient.bse, rslt_irls.bse, rtol=0.2, atol=5e-5\n+                    )\n \n-                    rslt_gradient_eim = mod_gradient.fit(max_start_irls=0,\n-                                                         cov_type='eim',\n-                                                         start_params=rslt_gradient.params,\n-                                                         method=\"newton\", maxiter=300)\n-                    assert_allclose(rslt_gradient_eim.bse, rslt_irls.bse, rtol=5e-5, atol=0)\n+                    rslt_gradient_eim = mod_gradient.fit(\n+                        max_start_irls=0,\n+                        cov_type=\"eim\",\n+                        start_params=rslt_gradient.params,\n+                        method=\"newton\",\n+                        maxiter=300,\n+                    )\n+                    assert_allclose(\n+                        rslt_gradient_eim.bse, rslt_irls.bse, rtol=5e-5, atol=0\n+                    )\n \n \n def test_gradient_irls_eim():\n@@ -1358,16 +1559,23 @@ def test_gradient_irls_eim():\n \n     fam = sm.families\n     lnk = sm.families.links\n-    families = [(fam.Binomial, [lnk.Logit, lnk.Probit, lnk.CLogLog, lnk.Log,\n-                                lnk.Cauchy]),\n-                (fam.Poisson, [lnk.Log, lnk.Identity, lnk.Sqrt]),\n-                (fam.Gamma, [lnk.Log, lnk.Identity, lnk.InversePower]),\n-                (fam.Gaussian, [lnk.Identity, lnk.Log, lnk.InversePower]),\n-                (fam.InverseGaussian, [lnk.Log, lnk.Identity,\n-                                       lnk.InversePower,\n-                                       lnk.InverseSquared]),\n-                (fam.NegativeBinomial, [lnk.Log, lnk.InversePower,\n-                                        lnk.InverseSquared, lnk.Identity])]\n+    families = [\n+        (\n+            fam.Binomial,\n+            [lnk.Logit, lnk.Probit, lnk.CLogLog, lnk.Log, lnk.Cauchy],\n+        ),\n+        (fam.Poisson, [lnk.Log, lnk.Identity, lnk.Sqrt]),\n+        (fam.Gamma, [lnk.Log, lnk.Identity, lnk.InversePower]),\n+        (fam.Gaussian, [lnk.Identity, lnk.Log, lnk.InversePower]),\n+        (\n+            fam.InverseGaussian,\n+            [lnk.Log, lnk.Identity, lnk.InversePower, lnk.InverseSquared],\n+        ),\n+        (\n+            fam.NegativeBinomial,\n+            [lnk.Log, lnk.InversePower, lnk.InverseSquared, lnk.Identity],\n+        ),\n+    ]\n \n     n = 100\n     p = 3\n@@ -1391,27 +1599,39 @@ def test_gradient_irls_eim():\n                 elif (family_class, link) == (fam.InverseGaussian, lnk.Log):\n                     # skip_zero = True\n                     lin_pred = -1 + exog.sum(1)\n-                elif (family_class, link) == (fam.InverseGaussian,\n-                                              lnk.Identity):\n-                    lin_pred = 20 + 5*exog.sum(1)\n+                elif (family_class, link) == (\n+                    fam.InverseGaussian,\n+                    lnk.Identity,\n+                ):\n+                    lin_pred = 20 + 5 * exog.sum(1)\n                     lin_pred = np.clip(lin_pred, 1e-4, np.inf)\n-                elif (family_class, link) == (fam.InverseGaussian,\n-                                              lnk.InverseSquared):\n+                elif (family_class, link) == (\n+                    fam.InverseGaussian,\n+                    lnk.InverseSquared,\n+                ):\n                     lin_pred = 0.5 + exog.sum(1) / 5\n                     continue  # skip due to non-convergence\n-                elif (family_class, link) == (fam.InverseGaussian,\n-                                              lnk.InversePower):\n+                elif (family_class, link) == (\n+                    fam.InverseGaussian,\n+                    lnk.InversePower,\n+                ):\n                     lin_pred = 1 + exog.sum(1) / 5\n-                elif (family_class, link) == (fam.NegativeBinomial,\n-                                              lnk.Identity):\n-                    lin_pred = 20 + 5*exog.sum(1)\n+                elif (family_class, link) == (\n+                    fam.NegativeBinomial,\n+                    lnk.Identity,\n+                ):\n+                    lin_pred = 20 + 5 * exog.sum(1)\n                     lin_pred = np.clip(lin_pred, 1e-4, np.inf)\n-                elif (family_class, link) == (fam.NegativeBinomial,\n-                                              lnk.InverseSquared):\n+                elif (family_class, link) == (\n+                    fam.NegativeBinomial,\n+                    lnk.InverseSquared,\n+                ):\n                     lin_pred = 0.1 + np.random.uniform(size=exog.shape[0])\n                     continue  # skip due to non-convergence\n-                elif (family_class, link) == (fam.NegativeBinomial,\n-                                              lnk.InversePower):\n+                elif (family_class, link) == (\n+                    fam.NegativeBinomial,\n+                    lnk.InversePower,\n+                ):\n                     lin_pred = 1 + exog.sum(1) / 5\n \n                 elif (family_class, link) == (fam.Gaussian, lnk.InversePower):\n@@ -1424,72 +1644,81 @@ def test_gradient_irls_eim():\n \n                 with warnings.catch_warnings():\n                     warnings.simplefilter(\"ignore\")\n-                    mod_irls = sm.GLM(endog, exog,\n-                                      family=family_class(link=link()))\n+                    mod_irls = sm.GLM(endog, exog, family=family_class(link=link()))\n                 rslt_irls = mod_irls.fit(method=\"IRLS\")\n \n                 # Try with and without starting values.\n-                for max_start_irls, start_params in ((0, rslt_irls.params),\n-                                                     (3, None)):\n+                for max_start_irls, start_params in (\n+                    (0, rslt_irls.params),\n+                    (3, None),\n+                ):\n                     # TODO: skip convergence failures for now\n                     if max_start_irls > 0 and skip_one:\n                         continue\n                     with warnings.catch_warnings():\n                         warnings.simplefilter(\"ignore\")\n-                        mod_gradient = sm.GLM(endog, exog,\n-                                              family=family_class(link=link()))\n+                        mod_gradient = sm.GLM(\n+                            endog, exog, family=family_class(link=link())\n+                        )\n                     rslt_gradient = mod_gradient.fit(\n-                            max_start_irls=max_start_irls,\n-                            start_params=start_params,\n-                            method=\"newton\",\n-                            optim_hessian='eim'\n+                        max_start_irls=max_start_irls,\n+                        start_params=start_params,\n+                        method=\"newton\",\n+                        optim_hessian=\"eim\",\n                     )\n \n-                    assert_allclose(rslt_gradient.params, rslt_irls.params,\n-                                    rtol=1e-6, atol=5e-5)\n+                    assert_allclose(\n+                        rslt_gradient.params,\n+                        rslt_irls.params,\n+                        rtol=1e-6,\n+                        atol=5e-5,\n+                    )\n \n-                    assert_allclose(rslt_gradient.llf, rslt_irls.llf,\n-                                    rtol=1e-6, atol=1e-6)\n+                    assert_allclose(\n+                        rslt_gradient.llf, rslt_irls.llf, rtol=1e-6, atol=1e-6\n+                    )\n \n-                    assert_allclose(rslt_gradient.scale, rslt_irls.scale,\n-                                    rtol=1e-6, atol=1e-6)\n+                    assert_allclose(\n+                        rslt_gradient.scale,\n+                        rslt_irls.scale,\n+                        rtol=1e-6,\n+                        atol=1e-6,\n+                    )\n \n                     # Get the standard errors using expected information.\n-                    ehess = mod_gradient.hessian(rslt_gradient.params,\n-                                                 observed=False)\n+                    ehess = mod_gradient.hessian(rslt_gradient.params, observed=False)\n                     gradient_bse = np.sqrt(-np.diag(np.linalg.inv(ehess)))\n \n-                    assert_allclose(gradient_bse, rslt_irls.bse, rtol=1e-6,\n-                                    atol=5e-5)\n+                    assert_allclose(gradient_bse, rslt_irls.bse, rtol=1e-6, atol=5e-5)\n \n \n def test_glm_irls_method():\n     nobs, k_vars = 50, 4\n     np.random.seed(987126)\n     x = np.random.randn(nobs, k_vars - 1)\n-    exog = add_constant(x, has_constant='add')\n+    exog = add_constant(x, has_constant=\"add\")\n     y = exog.sum(1) + np.random.randn(nobs)\n \n     mod = GLM(y, exog)\n     res1 = mod.fit()\n-    res2 = mod.fit(wls_method='pinv', attach_wls=True)\n-    res3 = mod.fit(wls_method='qr', attach_wls=True)\n+    res2 = mod.fit(wls_method=\"pinv\", attach_wls=True)\n+    res3 = mod.fit(wls_method=\"qr\", attach_wls=True)\n     # fit_gradient does not attach mle_settings\n-    res_g1 = mod.fit(start_params=res1.params, method='bfgs')\n+    res_g1 = mod.fit(start_params=res1.params, method=\"bfgs\")\n \n     for r in [res1, res2, res3]:\n-        assert_equal(r.mle_settings['optimizer'], 'IRLS')\n-        assert_equal(r.method, 'IRLS')\n+        assert_equal(r.mle_settings[\"optimizer\"], \"IRLS\")\n+        assert_equal(r.method, \"IRLS\")\n \n-    assert_equal(res1.mle_settings['wls_method'], 'lstsq')\n-    assert_equal(res2.mle_settings['wls_method'], 'pinv')\n-    assert_equal(res3.mle_settings['wls_method'], 'qr')\n+    assert_equal(res1.mle_settings[\"wls_method\"], \"lstsq\")\n+    assert_equal(res2.mle_settings[\"wls_method\"], \"pinv\")\n+    assert_equal(res3.mle_settings[\"wls_method\"], \"qr\")\n \n-    assert_(hasattr(res2.results_wls.model, 'pinv_wexog'))\n-    assert_(hasattr(res3.results_wls.model, 'exog_Q'))\n+    assert_(hasattr(res2.results_wls.model, \"pinv_wexog\"))\n+    assert_(hasattr(res3.results_wls.model, \"exog_Q\"))\n \n     # fit_gradient currently does not attach mle_settings\n-    assert_equal(res_g1.method, 'bfgs')\n+    assert_equal(res_g1.method, \"bfgs\")\n \n \n class CheckWtdDuplicationMixin:\n@@ -1508,8 +1737,7 @@ def setup_class(cls):\n         cls.exog_big = np.repeat(cls.exog, cls.weight, axis=0)\n \n     def test_params(self):\n-        assert_allclose(self.res1.params, self.res2.params,  atol=1e-6,\n-                        rtol=1e-6)\n+        assert_allclose(self.res1.params, self.res2.params, atol=1e-6, rtol=1e-6)\n \n     decimal_bse = DECIMAL_4\n \n@@ -1538,11 +1766,10 @@ def test_residuals(self):\n     def test_aic(self):\n         # R includes the estimation of the scale as a lost dof\n         # Does not with Gamma though\n-        assert_allclose(self.res1.aic, self.res2.aic,  atol=1e-6, rtol=1e-6)\n+        assert_allclose(self.res1.aic, self.res2.aic, atol=1e-6, rtol=1e-6)\n \n     def test_deviance(self):\n-        assert_allclose(self.res1.deviance, self.res2.deviance,  atol=1e-6,\n-                        rtol=1e-6)\n+        assert_allclose(self.res1.deviance, self.res2.deviance, atol=1e-6, rtol=1e-6)\n \n     def test_scale(self):\n         assert_allclose(self.res1.scale, self.res2.scale, atol=1e-6, rtol=1e-6)\n@@ -1558,271 +1785,319 @@ def test_null_deviance(self):\n         with warnings.catch_warnings():\n             warnings.simplefilter(\"ignore\", DomainWarning)\n \n-            assert_allclose(self.res1.null_deviance,\n-                            self.res2.null_deviance,\n-                            atol=1e-6,\n-                            rtol=1e-6)\n+            assert_allclose(\n+                self.res1.null_deviance,\n+                self.res2.null_deviance,\n+                atol=1e-6,\n+                rtol=1e-6,\n+            )\n \n     decimal_bic = DECIMAL_4\n \n     def test_bic(self):\n         with warnings.catch_warnings():\n             warnings.simplefilter(\"ignore\")\n-            assert_allclose(self.res1.bic, self.res2.bic,  atol=1e-6, rtol=1e-6)\n+            assert_allclose(self.res1.bic, self.res2.bic, atol=1e-6, rtol=1e-6)\n \n     decimal_fittedvalues = DECIMAL_4\n \n     def test_fittedvalues(self):\n         res2_fitted = self.res2.predict(self.res1.model.exog)\n-        assert_allclose(self.res1.fittedvalues, res2_fitted, atol=1e-5,\n-                        rtol=1e-5)\n+        assert_allclose(self.res1.fittedvalues, res2_fitted, atol=1e-5, rtol=1e-5)\n \n     decimal_tpvalues = DECIMAL_4\n \n     def test_tpvalues(self):\n         # test comparing tvalues and pvalues with normal implementation\n         # make sure they use normal distribution (inherited in results class)\n-        assert_allclose(self.res1.tvalues, self.res2.tvalues, atol=1e-6,\n-                        rtol=2e-4)\n-        assert_allclose(self.res1.pvalues, self.res2.pvalues, atol=1e-6,\n-                        rtol=1e-6)\n-        assert_allclose(self.res1.conf_int(), self.res2.conf_int(), atol=1e-6,\n-                        rtol=1e-6)\n+        assert_allclose(self.res1.tvalues, self.res2.tvalues, atol=1e-6, rtol=2e-4)\n+        assert_allclose(self.res1.pvalues, self.res2.pvalues, atol=1e-6, rtol=1e-6)\n+        assert_allclose(\n+            self.res1.conf_int(), self.res2.conf_int(), atol=1e-6, rtol=1e-6\n+        )\n \n \n class TestWtdGlmPoisson(CheckWtdDuplicationMixin):\n \n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests Poisson family with canonical log link.\n-        '''\n+        \"\"\"\n         super().setup_class()\n         cls.endog = np.asarray(cls.endog)\n         cls.exog = np.asarray(cls.exog)\n \n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                        freq_weights=cls.weight,\n-                        family=sm.families.Poisson()).fit()\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                        family=sm.families.Poisson()).fit()\n+        cls.res1 = GLM(\n+            cls.endog,\n+            cls.exog,\n+            freq_weights=cls.weight,\n+            family=sm.families.Poisson(),\n+        ).fit()\n+        cls.res2 = GLM(cls.endog_big, cls.exog_big, family=sm.families.Poisson()).fit()\n \n \n class TestWtdGlmPoissonNewton(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests Poisson family with canonical log link.\n-        '''\n+        \"\"\"\n         super().setup_class()\n \n-        start_params = np.array([1.82794424e-04, -4.76785037e-02,\n-                                 -9.48249717e-02, -2.92293226e-04,\n-                                 2.63728909e+00, -2.05934384e+01])\n+        start_params = np.array(\n+            [\n+                1.82794424e-04,\n+                -4.76785037e-02,\n+                -9.48249717e-02,\n+                -2.92293226e-04,\n+                2.63728909e00,\n+                -2.05934384e01,\n+            ]\n+        )\n \n-        fit_kwds = dict(method='newton')\n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                        freq_weights=cls.weight,\n-                        family=sm.families.Poisson()).fit(**fit_kwds)\n-        fit_kwds = dict(method='newton', start_params=start_params)\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                        family=sm.families.Poisson()).fit(**fit_kwds)\n+        fit_kwds = dict(method=\"newton\")\n+        cls.res1 = GLM(\n+            cls.endog,\n+            cls.exog,\n+            freq_weights=cls.weight,\n+            family=sm.families.Poisson(),\n+        ).fit(**fit_kwds)\n+        fit_kwds = dict(method=\"newton\", start_params=start_params)\n+        cls.res2 = GLM(cls.endog_big, cls.exog_big, family=sm.families.Poisson()).fit(\n+            **fit_kwds\n+        )\n \n \n class TestWtdGlmPoissonHC0(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-\n-        '''\n+        \"\"\"\n         Tests Poisson family with canonical log link.\n-        '''\n+        \"\"\"\n         super().setup_class()\n \n-        start_params = np.array([1.82794424e-04, -4.76785037e-02,\n-                                 -9.48249717e-02, -2.92293226e-04,\n-                                 2.63728909e+00, -2.05934384e+01])\n+        start_params = np.array(\n+            [\n+                1.82794424e-04,\n+                -4.76785037e-02,\n+                -9.48249717e-02,\n+                -2.92293226e-04,\n+                2.63728909e00,\n+                -2.05934384e01,\n+            ]\n+        )\n \n-        fit_kwds = dict(cov_type='HC0')\n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                        freq_weights=cls.weight,\n-                        family=sm.families.Poisson()).fit(**fit_kwds)\n-        fit_kwds = dict(cov_type='HC0', start_params=start_params)\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                        family=sm.families.Poisson()).fit(**fit_kwds)\n+        fit_kwds = dict(cov_type=\"HC0\")\n+        cls.res1 = GLM(\n+            cls.endog,\n+            cls.exog,\n+            freq_weights=cls.weight,\n+            family=sm.families.Poisson(),\n+        ).fit(**fit_kwds)\n+        fit_kwds = dict(cov_type=\"HC0\", start_params=start_params)\n+        cls.res2 = GLM(cls.endog_big, cls.exog_big, family=sm.families.Poisson()).fit(\n+            **fit_kwds\n+        )\n \n \n class TestWtdGlmPoissonClu(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-\n-        '''\n+        \"\"\"\n         Tests Poisson family with canonical log link.\n-        '''\n+        \"\"\"\n         super().setup_class()\n \n-        start_params = np.array([1.82794424e-04, -4.76785037e-02,\n-                                 -9.48249717e-02, -2.92293226e-04,\n-                                 2.63728909e+00, -2.05934384e+01])\n+        start_params = np.array(\n+            [\n+                1.82794424e-04,\n+                -4.76785037e-02,\n+                -9.48249717e-02,\n+                -2.92293226e-04,\n+                2.63728909e00,\n+                -2.05934384e01,\n+            ]\n+        )\n \n         gid = np.arange(1, len(cls.endog) + 1) // 2\n-        fit_kwds = dict(cov_type='cluster', cov_kwds={'groups': gid, 'use_correction':False})\n+        fit_kwds = dict(\n+            cov_type=\"cluster\",\n+            cov_kwds={\"groups\": gid, \"use_correction\": False},\n+        )\n \n         import warnings\n+\n         with warnings.catch_warnings():\n             warnings.simplefilter(\"ignore\")\n-            cls.res1 = GLM(cls.endog, cls.exog,\n-                            freq_weights=cls.weight,\n-                            family=sm.families.Poisson()).fit(**fit_kwds)\n+            cls.res1 = GLM(\n+                cls.endog,\n+                cls.exog,\n+                freq_weights=cls.weight,\n+                family=sm.families.Poisson(),\n+            ).fit(**fit_kwds)\n             gidr = np.repeat(gid, cls.weight)\n-            fit_kwds = dict(cov_type='cluster', cov_kwds={'groups': gidr, 'use_correction':False})\n-            cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                            family=sm.families.Poisson()).fit(start_params=start_params,\n-                                                              **fit_kwds)\n+            fit_kwds = dict(\n+                cov_type=\"cluster\",\n+                cov_kwds={\"groups\": gidr, \"use_correction\": False},\n+            )\n+            cls.res2 = GLM(\n+                cls.endog_big, cls.exog_big, family=sm.families.Poisson()\n+            ).fit(start_params=start_params, **fit_kwds)\n \n \n class TestWtdGlmBinomial(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-\n-        '''\n+        \"\"\"\n         Tests Binomial family with canonical logit link.\n-        '''\n+        \"\"\"\n         super().setup_class()\n         cls.endog = cls.endog / 100\n         cls.endog_big = cls.endog_big / 100\n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                       freq_weights=cls.weight,\n-                       family=sm.families.Binomial()).fit()\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                       family=sm.families.Binomial()).fit()\n+        cls.res1 = GLM(\n+            cls.endog,\n+            cls.exog,\n+            freq_weights=cls.weight,\n+            family=sm.families.Binomial(),\n+        ).fit()\n+        cls.res2 = GLM(cls.endog_big, cls.exog_big, family=sm.families.Binomial()).fit()\n \n \n class TestWtdGlmNegativeBinomial(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-\n-        '''\n+        \"\"\"\n         Tests Negative Binomial family with canonical link\n         g(p) = log(p/(p + 1/alpha))\n-        '''\n+        \"\"\"\n         super().setup_class()\n-        alpha = 1.\n+        alpha = 1.0\n \n         with warnings.catch_warnings():\n             warnings.simplefilter(\"ignore\", category=DomainWarning)\n             family_link = sm.families.NegativeBinomial(\n                 link=sm.families.links.NegativeBinomial(alpha=alpha),\n-                alpha=alpha)\n-            cls.res1 = GLM(cls.endog, cls.exog,\n-                           freq_weights=cls.weight,\n-                           family=family_link).fit()\n-            cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                           family=family_link).fit()\n+                alpha=alpha,\n+            )\n+            cls.res1 = GLM(\n+                cls.endog,\n+                cls.exog,\n+                freq_weights=cls.weight,\n+                family=family_link,\n+            ).fit()\n+            cls.res2 = GLM(cls.endog_big, cls.exog_big, family=family_link).fit()\n \n \n class TestWtdGlmGamma(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-\n-        '''\n+        \"\"\"\n         Tests Gamma family with log link.\n-        '''\n+        \"\"\"\n         super().setup_class()\n         family_link = sm.families.Gamma(sm.families.links.Log())\n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                       freq_weights=cls.weight,\n-                       family=family_link).fit()\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                       family=family_link).fit()\n+        cls.res1 = GLM(\n+            cls.endog, cls.exog, freq_weights=cls.weight, family=family_link\n+        ).fit()\n+        cls.res2 = GLM(cls.endog_big, cls.exog_big, family=family_link).fit()\n \n \n class TestWtdGlmGaussian(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests Gaussian family with log link.\n-        '''\n+        \"\"\"\n         super().setup_class()\n         family_link = sm.families.Gaussian(sm.families.links.Log())\n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                       freq_weights=cls.weight,\n-                       family=family_link).fit()\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                       family=family_link).fit()\n+        cls.res1 = GLM(\n+            cls.endog, cls.exog, freq_weights=cls.weight, family=family_link\n+        ).fit()\n+        cls.res2 = GLM(cls.endog_big, cls.exog_big, family=family_link).fit()\n \n \n class TestWtdGlmInverseGaussian(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests InverseGaussian family with log link.\n-        '''\n+        \"\"\"\n         super().setup_class()\n         family_link = sm.families.InverseGaussian(sm.families.links.Log())\n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                       freq_weights=cls.weight,\n-                       family=family_link).fit()\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                       family=family_link).fit()\n+        cls.res1 = GLM(\n+            cls.endog, cls.exog, freq_weights=cls.weight, family=family_link\n+        ).fit()\n+        cls.res2 = GLM(cls.endog_big, cls.exog_big, family=family_link).fit()\n \n \n class TestWtdGlmGammaNewton(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests Gamma family with log link.\n-        '''\n+        \"\"\"\n         super().setup_class()\n         family_link = sm.families.Gamma(sm.families.links.Log())\n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                       freq_weights=cls.weight,\n-                       family=family_link\n-                       ).fit(method='newton')\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                       family=family_link\n-                       ).fit(method='newton')\n+        cls.res1 = GLM(\n+            cls.endog, cls.exog, freq_weights=cls.weight, family=family_link\n+        ).fit(method=\"newton\")\n+        cls.res2 = GLM(cls.endog_big, cls.exog_big, family=family_link).fit(\n+            method=\"newton\"\n+        )\n \n     def test_init_kwargs(self):\n         family_link = sm.families.Gamma(sm.families.links.Log())\n \n         with pytest.warns(ValueWarning, match=\"unknown kwargs\"):\n-            GLM(self.endog, self.exog, family=family_link,\n+            GLM(\n+                self.endog,\n+                self.exog,\n+                family=family_link,\n                 weights=self.weight,  # incorrect keyword\n-                )\n+            )\n \n \n class TestWtdGlmGammaScale_X2(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests Gamma family with log link.\n-        '''\n+        \"\"\"\n         super().setup_class()\n         family_link = sm.families.Gamma(sm.families.links.Log())\n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                       freq_weights=cls.weight,\n-                       family=family_link,\n-                       ).fit(scale='X2')\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                       family=family_link,\n-                       ).fit(scale='X2')\n+        cls.res1 = GLM(\n+            cls.endog,\n+            cls.exog,\n+            freq_weights=cls.weight,\n+            family=family_link,\n+        ).fit(scale=\"X2\")\n+        cls.res2 = GLM(\n+            cls.endog_big,\n+            cls.exog_big,\n+            family=family_link,\n+        ).fit(scale=\"X2\")\n \n \n class TestWtdGlmGammaScale_dev(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests Gamma family with log link.\n-        '''\n+        \"\"\"\n         super().setup_class()\n         family_link = sm.families.Gamma(sm.families.links.Log())\n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                       freq_weights=cls.weight,\n-                       family=family_link,\n-                       ).fit(scale='dev')\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                       family=family_link,\n-                       ).fit(scale='dev')\n+        cls.res1 = GLM(\n+            cls.endog,\n+            cls.exog,\n+            freq_weights=cls.weight,\n+            family=family_link,\n+        ).fit(scale=\"dev\")\n+        cls.res2 = GLM(\n+            cls.endog_big,\n+            cls.exog_big,\n+            family=family_link,\n+        ).fit(scale=\"dev\")\n \n     def test_missing(self):\n         endog = self.data.endog.copy()\n@@ -1830,90 +2105,88 @@ def test_missing(self):\n         exog[0, 0] = np.nan\n         endog[[2, 4, 6, 8]] = np.nan\n         freq_weights = self.weight\n-        mod_misisng = GLM(endog, exog, family=self.res1.model.family,\n-                          freq_weights=freq_weights, missing='drop')\n-        assert_equal(mod_misisng.freq_weights.shape[0],\n-                     mod_misisng.endog.shape[0])\n-        assert_equal(mod_misisng.freq_weights.shape[0],\n-                     mod_misisng.exog.shape[0])\n-        keep_idx = np.array([1,  3,  5,  7,  9, 10, 11, 12, 13, 14, 15, 16])\n+        mod_misisng = GLM(\n+            endog,\n+            exog,\n+            family=self.res1.model.family,\n+            freq_weights=freq_weights,\n+            missing=\"drop\",\n+        )\n+        assert_equal(mod_misisng.freq_weights.shape[0], mod_misisng.endog.shape[0])\n+        assert_equal(mod_misisng.freq_weights.shape[0], mod_misisng.exog.shape[0])\n+        keep_idx = np.array([1, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16])\n         assert_equal(mod_misisng.freq_weights, self.weight[keep_idx])\n \n \n class TestWtdTweedieLog(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests Tweedie family with log link and var_power=1.\n-        '''\n+        \"\"\"\n         super().setup_class()\n-        family_link = sm.families.Tweedie(link=sm.families.links.Log(),\n-                                          var_power=1)\n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                        freq_weights=cls.weight,\n-                        family=family_link).fit()\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                        family=family_link).fit()\n+        family_link = sm.families.Tweedie(link=sm.families.links.Log(), var_power=1)\n+        cls.res1 = GLM(\n+            cls.endog, cls.exog, freq_weights=cls.weight, family=family_link\n+        ).fit()\n+        cls.res2 = GLM(cls.endog_big, cls.exog_big, family=family_link).fit()\n \n \n class TestWtdTweediePower2(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests Tweedie family with Power(1) link and var_power=2.\n-        '''\n+        \"\"\"\n         cls.data = cpunish.load_pandas()\n         cls.endog = cls.data.endog\n-        cls.exog = cls.data.exog[['INCOME', 'SOUTH']]\n+        cls.exog = cls.data.exog[[\"INCOME\", \"SOUTH\"]]\n         np.random.seed(1234)\n         cls.weight = np.random.randint(5, 100, len(cls.endog))\n         cls.endog_big = np.repeat(cls.endog.values, cls.weight)\n         cls.exog_big = np.repeat(cls.exog.values, cls.weight, axis=0)\n         link = sm.families.links.Power()\n         family_link = sm.families.Tweedie(link=link, var_power=2)\n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                       freq_weights=cls.weight,\n-                       family=family_link).fit()\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                       family=family_link).fit()\n+        cls.res1 = GLM(\n+            cls.endog, cls.exog, freq_weights=cls.weight, family=family_link\n+        ).fit()\n+        cls.res2 = GLM(cls.endog_big, cls.exog_big, family=family_link).fit()\n \n \n class TestWtdTweediePower15(CheckWtdDuplicationMixin):\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Tests Tweedie family with Power(0.5) link and var_power=1.5.\n-        '''\n+        \"\"\"\n         super().setup_class()\n-        family_link = sm.families.Tweedie(link=sm.families.links.Power(0.5),\n-                                          var_power=1.5)\n-        cls.res1 = GLM(cls.endog, cls.exog,\n-                        freq_weights=cls.weight,\n-                        family=family_link).fit()\n-        cls.res2 = GLM(cls.endog_big, cls.exog_big,\n-                        family=family_link).fit()\n+        family_link = sm.families.Tweedie(\n+            link=sm.families.links.Power(0.5), var_power=1.5\n+        )\n+        cls.res1 = GLM(\n+            cls.endog, cls.exog, freq_weights=cls.weight, family=family_link\n+        ).fit()\n+        cls.res2 = GLM(cls.endog_big, cls.exog_big, family=family_link).fit()\n \n \n def test_wtd_patsy_missing():\n     import pandas as pd\n+\n     data = cpunish.load()\n     data.endog = np.require(data.endog, requirements=\"W\")\n     data.exog = np.require(data.exog, requirements=\"W\")\n     data.exog[0, 0] = np.nan\n     data.endog[[2, 4, 6, 8]] = np.nan\n     data.pandas = pd.DataFrame(data.exog, columns=data.exog_name)\n-    data.pandas['EXECUTIONS'] = data.endog\n-    weights = np.arange(1, len(data.endog)+1)\n+    data.pandas[\"EXECUTIONS\"] = data.endog\n+    weights = np.arange(1, len(data.endog) + 1)\n     formula = \"\"\"EXECUTIONS ~ INCOME + PERPOVERTY + PERBLACK + VC100k96 +\n                  SOUTH + DEGREE\"\"\"\n-    mod_misisng = GLM.from_formula(formula, data=data.pandas,\n-                                   freq_weights=weights)\n-    assert_equal(mod_misisng.freq_weights.shape[0],\n-                 mod_misisng.endog.shape[0])\n-    assert_equal(mod_misisng.freq_weights.shape[0],\n-                 mod_misisng.exog.shape[0])\n+    mod_misisng = GLM.from_formula(formula, data=data.pandas, freq_weights=weights)\n+    assert_equal(mod_misisng.freq_weights.shape[0], mod_misisng.endog.shape[0])\n+    assert_equal(mod_misisng.freq_weights.shape[0], mod_misisng.exog.shape[0])\n     assert_equal(mod_misisng.freq_weights.shape[0], 12)\n-    keep_weights = np.array([2,  4,  6,  8, 10, 11, 12, 13, 14, 15, 16, 17])\n+    keep_weights = np.array([2, 4, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17])\n     assert_equal(mod_misisng.freq_weights, keep_weights)\n \n \n@@ -1921,39 +2194,68 @@ class CheckTweedie:\n     def test_resid(self):\n         idx1 = len(self.res1.resid_response) - 1\n         idx2 = len(self.res2.resid_response) - 1\n-        assert_allclose(np.concatenate((self.res1.resid_response[:17],\n-                                        [self.res1.resid_response[idx1]])),\n-                        np.concatenate((self.res2.resid_response[:17],\n-                                        [self.res2.resid_response[idx2]])),\n-                        rtol=1e-5, atol=1e-5)\n-        assert_allclose(np.concatenate((self.res1.resid_pearson[:17],\n-                                        [self.res1.resid_pearson[idx1]])),\n-                        np.concatenate((self.res2.resid_pearson[:17],\n-                                        [self.res2.resid_pearson[idx2]])),\n-                        rtol=1e-5, atol=1e-5)\n-        assert_allclose(np.concatenate((self.res1.resid_deviance[:17],\n-                                        [self.res1.resid_deviance[idx1]])),\n-                        np.concatenate((self.res2.resid_deviance[:17],\n-                                        [self.res2.resid_deviance[idx2]])),\n-                        rtol=1e-5, atol=1e-5)\n-\n-        assert_allclose(np.concatenate((self.res1.resid_working[:17],\n-                                        [self.res1.resid_working[idx1]])),\n-                        np.concatenate((self.res2.resid_working[:17],\n-                                        [self.res2.resid_working[idx2]])),\n-                        rtol=1e-5, atol=1e-5)\n+        assert_allclose(\n+            np.concatenate(\n+                (\n+                    self.res1.resid_response[:17],\n+                    [self.res1.resid_response[idx1]],\n+                )\n+            ),\n+            np.concatenate(\n+                (\n+                    self.res2.resid_response[:17],\n+                    [self.res2.resid_response[idx2]],\n+                )\n+            ),\n+            rtol=1e-5,\n+            atol=1e-5,\n+        )\n+        assert_allclose(\n+            np.concatenate(\n+                (self.res1.resid_pearson[:17], [self.res1.resid_pearson[idx1]])\n+            ),\n+            np.concatenate(\n+                (self.res2.resid_pearson[:17], [self.res2.resid_pearson[idx2]])\n+            ),\n+            rtol=1e-5,\n+            atol=1e-5,\n+        )\n+        assert_allclose(\n+            np.concatenate(\n+                (\n+                    self.res1.resid_deviance[:17],\n+                    [self.res1.resid_deviance[idx1]],\n+                )\n+            ),\n+            np.concatenate(\n+                (\n+                    self.res2.resid_deviance[:17],\n+                    [self.res2.resid_deviance[idx2]],\n+                )\n+            ),\n+            rtol=1e-5,\n+            atol=1e-5,\n+        )\n \n+        assert_allclose(\n+            np.concatenate(\n+                (self.res1.resid_working[:17], [self.res1.resid_working[idx1]])\n+            ),\n+            np.concatenate(\n+                (self.res2.resid_working[:17], [self.res2.resid_working[idx2]])\n+            ),\n+            rtol=1e-5,\n+            atol=1e-5,\n+        )\n \n     def test_bse(self):\n         assert_allclose(self.res1.bse, self.res2.bse, atol=1e-6, rtol=1e6)\n \n     def test_params(self):\n-        assert_allclose(self.res1.params, self.res2.params, atol=1e-5,\n-                        rtol=1e-5)\n+        assert_allclose(self.res1.params, self.res2.params, atol=1e-5, rtol=1e-5)\n \n     def test_deviance(self):\n-        assert_allclose(self.res1.deviance, self.res2.deviance, atol=1e-6,\n-                        rtol=1e-6)\n+        assert_allclose(self.res1.deviance, self.res2.deviance, atol=1e-6, rtol=1e-6)\n \n     def test_df(self):\n         assert_equal(self.res1.df_model, self.res2.df_model)\n@@ -1962,11 +2264,16 @@ def test_df(self):\n     def test_fittedvalues(self):\n         idx1 = len(self.res1.fittedvalues) - 1\n         idx2 = len(self.res2.resid_response) - 1\n-        assert_allclose(np.concatenate((self.res1.fittedvalues[:17],\n-                                        [self.res1.fittedvalues[idx1]])),\n-                        np.concatenate((self.res2.fittedvalues[:17],\n-                                        [self.res2.fittedvalues[idx2]])),\n-                        atol=1e-4, rtol=1e-4)\n+        assert_allclose(\n+            np.concatenate(\n+                (self.res1.fittedvalues[:17], [self.res1.fittedvalues[idx1]])\n+            ),\n+            np.concatenate(\n+                (self.res2.fittedvalues[:17], [self.res2.fittedvalues[idx2]])\n+            ),\n+            atol=1e-4,\n+            rtol=1e-4,\n+        )\n \n     def test_summary(self):\n         self.res1.summary()\n@@ -1977,14 +2284,18 @@ class TestTweediePower15(CheckTweedie):\n     @classmethod\n     def setup_class(cls):\n         from .results.results_glm import CpunishTweediePower15\n+\n         cls.data = cpunish.load_pandas()\n-        cls.exog = cls.data.exog[['INCOME', 'SOUTH']]\n+        cls.exog = cls.data.exog[[\"INCOME\", \"SOUTH\"]]\n         cls.endog = cls.data.endog\n-        family_link = sm.families.Tweedie(link=sm.families.links.Power(1),\n-                                          var_power=1.5)\n-        cls.res1 = sm.GLM(endog=cls.data.endog,\n-                          exog=cls.data.exog[['INCOME', 'SOUTH']],\n-                          family=family_link).fit()\n+        family_link = sm.families.Tweedie(\n+            link=sm.families.links.Power(1), var_power=1.5\n+        )\n+        cls.res1 = sm.GLM(\n+            endog=cls.data.endog,\n+            exog=cls.data.exog[[\"INCOME\", \"SOUTH\"]],\n+            family=family_link,\n+        ).fit()\n         cls.res2 = CpunishTweediePower15()\n \n \n@@ -1992,14 +2303,18 @@ class TestTweediePower2(CheckTweedie):\n     @classmethod\n     def setup_class(cls):\n         from .results.results_glm import CpunishTweediePower2\n+\n         cls.data = cpunish.load_pandas()\n-        cls.exog = cls.data.exog[['INCOME', 'SOUTH']]\n+        cls.exog = cls.data.exog[[\"INCOME\", \"SOUTH\"]]\n         cls.endog = cls.data.endog\n-        family_link = sm.families.Tweedie(link=sm.families.links.Power(1),\n-                                          var_power=2.)\n-        cls.res1 = sm.GLM(endog=cls.data.endog,\n-                          exog=cls.data.exog[['INCOME', 'SOUTH']],\n-                          family=family_link).fit()\n+        family_link = sm.families.Tweedie(\n+            link=sm.families.links.Power(1), var_power=2.0\n+        )\n+        cls.res1 = sm.GLM(\n+            endog=cls.data.endog,\n+            exog=cls.data.exog[[\"INCOME\", \"SOUTH\"]],\n+            family=family_link,\n+        ).fit()\n         cls.res2 = CpunishTweediePower2()\n \n \n@@ -2007,14 +2322,16 @@ class TestTweedieLog1(CheckTweedie):\n     @classmethod\n     def setup_class(cls):\n         from .results.results_glm import CpunishTweedieLog1\n+\n         cls.data = cpunish.load_pandas()\n-        cls.exog = cls.data.exog[['INCOME', 'SOUTH']]\n+        cls.exog = cls.data.exog[[\"INCOME\", \"SOUTH\"]]\n         cls.endog = cls.data.endog\n-        family_link = sm.families.Tweedie(link=sm.families.links.Log(),\n-                                          var_power=1.)\n-        cls.res1 = sm.GLM(endog=cls.data.endog,\n-                          exog=cls.data.exog[['INCOME', 'SOUTH']],\n-                          family=family_link).fit()\n+        family_link = sm.families.Tweedie(link=sm.families.links.Log(), var_power=1.0)\n+        cls.res1 = sm.GLM(\n+            endog=cls.data.endog,\n+            exog=cls.data.exog[[\"INCOME\", \"SOUTH\"]],\n+            family=family_link,\n+        ).fit()\n         cls.res2 = CpunishTweedieLog1()\n \n \n@@ -2024,13 +2341,14 @@ def setup_class(cls):\n         from statsmodels.datasets.fair import load_pandas\n \n         from .results.results_glm import FairTweedieLog15\n+\n         data = load_pandas()\n-        family_link = sm.families.Tweedie(link=sm.families.links.Log(),\n-                                          var_power=1.5)\n-        cls.res1 = sm.GLM(endog=data.endog,\n-                          exog=data.exog[['rate_marriage', 'age',\n-                                          'yrs_married']],\n-                          family=family_link).fit()\n+        family_link = sm.families.Tweedie(link=sm.families.links.Log(), var_power=1.5)\n+        cls.res1 = sm.GLM(\n+            endog=data.endog,\n+            exog=data.exog[[\"rate_marriage\", \"age\", \"yrs_married\"]],\n+            family=family_link,\n+        ).fit()\n         cls.res2 = FairTweedieLog15()\n \n \n@@ -2039,85 +2357,117 @@ def test_mu(self):\n         assert_allclose(self.res1.mu, self.res2.mu, rtol=1e-5, atol=1e-5)\n \n     def test_resid(self):\n-        assert_allclose(self.res1.resid_response, self.res2.resid_response,\n-                        rtol=1e-5, atol=1e-5)\n-        assert_allclose(self.res1.resid_pearson, self.res2.resid_pearson,\n-                        rtol=1e-5, atol=1e-5)\n-        assert_allclose(self.res1.resid_deviance, self.res2.resid_deviance,\n-                        rtol=1e-5, atol=1e-5)\n-        assert_allclose(self.res1.resid_working, self.res2.resid_working,\n-                        rtol=1e-5, atol=1e-5)\n-        assert_allclose(self.res1.resid_anscombe_unscaled,\n-                        self.res2.resid_anscombe_unscaled,\n-                        rtol=1e-5, atol=1e-5)\n+        assert_allclose(\n+            self.res1.resid_response,\n+            self.res2.resid_response,\n+            rtol=1e-5,\n+            atol=1e-5,\n+        )\n+        assert_allclose(\n+            self.res1.resid_pearson,\n+            self.res2.resid_pearson,\n+            rtol=1e-5,\n+            atol=1e-5,\n+        )\n+        assert_allclose(\n+            self.res1.resid_deviance,\n+            self.res2.resid_deviance,\n+            rtol=1e-5,\n+            atol=1e-5,\n+        )\n+        assert_allclose(\n+            self.res1.resid_working,\n+            self.res2.resid_working,\n+            rtol=1e-5,\n+            atol=1e-5,\n+        )\n+        assert_allclose(\n+            self.res1.resid_anscombe_unscaled,\n+            self.res2.resid_anscombe_unscaled,\n+            rtol=1e-5,\n+            atol=1e-5,\n+        )\n \n \n class TestTweedieSpecialLog0(CheckTweedieSpecial):\n     @classmethod\n     def setup_class(cls):\n         cls.data = cpunish.load_pandas()\n-        cls.exog = cls.data.exog[['INCOME', 'SOUTH']]\n+        cls.exog = cls.data.exog[[\"INCOME\", \"SOUTH\"]]\n         cls.endog = cls.data.endog\n         family1 = sm.families.Gaussian(link=sm.families.links.Log())\n-        cls.res1 = sm.GLM(endog=cls.data.endog,\n-                          exog=cls.data.exog[['INCOME', 'SOUTH']],\n-                          family=family1).fit()\n-        family2 = sm.families.Tweedie(link=sm.families.links.Log(),\n-                                      var_power=0)\n-        cls.res2 = sm.GLM(endog=cls.data.endog,\n-                          exog=cls.data.exog[['INCOME', 'SOUTH']],\n-                          family=family2).fit()\n+        cls.res1 = sm.GLM(\n+            endog=cls.data.endog,\n+            exog=cls.data.exog[[\"INCOME\", \"SOUTH\"]],\n+            family=family1,\n+        ).fit()\n+        family2 = sm.families.Tweedie(link=sm.families.links.Log(), var_power=0)\n+        cls.res2 = sm.GLM(\n+            endog=cls.data.endog,\n+            exog=cls.data.exog[[\"INCOME\", \"SOUTH\"]],\n+            family=family2,\n+        ).fit()\n \n \n class TestTweedieSpecialLog1(CheckTweedieSpecial):\n     @classmethod\n     def setup_class(cls):\n         cls.data = cpunish.load_pandas()\n-        cls.exog = cls.data.exog[['INCOME', 'SOUTH']]\n+        cls.exog = cls.data.exog[[\"INCOME\", \"SOUTH\"]]\n         cls.endog = cls.data.endog\n         family1 = sm.families.Poisson(link=sm.families.links.Log())\n-        cls.res1 = sm.GLM(endog=cls.data.endog,\n-                          exog=cls.data.exog[['INCOME', 'SOUTH']],\n-                          family=family1).fit()\n-        family2 = sm.families.Tweedie(link=sm.families.links.Log(),\n-                                      var_power=1)\n-        cls.res2 = sm.GLM(endog=cls.data.endog,\n-                          exog=cls.data.exog[['INCOME', 'SOUTH']],\n-                          family=family2).fit()\n+        cls.res1 = sm.GLM(\n+            endog=cls.data.endog,\n+            exog=cls.data.exog[[\"INCOME\", \"SOUTH\"]],\n+            family=family1,\n+        ).fit()\n+        family2 = sm.families.Tweedie(link=sm.families.links.Log(), var_power=1)\n+        cls.res2 = sm.GLM(\n+            endog=cls.data.endog,\n+            exog=cls.data.exog[[\"INCOME\", \"SOUTH\"]],\n+            family=family2,\n+        ).fit()\n \n \n class TestTweedieSpecialLog2(CheckTweedieSpecial):\n     @classmethod\n     def setup_class(cls):\n         cls.data = cpunish.load_pandas()\n-        cls.exog = cls.data.exog[['INCOME', 'SOUTH']]\n+        cls.exog = cls.data.exog[[\"INCOME\", \"SOUTH\"]]\n         cls.endog = cls.data.endog\n         family1 = sm.families.Gamma(link=sm.families.links.Log())\n-        cls.res1 = sm.GLM(endog=cls.data.endog,\n-                          exog=cls.data.exog[['INCOME', 'SOUTH']],\n-                          family=family1).fit()\n-        family2 = sm.families.Tweedie(link=sm.families.links.Log(),\n-                                      var_power=2)\n-        cls.res2 = sm.GLM(endog=cls.data.endog,\n-                          exog=cls.data.exog[['INCOME', 'SOUTH']],\n-                          family=family2).fit()\n+        cls.res1 = sm.GLM(\n+            endog=cls.data.endog,\n+            exog=cls.data.exog[[\"INCOME\", \"SOUTH\"]],\n+            family=family1,\n+        ).fit()\n+        family2 = sm.families.Tweedie(link=sm.families.links.Log(), var_power=2)\n+        cls.res2 = sm.GLM(\n+            endog=cls.data.endog,\n+            exog=cls.data.exog[[\"INCOME\", \"SOUTH\"]],\n+            family=family2,\n+        ).fit()\n \n \n class TestTweedieSpecialLog3(CheckTweedieSpecial):\n     @classmethod\n     def setup_class(cls):\n         cls.data = cpunish.load_pandas()\n-        cls.exog = cls.data.exog[['INCOME', 'SOUTH']]\n+        cls.exog = cls.data.exog[[\"INCOME\", \"SOUTH\"]]\n         cls.endog = cls.data.endog\n         family1 = sm.families.InverseGaussian(link=sm.families.links.Log())\n-        cls.res1 = sm.GLM(endog=cls.data.endog,\n-                          exog=cls.data.exog[['INCOME', 'SOUTH']],\n-                          family=family1).fit()\n-        family2 = sm.families.Tweedie(link=sm.families.links.Log(),\n-                                      var_power=3)\n-        cls.res2 = sm.GLM(endog=cls.data.endog,\n-                          exog=cls.data.exog[['INCOME', 'SOUTH']],\n-                          family=family2).fit()\n+        cls.res1 = sm.GLM(\n+            endog=cls.data.endog,\n+            exog=cls.data.exog[[\"INCOME\", \"SOUTH\"]],\n+            family=family1,\n+        ).fit()\n+        family2 = sm.families.Tweedie(link=sm.families.links.Log(), var_power=3)\n+        cls.res2 = sm.GLM(\n+            endog=cls.data.endog,\n+            exog=cls.data.exog[[\"INCOME\", \"SOUTH\"]],\n+            family=family2,\n+        ).fit()\n+\n \n def gen_tweedie(p):\n \n@@ -2126,9 +2476,9 @@ def gen_tweedie(p):\n     x = np.random.normal(size=(n, 4))\n     lpr = np.dot(x, np.r_[1, -1, 0, 0.5])\n     mu = np.exp(lpr)\n-    lam = 10 * mu**(2 - p) / (2 - p)\n+    lam = 10 * mu ** (2 - p) / (2 - p)\n     alp = (2 - p) / (p - 1)\n-    bet = 10 * mu**(1 - p) / (p - 1)\n+    bet = 10 * mu ** (1 - p) / (p - 1)\n \n     # Generate Tweedie values using commpound Poisson distribution\n     y = np.empty(n)\n@@ -2138,6 +2488,7 @@ def gen_tweedie(p):\n \n     return y, x\n \n+\n @pytest.mark.filterwarnings(\"ignore:GLM ridge optimization\")\n def test_tweedie_EQL():\n     # All tests below are regression tests, but the results\n@@ -2150,9 +2501,12 @@ def test_tweedie_EQL():\n     fam = sm.families.Tweedie(var_power=p, eql=True)\n     model1 = sm.GLM(y, x, family=fam)\n     result1 = model1.fit(method=\"newton\")\n-    assert_allclose(result1.params,\n-       np.array([1.00350497, -0.99656954, 0.00802702, 0.50713209]),\n-       rtol=1e-5, atol=1e-5)\n+    assert_allclose(\n+        result1.params,\n+        np.array([1.00350497, -0.99656954, 0.00802702, 0.50713209]),\n+        rtol=1e-5,\n+        atol=1e-5,\n+    )\n \n     # Un-regularized fit using IRLS\n     model1x = sm.GLM(y, x, family=fam)\n@@ -2164,18 +2518,22 @@ def test_tweedie_EQL():\n     # TODO: The search gets trapped in an infinite oscillation, so use\n     # a slack convergence tolerance.\n     model2 = sm.GLM(y, x, family=fam)\n-    result2 = model2.fit_regularized(L1_wt=1, alpha=0.07, maxiter=200,\n-                   cnvrg_tol=0.01)\n+    result2 = model2.fit_regularized(L1_wt=1, alpha=0.07, maxiter=200, cnvrg_tol=0.01)\n \n     rtol, atol = 1e-2, 1e-4\n-    assert_allclose(result2.params,\n-        np.array([0.976831, -0.952854, 0., 0.470171]),\n-        rtol=rtol, atol=atol)\n+    assert_allclose(\n+        result2.params,\n+        np.array([0.976831, -0.952854, 0.0, 0.470171]),\n+        rtol=rtol,\n+        atol=atol,\n+    )\n \n     # Series of ridge fits using gradients\n-    ev = (np.array([1.001778, -0.99388, 0.00797, 0.506183]),\n-          np.array([0.98586638, -0.96953481, 0.00749983, 0.4975267]),\n-          np.array([0.206429, -0.164547, 0.000235, 0.102489]))\n+    ev = (\n+        np.array([1.001778, -0.99388, 0.00797, 0.506183]),\n+        np.array([0.98586638, -0.96953481, 0.00749983, 0.4975267]),\n+        np.array([0.206429, -0.164547, 0.000235, 0.102489]),\n+    )\n     for j, alpha in enumerate([0.05, 0.5, 0.7]):\n         model3 = sm.GLM(y, x, family=fam)\n         result3 = model3.fit_regularized(L1_wt=0, alpha=alpha)\n@@ -2187,11 +2545,12 @@ def test_tweedie_EQL():\n         result5 = model3.fit_regularized(L1_wt=0, alpha=alpha)\n         assert not np.allclose(result5.params, result4.params)\n \n+\n def test_tweedie_elastic_net():\n     # Check that the coefficients vanish one-by-one\n     # when using the elastic net.\n \n-    p = 1.5 # Tweedie variance exponent\n+    p = 1.5  # Tweedie variance exponent\n     y, x = gen_tweedie(p)\n \n     # Un-regularized fit using gradients\n@@ -2219,7 +2578,7 @@ def test_tweedie_EQL_poisson_limit():\n     mn = np.exp(lpr)\n     y = np.random.poisson(mn)\n \n-    for scale in 1.0, 'x2', 'dev':\n+    for scale in 1.0, \"x2\", \"dev\":\n \n         # Un-regularized fit using gradients not IRLS\n         fam = sm.families.Tweedie(var_power=1, eql=True)\n@@ -2248,7 +2607,7 @@ def test_tweedie_EQL_upper_limit():\n     mn = np.exp(lpr)\n     y = np.random.poisson(mn)\n \n-    for scale in 'x2', 'dev', 1.0:\n+    for scale in \"x2\", \"dev\", 1.0:\n \n         # Un-regularized fit using gradients not IRLS\n         fam = sm.families.Tweedie(var_power=2, eql=True)\n@@ -2281,25 +2640,43 @@ def testTweediePowerEstimate():\n     #                                 1.9), link.power=0,\n     #                         data=data,do.plot = TRUE)\n     data = cpunish.load_pandas()\n-    y = [1.00113835e+05,   6.89668315e+03,   6.15726842e+03,\n-         1.41718806e+03,   5.11776456e+02,   2.55369154e+02,\n-         1.07147443e+01,   3.56874698e+00,   4.06797842e-02,\n-         7.06996731e-05,   2.10165106e-07,   4.34276938e-08,\n-         1.56354040e-09,   0.00000000e+00,   0.00000000e+00,\n-         0.00000000e+00,   0.00000000e+00]\n-    model1 = sm.GLM(y, data.exog[['INCOME', 'SOUTH']],\n-                    family=sm.families.Tweedie(link=sm.families.links.Log(),\n-                                               var_power=1.5))\n+    y = [\n+        1.00113835e05,\n+        6.89668315e03,\n+        6.15726842e03,\n+        1.41718806e03,\n+        5.11776456e02,\n+        2.55369154e02,\n+        1.07147443e01,\n+        3.56874698e00,\n+        4.06797842e-02,\n+        7.06996731e-05,\n+        2.10165106e-07,\n+        4.34276938e-08,\n+        1.56354040e-09,\n+        0.00000000e00,\n+        0.00000000e00,\n+        0.00000000e00,\n+        0.00000000e00,\n+    ]\n+    model1 = sm.GLM(\n+        y,\n+        data.exog[[\"INCOME\", \"SOUTH\"]],\n+        family=sm.families.Tweedie(link=sm.families.links.Log(), var_power=1.5),\n+    )\n     res1 = model1.fit()\n-    model2 = sm.GLM((y - res1.mu) ** 2,\n-                    np.column_stack((np.ones(len(res1.mu)), np.log(res1.mu))),\n-                    family=sm.families.Gamma(sm.families.links.Log()))\n+    model2 = sm.GLM(\n+        (y - res1.mu) ** 2,\n+        np.column_stack((np.ones(len(res1.mu)), np.log(res1.mu))),\n+        family=sm.families.Gamma(sm.families.links.Log()),\n+    )\n     res2 = model2.fit()\n     # Sample may be too small for this...\n     # assert_allclose(res1.scale, np.exp(res2.params[0]), rtol=0.25)\n     p = model1.estimate_tweedie_power(res1.mu)\n     assert_allclose(p, res2.params[1], rtol=0.25)\n \n+\n def test_glm_lasso_6431():\n \n     # Based on issue #6431\n@@ -2329,6 +2706,7 @@ def test_glm_lasso_6431():\n                     fit = model._fit_ridge(alpha=0, start_params=None, method=method)\n                 assert_allclose(params, fit.params, atol=1e-6, rtol=1e-6)\n \n+\n class TestRegularized:\n \n     def test_regularized(self):\n@@ -2340,14 +2718,18 @@ def test_regularized(self):\n         for dtype in \"binomial\", \"poisson\":\n \n             cur_dir = os.path.dirname(os.path.abspath(__file__))\n-            data = np.loadtxt(os.path.join(cur_dir, \"results\", \"enet_%s.csv\" % dtype),\n-                              delimiter=\",\")\n+            data = np.loadtxt(\n+                os.path.join(cur_dir, \"results\", \"enet_%s.csv\" % dtype),\n+                delimiter=\",\",\n+            )\n \n             endog = data[:, 0]\n             exog = data[:, 1:]\n \n-            fam = {\"binomial\" : sm.families.Binomial,\n-                   \"poisson\" : sm.families.Poisson}[dtype]\n+            fam = {\n+                \"binomial\": sm.families.Binomial,\n+                \"poisson\": sm.families.Poisson,\n+            }[dtype]\n \n             for j in range(9):\n \n@@ -2366,7 +2748,10 @@ def test_regularized(self):\n                 # The penalized log-likelihood that we are maximizing.\n                 def plf(params):\n                     llf = model.loglike(params) / len(endog)\n-                    llf = llf - alpha * ((1 - L1_wt)*np.sum(params**2) / 2 + L1_wt*np.sum(np.abs(params)))\n+                    llf = llf - alpha * (\n+                        (1 - L1_wt) * np.sum(params**2) / 2\n+                        + L1_wt * np.sum(np.abs(params))\n+                    )\n                     return llf\n \n                 # Confirm that we are doing better than glmnet.\n@@ -2378,115 +2763,112 @@ def plf(params):\n class TestConvergence:\n     @classmethod\n     def setup_class(cls):\n-        '''\n+        \"\"\"\n         Test Binomial family with canonical logit link using star98 dataset.\n-        '''\n+        \"\"\"\n         from statsmodels.datasets.star98 import load\n+\n         data = load()\n         data.exog = add_constant(data.exog, prepend=False)\n-        cls.model = GLM(data.endog, data.exog,\n-                         family=sm.families.Binomial())\n+        cls.model = GLM(data.endog, data.exog, family=sm.families.Binomial())\n \n-    def _when_converged(self, atol=1e-8, rtol=0, tol_criterion='deviance'):\n+    def _when_converged(self, atol=1e-8, rtol=0, tol_criterion=\"deviance\"):\n         for i, dev in enumerate(self.res.fit_history[tol_criterion]):\n             orig = self.res.fit_history[tol_criterion][i]\n             new = self.res.fit_history[tol_criterion][i + 1]\n             if np.allclose(orig, new, atol=atol, rtol=rtol):\n                 return i\n-        raise ValueError('CONVERGENCE CHECK: It seems this doens\\'t converge!')\n+        raise ValueError(\"CONVERGENCE CHECK: It seems this doens't converge!\")\n \n     def test_convergence_atol_only(self):\n         atol = 1e-8\n         rtol = 0\n         self.res = self.model.fit(atol=atol, rtol=rtol)\n         expected_iterations = self._when_converged(atol=atol, rtol=rtol)\n-        actual_iterations = self.res.fit_history['iteration']\n+        actual_iterations = self.res.fit_history[\"iteration\"]\n         # Note the first value is the list is np.inf. The second value\n         # is the initial guess based off of start_params or the\n         # estimate thereof. The third value (index = 2) is the actual \"first\n         # iteration\"\n         assert_equal(expected_iterations, actual_iterations)\n-        assert_equal(len(self.res.fit_history['deviance']) - 2,\n-                     actual_iterations)\n+        assert_equal(len(self.res.fit_history[\"deviance\"]) - 2, actual_iterations)\n \n     def test_convergence_rtol_only(self):\n         atol = 0\n         rtol = 1e-8\n         self.res = self.model.fit(atol=atol, rtol=rtol)\n         expected_iterations = self._when_converged(atol=atol, rtol=rtol)\n-        actual_iterations = self.res.fit_history['iteration']\n+        actual_iterations = self.res.fit_history[\"iteration\"]\n         # Note the first value is the list is np.inf. The second value\n         # is the initial guess based off of start_params or the\n         # estimate thereof. The third value (index = 2) is the actual \"first\n         # iteration\"\n         assert_equal(expected_iterations, actual_iterations)\n-        assert_equal(len(self.res.fit_history['deviance']) - 2,\n-                     actual_iterations)\n+        assert_equal(len(self.res.fit_history[\"deviance\"]) - 2, actual_iterations)\n \n     def test_convergence_atol_rtol(self):\n         atol = 1e-8\n         rtol = 1e-8\n         self.res = self.model.fit(atol=atol, rtol=rtol)\n         expected_iterations = self._when_converged(atol=atol, rtol=rtol)\n-        actual_iterations = self.res.fit_history['iteration']\n+        actual_iterations = self.res.fit_history[\"iteration\"]\n         # Note the first value is the list is np.inf. The second value\n         # is the initial guess based off of start_params or the\n         # estimate thereof. The third value (index = 2) is the actual \"first\n         # iteration\"\n         assert_equal(expected_iterations, actual_iterations)\n-        assert_equal(len(self.res.fit_history['deviance']) - 2,\n-                     actual_iterations)\n+        assert_equal(len(self.res.fit_history[\"deviance\"]) - 2, actual_iterations)\n \n     def test_convergence_atol_only_params(self):\n         atol = 1e-8\n         rtol = 0\n-        self.res = self.model.fit(atol=atol, rtol=rtol, tol_criterion='params')\n-        expected_iterations = self._when_converged(atol=atol, rtol=rtol,\n-                                                   tol_criterion='params')\n-        actual_iterations = self.res.fit_history['iteration']\n+        self.res = self.model.fit(atol=atol, rtol=rtol, tol_criterion=\"params\")\n+        expected_iterations = self._when_converged(\n+            atol=atol, rtol=rtol, tol_criterion=\"params\"\n+        )\n+        actual_iterations = self.res.fit_history[\"iteration\"]\n         # Note the first value is the list is np.inf. The second value\n         # is the initial guess based off of start_params or the\n         # estimate thereof. The third value (index = 2) is the actual \"first\n         # iteration\"\n         assert_equal(expected_iterations, actual_iterations)\n-        assert_equal(len(self.res.fit_history['deviance']) - 2,\n-                     actual_iterations)\n+        assert_equal(len(self.res.fit_history[\"deviance\"]) - 2, actual_iterations)\n \n     def test_convergence_rtol_only_params(self):\n         atol = 0\n         rtol = 1e-8\n-        self.res = self.model.fit(atol=atol, rtol=rtol, tol_criterion='params')\n-        expected_iterations = self._when_converged(atol=atol, rtol=rtol,\n-                                                   tol_criterion='params')\n-        actual_iterations = self.res.fit_history['iteration']\n+        self.res = self.model.fit(atol=atol, rtol=rtol, tol_criterion=\"params\")\n+        expected_iterations = self._when_converged(\n+            atol=atol, rtol=rtol, tol_criterion=\"params\"\n+        )\n+        actual_iterations = self.res.fit_history[\"iteration\"]\n         # Note the first value is the list is np.inf. The second value\n         # is the initial guess based off of start_params or the\n         # estimate thereof. The third value (index = 2) is the actual \"first\n         # iteration\"\n         assert_equal(expected_iterations, actual_iterations)\n-        assert_equal(len(self.res.fit_history['deviance']) - 2,\n-                     actual_iterations)\n+        assert_equal(len(self.res.fit_history[\"deviance\"]) - 2, actual_iterations)\n \n     def test_convergence_atol_rtol_params(self):\n         atol = 1e-8\n         rtol = 1e-8\n-        self.res = self.model.fit(atol=atol, rtol=rtol, tol_criterion='params')\n-        expected_iterations = self._when_converged(atol=atol, rtol=rtol,\n-                                                   tol_criterion='params')\n-        actual_iterations = self.res.fit_history['iteration']\n+        self.res = self.model.fit(atol=atol, rtol=rtol, tol_criterion=\"params\")\n+        expected_iterations = self._when_converged(\n+            atol=atol, rtol=rtol, tol_criterion=\"params\"\n+        )\n+        actual_iterations = self.res.fit_history[\"iteration\"]\n         # Note the first value is the list is np.inf. The second value\n         # is the initial guess based off of start_params or the\n         # estimate thereof. The third value (index = 2) is the actual \"first\n         # iteration\"\n         assert_equal(expected_iterations, actual_iterations)\n-        assert_equal(len(self.res.fit_history['deviance']) - 2,\n-                     actual_iterations)\n+        assert_equal(len(self.res.fit_history[\"deviance\"]) - 2, actual_iterations)\n \n \n def test_poisson_deviance():\n     # see #3355 missing term in deviance if resid_response.sum() != 0\n     np.random.seed(123987)\n-    nobs, k_vars = 50, 3-1\n+    nobs, k_vars = 50, 3 - 1\n     x = sm.add_constant(np.random.randn(nobs, k_vars))\n \n     mu_true = np.exp(x.sum(1))\n@@ -2497,8 +2879,9 @@ def test_poisson_deviance():\n \n     d_i = res.resid_deviance\n     d = res.deviance\n-    lr = (mod.family.loglike(y, y+1e-20) -\n-          mod.family.loglike(y, res.fittedvalues)) * 2\n+    lr = (\n+        mod.family.loglike(y, y + 1e-20) - mod.family.loglike(y, res.fittedvalues)\n+    ) * 2\n \n     assert_allclose(d, (d_i**2).sum(), rtol=1e-12)\n     assert_allclose(d, lr, rtol=1e-12)\n@@ -2509,8 +2892,9 @@ def test_poisson_deviance():\n \n     d_i = res_nc.resid_deviance\n     d = res_nc.deviance\n-    lr = (mod.family.loglike(y, y+1e-20) -\n-          mod.family.loglike(y, res_nc.fittedvalues)) * 2\n+    lr = (\n+        mod.family.loglike(y, y + 1e-20) - mod.family.loglike(y, res_nc.fittedvalues)\n+    ) * 2\n \n     assert_allclose(d, (d_i**2).sum(), rtol=1e-12)\n     assert_allclose(d, lr, rtol=1e-12)\n@@ -2526,7 +2910,7 @@ def test_non_invertible_hessian_fails_summary():\n         # and warnings in summary\n         warnings.simplefilter(\"ignore\")\n         mod = sm.GLM(data.endog, data.exog, family=sm.families.Gamma())\n-        res = mod.fit(maxiter=1, method='bfgs', max_start_irls=0)\n+        res = mod.fit(maxiter=1, method=\"bfgs\", max_start_irls=0)\n         res.summary()\n \n \n@@ -2547,7 +2931,7 @@ def test_int_exog(dtype):\n     x = np.asarray([[1, 1], [1, 0]]).astype(dtype)\n     exposure = np.asarray([n1, n2])\n     mod = GLM(y, x, exposure=exposure, family=sm.families.Poisson())\n-    res = mod.fit(method='bfgs', max_start_irls=0)\n+    res = mod.fit(method=\"bfgs\", max_start_irls=0)\n     assert isinstance(res.params, np.ndarray)\n \n \n@@ -2584,9 +2968,7 @@ def test_output_exposure_null(reset_randomstate):\n     y = [np.sum(rs.poisson(x, size=e)) for x, e in zip(x0, exposure)]\n     x = add_constant(x0)\n \n-    model = GLM(\n-        endog=y, exog=x, exposure=exposure, family=sm.families.Poisson()\n-    ).fit()\n+    model = GLM(endog=y, exog=x, exposure=exposure, family=sm.families.Poisson()).fit()\n     null_model = GLM(\n         endog=y, exog=x[:, 0], exposure=exposure, family=sm.families.Poisson()\n     ).fit()\n@@ -2602,15 +2984,16 @@ def test_qaic():\n \n     # Example from documentation of R package MuMIn\n     import patsy\n+\n     ldose = np.concatenate((np.arange(6), np.arange(6)))\n-    sex = [\"M\"]*6 + [\"F\"]*6\n+    sex = [\"M\"] * 6 + [\"F\"] * 6\n     numdead = [10, 4, 9, 12, 18, 20, 0, 2, 6, 10, 12, 16]\n     df = pd.DataFrame({\"ldose\": ldose, \"sex\": sex, \"numdead\": numdead})\n     df[\"numalive\"] = 20 - df[\"numdead\"]\n     df[\"SF\"] = df[\"numdead\"]\n \n     y = df[[\"numalive\", \"numdead\"]].values\n-    x = patsy.dmatrix(\"sex*ldose\", data=df, return_type='dataframe')\n+    x = patsy.dmatrix(\"sex*ldose\", data=df, return_type=\"dataframe\")\n     m = GLM(y, x, family=sm.families.Binomial())\n     r = m.fit()\n     scale = 2.412699\n@@ -2635,9 +3018,9 @@ def test_tweedie_score():\n     mu = np.exp(lpr)\n \n     p0 = 1.5\n-    lam = 10 * mu**(2 - p0) / (2 - p0)\n+    lam = 10 * mu ** (2 - p0) / (2 - p0)\n     alp = (2 - p0) / (p0 - 1)\n-    bet = 10 * mu**(1 - p0) / (p0 - 1)\n+    bet = 10 * mu ** (1 - p0) / (p0 - 1)\n     y = np.empty(n)\n     N = np.random.poisson(lam)\n     for i in range(n):\n@@ -2646,13 +3029,13 @@ def test_tweedie_score():\n     for eql in [True, False]:\n         for p in [1, 1.5, 2]:\n             if eql is False and SP_LT_17:\n-                pytest.skip('skip, scipy too old, no bessel_wright')\n+                pytest.skip(\"skip, scipy too old, no bessel_wright\")\n \n             fam = sm.families.Tweedie(var_power=p, eql=eql)\n             model = GLM(y, x, family=fam)\n             result = model.fit()\n \n-            pa = result.params + 0.2*np.random.normal(size=result.params.size)\n+            pa = result.params + 0.2 * np.random.normal(size=result.params.size)\n \n             ngrad = approx_fprime_cs(pa, lambda x: model.loglike(x, scale=1))\n             agrad = model.score(pa, scale=1)\n@@ -2662,6 +3045,7 @@ def test_tweedie_score():\n             ahess = model.hessian(pa, scale=1)\n             assert_allclose(nhess, ahess, atol=5e-8, rtol=5e-8)\n \n+\n def test_names():\n     \"\"\"Test the name properties if using a pandas series.\n \n@@ -2699,7 +3083,15 @@ def test_names_default():\n     Don't care about the data here, only testing the name properties.\n     \"\"\"\n     y = np.array([0, 1])\n-    x = np.array([[1, 1,], [1, 0]])\n+    x = np.array(\n+        [\n+            [\n+                1,\n+                1,\n+            ],\n+            [1, 0],\n+        ]\n+    )\n     exposure = np.array([0, 0])\n     freq_weights = np.array([0, 0])\n     offset = np.array([0, 0])\n@@ -2720,3 +3112,17 @@ def test_names_default():\n     assert model.var_weights_name == \"var_weights\"\n     assert model.endog_names == \"y\"\n     assert model.exog_names == [\"const\", \"x1\"]\n+\n+\n+def test_glm_summary2_method():\n+    nobs, k_vars = 50, 4\n+    np.random.seed(987126)\n+    x = np.random.randn(nobs, k_vars - 1)\n+    exog = add_constant(x, has_constant=\"add\")\n+    y = exog.sum(1) + np.random.randn(nobs)\n+\n+    mod = GLM(y, exog)\n+    res1 = mod.fit()\n+    res_g1 = mod.fit(start_params=res1.params, method=\"bfgs\")\n+    summ = res_g1.summary2()\n+    assert re.compile(r\"Method:\\s+bfgs\").findall(str(summ))\n", "problem_statement": "FIX: summary2 changes method #9257\nOne line change:\r\nCloses #9257\n", "hints_text": "", "created_at": "2024-10-17T09:53:36Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9395, "instance_id": "statsmodels__statsmodels-9395", "issue_numbers": ["9321", "9062"], "base_commit": "746a4858c72f2a9879b324f60cb3a10ce93aeda8", "patch": "diff --git a/statsmodels/tsa/statespace/dynamic_factor_mq.py b/statsmodels/tsa/statespace/dynamic_factor_mq.py\nindex 305fb2863f1..7caac527dfe 100644\n--- a/statsmodels/tsa/statespace/dynamic_factor_mq.py\n+++ b/statsmodels/tsa/statespace/dynamic_factor_mq.py\n@@ -440,8 +440,8 @@ def __init__(self, k_endog_M, k_endog_Q, endog_names, factors,\n                           tupleize_cols=False, name='block')\n             default_block_orders = pd.Series(np.ones(len(ix), dtype=int),\n                                              index=ix, name='order')\n-            self.factor_block_orders = (\n-                self.factor_block_orders.append(default_block_orders))\n+            self.factor_block_orders = pd.concat(\n+                [self.factor_block_orders, default_block_orders])\n             factor_names = pd.Series(\n                 np.concatenate(list(self.factor_block_orders.index)))\n         duplicates = factor_names.duplicated()\n", "test_patch": "diff --git a/statsmodels/tsa/statespace/tests/test_dynamic_factor_mq.py b/statsmodels/tsa/statespace/tests/test_dynamic_factor_mq.py\nindex 683ec310215..ff6d6012af4 100644\n--- a/statsmodels/tsa/statespace/tests/test_dynamic_factor_mq.py\n+++ b/statsmodels/tsa/statespace/tests/test_dynamic_factor_mq.py\n@@ -425,6 +425,78 @@ def test_factor_order_gt1():\n     assert_allclose(mod['state_cov'], desired)\n \n \n+def test_factor_order_12():\n+    # Includes 2 monthly and 2 quarterly series\n+    # This case: factors= 2, factor_orders=(1,2), idiosyncratic_ar1=True\n+\n+    # Create the datasets\n+    index_M = pd.period_range(start='2000', periods=12, freq='M')\n+    index_Q = pd.period_range(start='2000', periods=4, freq='Q')\n+\n+    dta_M = pd.DataFrame(np.zeros((12, 2)), index=index_M,\n+                         columns=['M0', 'M1'])\n+    dta_Q = pd.DataFrame(np.zeros((4, 2)), index=index_Q, columns=['Q0', 'Q1'])\n+    # Add some noise so the variables aren't constants\n+    dta_M.iloc[0] = 1.\n+    dta_Q.iloc[1] = 1.\n+\n+    # Create the model instance\n+    mod = dynamic_factor_mq.DynamicFactorMQ(\n+        dta_M, endog_quarterly=dta_Q, factors=2, factor_orders={'0': 2},\n+        idiosyncratic_ar1=True)\n+\n+    # Test dimensions\n+    assert_equal(mod.k_endog, 2 + 2)\n+    assert_equal(mod.k_states, 5 * 2 + 2 + 2 * 5)\n+    assert_equal(mod.ssm.k_posdef, 2 + 2 + 2)\n+\n+    # Test names\n+    assert_equal(mod.endog_names, ['M0', 'M1', 'Q0', 'Q1'])\n+    desired = (['0', 'L1.0', 'L2.0', 'L3.0', 'L4.0', '1',\n+                'L1.1', 'L2.1', 'L3.1', 'L4.1'] +\n+               ['eps_M.M0', 'eps_M.M1', 'eps_Q.Q0', 'eps_Q.Q1'] +\n+               ['L1.eps_Q.Q0', 'L1.eps_Q.Q1'] +\n+               ['L2.eps_Q.Q0', 'L2.eps_Q.Q1'] +\n+               ['L3.eps_Q.Q0', 'L3.eps_Q.Q1'] +\n+               ['L4.eps_Q.Q0', 'L4.eps_Q.Q1'])\n+    assert_equal(mod.state_names, desired)\n+    desired = [\n+        'loading.0->M0', 'loading.1->M0', 'loading.0->M1', 'loading.1->M1',\n+        'loading.0->Q0', 'loading.1->Q0', 'loading.0->Q1', 'loading.1->Q1',\n+        'L1.0->0', 'L2.0->0', 'L1.1->1',\n+        'fb(0).cov.chol[1,1]', 'fb(1).cov.chol[1,1]',\n+        'L1.eps_M.M0', 'L1.eps_M.M1',\n+        'L1.eps_Q.Q0', 'L1.eps_Q.Q1',\n+        'sigma2.M0', 'sigma2.M1', 'sigma2.Q0', 'sigma2.Q1']\n+    assert_equal(mod.param_names, desired)\n+\n+    # Test fixed elements of state space representation\n+    assert_allclose(mod['obs_intercept'], 0)\n+\n+    assert_allclose(mod['design', :2, 10:12], np.eye(2))\n+    assert_allclose(mod['design', 2:, 12:14], np.eye(2))\n+    assert_allclose(mod['design', 2:, 14:16], 2 * np.eye(2))\n+    assert_allclose(mod['design', 2:, 16:18], 3 * np.eye(2))\n+    assert_allclose(mod['design', 2:, 18:20], 2 * np.eye(2))\n+    assert_allclose(mod['design', 2:, 20:22], np.eye(2))\n+    assert_allclose(np.sum(mod['design']), 20)\n+\n+    assert_allclose(mod['obs_cov'], 0)\n+    assert_allclose(mod['state_intercept'], 0)\n+\n+    assert_allclose(mod['transition', 1:5, :4], np.eye(4))\n+    assert_allclose(mod['transition', 14:22, 12:20], np.eye(2 * 4))\n+    assert_allclose(np.sum(mod['transition']), 16)\n+\n+    assert_allclose(mod['selection', :2, :2], np.array([[1, 0], [0, 0]]))\n+    assert_allclose(mod['selection', 4:6, :2], np.array([[0, 0], [0, 1]]))\n+    assert_allclose(mod['selection', 10:12, 2:4], np.eye(2))\n+    assert_allclose(mod['selection', 12:14, 4:6], np.eye(2))\n+    assert_allclose(np.sum(mod['selection']), 6)\n+\n+    assert_allclose(mod['state_cov'], 0)\n+\n+\n def test_k_factors_gt1_factor_order_gt1():\n     # Includes 2 monthly and 2 quarterly series\n     # This case: kactors=2, factor_orders=6, idiosyncratic_ar1=True\n", "problem_statement": "BUG: Replace deprecated Pandas method\n- [x] closes #9062 \r\n- [x] tests added / passed. \r\n- [x] properly formatted commit message. See \r\n      [NumPy's guide](https://docs.scipy.org/doc/numpy-1.15.1/dev/gitwash/development_workflow.html#writing-the-commit-message). \r\n\r\n- Resolves raised error when specifying factor_orders as a dictionary\r\n- Replace deprecated pandas.Series.append with pandas.concat\r\n- Add test to ensure DynamicFactorMQ handles factor_orders dictionary properly\r\n\r\n<details>\r\n\r\n\r\n**Notes**:\r\n\r\n* It is essential that you add a test when making code changes. Tests are not \r\n  needed for doc changes.\r\n* When adding a new function, test values should usually be verified in another package (e.g., R/SAS/Stata).\r\n* When fixing a bug, you must add a test that would produce the bug in main and\r\n  then show that it is fixed with the new code.\r\n* New code additions must be well formatted. Changes should pass flake8. If on Linux or OSX, you can\r\n  verify you changes are well formatted by running \r\n  ```\r\n  git diff upstream/main -u -- \"*.py\" | flake8 --diff --isolated\r\n  ```\r\n  assuming `flake8` is installed. This command is also available on Windows \r\n  using the Windows System for Linux once `flake8` is installed in the \r\n  local Linux environment. While passing this test is not required, it is good practice and it help \r\n  improve code quality in `statsmodels`.\r\n* Docstring additions must render correctly, including escapes and LaTeX.\r\n\r\n</details>\r\n\nDynamicFactorMQ is not working \nI am running [this example](https://www.chadfulton.com/topics/statespace_large_dynamic_factor_models.html) \r\n\r\nIn the past I had no problems replicating tis example. Now it seems has something changed and I get the following errors when I  try to create the DFM object: \r\n\r\n```\r\n\r\n# Construct the dynamic factor model\r\nmodel = sm.tsa.DynamicFactorMQ(\r\n    endog_m, endog_quarterly=endog_q,\r\n    factors=factors, factor_orders=factor_orders,\r\n    factor_multiplicities=factor_multiplicities)\r\n\r\n\r\n```\r\n```\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/safishajjouz/opt/anaconda3/envs/myport_management_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-55-40928c00cd95>\", line 2, in <module>\r\n    model = sm.tsa.DynamicFactorMQ(\r\n  File \"/Users/safishajjouz/opt/anaconda3/envs/myport_management_env/lib/python3.8/site-packages/statsmodels/tsa/statespace/dynamic_factor_mq.py\", line 1320, in __init__\r\n    s = self._s = DynamicFactorMQStates(\r\n  File \"/Users/safishajjouz/opt/anaconda3/envs/myport_management_env/lib/python3.8/site-packages/statsmodels/tsa/statespace/dynamic_factor_mq.py\", line 443, in __init__\r\n    self.factor_block_orders.append(default_block_orders))\r\n  File \"/Users/safishajjouz/opt/anaconda3/envs/myport_management_env/lib/python3.8/site-packages/pandas/core/generic.py\", line 5989, in __getattr__\r\n    return object.__getattribute__(self, name)\r\nAttributeError: 'Series' object has no attribute 'append'\r\n```\n", "hints_text": "\nWhich version of pandas are you using? I think it is related to Pandas>2.0 [deprecation of append() in favor of concat()](https://github.com/pandas-dev/pandas/issues/35407) \nI met the same issue with pandas 2.2.2.", "created_at": "2024-10-17T09:26:47Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9394, "instance_id": "statsmodels__statsmodels-9394", "issue_numbers": ["9325"], "base_commit": "746a4858c72f2a9879b324f60cb3a10ce93aeda8", "patch": "diff --git a/statsmodels/graphics/gofplots.py b/statsmodels/graphics/gofplots.py\nindex 4f1b0f7c8e0..647664a0608 100644\n--- a/statsmodels/graphics/gofplots.py\n+++ b/statsmodels/graphics/gofplots.py\n@@ -184,9 +184,7 @@ def __init__(\n         self.fit = fit\n \n         self._is_frozen = isinstance(dist, stats.distributions.rv_frozen)\n-        if self._is_frozen and (\n-            fit or loc != 0 or scale != 1 or distargs != ()\n-        ):\n+        if self._is_frozen and (fit or loc != 0 or scale != 1 or distargs != ()):\n             raise ValueError(\n                 \"Frozen distributions cannot be combined with fit, loc, scale\"\n                 \" or distargs.\"\n@@ -287,9 +285,7 @@ def sample_percentiles(self):\n         _check_for(self.dist, \"cdf\")\n         if self._is_frozen:\n             return self.dist.cdf(self.sorted_data)\n-        quantiles = (self.sorted_data - self.fit_params[-2]) / self.fit_params[\n-            -1\n-        ]\n+        quantiles = (self.sorted_data - self.fit_params[-2]) / self.fit_params[-1]\n         return self.dist.cdf(quantiles)\n \n     def ppplot(\n@@ -352,9 +348,7 @@ def ppplot(\n             p_x = self.theoretical_percentiles\n             ecdf_x = ECDF(other.sample_quantiles)(self.sample_quantiles)\n \n-            fig, ax = _do_plot(\n-                p_x, ecdf_x, self.dist, ax=ax, line=line, **plotkwargs\n-            )\n+            fig, ax = _do_plot(p_x, ecdf_x, self.dist, ax=ax, line=line, **plotkwargs)\n \n             if xlabel is None:\n                 xlabel = \"Probabilities of 2nd Sample\"\n@@ -690,9 +684,7 @@ def qqplot(\n     return fig\n \n \n-def qqplot_2samples(\n-    data1, data2, xlabel=None, ylabel=None, line=None, ax=None\n-):\n+def qqplot_2samples(data1, data2, xlabel=None, ylabel=None, line=None, ax=None):\n     \"\"\"\n     Q-Q Plot of two samples' quantiles.\n \n@@ -773,9 +765,7 @@ def qqplot_2samples(\n     if not isinstance(data2, ProbPlot):\n         data2 = ProbPlot(data2)\n     if data2.data.shape[0] > data1.data.shape[0]:\n-        fig = data1.qqplot(\n-            xlabel=ylabel, ylabel=xlabel, line=line, other=data2, ax=ax\n-        )\n+        fig = data1.qqplot(xlabel=xlabel, ylabel=ylabel, line=line, other=data2, ax=ax)\n     else:\n         fig = data2.qqplot(\n             xlabel=ylabel,\n@@ -992,9 +982,7 @@ def _fmt_probplot_axis(ax, dist, nobs):\n     ax.set_xlim([axis_qntls.min(), axis_qntls.max()])\n \n \n-def _do_plot(\n-    x, y, dist=None, line=None, ax=None, fmt=\"b\", step=False, **kwargs\n-):\n+def _do_plot(x, y, dist=None, line=None, ax=None, fmt=\"b\", step=False, **kwargs):\n     \"\"\"\n     Boiler plate plotting function for the `ppplot`, `qqplot`, and\n     `probplot` methods of the `ProbPlot` class\n", "test_patch": "diff --git a/statsmodels/graphics/tests/test_gofplots.py b/statsmodels/graphics/tests/test_gofplots.py\nindex a73dad05089..b8446f824c0 100644\n--- a/statsmodels/graphics/tests/test_gofplots.py\n+++ b/statsmodels/graphics/tests/test_gofplots.py\n@@ -1,3 +1,5 @@\n+from statsmodels.compat.python import PYTHON_IMPL_WASM\n+\n import numpy as np\n import numpy.testing as nptest\n from numpy.testing import assert_equal\n@@ -5,7 +7,6 @@\n from scipy import stats\n \n import statsmodels.api as sm\n-from statsmodels.compat.python import PYTHON_IMPL_WASM\n from statsmodels.graphics import gofplots\n from statsmodels.graphics.gofplots import (\n     ProbPlot,\n@@ -72,8 +73,7 @@ def test_ppplot_other_array(self, close_figures):\n     @pytest.mark.xfail(strict=True)\n     @pytest.mark.matplotlib\n     @pytest.mark.skipif(\n-        PYTHON_IMPL_WASM,\n-        reason=\"Matplotlib uses different backend in WASM/Pyodide\"\n+        PYTHON_IMPL_WASM, reason=\"Matplotlib uses different backend in WASM/Pyodide\"\n     )\n     def test_probplot_other_array(self, close_figures):\n         self.prbplt.probplot(\n@@ -104,8 +104,7 @@ def test_ppplot_other_prbplt(self, close_figures):\n     @pytest.mark.xfail(strict=True)\n     @pytest.mark.matplotlib\n     @pytest.mark.skipif(\n-        PYTHON_IMPL_WASM,\n-        reason=\"Matplotlib uses different backend in WASM/Pyodide\"\n+        PYTHON_IMPL_WASM, reason=\"Matplotlib uses different backend in WASM/Pyodide\"\n     )\n     def test_probplot_other_prbplt(self, close_figures):\n         self.prbplt.probplot(\n@@ -184,8 +183,7 @@ def test_fit_params(self):\n \n \n @pytest.mark.skipif(\n-    PYTHON_IMPL_WASM,\n-    reason=\"Matplotlib uses different backend in WASM/Pyodide\"\n+    PYTHON_IMPL_WASM, reason=\"Matplotlib uses different backend in WASM/Pyodide\"\n )\n class TestProbPlotLongelyNoFit(BaseProbplotMixin):\n     def setup_method(self):\n@@ -538,9 +536,7 @@ def test_r_fmt(self, close_figures):\n \n     @pytest.mark.matplotlib\n     def test_r_fmt_lineoptions(self, close_figures):\n-        qqline(\n-            self.ax, \"r\", x=self.x, y=self.y, fmt=self.fmt, **self.lineoptions\n-        )\n+        qqline(self.ax, \"r\", x=self.x, y=self.y, fmt=self.fmt, **self.lineoptions)\n \n     @pytest.mark.matplotlib\n     def test_s(self, close_figures):\n@@ -554,9 +550,7 @@ def test_s_fmt(self, close_figures):\n \n     @pytest.mark.matplotlib\n     def test_s_fmt_lineoptions(self, close_figures):\n-        qqline(\n-            self.ax, \"s\", x=self.x, y=self.y, fmt=self.fmt, **self.lineoptions\n-        )\n+        qqline(self.ax, \"s\", x=self.x, y=self.y, fmt=self.fmt, **self.lineoptions)\n \n     @pytest.mark.matplotlib\n     def test_q(self, close_figures):\n@@ -588,9 +582,7 @@ def setup_method(self):\n \n     def do_test(self, alpha, beta):\n         smpp = gofplots.plotting_pos(self.N, a=alpha, b=beta)\n-        sppp = stats.mstats.plotting_positions(\n-            self.data, alpha=alpha, beta=beta\n-        )\n+        sppp = stats.mstats.plotting_positions(self.data, alpha=alpha, beta=beta)\n \n         nptest.assert_array_almost_equal(smpp, sppp, decimal=5)\n \n@@ -648,9 +640,7 @@ def test_param_unpacking():\n @pytest.mark.parametrize(\"x_size\", [30, 50])\n @pytest.mark.parametrize(\"y_size\", [30, 50])\n @pytest.mark.parametrize(\"line\", [None, \"45\", \"s\", \"r\", \"q\"])\n-def test_correct_labels(\n-    close_figures, reset_randomstate, line, x_size, y_size, labels\n-):\n+def test_correct_labels(close_figures, reset_randomstate, line, x_size, y_size, labels):\n     rs = np.random.RandomState(9876554)\n     x = rs.normal(loc=0, scale=0.1, size=x_size)\n     y = rs.standard_t(3, size=y_size)\n@@ -665,8 +655,8 @@ def test_correct_labels(\n             assert \"2nd\" in x_label\n             assert \"1st\" in y_label\n         else:\n-            assert \"Y\" in x_label\n-            assert \"X\" in y_label\n+            assert \"X\" in x_label\n+            assert \"Y\" in y_label\n     else:\n         if not labels:\n             assert \"1st\" in x_label\n@@ -699,3 +689,18 @@ def test_axis_order(close_figures):\n     y_range = np.diff(ax.get_ylim())[0]\n     x_range = np.diff(ax.get_xlim())[0]\n     assert x_range < y_range\n+\n+\n+@pytest.mark.matplotlib\n+def test_qqplot_2samples_labels():\n+    try:\n+        import matplotlib.pyplot as plt\n+    except ImportError:\n+        pass\n+    data1 = np.random.normal(0, 1, 100)\n+    data2 = np.random.normal(0, 1, 100)\n+    fig = qqplot_2samples(data1, data2, xlabel=\"Sample 1\", ylabel=\"Sample 2\")\n+    ax = fig.get_axes()[0]\n+    assert ax.get_xlabel() == \"Sample 1\"\n+    assert ax.get_ylabel() == \"Sample 2\"\n+    plt.close(ax.figure)\n", "problem_statement": "Fixed the typo with x/y labels in qqplot_2samples function\n### Description\r\n\r\nFixed the typo in the `qqplot_2samples` function where x and y labels were swapped. Now, `ax.set_xlabel` sets the correct x-label, and `ax.set_ylabel` sets the correct y-label.\r\n\r\n### Related Issues\r\n\r\n- [x] closes #9293\r\n\r\n### Changes Made\r\n\r\n- Corrected the label assignment in `qqplot_2samples` function.\r\n- Added a test case to verify the correct labeling of x and y axes.\r\n\r\n### Tests Added / Passed\r\n\r\n- Added a new test case `test_qqplot_2samples_labels` in `test_gofplots.py`.\r\n- Ran all tests locally, and they all passed.\r\n\r\n### Code/Documentation is Well Formatted\r\n\r\n- Verified that the code is well formatted and adheres to `flake8` guidelines.\r\n- Checked that the docstrings render correctly, including escapes and LaTeX.\r\n\r\n### Properly Formatted Commit Message\r\n\r\n- Followed [NumPy's guide](https://docs.scipy.org/doc/numpy-1.15.1/dev/gitwash/development_workflow.html#writing-the-commit-message) for commit messages.\r\n\r\n**Notes**:\r\n\r\n* It is essential that you add a test when making code changes. Tests are not needed for doc changes.\r\n* When adding a new function, test values should usually be verified in another package (e.g., R/SAS/Stata).\r\n* When fixing a bug, you must add a test that would produce the bug in main and then show that it is fixed with the new code.\r\n* New code additions must be well formatted. Changes should pass flake8. If on Linux or OSX, you can verify you changes are well formatted by running:\r\n  ```bash\r\n  git diff upstream/main -u -- \"*.py\" | flake8 --diff --isolated\r\n\n", "hints_text": "", "created_at": "2024-10-17T09:15:10Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9390, "instance_id": "statsmodels__statsmodels-9390", "issue_numbers": ["9323"], "base_commit": "d0da572b061faf1c691b471e6ad60257b0a3ccf2", "patch": "diff --git a/statsmodels/tools/docstring.py b/statsmodels/tools/docstring.py\nindex 272aaa4c963..b7492410bfe 100644\n--- a/statsmodels/tools/docstring.py\n+++ b/statsmodels/tools/docstring.py\n@@ -638,7 +638,7 @@ def replace_block(self, block_name, block):\n         block_name = \" \".join(map(str.capitalize, block_name.split(\" \")))\n         if block_name not in self._ds:\n             raise ValueError(\n-                \"{} is not a block in the \" \"docstring\".format(block_name)\n+                \"{} is not a block in the docstring\".format(block_name)\n             )\n         if not isinstance(block, list) and isinstance(\n             self._ds[block_name], list\ndiff --git a/statsmodels/tsa/ardl/model.py b/statsmodels/tsa/ardl/model.py\nindex ac20f5a3e68..c7450ab562c 100644\n--- a/statsmodels/tsa/ardl/model.py\n+++ b/statsmodels/tsa/ardl/model.py\n@@ -4,18 +4,12 @@\n from statsmodels.compat.python import Literal\n \n from collections import defaultdict\n+from collections.abc import Hashable, Mapping, Sequence\n import datetime as dt\n from itertools import combinations, product\n import textwrap\n from types import SimpleNamespace\n-from typing import (\n-    TYPE_CHECKING,\n-    Any,\n-    NamedTuple,\n-    Optional,\n-    Union,\n-)\n-from collections.abc import Hashable, Mapping, Sequence\n+from typing import TYPE_CHECKING, Any, NamedTuple, Optional, Union\n import warnings\n \n import numpy as np\n@@ -111,14 +105,10 @@ def _check_order(order: int | Sequence[int] | None, causal: bool) -> bool:\n         return True\n     for v in order:\n         if not isinstance(v, (int, np.integer)):\n-            raise TypeError(\n-                \"sequence orders must contain non-negative integer values\"\n-            )\n+            raise TypeError(\"sequence orders must contain non-negative integer values\")\n     order = [int(v) for v in order]\n     if len(set(order)) != len(order) or min(order) < 0:\n-        raise ValueError(\n-            \"sequence orders must contain distinct non-negative values\"\n-        )\n+        raise ValueError(\"sequence orders must contain distinct non-negative values\")\n     if int(causal) and min(order) < 1:\n         raise ValueError(\n             \"sequence orders must be strictly positive when causal is True\"\n@@ -362,9 +352,7 @@ def __init__(\n             if isinstance(fixed, pd.DataFrame):\n                 self._fixed_names = list(fixed.columns)\n             else:\n-                self._fixed_names = [\n-                    f\"z.{i}\" for i in range(fixed_arr.shape[1])\n-                ]\n+                self._fixed_names = [f\"z.{i}\" for i in range(fixed_arr.shape[1])]\n             self._fixed = fixed_arr\n         else:\n             self._fixed = np.empty((self.data.endog.shape[0], 0))\n@@ -463,9 +451,7 @@ def _fit(\n         if self._x.shape[1] == 0:\n             return np.empty((0,)), np.empty((0, 0)), np.empty((0, 0))\n         ols_mod = OLS(self._y, self._x)\n-        ols_res = ols_mod.fit(\n-            cov_type=cov_type, cov_kwds=cov_kwds, use_t=use_t\n-        )\n+        ols_res = ols_mod.fit(cov_type=cov_type, cov_kwds=cov_kwds, use_t=use_t)\n         cov_params = ols_res.cov_params()\n         use_t = ols_res.use_t\n         if cov_type == \"nonrobust\" and not use_t:\n@@ -542,9 +528,7 @@ def fit(\n         params, cov_params, norm_cov_params = self._fit(\n             cov_type=cov_type, cov_kwds=cov_kwds, use_t=use_t\n         )\n-        res = ARDLResults(\n-            self, params, cov_params, norm_cov_params, use_t=use_t\n-        )\n+        res = ARDLResults(self, params, cov_params, norm_cov_params, use_t=use_t)\n         return ARDLResultsWrapper(res)\n \n     def _construct_regressors(\n@@ -553,9 +537,7 @@ def _construct_regressors(\n         \"\"\"Construct and format model regressors\"\"\"\n         # TODO: Missing adjustment\n         self._maxlag = max(self._lags) if self._lags else 0\n-        _endog_reg, _endog = lagmat(\n-            self.data.endog, self._maxlag, original=\"sep\"\n-        )\n+        _endog_reg, _endog = lagmat(self.data.endog, self._maxlag, original=\"sep\")\n         assert isinstance(_endog, np.ndarray)\n         assert isinstance(_endog_reg, np.ndarray)\n         self._endog_reg, self._endog = _endog_reg, _endog\n@@ -649,9 +631,7 @@ def pad_x(x: np.ndarray, pad: int) -> np.ndarray:\n \n         if (end + 1) < self.endog.shape[0] and exog is None and fixed is None:\n             adjusted_start = max(start - self._hold_back, 0)\n-            return pad_x(\n-                self._x[adjusted_start : end + 1 - self._hold_back], pad\n-            )\n+            return pad_x(self._x[adjusted_start : end + 1 - self._hold_back], pad)\n \n         # If anything changed, rebuild x array\n         exog = self.data.exog if exog is None else np.asarray(exog)\n@@ -757,8 +737,7 @@ def check_exog(arr, name, orig, exact):\n                     )\n                 if sorted(arr.columns) != sorted(self.data.orig_exog.columns):\n                     raise ValueError(\n-                        f\"{name} must have the same columns as the original \"\n-                        \"exog\"\n+                        f\"{name} must have the same columns as the original exog\"\n                     )\n             else:\n                 arr = array_like(arr, name, ndim=2, optional=False)\n@@ -778,9 +757,7 @@ def check_exog(arr, name, orig, exact):\n         if exog is not None:\n             exog = check_exog(exog, \"exog\", self.data.orig_exog, True)\n         if exog_oos is not None:\n-            exog_oos = check_exog(\n-                exog_oos, \"exog_oos\", self.data.orig_exog, False\n-            )\n+            exog_oos = check_exog(exog_oos, \"exog_oos\", self.data.orig_exog, False)\n         if fixed is not None:\n             fixed = check_exog(fixed, \"fixed\", self._fixed, True)\n         if fixed_oos is not None:\n@@ -824,12 +801,8 @@ def check_exog(arr, name, orig, exact):\n         if self.exog is not None and exog_oos is None and num_oos:\n             exog_oos = np.full((num_oos, self.exog.shape[1]), np.nan)\n             if isinstance(self.data.orig_exog, pd.DataFrame):\n-                exog_oos = pd.DataFrame(\n-                    exog_oos, columns=self.data.orig_exog.columns\n-                )\n-        x = self._forecasting_x(\n-            start, end, num_oos, exog, exog_oos, fixed, fixed_oos\n-        )\n+                exog_oos = pd.DataFrame(exog_oos, columns=self.data.orig_exog.columns)\n+        x = self._forecasting_x(start, end, num_oos, exog, exog_oos, fixed, fixed_oos)\n         if dynamic is False:\n             dynamic_start = end + 1 - start\n         else:\n@@ -1018,9 +991,7 @@ def __init__(\n         scale: float = 1.0,\n         use_t: bool = False,\n     ):\n-        super().__init__(\n-            model, params, normalized_cov_params, scale, use_t=use_t\n-        )\n+        super().__init__(model, params, normalized_cov_params, scale, use_t=use_t)\n         self._cache = {}\n         self._params = params\n         self._nobs = model.nobs\n@@ -1301,9 +1272,7 @@ def summary(self, alpha: float = 0.05) -> Summary:\n         ]\n \n         smry = Summary()\n-        smry.add_table_2cols(\n-            self, gleft=top_left, gright=top_right, title=title\n-        )\n+        smry.add_table_2cols(self, gleft=top_left, gright=top_right, title=title)\n         smry.add_table_params(self, alpha=alpha, use_t=False)\n \n         return smry\n@@ -1337,15 +1306,11 @@ def __init__(self, model, ics, trend, seasonal, period):\n         def _to_dict(d):\n             return d[0], dict(d[1:])\n \n-        self._aic = pd.Series(\n-            {v[0]: _to_dict(k) for k, v in ics.items()}, dtype=object\n-        )\n+        self._aic = pd.Series({v[0]: _to_dict(k) for k, v in ics.items()}, dtype=object)\n         self._aic.index.name = self._aic.name = \"AIC\"\n         self._aic = self._aic.sort_index()\n \n-        self._bic = pd.Series(\n-            {v[1]: _to_dict(k) for k, v in ics.items()}, dtype=object\n-        )\n+        self._bic = pd.Series({v[1]: _to_dict(k) for k, v in ics.items()}, dtype=object)\n         self._bic.index.name = self._bic.name = \"BIC\"\n         self._bic = self._bic.sort_index()\n \n@@ -1789,9 +1754,7 @@ def _check_order(self, order: _ARDLOrder):\n         if isinstance(order, Mapping):\n             for k, v in order.items():\n                 if not isinstance(v, _INT_TYPES) and v is not None:\n-                    raise TypeError(\n-                        \"order values must be positive integers or None\"\n-                    )\n+                    raise TypeError(\"order values must be positive integers or None\")\n         elif not (isinstance(order, _INT_TYPES) or order is None):\n             raise TypeError(\n                 \"order must be None, a positive integer, or a dict \"\n@@ -1800,9 +1763,7 @@ def _check_order(self, order: _ARDLOrder):\n         # TODO: Check order is >= 1\n         order = super()._check_order(order)\n         if not order:\n-            raise ValueError(\n-                \"Model must contain at least one exogenous variable\"\n-            )\n+            raise ValueError(\"Model must contain at least one exogenous variable\")\n         for key, val in order.items():\n             if val == [0]:\n                 raise ValueError(\n@@ -1935,15 +1896,11 @@ def fit(\n         params, cov_params, norm_cov_params = self._fit(\n             cov_type=cov_type, cov_kwds=cov_kwds, use_t=use_t\n         )\n-        res = UECMResults(\n-            self, params, cov_params, norm_cov_params, use_t=use_t\n-        )\n+        res = UECMResults(self, params, cov_params, norm_cov_params, use_t=use_t)\n         return UECMResultsWrapper(res)\n \n     @classmethod\n-    def from_ardl(\n-        cls, ardl: ARDL, missing: Literal[\"none\", \"drop\", \"raise\"] = \"none\"\n-    ):\n+    def from_ardl(cls, ardl: ARDL, missing: Literal[\"none\", \"drop\", \"raise\"] = \"none\"):\n         \"\"\"\n         Construct a UECM from an ARDL model\n \n@@ -2068,9 +2025,7 @@ def predict(\n             params, exog, exog_oos, start, end\n         )\n         if num_oos != 0:\n-            raise NotImplementedError(\n-                \"Out-of-sample forecasts are not supported\"\n-            )\n+            raise NotImplementedError(\"Out-of-sample forecasts are not supported\")\n         pred = np.full(self.endog.shape[0], np.nan)\n         pred[-self._x.shape[0] :] = self._x @ params\n         return pred[start : end + 1]\n@@ -2144,6 +2099,14 @@ def _ci_wrap(\n             return pd.DataFrame(val, columns=lbls, index=lbls)\n         return pd.Series(val, index=lbls, name=name)\n \n+    @cache_readonly\n+    def resid(self):\n+        \"\"\"\n+        The residuals of the model.\n+        \"\"\"\n+        model = self.model\n+        return model._y - self.fittedvalues\n+\n     @cache_readonly\n     def ci_params(self) -> np.ndarray | pd.Series:\n         \"\"\"Parameters of normalized cointegrating relationship\"\"\"\n@@ -2272,11 +2235,9 @@ def bounds_test(\n         use_t: bool = True,\n         asymptotic: bool = True,\n         nsim: int = 100_000,\n-        seed: int\n-        | Sequence[int]\n-        | np.random.RandomState\n-        | np.random.Generator\n-        | None = None,\n+        seed: (\n+            int | Sequence[int] | np.random.RandomState | np.random.Generator | None\n+        ) = None,\n     ):\n         r\"\"\"\n         Cointegration bounds test of Pesaran, Shin, and Smith\n@@ -2461,11 +2422,7 @@ def _pss_simulate(\n     case: Literal[1, 2, 3, 4, 5],\n     nobs: int,\n     nsim: int,\n-    seed: int\n-    | Sequence[int]\n-    | np.random.RandomState\n-    | np.random.Generator\n-    | None,\n+    seed: int | Sequence[int] | np.random.RandomState | np.random.Generator | None,\n ) -> tuple[pd.DataFrame, pd.Series]:\n     rs: np.random.RandomState | np.random.Generator\n     if not isinstance(seed, np.random.RandomState):\ndiff --git a/statsmodels/tsa/arima_process.py b/statsmodels/tsa/arima_process.py\nindex 912ea65943d..b1ed1d641af 100644\n--- a/statsmodels/tsa/arima_process.py\n+++ b/statsmodels/tsa/arima_process.py\n@@ -307,7 +307,7 @@ def arma_periodogram(ar, ma, worN=None, whole=0):\n         import warnings\n \n         warnings.warn(\n-            \"Warning: nan in frequency response h, maybe a unit \" \"root\",\n+            \"Warning: nan in frequency response h, maybe a unit root\",\n             RuntimeWarning,\n             stacklevel=2,\n         )\ndiff --git a/statsmodels/tsa/stattools.py b/statsmodels/tsa/stattools.py\nindex fc7fb0433e4..f9a840ad864 100644\n--- a/statsmodels/tsa/stattools.py\n+++ b/statsmodels/tsa/stattools.py\n@@ -379,7 +379,7 @@ def adfuller(\n         resstore.critvalues = critvalues\n         resstore.nobs = nobs\n         resstore.H0 = (\n-            \"The coefficient on the lagged level equals 1 - \" \"unit root\"\n+            \"The coefficient on the lagged level equals 1 - unit root\"\n         )\n         resstore.HA = \"The coefficient on the lagged level < 1 - stationary\"\n         resstore.icbest = icbest\ndiff --git a/tools/nbgenerate.py b/tools/nbgenerate.py\nindex be74e18a7ab..a3a6da031de 100755\n--- a/tools/nbgenerate.py\n+++ b/tools/nbgenerate.py\n@@ -320,7 +320,7 @@ def find_kernel_name():\n     \"--fail-on-error\",\n     dest=\"error_fail\",\n     action=\"store_true\",\n-    help=\"Fail when an error occurs when executing a cell \" \"in a notebook.\",\n+    help=\"Fail when an error occurs when executing a cell in a notebook.\",\n )\n parser.add_argument(\n     \"--skip-existing\",\n", "test_patch": "diff --git a/statsmodels/tsa/ardl/tests/test_ardl.py b/statsmodels/tsa/ardl/tests/test_ardl.py\nindex ea2d636309c..a5bf6bad1f7 100644\n--- a/statsmodels/tsa/ardl/tests/test_ardl.py\n+++ b/statsmodels/tsa/ardl/tests/test_ardl.py\n@@ -159,9 +159,7 @@ def _convert_to_numpy(data, fixed, order, seasonal, use_numpy):\n def test_model_init(\n     data: Dataset, lags, order, trend, causal, fixed, use_numpy, seasonal\n ):\n-    y, x, z, order, period = _convert_to_numpy(\n-        data, fixed, order, seasonal, use_numpy\n-    )\n+    y, x, z, order, period = _convert_to_numpy(data, fixed, order, seasonal, use_numpy)\n \n     mod = ARDL(\n         y,\n@@ -194,23 +192,15 @@ def test_model_init(\n def test_ardl_order_exceptions(data):\n     with pytest.raises(ValueError, match=\"lags must be a non-negative\"):\n         ARDL(data.y, -1)\n-    with pytest.raises(\n-        ValueError, match=\"All values in lags must be positive\"\n-    ):\n+    with pytest.raises(ValueError, match=\"All values in lags must be positive\"):\n         ARDL(data.y, [-1, 0, 2])\n     with pytest.raises(ValueError, match=\"integer orders must be at least\"):\n         ARDL(data.y, 2, data.x, order=0, causal=True)\n     with pytest.raises(ValueError, match=\"integer orders must be at least\"):\n         ARDL(data.y, 2, data.x, -1, causal=False)\n-    with pytest.raises(\n-        ValueError, match=\"sequence orders must be strictly positive\"\n-    ):\n-        ARDL(\n-            data.y, 2, data.x, {\"lry\": [0, 1], \"ibo\": 3, \"ide\": 0}, causal=True\n-        )\n-    with pytest.raises(\n-        TypeError, match=\"sequence orders must contain non-negative\"\n-    ):\n+    with pytest.raises(ValueError, match=\"sequence orders must be strictly positive\"):\n+        ARDL(data.y, 2, data.x, {\"lry\": [0, 1], \"ibo\": 3, \"ide\": 0}, causal=True)\n+    with pytest.raises(TypeError, match=\"sequence orders must contain non-negative\"):\n         ARDL(\n             data.y,\n             2,\n@@ -218,9 +208,7 @@ def test_ardl_order_exceptions(data):\n             {\"lry\": [1, \"apple\"], \"ibo\": 3, \"ide\": 1},\n             causal=True,\n         )\n-    with pytest.raises(\n-        ValueError, match=\"sequence orders must contain distinct\"\n-    ):\n+    with pytest.raises(ValueError, match=\"sequence orders must contain distinct\"):\n         ARDL(\n             data.y,\n             2,\n@@ -228,9 +216,7 @@ def test_ardl_order_exceptions(data):\n             {\"lry\": [1, 1, 2, 3], \"ibo\": 3, \"ide\": [1, 1, 1]},\n             causal=True,\n         )\n-    with pytest.raises(\n-        ValueError, match=\"sequence orders must be strictly positive\"\n-    ):\n+    with pytest.raises(ValueError, match=\"sequence orders must be strictly positive\"):\n         ARDL(data.y, 2, data.x, [0, 1, 2], causal=True)\n \n \n@@ -245,21 +231,15 @@ def test_ardl_order_keys_exceptions(data):\n             {\"lry\": [1, 2], \"ibo\": 3, \"other\": 4},\n             causal=False,\n         )\n-    with pytest.warns(\n-        SpecificationWarning, match=\"exog contains variables that\"\n-    ):\n+    with pytest.warns(SpecificationWarning, match=\"exog contains variables that\"):\n         ARDL(data.y, 2, data.x, {\"lry\": [1, 2]}, causal=False)\n \n \n def test_ardl_deterministic_exceptions(data):\n     with pytest.raises(TypeError):\n         ARDL(data.y, 2, data.x, 2, deterministic=\"seasonal\")\n-    with pytest.warns(\n-        SpecificationWarning, match=\"When using deterministic, trend\"\n-    ):\n-        deterministic = DeterministicProcess(\n-            data.y.index, constant=True, order=1\n-        )\n+    with pytest.warns(SpecificationWarning, match=\"When using deterministic, trend\"):\n+        deterministic = DeterministicProcess(data.y.index, constant=True, order=1)\n         ARDL(data.y, 2, data.x, 2, deterministic=deterministic, trend=\"ct\")\n \n \n@@ -335,9 +315,7 @@ def test_ardl_only_y_lag(data):\n \n \n def test_ardl_only_x(data):\n-    res = ARDL(\n-        data.y, None, data.x, {\"lry\": 1, \"ibo\": 2, \"ide\": 3}, trend=\"n\"\n-    ).fit()\n+    res = ARDL(data.y, None, data.x, {\"lry\": 1, \"ibo\": 2, \"ide\": 3}, trend=\"n\").fit()\n     assert res.params.shape[0] == 9\n     res = ARDL(\n         data.y,\n@@ -365,9 +343,7 @@ def test_ardl_only_seasonal(data):\n \n def test_ardl_only_deterministic(data):\n     deterministic = DeterministicProcess(data.y.index, constant=True, order=3)\n-    res = ARDL(\n-        data.y, None, data.x, None, trend=\"n\", deterministic=deterministic\n-    ).fit()\n+    res = ARDL(data.y, None, data.x, None, trend=\"n\", deterministic=deterministic).fit()\n     assert res.params.shape[0] == 4\n     check_results(res)\n \n@@ -398,9 +374,7 @@ def test_ardl_parameter_names(data):\n         \"ide.L2\",\n     ]\n     assert mod.exog_names == expected\n-    mod = ARDL(\n-        np.asarray(data.y), 2, np.asarray(data.x), 2, causal=False, trend=\"ct\"\n-    )\n+    mod = ARDL(np.asarray(data.y), 2, np.asarray(data.x), 2, causal=False, trend=\"ct\")\n     expected = [\n         \"const\",\n         \"trend\",\n@@ -472,9 +446,7 @@ def test_against_autoreg(data, trend, seasonal):\n @pytest.mark.parametrize(\"start\", [None, 0, 2, 4])\n @pytest.mark.parametrize(\"end\", [None, 20])\n @pytest.mark.parametrize(\"dynamic\", [20, True])\n-def test_against_autoreg_predict_start_end(\n-    data, trend, seasonal, start, end, dynamic\n-):\n+def test_against_autoreg_predict_start_end(data, trend, seasonal, start, end, dynamic):\n     ar = AutoReg(data.y, 3, trend=trend, seasonal=seasonal)\n     ardl = ARDL(data.y, 3, trend=trend, seasonal=seasonal)\n     ar_res = ar.fit()\n@@ -489,13 +461,9 @@ def test_against_autoreg_predict_start_end(\n def test_invalid_init(data):\n     with pytest.raises(ValueError, match=\"lags must be a non-negative\"):\n         ARDL(data.y, -1)\n-    with pytest.raises(\n-        ValueError, match=\"All values in lags must be positive\"\n-    ):\n+    with pytest.raises(ValueError, match=\"All values in lags must be positive\"):\n         ARDL(data.y, [-1, 1, 2])\n-    with pytest.raises(\n-        ValueError, match=\"All values in lags must be positive\"\n-    ):\n+    with pytest.raises(ValueError, match=\"All values in lags must be positive\"):\n         ARDL(data.y, [1, 2, 2, 3])\n     with pytest.raises(ValueError, match=\"hold_back must be \"):\n         ARDL(data.y, 3, data.x, 4, hold_back=3)\n@@ -517,9 +485,7 @@ def test_prediction_exceptions(data, fixed, use_numpy):\n         res.forecast(1)\n     if isinstance(x, pd.DataFrame):\n         exog_oos = np.asarray(data.x)[:12]\n-        with pytest.raises(\n-            TypeError, match=\"exog_oos must be a DataFrame when\"\n-        ):\n+        with pytest.raises(TypeError, match=\"exog_oos must be a DataFrame when\"):\n             res.forecast(12, exog=exog_oos)\n         with pytest.raises(ValueError, match=\"must have the same columns\"):\n             res.forecast(12, exog=data.x.iloc[:12, :1])\n@@ -544,16 +510,12 @@ def test_prediction_wrong_shape(data):\n     res = ARDL(data.y, 4, x, [1, 3]).fit()\n     with pytest.raises(ValueError, match=\"exog must have the same number\"):\n         res.predict(exog=np.asarray(data.x)[:, :1])\n-    with pytest.raises(\n-        ValueError, match=\"exog must have the same number of rows\"\n-    ):\n+    with pytest.raises(ValueError, match=\"exog must have the same number of rows\"):\n         res.predict(exog=np.asarray(data.x)[:-2])\n     res = ARDL(data.y, 4, data.x, [1, 3]).fit()\n     with pytest.raises(ValueError, match=\"exog must have the same columns\"):\n         res.predict(exog=data.x.iloc[:, :1])\n-    with pytest.raises(\n-        ValueError, match=\"exog must have the same number of rows\"\n-    ):\n+    with pytest.raises(ValueError, match=\"exog must have the same number of rows\"):\n         res.predict(exog=data.x.iloc[:-2])\n \n \n@@ -562,16 +524,12 @@ def test_prediction_wrong_shape_fixed(data):\n     res = ARDL(data.y, 4, fixed=x).fit()\n     with pytest.raises(ValueError, match=\"fixed must have the same number\"):\n         res.predict(fixed=np.asarray(data.x)[:, :1])\n-    with pytest.raises(\n-        ValueError, match=\"fixed must have the same number of rows\"\n-    ):\n+    with pytest.raises(ValueError, match=\"fixed must have the same number of rows\"):\n         res.predict(fixed=np.asarray(data.x)[:-2])\n     res = ARDL(data.y, 4, fixed=data.x).fit()\n     with pytest.raises(ValueError, match=\"fixed must have the same number\"):\n         res.predict(fixed=data.x.iloc[:, :1])\n-    with pytest.raises(\n-        ValueError, match=\"fixed must have the same number of rows\"\n-    ):\n+    with pytest.raises(ValueError, match=\"fixed must have the same number of rows\"):\n         res.predict(fixed=data.x.iloc[:-2])\n \n \n@@ -682,9 +640,7 @@ def test_uecm_model_init(\n \n def test_from_ardl_none(data):\n     with pytest.warns(SpecificationWarning):\n-        mod = UECM.from_ardl(\n-            ARDL(data.y, 2, data.x, {\"lry\": 2, \"ide\": 2, \"ibo\": None})\n-        )\n+        mod = UECM.from_ardl(ARDL(data.y, 2, data.x, {\"lry\": 2, \"ide\": 2, \"ibo\": None}))\n     assert mod.ardl_order == (2, 2, 2)\n \n \n@@ -825,9 +781,7 @@ def test_bounds_test_seed(seed):\n         {\"lry\": 1, \"ibo\": 3, \"ide\": 2},\n     )\n     res = mod.fit()\n-    bounds_result = res.bounds_test(\n-        case=3, asymptotic=False, seed=seed, nsim=10_000\n-    )\n+    bounds_result = res.bounds_test(case=3, asymptotic=False, seed=seed, nsim=10_000)\n     assert (bounds_result.p_values >= 0.0).all()\n     assert (bounds_result.p_values <= 1.0).all()\n     assert (bounds_result.crit_vals > 0.0).all().all()\n@@ -848,3 +802,22 @@ def test_bounds_test_simulate_order():\n     )\n     assert_allclose(bounds_result.stat, bounds_result_sim.stat)\n     assert (bounds_result_sim.p_values > bounds_result.p_values).all()\n+\n+\n+def test_resids_ardl_uecm():\n+    ardl_mod = ARDL(\n+        dane_data.lrm,\n+        3,\n+        dane_data[[\"lry\", \"ibo\", \"ide\"]],\n+        {\"lry\": 1, \"ibo\": 3, \"ide\": 2},\n+    )\n+    ardl_res = ardl_mod.fit()\n+    uecm_mod = UECM(\n+        dane_data.lrm,\n+        3,\n+        dane_data[[\"lry\", \"ibo\", \"ide\"]],\n+        {\"lry\": 1, \"ibo\": 3, \"ide\": 2},\n+    )\n+    uecm_res = uecm_mod.fit()\n+\n+    assert_allclose(uecm_res.resid, ardl_res.resid)\ndiff --git a/statsmodels/tsa/vector_ar/tests/test_var_jmulti.py b/statsmodels/tsa/vector_ar/tests/test_var_jmulti.py\nindex db9d010be59..1bf647f5166 100644\n--- a/statsmodels/tsa/vector_ar/tests/test_var_jmulti.py\n+++ b/statsmodels/tsa/vector_ar/tests/test_var_jmulti.py\n@@ -625,7 +625,7 @@ def test_whiteness():\n             obtained = results_sm[ds][dt].test_whiteness(nlags=lags)\n             # test statistic\n             err_msg = build_err_msg(\n-                ds, dt, \"WHITENESS OF RESIDUALS - \" \"TEST STATISTIC\"\n+                ds, dt, \"WHITENESS OF RESIDUALS - TEST STATISTIC\"\n             )\n             desired = results_ref[ds][dt][\"whiteness\"][\"test statistic\"]\n             assert_allclose(\n@@ -633,7 +633,7 @@ def test_whiteness():\n             )\n             # p-value\n             err_msg = build_err_msg(\n-                ds, dt, \"WHITENESS OF RESIDUALS - \" \"P-VALUE\"\n+                ds, dt, \"WHITENESS OF RESIDUALS - P-VALUE\"\n             )\n             desired = results_ref[ds][dt][\"whiteness\"][\"p-value\"]\n             assert_allclose(\n@@ -647,7 +647,7 @@ def test_whiteness():\n             err_msg = build_err_msg(\n                 ds,\n                 dt,\n-                \"WHITENESS OF RESIDUALS - \" \"TEST STATISTIC (ADJUSTED TEST)\",\n+                \"WHITENESS OF RESIDUALS - TEST STATISTIC (ADJUSTED TEST)\",\n             )\n             desired = results_ref[ds][dt][\"whiteness\"][\"test statistic adj.\"]\n             assert_allclose(\n@@ -655,7 +655,7 @@ def test_whiteness():\n             )\n             # p-value (adjusted Portmanteau test)\n             err_msg = build_err_msg(\n-                ds, dt, \"WHITENESS OF RESIDUALS - \" \"P-VALUE (ADJUSTED TEST)\"\n+                ds, dt, \"WHITENESS OF RESIDUALS - P-VALUE (ADJUSTED TEST)\"\n             )\n             desired = results_ref[ds][dt][\"whiteness\"][\"p-value adjusted\"]\n             assert_allclose(\ndiff --git a/statsmodels/tsa/vector_ar/tests/test_vecm.py b/statsmodels/tsa/vector_ar/tests/test_vecm.py\nindex 4341369d218..345bde50050 100644\n--- a/statsmodels/tsa/vector_ar/tests/test_vecm.py\n+++ b/statsmodels/tsa/vector_ar/tests/test_vecm.py\n@@ -1681,7 +1681,7 @@ def test_whiteness():\n             )\n             # test statistic\n             err_msg = build_err_msg(\n-                ds, dt, \"WHITENESS OF RESIDUALS - \" \"TEST STATISTIC\"\n+                ds, dt, \"WHITENESS OF RESIDUALS - TEST STATISTIC\"\n             )\n             desired = results_ref[ds][dt][\"whiteness\"][\"test statistic\"]\n             assert_allclose(\n@@ -1701,7 +1701,7 @@ def test_whiteness():\n                 )\n             # p-value\n             err_msg = build_err_msg(\n-                ds, dt, \"WHITENESS OF RESIDUALS - \" \"P-VALUE\"\n+                ds, dt, \"WHITENESS OF RESIDUALS - P-VALUE\"\n             )\n             desired = results_ref[ds][dt][\"whiteness\"][\"p-value\"]\n             assert_allclose(\n@@ -1721,7 +1721,7 @@ def test_whiteness():\n             err_msg = build_err_msg(\n                 ds,\n                 dt,\n-                \"WHITENESS OF RESIDUALS - \" \"TEST STATISTIC (ADJUSTED TEST)\",\n+                \"WHITENESS OF RESIDUALS - TEST STATISTIC (ADJUSTED TEST)\",\n             )\n             desired = results_ref[ds][dt][\"whiteness\"][\"test statistic adj.\"]\n             assert_allclose(\n@@ -1741,7 +1741,7 @@ def test_whiteness():\n                 )\n             # p-value (adjusted Portmanteau test)\n             err_msg = build_err_msg(\n-                ds, dt, \"WHITENESS OF RESIDUALS - \" \"P-VALUE (ADJUSTED TEST)\"\n+                ds, dt, \"WHITENESS OF RESIDUALS - P-VALUE (ADJUSTED TEST)\"\n             )\n             desired = results_ref[ds][dt][\"whiteness\"][\"p-value adjusted\"]\n             assert_allclose(\n", "problem_statement": "BUG: UECM.from_ardl residuals\n#### Describe the bug\r\n\r\nWhen using statsmodels.tsa.ardl.UECM.from_ardl, the residuals method of the resulting UECM subtracts the fitted values of the UECM (i.e., in differences) from the endogenous value of the ARDL (i.e., in levels). This flows through into the methods for testing residuals (serial correlation, etc.).\r\n\r\nAs a stop-gap, users can perform tests on the residuals from the ARDL. The UECM should have the same residuals as the equivalent ARDL, since no transformation is made to the residuals in deriving the UECM from the ARDL.\r\n\r\n#### Code Sample, a copy-pastable example if possible\r\n\r\n\r\n```python\r\nimport statsmodels.api as sm\r\nimport pandas as pd\r\nimport numpy as np\r\nimport matplotlib as mp\r\n\r\n# simulate cointegrated series\r\nw = [1,-1]\r\nN = 100\r\nS = np.ones([N,len(w)])*2000\r\nkappa = 20\r\nsigma = 20\r\ndt = 1/N\r\ncorr = 0.6\r\nC = np.ones([len(w),len(w)])*corr+(1-corr)*np.eye(len(w))\r\nfor t in range(1,N):\r\n    eps = np.random.multivariate_normal([0]*len(w),C)\r\n    for i in range(len(w)):\r\n        si = 0\r\n        for j in range(len(w)):\r\n            si += w[j]/w[i]*S[t-1,j]\r\n        S[t,i] = S[t-1,i] - kappa*dt*si + sigma**2*np.sqrt(dt)*eps[i]\r\n        \r\nmp.pyplot.plot(S)\r\nmp.pyplot.show()\r\n\r\n# fit ardl and uecm\r\nardl = sm.tsa.ARDL(S[:,[0]], 1, S[:,[1]], 1)\r\nardlfit = ardl.fit()\r\nuecm = sm.tsa.UECM.from_ardl(ardl)\r\nuecmfit = uecm.fit()\r\n\r\n# observed\r\nuecmfit.resid\r\n\r\n# expected\r\nardlfit.resid\r\n\r\n# check equality of UECM endog variable and observation in levels\r\nS[:,0].squeeze() == uecmfit.model.endog.squeeze()\r\n\r\n```\r\n\r\n\n", "hints_text": "Definitely not the correct behavior w.r.t. residuals. I took a look and I don't think this is realted to `from_ardl`, since you get the same by directly constructing using `UECM`\n> Definitely not the correct behavior w.r.t. residuals. I took a look and I don't think this is realted to `from_ardl`, since you get the same by directly constructing using `UECM`\r\n\r\nI'm not familiar enough with the package internals, but if there's no situation where `UECM` would ever be passed an already-differenced dependent variable, differencing that in the `resid` method should address this.", "created_at": "2024-10-15T11:56:53Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9385, "instance_id": "statsmodels__statsmodels-9385", "issue_numbers": ["9383"], "base_commit": "3095a6559b549b0da88aebe3bfef05c6b5403ebe", "patch": "diff --git a/statsmodels/distributions/empirical_distribution.py b/statsmodels/distributions/empirical_distribution.py\nindex e83b02af1de..d9d971aa73a 100644\n--- a/statsmodels/distributions/empirical_distribution.py\n+++ b/statsmodels/distributions/empirical_distribution.py\n@@ -137,8 +137,7 @@ class ECDF(StepFunction):\n     array([ 0.75,  1.  ,  0.  ,  0.25])\n     \"\"\"\n     def __init__(self, x, side='right'):\n-        x = np.array(x, copy=True)\n-        x.sort()\n+        x = np.sort(np.asarray(x))\n         nobs = len(x)\n         y = np.linspace(1./nobs, 1, nobs)\n         super().__init__(x, y, side=side, sorted=True)\ndiff --git a/statsmodels/gam/smooth_basis.py b/statsmodels/gam/smooth_basis.py\nindex b87bfa262b0..9b4926460d1 100644\n--- a/statsmodels/gam/smooth_basis.py\n+++ b/statsmodels/gam/smooth_basis.py\n@@ -48,9 +48,8 @@ def _eval_bspline_basis(x, knots, degree, deriv='all', include_intercept=True):\n     # 'knots' are assumed to be already pre-processed. E.g. usually you\n     # want to include duplicate copies of boundary knots; you should do\n     # that *before* calling this constructor.\n-    knots = np.atleast_1d(np.asarray(knots, dtype=float))\n+    knots = np.sort(np.atleast_1d(np.asarray(knots, dtype=float)))\n     assert knots.ndim == 1\n-    knots.sort()\n     degree = int(degree)\n     x = np.atleast_1d(x)\n     if x.ndim == 2 and x.shape[1] == 1:\ndiff --git a/statsmodels/graphics/gofplots.py b/statsmodels/graphics/gofplots.py\nindex 8343fad1d96..4f1b0f7c8e0 100644\n--- a/statsmodels/graphics/gofplots.py\n+++ b/statsmodels/graphics/gofplots.py\n@@ -269,9 +269,7 @@ def theoretical_quantiles(self):\n     @cache_readonly\n     def sorted_data(self):\n         \"\"\"sorted data\"\"\"\n-        sorted_data = np.array(\n-            np.require(self.data, requirements=\"W\"), copy=True\n-        )\n+        sorted_data = np.sort(np.array(self.data))\n         sorted_data.sort()\n         return sorted_data\n \ndiff --git a/statsmodels/imputation/ros.py b/statsmodels/imputation/ros.py\nindex 942b135a49a..ec0ab16694d 100644\n--- a/statsmodels/imputation/ros.py\n+++ b/statsmodels/imputation/ros.py\n@@ -363,8 +363,7 @@ def plotting_positions(df, censorship, cohn):\n \n     # correctly sort the plotting positions of the ND data:\n     ND_plotpos = plot_pos[df[censorship]]\n-    ND_plotpos_arr = np.require(ND_plotpos, requirements=\"W\")\n-    ND_plotpos_arr.sort()\n+    ND_plotpos_arr = np.sort(np.array(ND_plotpos))\n     plot_pos.loc[df[censorship].index[df[censorship]]] = ND_plotpos_arr\n \n     return plot_pos\ndiff --git a/statsmodels/sandbox/nonparametric/dgp_examples.py b/statsmodels/sandbox/nonparametric/dgp_examples.py\nindex d116ea12f27..d461fc08837 100644\n--- a/statsmodels/sandbox/nonparametric/dgp_examples.py\n+++ b/statsmodels/sandbox/nonparametric/dgp_examples.py\n@@ -83,7 +83,7 @@ def __init__(self, nobs=200, x=None, distr_x=None, distr_noise=None):\n                 x = np.random.normal(loc=0, scale=self.s_x, size=nobs)\n             else:\n                 x = distr_x.rvs(size=nobs)\n-            x.sort()\n+            x = np.sort(x)\n \n         self.x = x\n \ndiff --git a/statsmodels/sandbox/nonparametric/smoothers.py b/statsmodels/sandbox/nonparametric/smoothers.py\nindex 44016928079..5659b42997c 100644\n--- a/statsmodels/sandbox/nonparametric/smoothers.py\n+++ b/statsmodels/sandbox/nonparametric/smoothers.py\n@@ -65,8 +65,7 @@ def conf(self, x):\n         is denser.\n         \"\"\"\n         if isinstance(x, int):\n-            sorted_x = np.array(self.x)\n-            sorted_x.sort()\n+            sorted_x = np.sort(np.array(self.x))\n             confx = sorted_x[::x]\n             conffit = self.conf(confx)\n             return (confx, conffit)\ndiff --git a/statsmodels/tools/grouputils.py b/statsmodels/tools/grouputils.py\nindex cb0260d8c94..45e2209f1c9 100644\n--- a/statsmodels/tools/grouputils.py\n+++ b/statsmodels/tools/grouputils.py\n@@ -398,8 +398,7 @@ def get_slices(self, level=0):\n         \"\"\"\n         # TODO: refactor this\n         groups = self.index.get_level_values(level).unique()\n-        groups = np.array(groups)\n-        groups.sort()\n+        groups = np.sort(np.array(groups))\n         if isinstance(self.index, MultiIndex):\n             self.slices = [self.index.get_loc_level(x, level=level)[0]\n                            for x in groups]\n", "test_patch": "diff --git a/statsmodels/distributions/tests/test_ecdf.py b/statsmodels/distributions/tests/test_ecdf.py\nindex 431fdb4ff3f..84350c764f0 100644\n--- a/statsmodels/distributions/tests/test_ecdf.py\n+++ b/statsmodels/distributions/tests/test_ecdf.py\n@@ -3,6 +3,8 @@\n from numpy.testing import assert_raises\n from statsmodels.distributions import StepFunction, monotone_fn_inverter\n from statsmodels.distributions import ECDFDiscrete\n+from statsmodels.distributions.empirical_distribution import ECDF\n+import pandas as pd\n \n \n class TestDistributions:\n@@ -54,3 +56,16 @@ def test_ecdf_discrete(self):\n         e2 = ECDFDiscrete([3.5, 1.5, 1, 4], freq_weights=[2, 1, 1, 1])\n         npt.assert_array_equal(e1.x, e2.x)\n         npt.assert_array_equal(e1.y, e2.y)\n+\n+    def test_ecdf_data_modification(self):\n+        # GH9383\n+        now = pd.to_datetime('2024-01-01')\n+        weeks = 2\n+        testdata = pd.DataFrame(columns=['dates', 'values', 'othervalues'])\n+        testdata['dates'] = pd.date_range(start=now, periods=weeks * 7, freq='D')\n+        testdata['values'] = np.random.randint(0, 100, size=(weeks * 7))\n+        testdata['othervalues'] = np.random.randint(0, 100, size=(weeks * 7))\n+        orig_testadata = testdata.copy()\n+\n+        ECDF(testdata['values'])\n+        pd.testing.assert_frame_equal(orig_testadata, testdata)\ndiff --git a/statsmodels/tsa/arima/estimators/tests/test_hannan_rissanen.py b/statsmodels/tsa/arima/estimators/tests/test_hannan_rissanen.py\nindex c874f239416..896ad62f0dd 100644\n--- a/statsmodels/tsa/arima/estimators/tests/test_hannan_rissanen.py\n+++ b/statsmodels/tsa/arima/estimators/tests/test_hannan_rissanen.py\n@@ -121,10 +121,10 @@ def test_set_default_unbiased():\n         endog, ar_order=1, ma_order=1, unbiased=True\n     )\n \n-    np.testing.assert_array_equal(p_1.ar_params, p_2.ar_params)\n-    np.testing.assert_array_equal(p_1.ma_params, p_2.ma_params)\n-    assert p_1.sigma2 == p_2.sigma2\n-    np.testing.assert_array_equal(other_results_1.resid, other_results_2.resid)\n+    assert_allclose(p_1.ar_params, p_2.ar_params)\n+    assert_allclose(p_1.ma_params, p_2.ma_params)\n+    assert_allclose(p_1.sigma2, p_2.sigma2)\n+    assert_allclose(other_results_1.resid, other_results_2.resid)\n \n     # unbiased=False\n     p_3, _ = hannan_rissanen(\n@@ -246,12 +246,12 @@ def test_package_fixed_and_free_params_info(fixed_params, spec_ar_lags,\n     for k in ixs:\n         assert isinstance(actual_bunch[k], np.ndarray)\n         assert actual_bunch[k].dtype in [np.int64, np.int32]\n-        np.testing.assert_array_equal(actual_bunch[k], expected_bunch[k])\n+        assert_allclose(actual_bunch[k], expected_bunch[k])\n \n     params = ['fixed_ar_params', 'fixed_ma_params']\n     for k in params:\n         assert isinstance(actual_bunch[k], np.ndarray)\n-        np.testing.assert_array_equal(actual_bunch[k], expected_bunch[k])\n+        assert_allclose(actual_bunch[k], expected_bunch[k])\n \n \n @pytest.mark.parametrize(\n@@ -344,7 +344,7 @@ def test_set_default_unbiased_with_fixed_params():\n         fixed_params={\"ar.L1\": 0.69607715}\n     )\n \n-    np.testing.assert_array_equal(p_1.ar_params, p_2.ar_params)\n-    np.testing.assert_array_equal(p_1.ma_params, p_2.ma_params)\n-    assert p_1.sigma2 == p_2.sigma2\n-    np.testing.assert_array_equal(other_results_1.resid, other_results_2.resid)\n+    assert_allclose(p_1.ar_params, p_2.ar_params)\n+    assert_allclose(p_1.ma_params, p_2.ma_params)\n+    assert_allclose(p_1.sigma2, p_2.sigma2)\n+    assert_allclose(other_results_1.resid, other_results_2.resid)\n", "problem_statement": "statsmodels.api.distributions.ECDF modifies base data in place\n#### Describe the bug\r\n\r\nWhen fitting an ECDF on a column of a Pandas dataframe, the column in sorted in place by value ascending, irrespective of the index of the dataframe and the dataframe's other columns.\r\n\r\nHere is an example:\r\nExample df before ECDF: \r\n![image](https://github.com/user-attachments/assets/98e3e54f-23f4-4a97-8cfe-b28794def73c)\r\n\r\nExample df after ECDF:\r\n![image](https://github.com/user-attachments/assets/eaa19550-7e10-4940-8325-6673c85d066c)\r\n\r\nIt can be clearly seen that the column we ran ECDF on was sorted in place, putting it out of sync with the rest of the dataframe and distorting the dataset.\r\n\r\n#### Code Sample, a copy-pastable example if possible\r\n\r\n\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\nimport statsmodels.api as sm\r\n\r\n# Start with a dataframe of values and dates\r\nnow = pd.to_datetime('2024-01-01')\r\nweeks = 2\r\ntestdata = pd.DataFrame(columns=['dates', 'values', 'othervalues'])\r\ntestdata['dates'] = pd.date_range(start=now, periods=weeks*7, freq='D')\r\n\r\n# Put random data in values and othervalues\r\ntestdata['values'] = np.random.randint(0, 100, size=(weeks*7))\r\ntestdata['othervalues'] = np.random.randint(0, 100, size=(weeks*7))\r\n\r\n# Display the df to show the original order\r\ndisplay(testdata)\r\n\r\n# Generate ECDF\r\necdf = sm.distributions.ECDF(testdata['values'])\r\n\r\n# Show that the data has been sorted even though no assignment has been made\r\ndisplay(testdata)\r\n```\r\n<details>\r\nDid not see an issue for this, closed or open, in the tracker\r\n\r\nPython version: 3.12.7 \r\nPandas version: 2.2.3\r\nNumpy version: 2.1.2\r\nStatsmodels version: 0.14.4\r\n\r\n</details>\r\n\r\n#### Expected Output\r\n\r\nExpected behavior is that Pandas dataframe column should not be modified in place by ecdf function. Since there is no assignment of anything back to the original dataframe, the original should be untouched. All assignment is to the new ecdf object.\r\n\r\n#### Output of ``import statsmodels.api as sm; sm.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\nPython: 3.12.7.final.0\r\n\r\nstatsmodels\r\n===========\r\n\r\nInstalled: 0.14.4 (c:\\Users\\David\\anaconda3\\envs\\doses\\Lib\\site-packages\\statsmodels)\r\n\r\nRequired Dependencies\r\n=====================\r\n\r\ncython: 3.0.11 (c:\\Users\\David\\anaconda3\\envs\\doses\\Lib\\site-packages\\Cython)\r\nnumpy: 2.1.2 (c:\\Users\\David\\anaconda3\\envs\\doses\\Lib\\site-packages\\numpy)\r\nscipy: 1.14.1 (c:\\Users\\David\\anaconda3\\envs\\doses\\Lib\\site-packages\\scipy)\r\npandas: 2.2.3 (c:\\Users\\David\\anaconda3\\envs\\doses\\Lib\\site-packages\\pandas)\r\n    dateutil: 2.9.0.post0 (c:\\Users\\David\\anaconda3\\envs\\doses\\Lib\\site-packages\\dateutil)\r\npatsy: 0.5.6 (c:\\Users\\David\\anaconda3\\envs\\doses\\Lib\\site-packages\\patsy)\r\n\r\nOptional Dependencies\r\n=====================\r\n\r\nmatplotlib: 3.9.2 (c:\\Users\\David\\anaconda3\\envs\\doses\\Lib\\site-packages\\matplotlib)\r\n    backend: module://matplotlib_inline.backend_inline \r\ncvxopt: Not installed\r\njoblib: 1.4.2 (c:\\Users\\David\\anaconda3\\envs\\doses\\Lib\\site-packages\\joblib)\r\n\r\nDeveloper Tools\r\n================\r\n\r\nIPython: 8.28.0 (c:\\Users\\David\\anaconda3\\envs\\doses\\Lib\\site-packages\\IPython)\r\n    jinja2: Not installed\r\nsphinx: Not installed\r\n    pygments: 2.18.0 (c:\\Users\\David\\anaconda3\\envs\\doses\\Lib\\site-packages\\pygments)\r\npytest: Not installed\r\nvirtualenv: Not installed\r\n\r\n</details>\r\n\n", "hints_text": "In my old python/numpy/pandas environment, the dataframes are the same before and after ecdf.\r\n\r\nThe first two lines of ECDF are\r\n\r\n```\r\nx = np.array(x, copy=True)\r\nx.sort()\r\n```\r\n\r\ncan you check this for `x = testdata['values']` ?\r\n\r\nWhat's the dtype of `testdata['values']` ?\r\n\r\neither the behavior of numpy or pandas has changed in recent versions.\r\n\r\n \nnumpy `array` docstring for `copy` options includes\r\n\"\r\nNote that any copy of the data is shallow, i.e., for arrays with object dtype, the new array will point to the same objects.\r\n\"\r\n\r\nwhich sounds like it's possible to have dtype problem between pandas and numpy.\r\n\r\n", "created_at": "2024-10-08T08:08:44Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9311, "instance_id": "statsmodels__statsmodels-9311", "issue_numbers": ["9307"], "base_commit": "fba5c05dcab9b5e8ec80115ae510874c80689d17", "patch": "diff --git a/statsmodels/tsa/stattools.py b/statsmodels/tsa/stattools.py\nindex bfca2fdf23b..bc3546db1ac 100644\n--- a/statsmodels/tsa/stattools.py\n+++ b/statsmodels/tsa/stattools.py\n@@ -2545,7 +2545,7 @@ def _format_regression_data(self, series, nobs, const, trend, cols, lags):\n         # first-diff y and standardize for numerical stability\n         endog = np.diff(series, axis=0)\n         endog /= np.sqrt(endog.T.dot(endog))\n-        series /= np.sqrt(series.T.dot(series))\n+        series = series / np.sqrt(series.T.dot(series))\n         # reserve exog space\n         exog = np.zeros((endog[lags:].shape[0], cols + lags))\n         exog[:, 0] = const\n@@ -2653,7 +2653,7 @@ def run(self, x, trim=0.15, maxlag=None, regression=\"c\", autolag=\"AIC\"):\n            great crash, the oil-price shock, and the unit-root hypothesis.\n            Journal of Business & Economic Studies, 10: 251-270.\n         \"\"\"\n-        x = array_like(x, \"x\")\n+        x = array_like(x, \"x\", dtype=np.double, ndim=1)\n         trim = float_like(trim, \"trim\")\n         maxlag = int_like(maxlag, \"maxlag\", optional=True)\n         regression = string_like(\n", "test_patch": "diff --git a/statsmodels/tsa/tests/test_stattools.py b/statsmodels/tsa/tests/test_stattools.py\nindex d910a29db14..b9427bad717 100644\n--- a/statsmodels/tsa/tests/test_stattools.py\n+++ b/statsmodels/tsa/tests/test_stattools.py\n@@ -1608,3 +1608,19 @@ def test_pacf_1_obs(reset_randomstate):\n     with pytest.raises(ValueError):\n         pacf_ols(y)\n     pacf_yw(y)\n+\n+\n+def test_zivot_andrews_change_data(reset_randomstate):\n+    # GH9307\n+    years = pd.date_range(start='1990-01-01', end='2023-12-31', freq='YS')\n+    df = pd.DataFrame(index=years)\n+    df['variable1'] = np.where(df.index.year <= 2002, 10, 20)\n+    df['variable2'] = np.where(df.index.year <= 2002, 10, 20)\n+    df.iloc[-1] = 30\n+\n+    # Zivot-Andrews test with data with type float64\n+    df = df.astype(float)\n+    df_original = df.copy()\n+    zivot_andrews(df['variable1'])\n+    zivot_andrews(df['variable1'], regression='c')\n+    pd.testing.assert_frame_equal(df, df_original)\n", "problem_statement": "Zivot-Andrews Test with data type float64 modifies dataset used in the test\n#### Describe the bug\r\n\r\nUsing the Zivot-Andrews Test (from statsmodels.tsa.stattools.zivot_andrews) with a variable with type float64 modifies the values of the variable used in the test (in the dataframe). This doesn't happen with variables with type int32, for example.\r\n\r\nThis is a problem because it changes the values in the dataframe being used for statistical analysis, considering that the Zivot-Andrews test is done before fitting a model.\r\n\r\n#### Code Sample, a copy-pastable example if possible\r\n\r\n\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\nimport statsmodels.api as sm\r\nfrom statsmodels.tsa.stattools import zivot_andrews\r\n\r\nsm.show_versions()\r\n\r\n# Create a range of years from 1990 to 2023 for the index\r\nyears = pd.date_range(start='1990-01-01', end='2023-12-31', freq='AS')\r\n# Create a DataFrame with variable years as the index\r\ndf = pd.DataFrame(index=years)\r\n# Set the values for the variable\r\ndf['variable1'] = np.where(df.index.year <= 2002, 10, 20)\r\ndf['variable2'] = np.where(df.index.year <= 2002, 10, 20)\r\ndf.info() \r\n\r\n# Zivot-Andrews test with data with type int32\r\nzivot_andrews(df['variable1'])\r\nzivot_andrews(df['variable1'],regression = 'c')\r\n\r\n# Zivot-Andrews test with data with type float64\r\ndf=df.astype(float)\r\nzivot_andrews(df['variable1'])\r\nzivot_andrews(df['variable1'],regression = 'c')\r\n\r\n```\r\n\r\n#### Expected Output\r\n\r\nTo keep the same dataframe after using the zivot_andrews function.\r\n\r\n#### Output of ``import statsmodels.api as sm; sm.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\nPython: 3.11.5.final.0\r\n\r\nstatsmodels\r\n===========\r\n\r\nInstalled: 0.14.0 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\statsmodels)\r\n\r\nRequired Dependencies\r\n=====================\r\n\r\ncython: Not installed\r\nnumpy: 1.24.3 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy)\r\nscipy: 1.11.1 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy)\r\npandas: 2.0.3 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas)\r\n    dateutil: 2.8.2 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dateutil)\r\npatsy: 0.5.3 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\patsy)\r\n\r\nOptional Dependencies\r\n=====================\r\n\r\nmatplotlib: 3.7.2 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib)\r\n    backend: module://matplotlib_inline.backend_inline \r\ncvxopt: Not installed\r\njoblib: 1.2.0 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib)\r\n\r\nDeveloper Tools\r\n================\r\n\r\nIPython: 8.15.0 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython)\r\n    jinja2: 3.1.2 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\jinja2)\r\nsphinx: 5.0.2 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sphinx)\r\n    pygments: 2.15.1 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pygments)\r\npytest: 7.4.0 (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pytest)\r\nvirtualenv: Not installed\r\n\r\n</details>\r\n\n", "hints_text": "", "created_at": "2024-07-15T09:22:25Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9291, "instance_id": "statsmodels__statsmodels-9291", "issue_numbers": ["9289"], "base_commit": "b276c2e08807c41324b217a8ae51a5120e708223", "patch": "diff --git a/statsmodels/__init__.py b/statsmodels/__init__.py\nindex 17799ff7be0..8cc3679d687 100644\n--- a/statsmodels/__init__.py\n+++ b/statsmodels/__init__.py\n@@ -33,7 +33,7 @@ def test(extra_args=None, exit=False):\n     int\n         The status code from the test run if exit is False.\n     \"\"\"\n-    from .tools._testing import PytestTester\n+    from .tools._test_runner import PytestTester\n \n     tst = PytestTester(package_path=__file__)\n     return tst(extra_args=extra_args, exit=exit)\ndiff --git a/statsmodels/base/__init__.py b/statsmodels/base/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/base/__init__.py\n+++ b/statsmodels/base/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/compat/__init__.py b/statsmodels/compat/__init__.py\nindex 110146bd201..0ac5c471210 100644\n--- a/statsmodels/compat/__init__.py\n+++ b/statsmodels/compat/__init__.py\n@@ -1,4 +1,4 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n from .python import (\n     PY37,\ndiff --git a/statsmodels/datasets/__init__.py b/statsmodels/datasets/__init__.py\nindex 78d2147a147..2232c1008d3 100644\n--- a/statsmodels/datasets/__init__.py\n+++ b/statsmodels/datasets/__init__.py\n@@ -1,7 +1,7 @@\n \"\"\"\n Datasets module\n \"\"\"\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n from . import (\n     anes96,\ndiff --git a/statsmodels/discrete/__init__.py b/statsmodels/discrete/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/discrete/__init__.py\n+++ b/statsmodels/discrete/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/distributions/__init__.py b/statsmodels/distributions/__init__.py\nindex 5fae89ae58e..a08cee1462a 100644\n--- a/statsmodels/distributions/__init__.py\n+++ b/statsmodels/distributions/__init__.py\n@@ -1,4 +1,4 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n from .empirical_distribution import (\n     ECDF, ECDFDiscrete, monotone_fn_inverter, StepFunction\n     )\ndiff --git a/statsmodels/duration/__init__.py b/statsmodels/duration/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/duration/__init__.py\n+++ b/statsmodels/duration/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/emplike/__init__.py b/statsmodels/emplike/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/emplike/__init__.py\n+++ b/statsmodels/emplike/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/formula/__init__.py b/statsmodels/formula/__init__.py\nindex f2f1d74f434..97a30c8c791 100644\n--- a/statsmodels/formula/__init__.py\n+++ b/statsmodels/formula/__init__.py\n@@ -1,6 +1,6 @@\n __all__ = ['handle_formula_data', 'test']\n from .formulatools import handle_formula_data\n \n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/gam/__init__.py b/statsmodels/gam/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/gam/__init__.py\n+++ b/statsmodels/gam/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/genmod/__init__.py b/statsmodels/genmod/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/genmod/__init__.py\n+++ b/statsmodels/genmod/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/genmod/families/__init__.py b/statsmodels/genmod/families/__init__.py\nindex a45a9e4ec97..d1433475736 100644\n--- a/statsmodels/genmod/families/__init__.py\n+++ b/statsmodels/genmod/families/__init__.py\n@@ -13,7 +13,7 @@\n from statsmodels.genmod.families import links\n from .family import Gaussian, Family, Poisson, Gamma, \\\n     InverseGaussian, Binomial, NegativeBinomial, Tweedie\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n __all__ = ['test', 'links', 'Family', 'Gamma', 'Gaussian', 'Poisson',\n            'InverseGaussian', 'Binomial', 'NegativeBinomial', 'Tweedie']\ndiff --git a/statsmodels/graphics/__init__.py b/statsmodels/graphics/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/graphics/__init__.py\n+++ b/statsmodels/graphics/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/imputation/__init__.py b/statsmodels/imputation/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/imputation/__init__.py\n+++ b/statsmodels/imputation/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/iolib/__init__.py b/statsmodels/iolib/__init__.py\nindex 304b2458da9..253371b29e2 100644\n--- a/statsmodels/iolib/__init__.py\n+++ b/statsmodels/iolib/__init__.py\n@@ -2,7 +2,7 @@\n from .table import SimpleTable, csv2st\n from .smpickle import save_pickle, load_pickle\n \n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n __all__ = ['test', 'csv2st', 'SimpleTable', 'savetxt',\n            'save_pickle', 'load_pickle']\ndiff --git a/statsmodels/miscmodels/__init__.py b/statsmodels/miscmodels/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/miscmodels/__init__.py\n+++ b/statsmodels/miscmodels/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/multivariate/__init__.py b/statsmodels/multivariate/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/multivariate/__init__.py\n+++ b/statsmodels/multivariate/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/multivariate/factor_rotation/__init__.py b/statsmodels/multivariate/factor_rotation/__init__.py\nindex 56eda5479c3..eec697396ef 100644\n--- a/statsmodels/multivariate/factor_rotation/__init__.py\n+++ b/statsmodels/multivariate/factor_rotation/__init__.py\n@@ -24,7 +24,7 @@\n from ._wrappers import rotate_factors\n \n from ._analytic_rotation import target_rotation, procrustes, promax\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n __all__ = ['rotate_factors', 'target_rotation', 'procrustes', 'promax',\n            'test']\ndiff --git a/statsmodels/nonparametric/__init__.py b/statsmodels/nonparametric/__init__.py\nindex bdd0fc3a075..a48e1b22c6c 100644\n--- a/statsmodels/nonparametric/__init__.py\n+++ b/statsmodels/nonparametric/__init__.py\n@@ -4,6 +4,6 @@\n For an overview of this module, see docs/source/nonparametric.rst\n \"\"\"\n \n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/othermod/__init__.py b/statsmodels/othermod/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/othermod/__init__.py\n+++ b/statsmodels/othermod/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/regression/__init__.py b/statsmodels/regression/__init__.py\nindex dcdcf84a070..25df44cbc3d 100644\n--- a/statsmodels/regression/__init__.py\n+++ b/statsmodels/regression/__init__.py\n@@ -1,6 +1,6 @@\n from .linear_model import yule_walker\n \n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n __all__ = ['yule_walker', 'test']\n \ndiff --git a/statsmodels/robust/__init__.py b/statsmodels/robust/__init__.py\nindex 69e78e9fc80..a02632942e8 100644\n--- a/statsmodels/robust/__init__.py\n+++ b/statsmodels/robust/__init__.py\n@@ -5,6 +5,6 @@\n from . import norms\n from .scale import mad, Huber, HuberScale, hubers_scale\n \n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/sandbox/__init__.py b/statsmodels/sandbox/__init__.py\nindex 48965ffc70c..91bf289559a 100644\n--- a/statsmodels/sandbox/__init__.py\n+++ b/statsmodels/sandbox/__init__.py\n@@ -1,6 +1,6 @@\n '''This is sandbox code\n \n '''\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/stats/__init__.py b/statsmodels/stats/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/stats/__init__.py\n+++ b/statsmodels/stats/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/stats/libqsturng/__init__.py b/statsmodels/stats/libqsturng/__init__.py\nindex 88cdcbdf0ba..fb213d260f3 100644\n--- a/statsmodels/stats/libqsturng/__init__.py\n+++ b/statsmodels/stats/libqsturng/__init__.py\n@@ -1,6 +1,6 @@\n from .qsturng_ import psturng, qsturng, p_keys, v_keys\n \n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n __all__ = ['p_keys', 'psturng', 'qsturng', 'v_keys', 'test']\n \ndiff --git a/statsmodels/tools/__init__.py b/statsmodels/tools/__init__.py\nindex 0050de350fb..d6c589b7655 100644\n--- a/statsmodels/tools/__init__.py\n+++ b/statsmodels/tools/__init__.py\n@@ -1,5 +1,5 @@\n from .tools import add_constant, categorical\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n __all__ = ['test', 'add_constant', 'categorical']\n \ndiff --git a/statsmodels/tsa/__init__.py b/statsmodels/tsa/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/tsa/__init__.py\n+++ b/statsmodels/tsa/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/tsa/base/__init__.py b/statsmodels/tsa/base/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/tsa/base/__init__.py\n+++ b/statsmodels/tsa/base/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/tsa/filters/__init__.py b/statsmodels/tsa/filters/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/tsa/filters/__init__.py\n+++ b/statsmodels/tsa/filters/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/tsa/innovations/__init__.py b/statsmodels/tsa/innovations/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/tsa/innovations/__init__.py\n+++ b/statsmodels/tsa/innovations/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/tsa/interp/__init__.py b/statsmodels/tsa/interp/__init__.py\nindex 6bc4552b40c..e5ff9757dee 100644\n--- a/statsmodels/tsa/interp/__init__.py\n+++ b/statsmodels/tsa/interp/__init__.py\n@@ -1,5 +1,5 @@\n __all__ = ['dentonm', 'test']\n from .denton import dentonm\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/tsa/regime_switching/__init__.py b/statsmodels/tsa/regime_switching/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/tsa/regime_switching/__init__.py\n+++ b/statsmodels/tsa/regime_switching/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/tsa/statespace/__init__.py b/statsmodels/tsa/statespace/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/tsa/statespace/__init__.py\n+++ b/statsmodels/tsa/statespace/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/tsa/stl/__init__.py b/statsmodels/tsa/stl/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/tsa/stl/__init__.py\n+++ b/statsmodels/tsa/stl/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\ndiff --git a/statsmodels/tsa/vector_ar/__init__.py b/statsmodels/tsa/vector_ar/__init__.py\nindex 2807e65ff41..691559ca60f 100644\n--- a/statsmodels/tsa/vector_ar/__init__.py\n+++ b/statsmodels/tsa/vector_ar/__init__.py\n@@ -1,3 +1,3 @@\n-from statsmodels.tools._testing import PytestTester\n+from statsmodels.tools._test_runner import PytestTester\n \n test = PytestTester()\n", "test_patch": "diff --git a/statsmodels/tools/_test_runner.py b/statsmodels/tools/_test_runner.py\nnew file mode 100644\nindex 00000000000..b805c55f184\n--- /dev/null\n+++ b/statsmodels/tools/_test_runner.py\n@@ -0,0 +1,35 @@\n+\"\"\"\n+Pytest runner that allows test to be run within python\n+\"\"\"\n+\n+import os\n+import sys\n+from packaging.version import Version, parse\n+\n+\n+class PytestTester:\n+    def __init__(self, package_path=None):\n+        f = sys._getframe(1)\n+        if package_path is None:\n+            package_path = f.f_locals.get(\"__file__\", None)\n+            if package_path is None:\n+                raise ValueError(\"Unable to determine path\")\n+        self.package_path = os.path.dirname(package_path)\n+        self.package_name = f.f_locals.get(\"__name__\", None)\n+\n+    def __call__(self, extra_args=None, exit=False):\n+        try:\n+            import pytest\n+\n+            if not parse(pytest.__version__) >= Version(\"3.0\"):\n+                raise ImportError\n+            if extra_args is None:\n+                extra_args = [\"--tb=short\", \"--disable-pytest-warnings\"]\n+            cmd = [self.package_path] + extra_args\n+            print(\"Running pytest \" + \" \".join(cmd))\n+            status = pytest.main(cmd)\n+            if exit:\n+                print(f\"Exit status: {status}\")\n+                sys.exit(status)\n+        except ImportError:\n+            raise ImportError(\"pytest>=3 required to run the test\")\ndiff --git a/statsmodels/tools/_testing.py b/statsmodels/tools/_testing.py\nindex 072dcffd1ac..1305e7e7942 100644\n--- a/statsmodels/tools/_testing.py\n+++ b/statsmodels/tools/_testing.py\n@@ -9,43 +9,12 @@\n \n \"\"\"\n \n-import os\n-import sys\n-from packaging.version import Version, parse\n-\n import numpy as np\n from numpy.testing import assert_allclose, assert_\n \n import pandas as pd\n \n \n-class PytestTester:\n-    def __init__(self, package_path=None):\n-        f = sys._getframe(1)\n-        if package_path is None:\n-            package_path = f.f_locals.get('__file__', None)\n-            if package_path is None:\n-                raise ValueError('Unable to determine path')\n-        self.package_path = os.path.dirname(package_path)\n-        self.package_name = f.f_locals.get('__name__', None)\n-\n-    def __call__(self, extra_args=None, exit=False):\n-        try:\n-            import pytest\n-            if not parse(pytest.__version__) >= Version('3.0'):\n-                raise ImportError\n-            if extra_args is None:\n-                extra_args = ['--tb=short', '--disable-pytest-warnings']\n-            cmd = [self.package_path] + extra_args\n-            print('Running pytest ' + ' '.join(cmd))\n-            status = pytest.main(cmd)\n-            if exit:\n-                print(f\"Exit status: {status}\")\n-                sys.exit(status)\n-        except ImportError:\n-            raise ImportError('pytest>=3 required to run the test')\n-\n-\n def check_ttest_tvalues(results):\n     # test that t_test has same results a params, bse, tvalues, ...\n     res = results\n@@ -60,16 +29,17 @@ def check_ttest_tvalues(results):\n     assert_allclose(tt.conf_int(), res.conf_int(), rtol=1e-10)\n \n     # test params table frame returned by t_test\n-    table_res = np.column_stack((res.params, res.bse, res.tvalues,\n-                                 res.pvalues, res.conf_int()))\n+    table_res = np.column_stack(\n+        (res.params, res.bse, res.tvalues, res.pvalues, res.conf_int())\n+    )\n     table2 = tt.summary_frame().values\n     assert_allclose(table2, table_res, rtol=1e-12)\n \n     # TODO: move this to test_attributes ?\n-    assert_(hasattr(res, 'use_t'))\n+    assert_(hasattr(res, \"use_t\"))\n \n     tt = res.t_test(mat[0])\n-    tt.summary()   # smoke test for #1323\n+    tt.summary()  # smoke test for #1323\n     pvalues = np.asarray(res.pvalues)\n     assert_allclose(tt.pvalue, pvalues[0], rtol=5e-10)\n     # TODO: Adapt more of test_generic_methods.test_ttest_values here?\n@@ -95,18 +65,22 @@ def check_ftest_pvalues(results):\n     use_t = res.use_t\n     k_vars = len(res.params)\n     # check default use_t\n-    pvals = [res.wald_test(np.eye(k_vars)[k], use_f=use_t, scalar=True).pvalue\n-             for k in range(k_vars)]\n+    pvals = [\n+        res.wald_test(np.eye(k_vars)[k], use_f=use_t, scalar=True).pvalue\n+        for k in range(k_vars)\n+    ]\n     assert_allclose(pvals, res.pvalues, rtol=5e-10, atol=1e-25)\n \n     # automatic use_f based on results class use_t\n-    pvals = [res.wald_test(np.eye(k_vars)[k], scalar=True).pvalue\n-             for k in range(k_vars)]\n+    pvals = [\n+        res.wald_test(np.eye(k_vars)[k], scalar=True).pvalue\n+        for k in range(k_vars)\n+    ]\n     assert_allclose(pvals, res.pvalues, rtol=5e-10, atol=1e-25)\n \n     # TODO: Separate these out into summary/summary2 tests?\n     # label for pvalues in summary\n-    string_use_t = 'P>|z|' if use_t is False else 'P>|t|'\n+    string_use_t = \"P>|z|\" if use_t is False else \"P>|t|\"\n     summ = str(res.summary())\n     assert_(string_use_t in summ)\n \n@@ -127,10 +101,10 @@ def check_fitted(results):\n     from statsmodels.discrete.discrete_model import DiscreteResults\n \n     # possibly unwrap -- GEE has no wrapper\n-    results = getattr(results, '_results', results)\n+    results = getattr(results, \"_results\", results)\n \n     if isinstance(results, (GLMResults, DiscreteResults)):\n-        pytest.skip(f'Not supported for {type(results)}')\n+        pytest.skip(f\"Not supported for {type(results)}\")\n \n     res = results\n     fitted = res.fittedvalues\n@@ -158,10 +132,13 @@ def check_predict_types(results):\n     # ignore wrapper for isinstance check\n     from statsmodels.genmod.generalized_linear_model import GLMResults\n     from statsmodels.discrete.discrete_model import DiscreteResults\n-    from statsmodels.compat.pandas import assert_frame_equal, assert_series_equal\n+    from statsmodels.compat.pandas import (\n+        assert_frame_equal,\n+        assert_series_equal,\n+    )\n \n     # possibly unwrap -- GEE has no wrapper\n-    results = getattr(results, '_results', results)\n+    results = getattr(results, \"_results\", results)\n \n     if isinstance(results, (GLMResults, DiscreteResults)):\n         # SMOKE test only  TODO: mark this somehow\n@@ -172,13 +149,14 @@ def check_predict_types(results):\n         fitted = res.fittedvalues[:2]\n         assert_allclose(fitted, res.predict(p_exog), rtol=1e-12)\n         # this needs reshape to column-vector:\n-        assert_allclose(fitted, res.predict(np.squeeze(p_exog).tolist()),\n-                        rtol=1e-12)\n+        assert_allclose(\n+            fitted, res.predict(np.squeeze(p_exog).tolist()), rtol=1e-12\n+        )\n         # only one prediction:\n-        assert_allclose(fitted[:1], res.predict(p_exog[0].tolist()),\n-                        rtol=1e-12)\n-        assert_allclose(fitted[:1], res.predict(p_exog[0]),\n-                        rtol=1e-12)\n+        assert_allclose(\n+            fitted[:1], res.predict(p_exog[0].tolist()), rtol=1e-12\n+        )\n+        assert_allclose(fitted[:1], res.predict(p_exog[0]), rtol=1e-12)\n \n         # Check that pandas wrapping works as expected\n         exog_index = range(len(p_exog))\n", "problem_statement": "Start from 0.14.0, unwanted `fork` can happened when importing statsmodels\n#### Describe the bug\r\n\r\nWhen importing statsmodels, a system call `fork` is called, but I don't think it's necessry.\r\n\r\nI'm using statsmodels with numpy 1.26.1 version, but I think I can verify that we have the same issue when using numpy 2.0.\r\n\r\nHere is relative backtrace:\r\n```shell\r\n   import statsmodels.api as sm\r\n  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\r\n  File \"/usr/local/lib/python3.9/site-packages/statsmodels/__init__.py\", line 1, in <module>\r\n    from statsmodels.compat.patsy import monkey_patch_cat_dtype\r\n  File \"/usr/local/lib/python3.9/site-packages/statsmodels/compat/__init__.py\", line 1, in <module>\r\n    from statsmodels.tools._testing import PytestTester\r\n  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\r\n  File \"/usr/local/lib/python3.9/site-packages/statsmodels/tools/__init__.py\", line 2, in <module>\r\n    from statsmodels.tools._testing import PytestTester\r\n  File \"/usr/local/lib/python3.9/site-packages/statsmodels/tools/_testing.py\", line 17, in <module>\r\n    from numpy.testing import assert_allclose, assert_\r\n  File \"/usr/local/lib/python3.9/site-packages/numpy/testing/__init__.py\", line 11, in <module>\r\n    from ._private.utils import *\r\n  File \"/usr/local/lib/python3.9/site-packages/numpy/testing/_private/utils.py\", line 1253, in <module>\r\n    _SUPPORTS_SVE = check_support_sve()\r\n  File \"/usr/local/lib/python3.9/site-packages/numpy/testing/_private/utils.py\", line 1247, in check_support_sve\r\n    output = subprocess.run(cmd, capture_output=True, text=True)\r\n```\r\n\r\nThe issue is that when import it, it runs this:\r\n```\r\nfrom numpy.testing import assert_allclose, assert_\r\n```\r\nThen in numpy, it will run something like `fork` in the end.\r\n\r\n#### Code Sample, a copy-pastable example if possible\r\n\r\n\r\n```python\r\nimport statsmodels.api as sm\r\n```\r\n<details>\r\n\r\n</details>\r\n\r\n\r\nIf the issue has not been resolved, please file it in the issue tracker.\r\n\r\n#### Expected Output\r\n\r\nI expected it doesn't call `fork`.\r\n\r\n#### Output of ``import statsmodels.api as sm; sm.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\nPython: 3.9.7.final.0\r\nOS: Darwin 22.6.0 Darwin Kernel Version 22.6.0: Mon Apr 22 20:54:28 PDT 2024; root:xnu-8796.141.3.705.2~1/RELEASE_X86_64 x86_64\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: None\r\n\r\nstatsmodels\r\n===========\r\n\r\nInstalled: 0.14.2 (/local/lib/python3.9/site-packages/statsmodels)\r\n\r\nRequired Dependencies\r\n=====================\r\n\r\ncython: 0.29.26 (/local/lib/python3.9/site-packages/Cython)\r\nnumpy: 1.26.4 (/local/lib/python3.9/site-packages/numpy)\r\nscipy: 1.13.1 (/local/lib/python3.9/site-packages/scipy)\r\npandas: 1.5.3 (/local/lib/python3.9/site-packages/pandas)\r\n    dateutil: 2.8.2 (/local/lib/python3.9/site-packages/dateutil)\r\npatsy: 0.5.6 (/local/lib/python3.9/site-packages/patsy)\r\n\r\nOptional Dependencies\r\n=====================\r\n\r\nmatplotlib: 3.6.3 (/local/lib/python3.9/site-packages/matplotlib)\r\n    backend: MacOSX\r\ncvxopt: Not installed\r\njoblib: Not installed\r\n\r\nDeveloper Tools\r\n================\r\n\r\nIPython: 8.18.1 (/local/lib/python3.9/site-packages/IPython)\r\n    jinja2: 3.0.1 (/local/lib/python3.9/site-packages/jinja2)\r\nsphinx: Not installed\r\n    pygments: 2.14.0 (/local/lib/python3.9/site-packages/pygments)\r\npytest: 6.2.4 (/local/lib/python3.9/site-packages/pytest)\r\nvirtualenv: Not installed\r\n\r\n</details>\r\n\n", "hints_text": "Is there anything specific to statsmodels or is this just numpy behavior that we cannot control?\nThis is a numpy issue. It uses subprocess to detect certain capabilities which is causing problems for you.  \n\nAre you running in some nonstandard environment (e.g., a compiled executable?)\n> Is there anything specific to statsmodels or is this just numpy behavior that we cannot control?\r\n\r\nI'm not pretty sure, because before 0.14.0, when I run `import statsmodel`, it didn't run something like this:\r\n```python\r\nfrom statsmodels.compat.patsy import monkey_patch_cat_dtype\r\n```\r\nWhich makes numpy to `check_support_sve` \r\n\r\n> Are you running in some nonstandard environment (e.g., a compiled executable?)\r\n\r\nNope, I'm just running a regular python script.\nYes, the monkey patch is new and due to breaks in some versions of pandas.  What version of statsmodels are you using?  What NumPy are you using?\nI'm using statsmodels 0.14.2 and numpy 1.26.4.\r\n\r\nSorry I think I have post these information in the description, which is outputed by `import statsmodels.api as sm; sm.show_versions()`\nI can't reproduce.  On ubuntu:\r\n\r\n```bash\r\nsudo apt update\\nsudo apt install software-properties-common\r\nsudo add-apt-repository ppa:deadsnakes/ppa\r\nsudo apt update\r\nsudo apt install python3.9 python3.9-dev\r\nvirtualenv sm-test --python=python3.9\r\nsource sm-test/bin/activate\r\npython -m pip install \"statsmodels==0.14.2\" \"numpy==1.26.4\"\r\npython -c \"import statsmodels.api as sm; print('Working')\"\r\n```\r\n\r\nSeems to be something specific to your install.  Are you running Linux, Windows or OSX?\nCan you post the full traceback with the error details?\nOh, I'm sorry.  The trackback is printed by myself.  `import statsmodels.api as sm` doesn't raise such exception.\r\n\r\nThe point of my issue is that when import statsmodels, it shouldn't execute this statement:\r\n```python\r\nfrom statsmodels.tools._testing import PytestTester\r\n```\r\nBecause it will activate a `fork()` system call.\r\nIt is a waste of resource.  And some tcp relative libraries may recreate a connection after `fork()`.\n`import statsmodels.api` should trigger `import statsmodels.__init__`\r\nso it will also import the pytester.\r\nsomething sounds strange here.\r\n\r\nchecking some details.\r\n\r\n`statsmodels.__init__` uses a lazy import of Pytester in a `test` function just to avoid the unconditional import.\r\nHowever, `statsmodels.compat.__init__` is called to have the monkeypatch, and that module does not have a lazy import.\r\n\r\nWe could make the import also lazy in `statsmodels.compat.__init__`.\r\nHowever, what's the point?  Any usage of statsmodels (except for the plain `import statsmodels`) will trigger the Pytester import. It's supposed to be in every `__init__` of a subdirectory and will be imported before importing any useful function or class.\r\n\r\n", "created_at": "2024-06-25T09:07:44Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9280, "instance_id": "statsmodels__statsmodels-9280", "issue_numbers": ["9191"], "base_commit": "52edda81159e557dd845cc97a8a9324915c69792", "patch": "diff --git a/statsmodels/iolib/summary2.py b/statsmodels/iolib/summary2.py\nindex d874096a29e..041ced1bce3 100644\n--- a/statsmodels/iolib/summary2.py\n+++ b/statsmodels/iolib/summary2.py\n@@ -471,7 +471,8 @@ def _make_unique(list_of_names):\n \n def summary_col(results, float_format='%.4f', model_names=(), stars=False,\n                 info_dict=None, regressor_order=(), drop_omitted=False,\n-                include_r2=True):\n+                include_r2=True, fixed_effects=None, fe_present='Yes',\n+                fe_absent=''):\n     \"\"\"\n     Summarize multiple results instances side-by-side (coefs and SEs)\n \n@@ -504,6 +505,14 @@ def summary_col(results, float_format='%.4f', model_names=(), stars=False,\n         If True, only regressors in regressor_order will be included.\n     include_r2 : bool, optional\n         Includes R2 and adjusted R2 in the summary table.\n+    fixed_effects : list[str], optional\n+        List of categorical variables for which to indicate presence of\n+        fixed effects.\n+    fe_present : str, optional\n+        String to indicate the presence of fixed effects. Default is \"Yes\".\n+    fe_absent : str, optional\n+        String to indicate the absence of fixed effects. Default is empty\n+        string.\n     \"\"\"\n \n     if not isinstance(results, list):\n@@ -562,6 +571,19 @@ def merg(x, y):\n             idx.append(index[i + 1])\n     summ.index = idx\n \n+    # add fixed effects info\n+    if fixed_effects:\n+        if not info_dict:\n+            info_dict = {}\n+\n+        for fe in fixed_effects:\n+            info_dict[fe + ' FE'] = (\n+                lambda x, fe=fe, fe_present=fe_present, fe_absent=fe_absent:\n+                    fe_present\n+                    if any((f'C({fe})' in param) for param in x.params.index)\n+                    else fe_absent\n+                )\n+\n     # add infos about the models.\n     if info_dict:\n         cols = [_col_info(x, info_dict.get(x.model.__class__.__name__,\n@@ -581,6 +603,21 @@ def merg(x, y):\n \n     summ = summ.fillna('')\n \n+    # fixed effects processing\n+    if fixed_effects:\n+        index_series = pd.Series(summ.index, index=summ.index)\n+        skip_flag = index_series.apply(\n+            lambda x: any((f'C({fe})' in x) for fe in fixed_effects)\n+            )\n+        skip_next_flag = skip_flag.shift(fill_value=False)\n+        final_skip = skip_flag | skip_next_flag\n+        summ = summ[~final_skip]\n+\n+        r_squared_rows = summ.index[summ.index.str.contains('R-squared')]\n+        r_squared_section = summ.loc[r_squared_rows]\n+        summ = summ.drop(index=r_squared_rows)\n+        summ = pd.concat([summ, r_squared_section])\n+\n     smry = Summary()\n     smry._merge_latex = True\n     smry.add_df(summ, header=True, align='l')\n", "test_patch": "diff --git a/statsmodels/iolib/tests/test_summary2.py b/statsmodels/iolib/tests/test_summary2.py\nindex 4f756bbc3a1..fbc4e7bfcb6 100644\n--- a/statsmodels/iolib/tests/test_summary2.py\n+++ b/statsmodels/iolib/tests/test_summary2.py\n@@ -168,6 +168,72 @@ def test_OLSsummary(self):\n         result = string_to_find in actual\n         assert (result is True)\n \n+    def test_summarycol_fixed_effects(self):\n+        desired1 = r\"\"\"\n+======================================\n+               model_0 model_1 model_2\n+--------------------------------------\n+Intercept      1.35    1.32    1.48   \n+               (0.19)  (0.42)  (0.73) \n+yrs_married    -0.03   -0.02   -0.02  \n+               (0.00)  (0.00)  (0.00) \n+educ           -0.03   -0.02   -0.02  \n+               (0.01)  (0.02)  (0.02) \n+occupation FE          Yes     Yes    \n+religious FE           Yes     Yes    \n+R-squared      0.01    0.02    0.03   \n+R-squared Adj. 0.01    0.02    0.02   \n+======================================\n+Standard errors in parentheses.\"\"\"  # noqa:W291\n+\n+        desired2 = r\"\"\"\n+========================================\n+                     mod0   mod1   mod2 \n+----------------------------------------\n+Intercept           1.35   1.32   1.48  \n+                    (0.19) (0.42) (0.73)\n+yrs_married         -0.03  -0.02  -0.02 \n+                    (0.00) (0.00) (0.00)\n+educ                -0.03  -0.02  -0.02 \n+                    (0.01) (0.02) (0.02)\n+C(religious)[T.2.0]        -0.46  -0.86 \n+                           (0.08) (0.87)\n+C(religious)[T.3.0]        -0.66  -0.71 \n+                           (0.08) (1.13)\n+C(religious)[T.4.0]        -0.91  -0.92 \n+                           (0.11) (1.03)\n+occupation FE              Yes    Yes   \n+R-squared           0.01   0.02   0.03  \n+R-squared Adj.      0.01   0.02   0.02  \n+========================================\n+Standard errors in parentheses.\"\"\"  # noqa:W291\n+\n+        from statsmodels.datasets.fair import load_pandas\n+        df_fair = load_pandas().data\n+\n+        res0 = OLS.from_formula(\"affairs ~ yrs_married + educ\", df_fair).fit()\n+        form1 = \"affairs ~ yrs_married + educ + C(occupation) + C(religious)\"\n+        res1 = OLS.from_formula(form1, df_fair).fit()\n+        form2 = \"affairs ~ yrs_married + educ + C(occupation) : C(religious)\"\n+        res2 = OLS.from_formula(form2, df_fair).fit()\n+\n+        regressions = [res0, res1, res2]\n+        summary1 = summary_col(\n+            regressions,\n+            model_names=[f'model_{i}' for i, _ in enumerate(regressions)],\n+            fixed_effects=['occupation', \"religious\"],\n+            float_format='%0.2f',)\n+\n+        assert_equal(summary1.as_text(), desired1)\n+\n+        summary2 = summary_col(\n+            regressions,\n+            model_names=[f'mod{i}' for i, _ in enumerate(regressions)],\n+            fixed_effects=['occupation'],\n+            float_format='%0.2f',)\n+\n+        assert_equal(summary2.as_text(), desired2)\n+\n \n def test_ols_summary_rsquared_label():\n     # Check that the \"uncentered\" label is correctly added after rsquared\n", "problem_statement": "ENH: Add optional parameters for summary_col to indicate FEs\nResearchers tend to show they used categorical variables without all the coefficients, saying whether they included a fixed effect. This PR adds that feature.\r\n\r\n### Example\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport seaborn as sns\r\nimport statsmodels.formula.api as smf\r\nfrom statsmodels.iolib.summary2 import summary_col\r\n\r\n# Load the diamonds dataset\r\ndiamonds = sns.load_dataset('diamonds')\r\n\r\n# Adapted regressions for the diamonds dataset\r\nregressions = [\r\n    (smf.ols('np.log(price) ~ carat', data=diamonds).fit(), 'log(Price) ~ Carat'),\r\n    (smf.ols('np.log(price) ~ np.log(carat)', data=diamonds).fit(), 'log(Price) ~ log(Carat)'),\r\n    (smf.ols('np.log(price) ~ C(cut)', data=diamonds).fit(), 'log(Price) ~ C(Cut)'),\r\n    (smf.ols('np.log(price) ~ C(clarity)', data=diamonds).fit(), 'log(Price) ~ C(Clarity)'),\r\n    (smf.ols('np.log(price) ~ carat + C(cut) + C(clarity)', data=diamonds).fit(), 'log(Price) ~ Carat + C(Cut) + C(Clarity)')\r\n]\r\n\r\n# Output summary of all regressions\r\nsummary = summary_col([reg[0] for reg in regressions],\r\n                      model_names=[f'{i}. '+reg[1] for i, reg in enumerate(regressions, 1)]\r\n                    )\r\n\r\nsummary\r\n```\r\n\r\n<img width=\"971\" alt=\"Screenshot 2024-04-02 at 9 50 22\u202fPM\" src=\"https://github.com/statsmodels/statsmodels/assets/72167238/6b075616-c711-4fc2-a3fe-ccd0cf943ef2\">\r\n\r\n\r\nWith more complicated regressions or broader categories, this can quickly overwhelm the summary.\r\n\r\nNow, with amended function.\r\n\r\n```\r\n\"\"\"\r\nfixed_effects : list[str], optional\r\n        List of categorical variables for which to indicate presence of fixed effects.\r\nfe_present : str, optional\r\n    String to indicate the presence of fixed effects. Default is \"Yes\".\r\nfe_absent : str, optional\r\n    String to indicate the absence of fixed effects. Default is empty string.\r\n\"\"\"\r\n\r\nsummary = summary_col([reg[0] for reg in regressions],\r\n                      model_names=[f'{i}. '+reg[1] for i, reg in enumerate(regressions, 1)],\r\n                      fixed_effects=['cut', 'clarity'],\r\n                    )\r\n```\r\n\r\n<img width=\"997\" alt=\"Screenshot 2024-04-02 at 9 50 30\u202fPM\" src=\"https://github.com/statsmodels/statsmodels/assets/72167238/2ad0dec7-f678-418b-926f-de3708002966\">\r\n\r\n\r\nMuch more concise.\n", "hints_text": "", "created_at": "2024-06-14T15:39:28Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9270, "instance_id": "statsmodels__statsmodels-9270", "issue_numbers": ["9166"], "base_commit": "d02d785b618afc3ce79859b9417ea7c0165d89ea", "patch": "diff --git a/.github/workflows/emscripten.yml b/.github/workflows/emscripten.yml\nnew file mode 100644\nindex 00000000000..e5716b09018\n--- /dev/null\n+++ b/.github/workflows/emscripten.yml\n@@ -0,0 +1,68 @@\n+# Attributed to NumPy via https://github.com/numpy/numpy/pull/25894\n+# https://github.com/numpy/numpy/blob/d2d2c25fa81b47810f5cbd85ea6485eb3a3ffec3/.github/workflows/emscripten.yml\n+name: Test Emscripten/Pyodide build\n+\n+on:\n+  push:\n+    branches: [ 'main']\n+  pull_request:\n+    branches: [ 'main' ]\n+\n+# Cancel intermediate runs if a new run is queued\n+concurrency:\n+  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n+  cancel-in-progress: true\n+\n+jobs:\n+  build-wasm-emscripten:\n+    name: Build statsmodels distribution for Pyodide\n+    runs-on: ubuntu-latest\n+    env:\n+      PYODIDE_VERSION: 0.26.1\n+      # PYTHON_VERSION and EMSCRIPTEN_VERSION are determined by PYODIDE_VERSION.\n+      # The appropriate versions can be found in the Pyodide repodata.json\n+      # \"info\" field, or in Makefile.envs:\n+      # https://github.com/pyodide/pyodide/blob/main/Makefile.envs#L2\n+      PYTHON_VERSION: 3.12.1\n+      EMSCRIPTEN_VERSION: 3.1.58\n+      NODE_VERSION: 20\n+    steps:\n+    - name: Checkout statsmodels\n+      uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11  # v4.1.1\n+\n+    - name: Set up Python ${{ env.PYTHON_VERSION }}\n+      id: setup-python\n+      uses: actions/setup-python@0a5c61591373683505ea898e09a3ea4f39ef2b9c  # v5.0.0\n+      with:\n+        python-version: ${{ env.PYTHON_VERSION }}\n+\n+    - name: Set up Emscripten toolchain\n+      uses: mymindstorm/setup-emsdk@6ab9eb1bda2574c4ddb79809fc9247783eaf9021  # v14\n+      with:\n+        version: ${{ env.EMSCRIPTEN_VERSION }}\n+        actions-cache-folder: emsdk-cache\n+\n+    - name: Install pyodide-build\n+      run: pip install pyodide-build==${{ env.PYODIDE_VERSION }}\n+\n+    - name: Build statsmodels for Pyodide\n+      run: |\n+        # pass verbose option to pypa/build\n+        pyodide build -C=\"--global-option=--verbose\"\n+\n+    - name: Set up Node.js\n+      uses: actions/setup-node@60edb5dd545a775178f52524783378180af0d1f8  # v4.0.2\n+      with:\n+        node-version: ${{ env.NODE_VERSION }}\n+\n+    - name: Set up Pyodide virtual environment and test statsmodels for Pyodide\n+      run: |\n+        pyodide venv .venv-pyodide\n+\n+    - name: Install Pyodide package from npm registry\n+      run: npm install pyodide@${{ env.PYODIDE_VERSION }}\n+\n+    - name: Test statsmodels for Pyodide in activated virtual environment\n+      run: |\n+        source .venv-pyodide/bin/activate\n+        node tools/ci/run_statsmodels_test_suite.js\ndiff --git a/docs/source/install.rst b/docs/source/install.rst\nindex 5378e9189d1..35efa0c079b 100644\n--- a/docs/source/install.rst\n+++ b/docs/source/install.rst\n@@ -76,7 +76,7 @@ If your system is already set up with pip, a compiler, and git, you can try:\n \n     python -m pip install git+https://github.com/statsmodels/statsmodels\n \n-If you do not have pip installed or want to do the installation more manually,\n+If you do not have git installed or want to do the installation more manually,\n you can also type:\n \n .. code-block:: bash\n@@ -114,12 +114,16 @@ Python has been built using a variety of different Windows C compilers.\n `This guide <https://wiki.python.org/moin/WindowsCompilers>`_ should help\n clarify which version of Python uses which compiler by default.\n \n-Mac\n+macOS\n ^^^\n \n-Installing statsmodels on MacOS requires installing `gcc` which provides\n+Installing statsmodels on macOS requires installing `gcc` which provides\n a suitable C compiler. We recommend installing Xcode and the Command Line\n-Tools.\n+Tools, which can be done through the following command:\n+\n+.. code-block:: bash\n+\n+    xcode-select --install\n \n Dependencies\n ------------\n@@ -159,3 +163,13 @@ Optional Dependencies\n * `joblib <https://joblib.readthedocs.io/>`__ >= 1.0can be used to accelerate distributed\n   estimation for certain models.\n * `jupyter <https://jupyter.org/>`__ is needed to run the notebooks.\n+\n+The optional dependencies can be installed along with `statsmodels` by modifying\n+the installation command:\n+\n+.. code-block:: bash\n+\n+    python -m pip install statsmodels[extras]\n+\n+where ``<extras>`` is a comma-separated list of extras to install (``build``,\n+``develop``, ``docs``).\ndiff --git a/statsmodels/__init__.py b/statsmodels/__init__.py\nindex 8cc3679d687..419ab809630 100644\n--- a/statsmodels/__init__.py\n+++ b/statsmodels/__init__.py\n@@ -26,7 +26,7 @@ def test(extra_args=None, exit=False):\n         List of argument to pass to pytest when running the test suite. The\n         default is ['--tb=short', '--disable-pytest-warnings'].\n     exit : bool\n-        Flag indicating whether the test runner should exist when finished.\n+        Flag indicating whether the test runner should exit when finished.\n \n     Returns\n     -------\ndiff --git a/statsmodels/compat/__init__.py b/statsmodels/compat/__init__.py\nindex 0ac5c471210..83cda0ee87d 100644\n--- a/statsmodels/compat/__init__.py\n+++ b/statsmodels/compat/__init__.py\n@@ -1,7 +1,6 @@\n from statsmodels.tools._test_runner import PytestTester\n \n from .python import (\n-    PY37,\n     asunicode,\n     asbytes,\n     asstr,\n@@ -12,7 +11,6 @@\n )\n \n __all__ = [\n-    \"PY37\",\n     \"asunicode\",\n     \"asbytes\",\n     \"asstr\",\ndiff --git a/statsmodels/compat/python.py b/statsmodels/compat/python.py\nindex 8d473f5d237..9aa6c5d46a0 100644\n--- a/statsmodels/compat/python.py\n+++ b/statsmodels/compat/python.py\n@@ -1,10 +1,16 @@\n \"\"\"\n Compatibility tools for differences between Python 2 and 3\n \"\"\"\n+\n+import platform\n import sys\n from typing import Literal\n \n-PY37 = sys.version_info[:2] == (3, 7)\n+\n+PYTHON_IMPL_WASM = (\n+    sys.platform == \"emscripten\" or platform.machine() in [\"wasm32\", \"wasm64\"]\n+)\n+\n \n asunicode = lambda x, _: str(x)  # noqa:E731\n \n@@ -19,6 +25,7 @@\n     \"lrange\",\n     \"lfilter\",\n     \"with_metaclass\",\n+    \"PYTHON_IMPL_WASM\",\n ]\n \n \ndiff --git a/statsmodels/tools/tools.py b/statsmodels/tools/tools.py\nindex 36a61ba9ab6..38035fc275d 100644\n--- a/statsmodels/tools/tools.py\n+++ b/statsmodels/tools/tools.py\n@@ -18,17 +18,6 @@ def asstr2(s):\n         return str(s)\n \n \n-def _make_dictnames(tmp_arr, offset=0):\n-    \"\"\"\n-    Helper function to create a dictionary mapping a column number\n-    to the name in tmp_arr.\n-    \"\"\"\n-    col_map = {}\n-    for i, col_name in enumerate(tmp_arr):\n-        col_map[i + offset] = col_name\n-    return col_map\n-\n-\n def drop_missing(Y, X=None, axis=1):\n     \"\"\"\n     Returns views on the arrays Y and X where missing observations are dropped.\ndiff --git a/statsmodels/tsa/ardl/_pss_critical_values/pss-process.py b/statsmodels/tsa/ardl/_pss_critical_values/pss-process.py\nindex 6cd0fc75cd5..b67ab124302 100644\n--- a/statsmodels/tsa/ardl/_pss_critical_values/pss-process.py\n+++ b/statsmodels/tsa/ardl/_pss_critical_values/pss-process.py\n@@ -158,7 +158,7 @@ def setup_regressors(df, low_pow=3, high_pow=3, cut=70, log=False):\n crit_vals = {crit_vals}\n \"\"\"\n \n-    targets = {TargetVersion.PY37, TargetVersion.PY38, TargetVersion.PY39}\n+    targets = {TargetVersion.PY38, TargetVersion.PY39}\n     fm = FileMode(target_versions=targets, line_length=79)\n     formatted_code = format_file_contents(raw_code, fast=False, mode=fm)\n \n", "test_patch": "diff --git a/statsmodels/base/tests/test_generic_methods.py b/statsmodels/base/tests/test_generic_methods.py\nindex b4a3a1c2bb3..fd812fe6aa8 100644\n--- a/statsmodels/base/tests/test_generic_methods.py\n+++ b/statsmodels/base/tests/test_generic_methods.py\n@@ -16,6 +16,7 @@\n     PLATFORM_OSX,\n     PLATFORM_WIN32,\n )\n+from statsmodels.compat.python import PYTHON_IMPL_WASM\n from statsmodels.compat.scipy import SCIPY_GT_14\n \n import numpy as np\n@@ -160,6 +161,7 @@ def _get_constrained(self, keep_index, keep_index_p):\n             res = mod.fit(maxiter=500)\n         return res\n \n+\n     def test_zero_collinear(self):\n         # not completely generic yet\n         if isinstance(self.results.model, (sm.GEE)):\n@@ -194,9 +196,12 @@ def test_zero_collinear(self):\n             k_extra = mod.k_extra\n \n         # TODO: Can we choose a test case without this issue?\n-        #  If not, should we be getting this warning for all\n-        #  model subclasses?\n-        warn_cls = HessianInversionWarning if isinstance(mod, sm.GLM) else None\n+        # If not, should we be getting this warning for all\n+        # model subclasses?\n+        # TODO: Investigate how to resolve unseen warnings for Pyodide\n+        # Most likely coming from NumPy.linalg + lack of fp exceptions\n+        # support under WASM\n+        warn_cls = HessianInversionWarning if (isinstance(mod, sm.GLM) and not PYTHON_IMPL_WASM) else None\n \n         cov_types = ['nonrobust', 'HC0']\n \ndiff --git a/statsmodels/conftest.py b/statsmodels/conftest.py\nindex 9553a2f373d..098d4c68b49 100644\n--- a/statsmodels/conftest.py\n+++ b/statsmodels/conftest.py\n@@ -5,6 +5,8 @@\n import pandas as pd\n import pytest\n \n+from statsmodels.compat.python import PYTHON_IMPL_WASM\n+\n try:\n     import matplotlib\n \n@@ -141,3 +143,26 @@ def test_some_plot(reset_randomstate):\n     np.random.seed(1)\n     yield\n     np.random.set_state(state)\n+\n+\n+# This is a special hook that converts all xfail marks to have strict=False\n+# instead of strict=True. This is useful to have for Pyodide tests, where\n+# some tests will consistently xfail due to missing functionality (such as\n+# NotImplementedErrors) or floating point imprecisions, but we don't want\n+# to mark them as strict xfails because they are more prominently expected\n+# to fail in a Pyodide environment.\n+def pytest_collection_modifyitems(config, items):\n+    if PYTHON_IMPL_WASM:\n+        for item in items:\n+            if 'xfail' in item.keywords:\n+                mark = item.get_closest_marker('xfail')\n+                if mark:\n+                    # Modify the existing xfail mark if it exists\n+                    # to set strict=False\n+                    new_kwargs = dict(mark.kwargs)\n+                    new_kwargs['strict'] = False\n+                    new_mark = pytest.mark.xfail(**new_kwargs)\n+                    item.add_marker(new_mark)\n+                    item.keywords['xfail'] = new_mark\n+    else:\n+        pass\ndiff --git a/statsmodels/datasets/tests/test_utils.py b/statsmodels/datasets/tests/test_utils.py\nindex cf8458c8153..b4cdc0b4745 100644\n--- a/statsmodels/datasets/tests/test_utils.py\n+++ b/statsmodels/datasets/tests/test_utils.py\n@@ -1,18 +1,22 @@\n import os\n-from ssl import SSLError\n from socket import timeout\n+\n from urllib.error import HTTPError, URLError\n \n import numpy as np\n from numpy.testing import assert_, assert_array_equal\n import pytest\n \n+from statsmodels.compat.python import PYTHON_IMPL_WASM\n from statsmodels.datasets import get_rdataset, webuse, check_internet, utils\n \n-cur_dir = os.path.dirname(os.path.abspath(__file__))\n \n-IGNORED_EXCEPTIONS = (HTTPError, URLError, SSLError,  UnicodeEncodeError,\n-                      timeout)\n+CUR_DIR = os.path.dirname(os.path.abspath(__file__))\n+\n+IGNORED_EXCEPTIONS = (HTTPError, URLError, UnicodeEncodeError, timeout)\n+if not PYTHON_IMPL_WASM:\n+    from ssl import SSLError\n+    IGNORED_EXCEPTIONS += (SSLError,)\n \n \n @pytest.mark.smoke\n@@ -23,11 +27,11 @@ def test_get_rdataset():\n     if not internet_available:  # pragma: no cover\n         pytest.skip('Unable to retrieve file - skipping test')\n     try:\n-        duncan = get_rdataset(\"Duncan\", \"carData\", cache=cur_dir)\n+        duncan = get_rdataset(\"Duncan\", \"carData\", cache=CUR_DIR)\n     except IGNORED_EXCEPTIONS:\n         pytest.skip('Failed with HTTPError or URLError, these are random')\n     assert_(isinstance(duncan, utils.Dataset))\n-    duncan = get_rdataset(\"Duncan\", \"carData\", cache=cur_dir)\n+    duncan = get_rdataset(\"Duncan\", \"carData\", cache=CUR_DIR)\n     assert_(duncan.from_cache)\n \n \n@@ -35,19 +39,19 @@ def test_get_rdataset():\n def test_get_rdataset_write_read_cache():\n     # test writing and reading cache\n     try:\n-        guerry = get_rdataset(\"Guerry\", \"HistData\", cache=cur_dir)\n+        guerry = get_rdataset(\"Guerry\", \"HistData\", cache=CUR_DIR)\n     except IGNORED_EXCEPTIONS:\n         pytest.skip('Failed with HTTPError or URLError, these are random')\n \n     assert_(guerry.from_cache is False)\n-    guerry2 = get_rdataset(\"Guerry\", \"HistData\", cache=cur_dir)\n+    guerry2 = get_rdataset(\"Guerry\", \"HistData\", cache=CUR_DIR)\n     assert_(guerry2.from_cache is True)\n     fn = \"raw.githubusercontent.com,vincentarelbundock,Rdatasets,master,csv,\" \\\n          \"HistData,Guerry-v2.csv.zip\"\n-    os.remove(os.path.join(cur_dir, fn))\n+    os.remove(os.path.join(CUR_DIR, fn))\n     fn = \"raw.githubusercontent.com,vincentarelbundock,Rdatasets,master,doc,\" \\\n          \"HistData,rst,Guerry-v2.rst.zip\"\n-    os.remove(os.path.join(cur_dir, fn))\n+    os.remove(os.path.join(CUR_DIR, fn))\n \n \n def test_webuse():\ndiff --git a/statsmodels/distributions/tests/test_discrete.py b/statsmodels/distributions/tests/test_discrete.py\nindex f05b13d0d91..609198787e1 100644\n--- a/statsmodels/distributions/tests/test_discrete.py\n+++ b/statsmodels/distributions/tests/test_discrete.py\n@@ -4,6 +4,7 @@\n from scipy import stats\n from scipy.stats import poisson, nbinom\n \n+from statsmodels.compat.python import PYTHON_IMPL_WASM\n from statsmodels.tools.tools import Bunch\n \n from statsmodels.distributions.discrete import (\n@@ -330,6 +331,12 @@ def test_basic(self):\n         dfr = mod.get_distr(res.params)\n         nobs_rvs = 500\n         rvs = dfr.rvs(size=nobs_rvs)\n+        # TypeError: Cannot cast array data from dtype('int64') to\n+        # dtype('int32') according to the rule 'safe'.\n+        # To fix this, change the dtype of rvs to int32 so that it\n+        # can bepassed to np.bincount\n+        if PYTHON_IMPL_WASM:\n+            rvs = rvs.astype(np.int32)\n         freq = np.bincount(rvs)\n         p = mod.predict(res.params, which=\"probs\", k_max=nobs_rvs)\n         k = len(freq)\ndiff --git a/statsmodels/graphics/tests/test_functional.py b/statsmodels/graphics/tests/test_functional.py\nindex 36d487ff62c..b23a6e116c3 100644\n--- a/statsmodels/graphics/tests/test_functional.py\n+++ b/statsmodels/graphics/tests/test_functional.py\n@@ -2,6 +2,7 @@\n from numpy.testing import assert_almost_equal, assert_equal\n import pytest\n \n+from statsmodels.compat.python import PYTHON_IMPL_WASM\n from statsmodels.datasets import elnino\n from statsmodels.graphics.functional import (\n     banddepth,\n@@ -22,6 +23,10 @@\n data = data.raw_data[:, 1:]\n \n \n+@pytest.mark.skipif(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Matplotlib uses different backend in WASM\"\n+)\n @pytest.mark.matplotlib\n def test_hdr_basic(close_figures):\n     try:\n@@ -77,6 +82,10 @@ def test_hdr_basic_brute(close_figures, reset_randomstate):\n         pytest.xfail('Multiprocess randomly crashes in Windows testing')\n \n \n+@pytest.mark.skipif(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Multiprocessing is not supported in WASM/Pyodide\"\n+)\n @pytest.mark.slow\n @pytest.mark.matplotlib\n def test_hdr_plot(close_figures):\n@@ -96,6 +105,10 @@ def test_hdr_plot(close_figures):\n         pytest.xfail('Multiprocess randomly crashes in Windows testing')\n \n \n+@pytest.mark.skipif(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Multiprocessing is not supported in WASM/Pyodide\"\n+)\n @pytest.mark.slow\n @pytest.mark.matplotlib\n def test_hdr_alpha(close_figures):\n@@ -111,6 +124,10 @@ def test_hdr_alpha(close_figures):\n         pytest.xfail('Multiprocess randomly crashes in Windows testing')\n \n \n+@pytest.mark.skipif(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Multiprocessing is not supported in WASM/Pyodide\"\n+)\n @pytest.mark.slow\n @pytest.mark.matplotlib\n def test_hdr_multiple_alpha(close_figures):\n@@ -135,6 +152,10 @@ def test_hdr_multiple_alpha(close_figures):\n         pytest.xfail('Multiprocess randomly crashes in Windows testing')\n \n \n+@pytest.mark.skipif(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Multiprocessing is not supported in WASM/Pyodide\"\n+)\n @pytest.mark.slow\n @pytest.mark.matplotlib\n def test_hdr_threshold(close_figures):\n@@ -149,6 +170,10 @@ def test_hdr_threshold(close_figures):\n         pytest.xfail('Multiprocess randomly crashes in Windows testing')\n \n \n+@pytest.mark.skipif(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Multiprocessing is not supported in WASM/Pyodide\"\n+)\n @pytest.mark.matplotlib\n def test_hdr_bw(close_figures):\n     try:\n@@ -162,6 +187,10 @@ def test_hdr_bw(close_figures):\n         pytest.xfail('Multiprocess randomly crashes in Windows testing')\n \n \n+@pytest.mark.skipif(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Multiprocessing is not supported in WASM/Pyodide\"\n+)\n @pytest.mark.slow\n @pytest.mark.matplotlib\n def test_hdr_ncomp(close_figures):\ndiff --git a/statsmodels/graphics/tests/test_gofplots.py b/statsmodels/graphics/tests/test_gofplots.py\nindex b66469d8e08..a73dad05089 100644\n--- a/statsmodels/graphics/tests/test_gofplots.py\n+++ b/statsmodels/graphics/tests/test_gofplots.py\n@@ -5,6 +5,7 @@\n from scipy import stats\n \n import statsmodels.api as sm\n+from statsmodels.compat.python import PYTHON_IMPL_WASM\n from statsmodels.graphics import gofplots\n from statsmodels.graphics.gofplots import (\n     ProbPlot,\n@@ -70,6 +71,10 @@ def test_ppplot_other_array(self, close_figures):\n \n     @pytest.mark.xfail(strict=True)\n     @pytest.mark.matplotlib\n+    @pytest.mark.skipif(\n+        PYTHON_IMPL_WASM,\n+        reason=\"Matplotlib uses different backend in WASM/Pyodide\"\n+    )\n     def test_probplot_other_array(self, close_figures):\n         self.prbplt.probplot(\n             ax=self.ax,\n@@ -98,6 +103,10 @@ def test_ppplot_other_prbplt(self, close_figures):\n \n     @pytest.mark.xfail(strict=True)\n     @pytest.mark.matplotlib\n+    @pytest.mark.skipif(\n+        PYTHON_IMPL_WASM,\n+        reason=\"Matplotlib uses different backend in WASM/Pyodide\"\n+    )\n     def test_probplot_other_prbplt(self, close_figures):\n         self.prbplt.probplot(\n             ax=self.ax,\n@@ -174,6 +183,10 @@ def test_fit_params(self):\n         assert self.prbplt.fit_params[-1] == self.prbplt.scale\n \n \n+@pytest.mark.skipif(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Matplotlib uses different backend in WASM/Pyodide\"\n+)\n class TestProbPlotLongelyNoFit(BaseProbplotMixin):\n     def setup_method(self):\n         np.random.seed(5)\ndiff --git a/statsmodels/graphics/tests/test_tsaplots.py b/statsmodels/graphics/tests/test_tsaplots.py\nindex da8c9ed6ba5..41ef7e5457f 100644\n--- a/statsmodels/graphics/tests/test_tsaplots.py\n+++ b/statsmodels/graphics/tests/test_tsaplots.py\n@@ -10,6 +10,7 @@\n import pandas as pd\n import pytest\n \n+from statsmodels.compat.python import PYTHON_IMPL_WASM\n from statsmodels.datasets import elnino, macrodata\n from statsmodels.graphics.tsaplots import (\n     month_plot,\n@@ -242,6 +243,10 @@ def test_plot_accf_grid(close_figures):\n     plot_accf_grid(x, fig=fig, use_vlines=False)\n \n \n+@pytest.mark.skipif(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Matplotlib uses different backend in WASM\"\n+)\n @pytest.mark.matplotlib\n def test_plot_month(close_figures):\n     dta = elnino.load_pandas().data\ndiff --git a/statsmodels/stats/tests/test_multi.py b/statsmodels/stats/tests/test_multi.py\nindex 94519d9d314..7f63c7f5367 100644\n--- a/statsmodels/stats/tests/test_multi.py\n+++ b/statsmodels/stats/tests/test_multi.py\n@@ -17,6 +17,7 @@\n from numpy.testing import (assert_almost_equal, assert_equal,\n                            assert_allclose)\n \n+from statsmodels.compat.python import PYTHON_IMPL_WASM\n from statsmodels.stats.multitest import (multipletests, fdrcorrection,\n                                          fdrcorrection_twostage,\n                                          NullDistribution,\n@@ -26,6 +27,7 @@\n import scipy\n from packaging import version\n \n+\n pval0 = np.array([\n     0.838541367553,  0.642193923795,  0.680845947633,\n     0.967833824309,  0.71626938238,  0.177096952723,  5.23656777208e-005,\n@@ -423,6 +425,10 @@ def test_floating_precision(method):\n     assert multipletests(pvals, method=method)[1][0] > 1e-60\n \n \n+@pytest.mark.xfail(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Failing on Pyodide due to issues with scipy.optimize's solver\"\n+)\n def test_tukeyhsd():\n     # example multicomp in R p 83\n \ndiff --git a/statsmodels/stats/tests/test_pairwise.py b/statsmodels/stats/tests/test_pairwise.py\nindex be4ac4fd7bf..b138494919f 100644\n--- a/statsmodels/stats/tests/test_pairwise.py\n+++ b/statsmodels/stats/tests/test_pairwise.py\n@@ -4,7 +4,6 @@\n \n Author: Josef Perktold\n \"\"\"\n-from statsmodels.compat.python import asbytes\n \n from io import BytesIO\n import warnings\n@@ -15,6 +14,7 @@\n from numpy.testing import assert_, assert_allclose, assert_almost_equal, assert_equal, \\\n     assert_raises\n \n+from statsmodels.compat.python import PYTHON_IMPL_WASM, asbytes\n from statsmodels.stats.libqsturng import qsturng\n from statsmodels.stats.multicomp import (tukeyhsd, pairwise_tukeyhsd,\n                                          MultiComparison)\n@@ -196,6 +196,10 @@ def test_plot_simultaneous_ci(self, close_figures):\n         self.res.plot_simultaneous(comparison_name=reference)\n \n \n+@pytest.mark.xfail(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Failing on Pyodide due to issues with scipy.optimize's solver\"\n+)\n class TestTuckeyHSD2(CheckTuckeyHSDMixin):\n \n     @classmethod\n@@ -245,6 +249,10 @@ def test_table_names_custom_group_order(self):\n             assert_((first_group, second_group) == expected_order[i - 1])\n \n \n+@pytest.mark.xfail(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Failing on Pyodide due to issues with scipy.optimize's solver\"\n+)\n class TestTuckeyHSD2Pandas(TestTuckeyHSD2):\n \n     @classmethod\n@@ -302,6 +310,10 @@ def test_incorrect_output(self):\n                             err_msg=err_msg)\n \n \n+@pytest.mark.xfail(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Failing on Pyodide due to issues with scipy.optimize's solver\"\n+)\n class TestTuckeyHSD2s(CheckTuckeyHSDMixin):\n     @classmethod\n     def setup_class(cls):\n@@ -323,6 +335,10 @@ def setup_class(cls):\n         cls.reject2 = pvals < 0.01\n \n \n+@pytest.mark.xfail(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Failing on Pyodide due to issues with scipy.optimize's solver\"\n+)\n class TestTuckeyHSD3(CheckTuckeyHSDMixin):\n \n     @classmethod\n@@ -339,6 +355,10 @@ def setup_class(cls):\n         cls.reject2 = sas_['sig'] == asbytes('***')\n \n \n+@pytest.mark.xfail(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Failing on Pyodide due to issues with scipy.optimize's solver\"\n+)\n class TestTuckeyHSD4(CheckTuckeyHSDMixin):\n \n     @classmethod\ndiff --git a/statsmodels/stats/tests/test_rates_poisson.py b/statsmodels/stats/tests/test_rates_poisson.py\nindex ff57cef6bce..dd3ae8edb98 100644\n--- a/statsmodels/stats/tests/test_rates_poisson.py\n+++ b/statsmodels/stats/tests/test_rates_poisson.py\n@@ -6,6 +6,7 @@\n from scipy import stats\n \n # we cannot import test_poisson_2indep directly, pytest treats that as test\n+from statsmodels.compat.python import PYTHON_IMPL_WASM\n import statsmodels.stats.rates as smr\n from statsmodels.stats.rates import (\n     # test_poisson, # cannot import functions that start with test\n@@ -716,10 +717,13 @@ def test_test(self, meth, compare):\n         assert_allclose(tst2.pvalue, tst.pvalue, rtol=rtol)\n \n         # check corner case count2 = 0, see issue #8313\n-        with pytest.warns(RuntimeWarning):\n-            tst = smr.test_poisson_2indep(count1, n1, 0, n2, method=meth,\n-                                          compare=compare,\n-                                          value=None, alternative='two-sided')\n+        if not PYTHON_IMPL_WASM:  # No fp exception support in WASM\n+            with pytest.warns(RuntimeWarning):\n+                smr.test_poisson_2indep(\n+                    count1, n1, 0, n2, method=meth,\n+                    compare=compare,\n+                    value=None, alternative='two-sided'\n+                )\n \n     @pytest.mark.parametrize(\n         \"compare, meth\",\ndiff --git a/statsmodels/tests/test_package.py b/statsmodels/tests/test_package.py\nindex 95bf9380f64..4397fa6d3ab 100644\n--- a/statsmodels/tests/test_package.py\n+++ b/statsmodels/tests/test_package.py\n@@ -1,7 +1,15 @@\n import subprocess\n import sys\n \n+from statsmodels.compat.python import PYTHON_IMPL_WASM\n \n+import pytest\n+\n+\n+@pytest.mark.skipif(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Can't start subprocess in WASM/Pyodide\"\n+)\n def test_lazy_imports():\n     # Check that when statsmodels.api is imported, matplotlib is _not_ imported\n     cmd = (\"import statsmodels.api as sm; \"\n@@ -15,6 +23,10 @@ def test_lazy_imports():\n     assert rc == 0\n \n \n+@pytest.mark.skipif(\n+    PYTHON_IMPL_WASM,\n+    reason=\"Can't start subprocess in WASM/Pyodide\"\n+)\n def test_docstring_optimization_compat():\n     # GH#5235 check that importing with stripped docstrings does not raise\n     cmd = sys.executable + ' -OO -c \"import statsmodels.api as sm\"'\ndiff --git a/statsmodels/tools/_test_runner.py b/statsmodels/tools/_test_runner.py\nindex b805c55f184..c276da9d85b 100644\n--- a/statsmodels/tools/_test_runner.py\n+++ b/statsmodels/tools/_test_runner.py\n@@ -4,7 +4,6 @@\n \n import os\n import sys\n-from packaging.version import Version, parse\n \n \n class PytestTester:\n@@ -18,18 +17,15 @@ def __init__(self, package_path=None):\n         self.package_name = f.f_locals.get(\"__name__\", None)\n \n     def __call__(self, extra_args=None, exit=False):\n-        try:\n-            import pytest\n+        import pytest\n \n-            if not parse(pytest.__version__) >= Version(\"3.0\"):\n-                raise ImportError\n-            if extra_args is None:\n-                extra_args = [\"--tb=short\", \"--disable-pytest-warnings\"]\n-            cmd = [self.package_path] + extra_args\n-            print(\"Running pytest \" + \" \".join(cmd))\n-            status = pytest.main(cmd)\n-            if exit:\n-                print(f\"Exit status: {status}\")\n-                sys.exit(status)\n-        except ImportError:\n-            raise ImportError(\"pytest>=3 required to run the test\")\n+        if extra_args is None:\n+            extra_args = [\"--tb=short\", \"--disable-pytest-warnings\"]\n+        cmd = [self.package_path] + extra_args\n+        print(\"Running pytest \" + \" \".join(cmd))\n+        status = pytest.main(cmd)\n+        if exit:\n+            print(f\"Exit status: {status}\")\n+            sys.exit(status)\n+\n+        return (status == 0)\ndiff --git a/statsmodels/tsa/tests/test_stattools.py b/statsmodels/tsa/tests/test_stattools.py\nindex b9427bad717..064ddad0d76 100644\n--- a/statsmodels/tsa/tests/test_stattools.py\n+++ b/statsmodels/tsa/tests/test_stattools.py\n@@ -20,6 +20,7 @@\n from scipy import stats\n from scipy.interpolate import interp1d\n \n+from statsmodels.compat.python import PYTHON_IMPL_WASM\n from statsmodels.datasets import macrodata, modechoice, nile, randhie, sunspots\n from statsmodels.tools.sm_exceptions import (\n     CollinearityWarning,\n@@ -349,6 +350,10 @@ def test_yw(self):\n         pacfyw = pacf_yw(self.x, nlags=40, method=\"mle\")\n         assert_almost_equal(pacfyw[1:], self.pacfyw, DECIMAL_8)\n \n+    @pytest.mark.skipif(\n+        PYTHON_IMPL_WASM,\n+        reason=\"No fp exception support in WASM\"\n+    )\n     def test_yw_singular(self):\n         with pytest.warns(ValueWarning):\n             pacf(np.ones(30), nlags=6)\n@@ -1084,7 +1089,6 @@ def test_arma_order_select_ic():\n     arparams = np.array([0.75, -0.25])\n     maparams = np.array([0.65, 0.35])\n     arparams = np.r_[1, -arparams]\n-    maparam = np.r_[1, maparams]  # FIXME: Never used\n     nobs = 250\n     np.random.seed(2014)\n     y = arma_generate_sample(arparams, maparams, nobs)\ndiff --git a/tools/ci/run_statsmodels_test_suite.js b/tools/ci/run_statsmodels_test_suite.js\nnew file mode 100644\nindex 00000000000..03460d672e5\n--- /dev/null\n+++ b/tools/ci/run_statsmodels_test_suite.js\n@@ -0,0 +1,55 @@\n+// A JavaScript file to run the statsmodels test suite using Pyodide\n+// This file is used by the GitHub Actions workflow to run the tests\n+// against the Pyodide build of statsmodels defined in emscripten.yml.\n+\n+// The contents of this file are attributed to the scikit-learn developers,\n+// who have a similar file in their repository:\n+// https://github.com/scikit-learn/scikit-learn/blob/main/build_tools/azure/pytest-pyodide.js\n+\n+\n+const { opendir } = require('node:fs/promises');\n+const { loadPyodide } = require(\"pyodide\");\n+\n+async function main() {\n+    let exit_code = 0;\n+    try {\n+        global.pyodide = await loadPyodide();\n+        let pyodide = global.pyodide;\n+\n+        let mountDir = \"/mnt\";\n+        pyodide.FS.mkdir(mountDir);\n+        pyodide.FS.mount(pyodide.FS.filesystems.NODEFS, { root: \".\" }, mountDir);\n+\n+        await pyodide.loadPackage([\"micropip\"]);\n+        await pyodide.runPythonAsync(`\n+            import glob\n+            import micropip\n+\n+            wheels = glob.glob(\"/mnt/dist/*.whl\")\n+            wheels = [f'emfs://{wheel}' for wheel in wheels]\n+            print(f\"Installing wheels: {wheels}\")\n+            await micropip.install(wheels);\n+\n+            pkg_list = micropip.list()\n+            print(pkg_list)\n+        `);\n+\n+\n+        await pyodide.runPythonAsync(\"import micropip; micropip.install('pytest')\");\n+        await pyodide.runPythonAsync(\"import micropip; micropip.install('pytest-cov')\");\n+        await pyodide.runPythonAsync(\"import micropip; micropip.install('matplotlib')\");\n+        await pyodide.runPython(`\n+        import sys\n+        import statsmodels\n+        result = statsmodels.test(['-ra', '--skip-examples', '--skip-slow'], exit=True)\n+        sys.exit(result)\n+        `);\n+    } catch (e) {\n+        console.error(e);\n+        exit_code = e.status;\n+    } finally {\n+        process.exit(exit_code);\n+    }\n+}\n+\n+main();\ndiff --git a/tools/ci/run_test.bat b/tools/ci/run_test.bat\nindex b09774fd1dc..8d67f29edfc 100644\n--- a/tools/ci/run_test.bat\n+++ b/tools/ci/run_test.bat\n@@ -14,7 +14,7 @@ mkdir test-run\n cd test-run\n @echo PYTEST_DIRECTIVES is not defined, testing using install\n @echo Running test from %CD%\n-@echo python -c \"import statsmodels;statsmodels.test(['-r s', '-n 2', '--skip-examples'], exit=True)\n-python -c \"import statsmodels;statsmodels.test(['-r s', '-n 2', '--skip-examples'], exit=True)\n+@echo python -c \"import statsmodels;statsmodels.test(['-r s', '-n 2', '--skip-examples'], exit=True)\"\n+python -c \"import statsmodels;statsmodels.test(['-r s', '-n 2', '--skip-examples'], exit=True)\"\n \n :End\n", "problem_statement": "Feature request: out-of-tree Pyodide builds for `statsmodels`\n#### Is your feature request related to a problem? Please describe\r\n\r\nHi there! I am opening this feature request to gauge ideas and comments about out-of-tree Pyodide builds, i.e., wasm32 wheels via [the Emscripten toolchain](https://emscripten.org/) for `statsmodels`. In my most recent work assignment, I am working on improving the interoperability for the Scientific Python ecosystem of packages with Pyodide and with each other, which shall culminate with efforts towards bringing interactive documentation for these packages where they can then be run in [JupyterLite notebooks](https://jupyter.org/try-jupyter/lab/index.html), through nightly builds and wheels for these packages pushed to PyPI-like indices on Anaconda, at and during a later phase during the project.\r\n\r\nIt looks like in-tree builds in the Pyodide have been built in the past as noted by the conversations in https://github.com/statsmodels/statsmodels/issues/7956 \u2013  and they seem to be maintained with every release for Pyodide. However, this issue proposes out-of-tree builds for `statsmodels` on its own CI and build infrastructure. I would be glad to work on this for `statsmodels`.\r\n\r\n#### Describe the solution you'd like\r\n\r\n1. A CI pipeline on Azure Pipelines or GitHub Actions (I would prefer the latter, but I have no qualms with the former) where Emscripten/Pyodide builds for the development version of `statsmodels` are pursued\r\n2. Testing the built wheels against a Pyodide wasm32 runtime virtual environment within the same workflow\r\n3. Fixing up and skipping failing tests as necessary based on current Pyodide limitations and ensuring that all relevant test cases pass\r\n\r\n#### Describe alternatives you have considered\r\n\r\nN/A\r\n\r\n#### Additional context\r\n\r\nThis project is being tracked at https://github.com/Quansight-Labs/czi-scientific-python-mgmt/issues/18 and has started out with packages like PyWavelets (https://github.com/PyWavelets/pywt/pull/701) and NumPy (https://github.com/numpy/numpy/pull/25894) being complete, thanks to @rgommers. Other packages besides `statsmodels`, such as `matplotlib`, `zarr`, `pandas`, and many more are planned to follow suit soon in the coming months.\n", "hints_text": "Someone who had significant time would need to contribute this.  The core team is pretty small and mostly focused on quality and new features. \n> Someone who had significant time would need to contribute this. The core team is pretty small and mostly focused on quality and new features.\r\n\r\nIndeed, I would be happy to start working on this (I edited the issue description a bit in the time you responded). It might be a long ordeal given that this is to be done from the ground up \u2013 but as long as someone can help out with code review and suggestions, that would help streamline the process.\nI\"m happy to try and help.  I have no idea what the process looks like since we \r\n\r\n* Have templated cython code\r\n* Link to SciPy provided blas\r\n* Require patsy and pandas\r\n\nThanks for sharing, @bashtage. The compilation procedure should take care of Cythonizing and building wasm32-compatible shared object files, but I am not sure about how to get a BLAS distribution on WASM working (xref: https://github.com/OpenMathLib/OpenBLAS/issues/4023). The requirements should be partly satisfied, since `patsy==0.5.3` and `pandas==1.5.3` exist in the current Pyodide packages[^1], but from the [`requirements.txt` file](https://github.com/statsmodels/statsmodels/blob/main/requirements.txt) it looks like I will have to get `patsy` bumped to `0.5.6` \u2013 let me see how that goes. It does look like [the `patsy` project](https://github.com/pydata/patsy) is no longer developed actively, but they are trying to keep compatibility for newer Python versions and for their dependents, and version `0.5.6` came out last month \u2013 I will hope it is trivial to bump that for Pyodide.\r\n\r\nEdit: [`patsy==0.5.6` is out](https://github.com/pyodide/pyodide/blob/main/packages/patsy/meta.yaml) in the development branch for Pyodide, all we need is to wait for a release from their end.\r\n\r\n[^1]: https://pyodide.org/en/stable/usage/packages-in-pyodide.html\nThe use of `scipy.linalg.cython_blas` is the interesting one here I guess - I don't know yet how that works in the Pyodide build, just that it should work in principle because statsmodels and scikit-learn are both using that and are packaged in Pyodide. I'll note that it doesn't specifically require OpenBLAS; any BLAS library will do (and IIRC Pyodide used reference BLAS; getting OpenBLAS to work is about improving performance only).\r\n\r\n@agriyakhetarpal maybe you can look into how this works in the in-tree Pyodide build for statsmodels? CI logs, code comments and/or patches may show that. The first questions I would ask are:\r\n- is `scipy/linalg/cython_blas.pxd` shipped inside a Pyodide-provided SciPy wheel?\r\n- if so, does the build use that, or does it use the `cython_blas.pxd` from a native (i.e., for the architecture of the build machine, usually x86-64) `scipy` package and rely on the` .pxd` file contents being the same between x86-64 and wasm32?\n> but as long as someone can help out with code review and suggestions, that would help streamline the process.\r\n\r\nFor the record, I can help with this. I even still have my statsmodels commit rights, although I haven't exercised them in a long time.", "created_at": "2024-06-06T11:26:25Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9255, "instance_id": "statsmodels__statsmodels-9255", "issue_numbers": ["9254"], "base_commit": "bf91082711ce95a5bbca557c4d9ab79afb990dbd", "patch": "diff --git a/statsmodels/stats/rates.py b/statsmodels/stats/rates.py\nindex dd6654c7f48..8b226c9be42 100644\n--- a/statsmodels/stats/rates.py\n+++ b/statsmodels/stats/rates.py\n@@ -186,15 +186,15 @@ def test_poisson(count, nobs, value, method=None, alternative=\"two-sided\",\n     return res\n \n \n-def confint_poisson(count, exposure, method=None, alpha=0.05):\n+def confint_poisson(count, exposure, method=None, alpha=0.05,\n+                    alternative=\"two-sided\"):\n     \"\"\"Confidence interval for a Poisson mean or rate\n \n     The function is vectorized for all methods except \"midp-c\", which uses\n     an iterative method to invert the hypothesis test function.\n \n     All current methods are central, that is the probability of each tail is\n-    smaller or equal to alpha / 2. The one-sided interval limits can be\n-    obtained by doubling alpha.\n+    smaller or equal to alpha / 2.\n \n     Parameters\n     ----------\n@@ -209,10 +209,16 @@ def confint_poisson(count, exposure, method=None, alpha=0.05):\n     alpha : float in (0, 1)\n         Significance level, nominal coverage of the confidence interval is\n         1 - alpha.\n+    alternative : {\"two-sider\", \"larger\", \"smaller\")\n+        default: \"two-sided\"\n+        Specifies whether to calculate a two-sided or one-sided confidence\n+        interval.\n \n     Returns\n     -------\n     tuple (low, upp) : confidence limits.\n+        When alternative is not \"two-sided\", lower or upper bound is set to\n+        0 or inf respectively.\n \n     Notes\n     -----\n@@ -270,7 +276,12 @@ def confint_poisson(count, exposure, method=None, alpha=0.05):\n     \"\"\"\n     n = exposure  # short hand\n     rate = count / exposure\n-    alpha = alpha / 2  # two-sided\n+\n+    if alternative == 'two-sided':\n+        alpha = alpha / 2\n+    elif alternative not in ['larger', 'smaller']:\n+        raise NotImplementedError(\n+            f\"alternative {alternative} is not available\")\n \n     if method is None:\n         msg = \"method needs to be specified, currently no default method\"\n@@ -365,6 +376,11 @@ def confint_poisson(count, exposure, method=None, alpha=0.05):\n     else:\n         raise ValueError(\"unknown method %s\" % method)\n \n+    if alternative == \"larger\":\n+        ci = (0, ci[1])\n+    elif alternative == \"smaller\":\n+        ci = (ci[0], np.inf)\n+\n     ci = (np.maximum(ci[0], 0), ci[1])\n     return ci\n \n", "test_patch": "diff --git a/statsmodels/stats/tests/test_rates_poisson.py b/statsmodels/stats/tests/test_rates_poisson.py\nindex 28baefb9757..ff57cef6bce 100644\n--- a/statsmodels/stats/tests/test_rates_poisson.py\n+++ b/statsmodels/stats/tests/test_rates_poisson.py\n@@ -1146,3 +1146,24 @@ def test_power_negbin():\n \n     assert_allclose(pow_p, pow1, atol=5e-2)\n     assert_allclose(pow_p, pow_, rtol=1e-13)\n+\n+\n+@pytest.mark.parametrize('count',    [0, 1, 10, 100])\n+@pytest.mark.parametrize('exposure', [1, 10, 100, 1000])\n+@pytest.mark.parametrize('alpha',    [0.01, 0.05, 0.1])\n+@pytest.mark.parametrize('method',\n+                         method_names_poisson_1samp['confint'])\n+@pytest.mark.parametrize('alternative', ['larger', 'smaller'])\n+def test_confint_poisson_alternative(count, exposure, method, alpha,\n+                                     alternative):\n+    # regression test\n+    two_sided_ci = confint_poisson(count, exposure, method=method,\n+                                   alpha=alpha * 2, alternative='two-sided')\n+    one_sided_ci = confint_poisson(count, exposure, method=method,\n+                                   alpha=alpha, alternative=alternative)\n+    if alternative == 'larger':\n+        two_sided_ci = (0, two_sided_ci[1])\n+        assert_allclose(one_sided_ci, two_sided_ci, rtol=1e-12)\n+    elif alternative == 'smaller':\n+        two_sided_ci = (two_sided_ci[0], np.inf)\n+        assert_allclose(one_sided_ci, two_sided_ci, rtol=1e-12)\n", "problem_statement": "ENH: confint_poisson only has two-sided confidence intervals\nhttps://www.statsmodels.org/dev/generated/statsmodels.stats.rates.confint_poisson.html\r\n\r\nconfint_poisson does not have an one-sided confidence interval option.\r\nAs mentioned in #9249, add a new option 'alternative' to confint_poisson.\r\n\r\nMaybe same for multinomial_proportions_confint, later.\n", "hints_text": "for docstrings: \r\nI will come up with a short explanation for the meaning and direction of alternative option for confidence intervals. Then, we can copy it to all confint functions that have the alternative keyword.\r\n\none sided confint for multinomial_proportions_confint will, most likely, not be obvious and we might have to check with the original articles.\nFor docstrings, should we create a new issue and PR like 'DOCS: XXX'?", "created_at": "2024-05-26T00:37:06Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9249, "instance_id": "statsmodels__statsmodels-9249", "issue_numbers": ["9239"], "base_commit": "85fef91bdbde9c90be0055fb712459f6860861f8", "patch": "diff --git a/statsmodels/stats/proportion.py b/statsmodels/stats/proportion.py\nindex f9901d80e8b..1ae0135f693 100644\n--- a/statsmodels/stats/proportion.py\n+++ b/statsmodels/stats/proportion.py\n@@ -108,7 +108,7 @@ def _bisection_search_conservative(\n     return best_pt, best\n \n \n-def proportion_confint(count, nobs, alpha:float=0.05, method=\"normal\"):\n+def proportion_confint(count, nobs, alpha:float=0.05, method=\"normal\", alternative:str='two-sided'):\n     \"\"\"\n     Confidence interval for a binomial proportion\n \n@@ -133,11 +133,16 @@ def proportion_confint(count, nobs, alpha:float=0.05, method=\"normal\"):\n          - `jeffreys` : Jeffreys Bayesian Interval\n          - `binom_test` : Numerical inversion of binom_test\n \n+    alternative : {\"two-sided\", \"larger\", \"smaller\"}\n+        default: \"two-sided\"\n+        specifies whether to calculate a two-sided or one-sided confidence interval.\n+\n     Returns\n     -------\n     ci_low, ci_upp : {float, ndarray, Series DataFrame}\n-        lower and upper confidence level with coverage (approximately) 1-alpha.\n+        larger and smaller confidence level with coverage (approximately) 1-alpha.\n         When a pandas object is returned, then the index is taken from `count`.\n+        When side is not \"two-sided\", lower or upper bound is set to 0 or 1 respectively.\n \n     Notes\n     -----\n@@ -188,21 +193,24 @@ def _check(x: np.ndarray, name: str) -> np.ndarray:\n         nobs_a = _check(np.asarray(nobs_a), \"count\")\n \n     q_ = count_a / nobs_a\n-    alpha_2 = 0.5 * alpha\n+\n+\n+    if alternative == 'two-sided':\n+        if method != \"binom_test\":\n+            alpha = alpha / 2.0\n+    elif alternative not in ['larger', 'smaller']:\n+        raise NotImplementedError(f\"alternative {alternative} is not available\")\n \n     if method == \"normal\":\n         std_ = np.sqrt(q_ * (1 - q_) / nobs_a)\n-        dist = stats.norm.isf(alpha / 2.0) * std_\n+        dist = stats.norm.isf(alpha) * std_\n         ci_low = q_ - dist\n         ci_upp = q_ + dist\n-    elif method == \"binom_test\":\n-        # inverting the binomial test\n+    elif method == \"binom_test\" and alternative == 'two-sided':\n         def func_factory(count: int, nobs: int) -> Callable[[float], float]:\n             if hasattr(stats, \"binomtest\"):\n-\n                 def func(qi):\n                     return stats.binomtest(count, nobs, p=qi).pvalue - alpha\n-\n             else:\n                 # Remove after min SciPy >= 1.7\n                 def func(qi):\n@@ -258,9 +266,9 @@ def func(qi):\n                 ci_upp.flat[index] = 1 - ci_low.flat[index]\n                 ci_low.flat[index] = 1 - temp\n             index = bcast.index\n-    elif method == \"beta\":\n-        ci_low = stats.beta.ppf(alpha_2, count_a, nobs_a - count_a + 1)\n-        ci_upp = stats.beta.isf(alpha_2, count_a + 1, nobs_a - count_a)\n+    elif method == \"beta\" or (method == \"binom_test\" and alternative != 'two-sided'):\n+        ci_low = stats.beta.ppf(alpha, count_a, nobs_a - count_a + 1)\n+        ci_upp = stats.beta.isf(alpha, count_a + 1, nobs_a - count_a)\n \n         if np.ndim(ci_low) > 0:\n             ci_low.flat[q_.flat == 0] = 0\n@@ -269,7 +277,7 @@ def func(qi):\n             ci_low = 0 if q_ == 0 else ci_low\n             ci_upp = 1 if q_ == 1 else ci_upp\n     elif method == \"agresti_coull\":\n-        crit = stats.norm.isf(alpha / 2.0)\n+        crit = stats.norm.isf(alpha)\n         nobs_c = nobs_a + crit**2\n         q_c = (count_a + crit**2 / 2.0) / nobs_c\n         std_c = np.sqrt(q_c * (1.0 - q_c) / nobs_c)\n@@ -277,7 +285,7 @@ def func(qi):\n         ci_low = q_c - dist\n         ci_upp = q_c + dist\n     elif method == \"wilson\":\n-        crit = stats.norm.isf(alpha / 2.0)\n+        crit = stats.norm.isf(alpha)\n         crit2 = crit**2\n         denom = 1 + crit2 / nobs_a\n         center = (q_ + crit2 / (2 * nobs_a)) / denom\n@@ -289,9 +297,8 @@ def func(qi):\n         ci_upp = center + dist\n     # method adjusted to be more forgiving of misspellings or incorrect option name\n     elif method[:4] == \"jeff\":\n-        ci_low, ci_upp = stats.beta.interval(\n-            1 - alpha, count_a + 0.5, nobs_a - count_a + 0.5\n-        )\n+        ci_low = stats.beta.ppf(alpha, count_a + 0.5, nobs_a - count_a + 0.5)\n+        ci_upp = stats.beta.isf(alpha, count_a + 0.5, nobs_a - count_a + 0.5)\n     else:\n         raise NotImplementedError(f\"method {method} is not available\")\n     if method in [\"normal\", \"agresti_coull\"]:\n@@ -301,6 +308,10 @@ def func(qi):\n         container = pd.Series if isinstance(count, pd.Series) else pd.DataFrame\n         ci_low = container(ci_low, index=count.index)\n         ci_upp = container(ci_upp, index=count.index)\n+    if alternative == 'larger':\n+        ci_low = 0\n+    elif alternative == 'smaller':\n+        ci_upp = 1\n     if is_scalar:\n         return float(ci_low), float(ci_upp)\n     return ci_low, ci_upp\n", "test_patch": "diff --git a/statsmodels/stats/tests/test_proportion.py b/statsmodels/stats/tests/test_proportion.py\nindex 360c422e0f2..1e47c2b9b9c 100644\n--- a/statsmodels/stats/tests/test_proportion.py\n+++ b/statsmodels/stats/tests/test_proportion.py\n@@ -995,3 +995,67 @@ def test_ci_symmetry_array(count, method):\n     a = proportion_confint([count, count], n, method=method)\n     b = proportion_confint([n - count, n - count], n, method=method)\n     assert_allclose(np.array(a), 1.0 - np.array(b[::-1]))\n+\n+\n+@pytest.mark.parametrize(\"count, nobs, alternative, expected\", [\n+    (1, 1, 'two-sided', [1.0, 1.0]),\n+    (0, 1, 'two-sided', [0.0, 0.0]),\n+    (1, 1, 'larger',   [0.0, 1.0]),\n+    (0, 1, 'larger',   [0.0, 0.0]),\n+    (1, 1, 'smaller',    [1.0, 1.0]),\n+    (0, 1, 'smaller',    [0.0, 1.0]),\n+])\n+def test_proportion_confint_edge(count, nobs, alternative, expected):\n+    # test against R 4.3.3 / DescTools / BinomCI and binom.test\n+    ci_low, ci_upp = proportion_confint(count, nobs, alternative=alternative)\n+    assert_allclose(np.array([ci_low, ci_upp]), np.array(expected))\n+\n+\n+@pytest.mark.parametrize(\"count\", [100])\n+@pytest.mark.parametrize(\"nobs\", [200])\n+@pytest.mark.parametrize(\"method, alpha, alternative, expected\", [\n+    # two-sided\n+    (\"normal\",          0.05, \"two-sided\",  [0.4307048, 0.5692952]),\n+    (\"normal\",          0.01, \"two-sided\",  [0.4089307, 0.5910693]),\n+    (\"normal\",          0.10, \"two-sided\",  [0.4418456, 0.5581544]),\n+    (\"agresti_coull\",   0.05, \"two-sided\",  [0.4313609, 0.5686391]),\n+    (\"beta\",            0.05, \"two-sided\",  [0.4286584, 0.5713416]),\n+    (\"wilson\",          0.05, \"two-sided\",  [0.4313609, 0.5686391]),\n+    (\"jeffreys\",        0.05, \"two-sided\",  [0.4311217, 0.5688783]),\n+    # larger\n+    (\"normal\",          0.05, \"larger\",    [0.0, 0.5581544]),\n+    (\"agresti_coull\",   0.05, \"larger\",    [0.0, 0.557765]),\n+    (\"beta\",            0.05, \"larger\",    [0.0, 0.560359]),\n+    (\"wilson\",          0.05, \"larger\",    [0.0, 0.557765]),\n+    (\"jeffreys\",        0.05, \"larger\",    [0.0, 0.5578862]),\n+    # smaller\n+    (\"normal\",          0.05, \"smaller\",     [0.4418456, 1.0]),\n+    (\"agresti_coull\",   0.05, \"smaller\",     [0.442235, 1.0]),\n+    (\"beta\",            0.05, \"smaller\",     [0.439641, 1.0]),\n+    (\"wilson\",          0.05, \"smaller\",     [0.442235, 1.0]),\n+    (\"jeffreys\",        0.05, \"smaller\",     [0.4421138, 1.0]),\n+])\n+def test_proportion_confint(count, nobs, method, alpha, alternative, expected):\n+    # test against R 4.3.3 / DescTools / BinomCI and binom.test\n+    ci_low, ci_upp = proportion_confint(count, nobs, alpha=alpha, method=method, alternative=alternative)\n+    assert_allclose(np.array([ci_low, ci_upp]), np.array(expected))\n+\n+\n+@pytest.mark.parametrize(\"count\", [100])\n+@pytest.mark.parametrize(\"nobs\", [200])\n+@pytest.mark.parametrize(\"alpha, alternative, expected, rtol\", [\n+    # binom.exact with method=\"two.sided\" returns values with a precision of up to 4 decimal places.\n+    (0.01, \"two-sided\",  [0.4094, 0.5906],  1e-4),\n+    (0.05, \"two-sided\",  [0.4299, 0.5701],  1e-4),\n+    (0.10, \"two-sided\",  [0.44, 0.56],      1e-4),\n+    (0.01, \"larger\",    [0.0, 0.5840449],  1e-7),\n+    (0.05, \"larger\",    [0.0, 0.560359],   1e-7),\n+    (0.10, \"larger\",    [0.0, 0.5476422],  1e-7),\n+    (0.01, \"smaller\",     [0.4159551, 1.0],  1e-7),\n+    (0.05, \"smaller\",     [0.439641, 1.0],   1e-7),\n+    (0.10, \"smaller\",     [0.4523578, 1.0],  1e-7),\n+])\n+def test_proportion_confint_binom_test(count, nobs, alpha, alternative, expected, rtol):\n+    # test against R 4.3.3 / DescTools / exactci\n+    ci_low, ci_upp = proportion_confint(count, nobs, alpha=alpha, method=\"binom_test\", alternative=alternative)\n+    assert_allclose(np.array([ci_low, ci_upp]), np.array(expected), rtol=rtol)\n", "problem_statement": "ENH: proportion_confint only has two-sided confidence intervals, no \"alternative\" option\nsee\r\nhttps://stats.stackexchange.com/questions/646445/multinomial-one-sided-confidence-intervals\r\n\r\nsame for multinomial_proportions_confint\r\n\r\nI think for proportion_confint it should be just one interval at 2*alpha, except for \"beta-test\" which is minlike, and the one-sided will correspond to one side of equal-tail intervals.\r\n\r\nI don't have a guess on one-sided interval for multinomial_proportions_confint. (too long ago). But it might be based on an equal-tail derivation.\r\n\n", "hints_text": "@josef-pkt \r\nHi, Josef.\r\nI read the thread and agree that the one-sided interval is the same as one side of the two-sided interval for doubled alpha in a binomial distribution.\r\nCan I take this issue on propotion_confint to add an option to explicitly get one-sided ci?\nYes, we want to add the `alternative` option and include one sided intervals.\r\n\r\nNote, \"binomtest\" will have different one-sided intervals which should be easy to compute.\r\nThe will be the same as for the central, equal-tail binom test.\r\n\r\npull request would be welcome.\r\n", "created_at": "2024-05-19T14:51:31Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9240, "instance_id": "statsmodels__statsmodels-9240", "issue_numbers": ["9121"], "base_commit": "c22837f0632ae8890f56886460c429ebf356bd9b", "patch": "diff --git a/examples/notebooks/gls.ipynb b/examples/notebooks/gls.ipynb\nindex d19947ba6db..de5afc41591 100644\n--- a/examples/notebooks/gls.ipynb\n+++ b/examples/notebooks/gls.ipynb\n@@ -15,12 +15,12 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"import numpy as np\\n\",\n     \"\\n\",\n     \"import statsmodels.api as sm\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -37,12 +37,12 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"data = sm.datasets.longley.load()\\n\",\n     \"data.exog = sm.add_constant(data.exog)\\n\",\n     \"print(data.exog.head())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -64,10 +64,10 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"ols_resid = sm.OLS(data.endog, data.exog).fit().resid\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -90,14 +90,14 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"resid_fit = sm.OLS(\\n\",\n     \"    np.asarray(ols_resid)[1:], sm.add_constant(np.asarray(ols_resid)[:-1])\\n\",\n     \").fit()\\n\",\n     \"print(resid_fit.tvalues[1])\\n\",\n     \"print(resid_fit.pvalues[1])\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -115,10 +115,10 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"rho = resid_fit.params[1]\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -136,12 +136,12 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"from scipy.linalg import toeplitz\\n\",\n     \"\\n\",\n     \"toeplitz(range(5))\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -151,10 +151,10 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"order = toeplitz(range(len(ols_resid)))\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -168,12 +168,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"sigma = rho ** order\\n\",\n     \"gls_model = sm.GLS(data.endog, data.exog, sigma=sigma)\\n\",\n     \"gls_results = gls_model.fit()\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -188,12 +188,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"glsar_model = sm.GLSAR(data.endog, data.exog, 1)\\n\",\n     \"glsar_results = glsar_model.iterative_fit(1)\\n\",\n     \"print(glsar_results.summary())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -210,13 +210,13 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(gls_results.params)\\n\",\n     \"print(glsar_results.params)\\n\",\n     \"print(gls_results.bse)\\n\",\n     \"print(glsar_results.bse)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   }\n  ],\n  \"metadata\": {\ndiff --git a/examples/notebooks/influence_glm_logit.ipynb b/examples/notebooks/influence_glm_logit.ipynb\nindex ca371ebaadb..7a87d7b1cfe 100644\n--- a/examples/notebooks/influence_glm_logit.ipynb\n+++ b/examples/notebooks/influence_glm_logit.ipynb\n@@ -22,7 +22,6 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"import os.path\\n\",\n     \"import pandas as pd\\n\",\n@@ -33,7 +32,8 @@\n     \"\\n\",\n     \"plt.rc(\\\"figure\\\", figsize=(16, 8))\\n\",\n     \"plt.rc(\\\"font\\\", size=14)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -43,7 +43,6 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"import statsmodels.stats.tests.test_influence\\n\",\n     \"\\n\",\n@@ -53,7 +52,8 @@\n     \"file_name = \\\"binary_constrict.csv\\\"\\n\",\n     \"file_path = os.path.join(cur_dir, \\\"results\\\", file_name)\\n\",\n     \"df = pd.read_csv(file_path, index_col=0)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -63,7 +63,6 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"res = GLM(\\n\",\n     \"    df[\\\"constrict\\\"],\\n\",\n@@ -71,7 +70,8 @@\n     \"    family=families.Binomial(),\\n\",\n     \").fit(attach_wls=True, atol=1e-10)\\n\",\n     \"print(res.summary())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -92,10 +92,10 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"infl = res.get_influence(observed=False)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -105,11 +105,11 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"summ_df = infl.summary_frame()\\n\",\n     \"summ_df.sort_values(\\\"cooks_d\\\", ascending=False)[:10]\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -119,11 +119,11 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"fig = infl.plot_influence()\\n\",\n     \"fig.tight_layout(pad=1.0)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -133,11 +133,11 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"fig = infl.plot_index(y_var=\\\"cooks\\\", threshold=2 * infl.cooks_distance[0].mean())\\n\",\n     \"fig.tight_layout(pad=1.0)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -147,11 +147,11 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"fig = infl.plot_index(y_var=\\\"resid\\\", threshold=1)\\n\",\n     \"fig.tight_layout(pad=1.0)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -161,11 +161,11 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"fig = infl.plot_index(y_var=\\\"dfbeta\\\", idx=1, threshold=0.5)\\n\",\n     \"fig.tight_layout(pad=1.0)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -175,11 +175,11 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"fig = infl.plot_index(y_var=\\\"dfbeta\\\", idx=2, threshold=0.5)\\n\",\n     \"fig.tight_layout(pad=1.0)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -189,11 +189,11 @@\n      \"outputs_hidden\": false\n     }\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"fig = infl.plot_index(y_var=\\\"dfbeta\\\", idx=0, threshold=0.5)\\n\",\n     \"fig.tight_layout(pad=1.0)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -201,8 +201,8 @@\n    \"metadata\": {\n     \"tags\": []\n    },\n-   \"outputs\": [],\n-   \"source\": []\n+   \"source\": [],\n+   \"outputs\": []\n   }\n  ],\n  \"metadata\": {\ndiff --git a/examples/notebooks/ols.ipynb b/examples/notebooks/ols.ipynb\nindex f322cb1988d..3af23dcca56 100644\n--- a/examples/notebooks/ols.ipynb\n+++ b/examples/notebooks/ols.ipynb\n@@ -11,16 +11,15 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"%matplotlib inline\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"import matplotlib.pyplot as plt\\n\",\n     \"import numpy as np\\n\",\n@@ -28,7 +27,8 @@\n     \"import statsmodels.api as sm\\n\",\n     \"\\n\",\n     \"np.random.seed(9876789)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -43,14 +43,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"nsample = 100\\n\",\n     \"x = np.linspace(0, 10, 100)\\n\",\n     \"X = np.column_stack((x, x ** 2))\\n\",\n     \"beta = np.array([1, 0.1, 10])\\n\",\n     \"e = np.random.normal(size=nsample)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -63,11 +63,11 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"X = sm.add_constant(X)\\n\",\n     \"y = np.dot(X, beta) + e\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -80,12 +80,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"model = sm.OLS(y, X)\\n\",\n     \"results = model.fit()\\n\",\n     \"print(results.summary())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -98,11 +98,11 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(\\\"Parameters: \\\", results.params)\\n\",\n     \"print(\\\"R2: \\\", results.rsquared)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -117,7 +117,6 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"nsample = 50\\n\",\n     \"sig = 0.5\\n\",\n@@ -127,7 +126,8 @@\n     \"\\n\",\n     \"y_true = np.dot(X, beta)\\n\",\n     \"y = y_true + sig * np.random.normal(size=nsample)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -140,11 +140,11 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"res = sm.OLS(y, X).fit()\\n\",\n     \"print(res.summary())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -157,12 +157,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(\\\"Parameters: \\\", res.params)\\n\",\n     \"print(\\\"Standard errors: \\\", res.bse)\\n\",\n     \"print(\\\"Predicted values: \\\", res.predict())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -175,7 +175,6 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"pred_ols = res.get_prediction()\\n\",\n     \"iv_l = pred_ols.summary_frame()[\\\"obs_ci_lower\\\"]\\n\",\n@@ -189,7 +188,8 @@\n     \"ax.plot(x, iv_u, \\\"r--\\\")\\n\",\n     \"ax.plot(x, iv_l, \\\"r--\\\")\\n\",\n     \"ax.legend(loc=\\\"best\\\")\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -204,7 +204,6 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"nsample = 50\\n\",\n     \"groups = np.zeros(nsample, int)\\n\",\n@@ -222,7 +221,8 @@\n     \"y_true = np.dot(X, beta)\\n\",\n     \"e = np.random.normal(size=nsample)\\n\",\n     \"y = y_true + e\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -235,13 +235,13 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(X[:5, :])\\n\",\n     \"print(y[:5])\\n\",\n     \"print(groups)\\n\",\n     \"print(dummy[:5, :])\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -254,11 +254,11 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"res2 = sm.OLS(y, X).fit()\\n\",\n     \"print(res2.summary())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -271,7 +271,6 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"pred_ols2 = res2.get_prediction()\\n\",\n     \"iv_l = pred_ols2.summary_frame()[\\\"obs_ci_lower\\\"]\\n\",\n@@ -285,7 +284,8 @@\n     \"ax.plot(x, iv_u, \\\"r--\\\")\\n\",\n     \"ax.plot(x, iv_l, \\\"r--\\\")\\n\",\n     \"legend = ax.legend(loc=\\\"best\\\")\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -302,12 +302,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"R = [[0, 1, 0, 0], [0, 0, 1, 0]]\\n\",\n     \"print(np.array(R))\\n\",\n     \"print(res2.f_test(R))\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -320,10 +320,10 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(res2.f_test(\\\"x2 = x3 = 0\\\"))\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -338,32 +338,32 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"beta = [1.0, 0.3, -0.0, 10]\\n\",\n     \"y_true = np.dot(X, beta)\\n\",\n     \"y = y_true + np.random.normal(size=nsample)\\n\",\n     \"\\n\",\n     \"res3 = sm.OLS(y, X).fit()\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(res3.f_test(R))\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(res3.f_test(\\\"x2 = x3 = 0\\\"))\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -378,14 +378,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"from statsmodels.datasets.longley import load_pandas\\n\",\n     \"\\n\",\n     \"y = load_pandas().endog\\n\",\n     \"X = load_pandas().exog\\n\",\n     \"X = sm.add_constant(X)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -398,12 +398,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"ols_model = sm.OLS(y, X)\\n\",\n     \"ols_results = ols_model.fit()\\n\",\n     \"print(ols_results.summary())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -418,7 +418,6 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"norm_x = X.values\\n\",\n     \"for i, name in enumerate(X):\\n\",\n@@ -426,7 +425,8 @@\n     \"        continue\\n\",\n     \"    norm_x[:, i] = X[name] / np.linalg.norm(X[name])\\n\",\n     \"norm_xtx = np.dot(norm_x.T, norm_x)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -439,12 +439,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"eigs = np.linalg.eigvals(norm_xtx)\\n\",\n     \"condition_number = np.sqrt(eigs.max() / eigs.min())\\n\",\n     \"print(condition_number)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -459,7 +459,6 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"ols_results2 = sm.OLS(y.iloc[:14], X.iloc[:14]).fit()\\n\",\n     \"print(\\n\",\n@@ -474,7 +473,8 @@\n     \"        ]\\n\",\n     \"    )\\n\",\n     \")\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -487,10 +487,10 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"infl = ols_results.get_influence()\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -503,19 +503,19 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"2.0 / len(X) ** 0.5\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(infl.summary_frame().filter(regex=\\\"dfb\\\"))\"\n-   ]\n+   ],\n+   \"outputs\": []\n   }\n  ],\n  \"metadata\": {\n@@ -539,4 +539,4 @@\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 4\n-}\n\\ No newline at end of file\n+}\ndiff --git a/examples/notebooks/regression_diagnostics.ipynb b/examples/notebooks/regression_diagnostics.ipynb\nindex 55a5cc047df..bf948f06b25 100644\n--- a/examples/notebooks/regression_diagnostics.ipynb\n+++ b/examples/notebooks/regression_diagnostics.ipynb\n@@ -27,16 +27,15 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"%matplotlib inline\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"from statsmodels.compat import lzip\\n\",\n     \"\\n\",\n@@ -55,7 +54,8 @@\n     \"\\n\",\n     \"# Inspect the results\\n\",\n     \"print(results.summary())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -75,12 +75,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"name = [\\\"Jarque-Bera\\\", \\\"Chi^2 two-tail prob.\\\", \\\"Skew\\\", \\\"Kurtosis\\\"]\\n\",\n     \"test = sms.jarque_bera(results.resid)\\n\",\n     \"lzip(name, test)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -93,12 +93,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"name = [\\\"Chi^2\\\", \\\"Two-tail probability\\\"]\\n\",\n     \"test = sms.omni_normtest(results.resid)\\n\",\n     \"lzip(name, test)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -113,13 +113,13 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"from statsmodels.stats.outliers_influence import OLSInfluence\\n\",\n     \"\\n\",\n     \"test_class = OLSInfluence(results)\\n\",\n     \"test_class.dfbetas[:5, :]\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -134,13 +134,13 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"from statsmodels.graphics.regressionplots import plot_leverage_resid2\\n\",\n     \"\\n\",\n     \"fig, ax = plt.subplots(figsize=(8, 6))\\n\",\n     \"fig = plot_leverage_resid2(results, ax=ax)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -162,10 +162,10 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"np.linalg.cond(results.model.exog)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -180,12 +180,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"name = [\\\"Lagrange multiplier statistic\\\", \\\"p-value\\\", \\\"f-value\\\", \\\"f p-value\\\"]\\n\",\n     \"test = sms.het_breuschpagan(results.resid, results.model.exog)\\n\",\n     \"lzip(name, test)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -198,12 +198,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"name = [\\\"F statistic\\\", \\\"p-value\\\"]\\n\",\n     \"test = sms.het_goldfeldquandt(results.resid, results.model.exog)\\n\",\n     \"lzip(name, test)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -218,12 +218,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"name = [\\\"t value\\\", \\\"p value\\\"]\\n\",\n     \"test = sms.linear_harvey_collier(results)\\n\",\n     \"lzip(name, test)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   }\n  ],\n  \"metadata\": {\ndiff --git a/examples/notebooks/robust_models_1.ipynb b/examples/notebooks/robust_models_1.ipynb\nindex 21414cc29e9..a65afcfed9f 100644\n--- a/examples/notebooks/robust_models_1.ipynb\n+++ b/examples/notebooks/robust_models_1.ipynb\n@@ -11,16 +11,15 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"%matplotlib inline\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"from statsmodels.compat import lmap\\n\",\n     \"import numpy as np\\n\",\n@@ -28,7 +27,8 @@\n     \"import matplotlib.pyplot as plt\\n\",\n     \"\\n\",\n     \"import statsmodels.api as sm\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -56,16 +56,15 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"norms = sm.robust.norms\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"def plot_weights(support, weights_func, xlabels, xticks):\\n\",\n     \"    fig = plt.figure(figsize=(12, 8))\\n\",\n@@ -75,7 +74,8 @@\n     \"    ax.set_xticklabels(xlabels, fontsize=16)\\n\",\n     \"    ax.set_ylim(-0.1, 1.1)\\n\",\n     \"    return ax\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -88,16 +88,15 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"help(norms.AndrewWave.weights)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"a = 1.339\\n\",\n     \"support = np.linspace(-np.pi * a, np.pi * a, 100)\\n\",\n@@ -105,7 +104,8 @@\n     \"plot_weights(\\n\",\n     \"    support, andrew.weights, [\\\"$-\\\\pi*a$\\\", \\\"0\\\", \\\"$\\\\pi*a$\\\"], [-np.pi * a, 0, np.pi * a]\\n\",\n     \")\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -118,22 +118,22 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"help(norms.Hampel.weights)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"c = 8\\n\",\n     \"support = np.linspace(-3 * c, 3 * c, 1000)\\n\",\n     \"hampel = norms.Hampel(a=2.0, b=4.0, c=c)\\n\",\n     \"plot_weights(support, hampel.weights, [\\\"3*c\\\", \\\"0\\\", \\\"3*c\\\"], [-3 * c, 0, 3 * c])\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -146,22 +146,22 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"help(norms.HuberT.weights)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"t = 1.345\\n\",\n     \"support = np.linspace(-3 * t, 3 * t, 1000)\\n\",\n     \"huber = norms.HuberT(t=t)\\n\",\n     \"plot_weights(support, huber.weights, [\\\"-3*t\\\", \\\"0\\\", \\\"3*t\\\"], [-3 * t, 0, 3 * t])\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -174,21 +174,21 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"help(norms.LeastSquares.weights)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"support = np.linspace(-3, 3, 1000)\\n\",\n     \"lst_sq = norms.LeastSquares()\\n\",\n     \"plot_weights(support, lst_sq.weights, [\\\"-3\\\", \\\"0\\\", \\\"3\\\"], [-3, 0, 3])\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -201,22 +201,22 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"help(norms.RamsayE.weights)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"a = 0.3\\n\",\n     \"support = np.linspace(-3 * a, 3 * a, 1000)\\n\",\n     \"ramsay = norms.RamsayE(a=a)\\n\",\n     \"plot_weights(support, ramsay.weights, [\\\"-3*a\\\", \\\"0\\\", \\\"3*a\\\"], [-3 * a, 0, 3 * a])\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -229,22 +229,22 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"help(norms.TrimmedMean.weights)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"c = 2\\n\",\n     \"support = np.linspace(-3 * c, 3 * c, 1000)\\n\",\n     \"trimmed = norms.TrimmedMean(c=c)\\n\",\n     \"plot_weights(support, trimmed.weights, [\\\"-3*c\\\", \\\"0\\\", \\\"3*c\\\"], [-3 * c, 0, 3 * c])\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -257,22 +257,22 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"help(norms.TukeyBiweight.weights)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"c = 4.685\\n\",\n     \"support = np.linspace(-3 * c, 3 * c, 1000)\\n\",\n     \"tukey = norms.TukeyBiweight(c=c)\\n\",\n     \"plot_weights(support, tukey.weights, [\\\"-3*c\\\", \\\"0\\\", \\\"3*c\\\"], [-3 * c, 0, 3 * c])\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -292,10 +292,10 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"x = np.array([1, 2, 3, 4, 500])\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -308,10 +308,10 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"x.mean()\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -324,10 +324,10 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"np.median(x)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -341,10 +341,10 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"x.std()\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -372,37 +372,37 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"stats.norm.ppf(0.75)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(x)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"sm.robust.scale.mad(x)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"np.array([1, 2, 3, 4, 5.0]).std()\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -428,10 +428,10 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"sm.robust.scale.iqr(x)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -455,10 +455,10 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"sm.robust.scale.qn_scale(x)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -472,89 +472,89 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"np.random.seed(12345)\\n\",\n     \"fat_tails = stats.t(6).rvs(40)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"kde = sm.nonparametric.KDEUnivariate(fat_tails)\\n\",\n     \"kde.fit()\\n\",\n     \"fig = plt.figure(figsize=(12, 8))\\n\",\n     \"ax = fig.add_subplot(111)\\n\",\n     \"ax.plot(kde.support, kde.density)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(fat_tails.mean(), fat_tails.std())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(stats.norm.fit(fat_tails))\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(stats.t.fit(fat_tails, f0=6))\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"huber = sm.robust.scale.Huber()\\n\",\n     \"loc, scale = huber(fat_tails)\\n\",\n     \"print(loc, scale)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"sm.robust.mad(fat_tails)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"sm.robust.mad(fat_tails, c=stats.t(6).ppf(0.75))\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"sm.robust.scale.mad(fat_tails)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -567,35 +567,34 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"from statsmodels.graphics.api import abline_plot\\n\",\n     \"from statsmodels.formula.api import ols, rlm\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"prestige = sm.datasets.get_rdataset(\\\"Duncan\\\", \\\"carData\\\", cache=True).data\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(prestige.head(10))\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"fig = plt.figure(figsize=(12, 12))\\n\",\n     \"ax1 = fig.add_subplot(211, xlabel=\\\"Income\\\", ylabel=\\\"Prestige\\\")\\n\",\n@@ -604,87 +603,88 @@\n     \"ax1.annotate(\\\"Minister\\\", xy_outlier, xy_outlier + 1, fontsize=16)\\n\",\n     \"ax2 = fig.add_subplot(212, xlabel=\\\"Education\\\", ylabel=\\\"Prestige\\\")\\n\",\n     \"ax2.scatter(prestige.education, prestige.prestige)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"ols_model = ols(\\\"prestige ~ income + education\\\", prestige).fit()\\n\",\n     \"print(ols_model.summary())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"infl = ols_model.get_influence()\\n\",\n     \"student = infl.summary_frame()[\\\"student_resid\\\"]\\n\",\n     \"print(student)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(student.loc[np.abs(student) > 2])\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(infl.summary_frame().loc[\\\"minister\\\"])\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"sidak = ols_model.outlier_test(\\\"sidak\\\")\\n\",\n     \"sidak.sort_values(\\\"unadj_p\\\", inplace=True)\\n\",\n     \"print(sidak)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"fdr = ols_model.outlier_test(\\\"fdr_bh\\\")\\n\",\n     \"fdr.sort_values(\\\"unadj_p\\\", inplace=True)\\n\",\n     \"print(fdr)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"rlm_model = rlm(\\\"prestige ~ income + education\\\", prestige).fit()\\n\",\n     \"print(rlm_model.summary())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"print(rlm_model.weights)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -704,16 +704,15 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"dta = sm.datasets.get_rdataset(\\\"starsCYG\\\", \\\"robustbase\\\", cache=True).data\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"from matplotlib.patches import Ellipse\\n\",\n     \"\\n\",\n@@ -742,40 +741,41 @@\n     \"for i, row in dta.loc[dta[\\\"log.Te\\\"] < 3.8].iterrows():\\n\",\n     \"    ax.annotate(i, row, row + 0.01, fontsize=14)\\n\",\n     \"xlim, ylim = ax.get_xlim(), ax.get_ylim()\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"from IPython.display import Image\\n\",\n     \"\\n\",\n     \"Image(filename=\\\"star_diagram.png\\\")\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"y = dta[\\\"log.light\\\"]\\n\",\n     \"X = sm.add_constant(dta[\\\"log.Te\\\"], prepend=True)\\n\",\n     \"ols_model = sm.OLS(y, X).fit()\\n\",\n     \"abline_plot(model_results=ols_model, ax=ax)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"rlm_mod = sm.RLM(y, X, sm.robust.norms.TrimmedMean(0.5)).fit()\\n\",\n     \"abline_plot(model_results=rlm_mod, ax=ax, color=\\\"red\\\")\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -788,43 +788,43 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"infl = ols_model.get_influence()\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"h_bar = 2 * (ols_model.df_model + 1) / ols_model.nobs\\n\",\n     \"hat_diag = infl.summary_frame()[\\\"hat_diag\\\"]\\n\",\n     \"hat_diag.loc[hat_diag > h_bar]\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"sidak2 = ols_model.outlier_test(\\\"sidak\\\")\\n\",\n     \"sidak2.sort_values(\\\"unadj_p\\\", inplace=True)\\n\",\n     \"print(sidak2)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"fdr2 = ols_model.outlier_test(\\\"fdr_bh\\\")\\n\",\n     \"fdr2.sort_values(\\\"unadj_p\\\", inplace=True)\\n\",\n     \"print(fdr2)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -837,24 +837,24 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"l = ax.lines[-1]\\n\",\n     \"l.remove()\\n\",\n     \"del l\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"weights = np.ones(len(X))\\n\",\n     \"weights[X[X[\\\"log.Te\\\"] < 3.8].index.values - 1] = 0\\n\",\n     \"wls_model = sm.WLS(y, X, weights=weights).fit()\\n\",\n     \"abline_plot(model_results=wls_model, ax=ax, color=\\\"green\\\")\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -868,11 +868,11 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"yy = y.values[:, None]\\n\",\n     \"xx = X[\\\"log.Te\\\"].values[:, None]\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -923,20 +923,20 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"params = [-4.969387980288108, 2.2531613477892365]  # Computed using R\\n\",\n     \"print(params[0], params[1])\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"abline_plot(intercept=params[0], slope=params[1], ax=ax, color=\\\"red\\\")\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -949,7 +949,6 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"np.random.seed(12345)\\n\",\n     \"nobs = 200\\n\",\n@@ -959,13 +958,13 @@\n     \"X = sm.add_constant(X, prepend=True)  # np.c_[np.ones(nobs), X]\\n\",\n     \"mc_iter = 500\\n\",\n     \"contaminate = 0.25  # percentage of response variables to contaminate\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"all_betas = []\\n\",\n     \"for i in range(mc_iter):\\n\",\n@@ -974,18 +973,19 @@\n     \"    y[random_idx] = np.random.uniform(-750, 750)\\n\",\n     \"    beta_hat = sm.RLM(y, X).fit().params\\n\",\n     \"    all_betas.append(beta_hat)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"all_betas = np.asarray(all_betas)\\n\",\n     \"se_loss = lambda x: np.linalg.norm(x, ord=2) ** 2\\n\",\n     \"se_beta = lmap(se_loss, all_betas - beta_true)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -998,37 +998,37 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"np.array(se_beta).mean()\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"all_betas.mean(0)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"beta_true\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"se_loss(all_betas.mean(0) - beta_true)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   }\n  ],\n  \"metadata\": {\ndiff --git a/examples/notebooks/wls.ipynb b/examples/notebooks/wls.ipynb\nindex df208af67f1..4bbf503e207 100644\n--- a/examples/notebooks/wls.ipynb\n+++ b/examples/notebooks/wls.ipynb\n@@ -11,16 +11,15 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"%matplotlib inline\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"import matplotlib.pyplot as plt\\n\",\n     \"import numpy as np\\n\",\n@@ -29,7 +28,8 @@\n     \"from statsmodels.iolib.table import SimpleTable, default_txt_fmt\\n\",\n     \"\\n\",\n     \"np.random.seed(1024)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -50,7 +50,6 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"nsample = 50\\n\",\n     \"x = np.linspace(0, 20, nsample)\\n\",\n@@ -64,7 +63,8 @@\n     \"e = np.random.normal(size=nsample)\\n\",\n     \"y = y_true + sig * w * e\\n\",\n     \"X = X[:, [0, 1]]\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -79,12 +79,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"mod_wls = sm.WLS(y, X, weights=1.0 / (w ** 2))\\n\",\n     \"res_wls = mod_wls.fit()\\n\",\n     \"print(res_wls.summary())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -99,12 +99,12 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"res_ols = sm.OLS(y, X).fit()\\n\",\n     \"print(res_ols.params)\\n\",\n     \"print(res_wls.params)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -119,7 +119,6 @@\n    \"metadata\": {\n     \"scrolled\": true\n    },\n-   \"outputs\": [],\n    \"source\": [\n     \"se = np.vstack(\\n\",\n     \"    [\\n\",\n@@ -136,7 +135,8 @@\n     \"rownames = [\\\"WLS\\\", \\\"OLS\\\", \\\"OLS_HC0\\\", \\\"OLS_HC1\\\", \\\"OLS_HC3\\\", \\\"OLS_HC3\\\"]\\n\",\n     \"tabl = SimpleTable(se, colnames, rownames, txt_fmt=default_txt_fmt)\\n\",\n     \"print(tabl)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -149,24 +149,24 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"covb = res_ols.cov_params()\\n\",\n     \"prediction_var = res_ols.mse_resid + (X * np.dot(covb, X.T).T).sum(1)\\n\",\n     \"prediction_std = np.sqrt(prediction_var)\\n\",\n     \"tppf = stats.t.ppf(0.975, res_ols.df_resid)\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"pred_ols = res_ols.get_prediction()\\n\",\n     \"iv_l_ols = pred_ols.summary_frame()[\\\"obs_ci_lower\\\"]\\n\",\n     \"iv_u_ols = pred_ols.summary_frame()[\\\"obs_ci_upper\\\"]\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -179,7 +179,6 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"pred_wls = res_wls.get_prediction()\\n\",\n     \"iv_l = pred_wls.summary_frame()[\\\"obs_ci_lower\\\"]\\n\",\n@@ -197,7 +196,8 @@\n     \"ax.plot(x, iv_u, \\\"g--\\\", label=\\\"WLS\\\")\\n\",\n     \"ax.plot(x, iv_l, \\\"g--\\\")\\n\",\n     \"ax.legend(loc=\\\"best\\\")\"\n-   ]\n+   ],\n+   \"outputs\": []\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -212,7 +212,6 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {},\n-   \"outputs\": [],\n    \"source\": [\n     \"resid1 = res_ols.resid[w == 1.0]\\n\",\n     \"var1 = resid1.var(ddof=int(res_ols.df_model) + 1)\\n\",\n@@ -222,7 +221,8 @@\n     \"w_est[w != 1.0] = np.sqrt(var2) / np.sqrt(var1)\\n\",\n     \"res_fwls = sm.WLS(y, X, 1.0 / ((w_est ** 2))).fit()\\n\",\n     \"print(res_fwls.summary())\"\n-   ]\n+   ],\n+   \"outputs\": []\n   }\n  ],\n  \"metadata\": {\ndiff --git a/statsmodels/stats/diagnostic.py b/statsmodels/stats/diagnostic.py\nindex 8ab3791347e..a9f001c17b5 100644\n--- a/statsmodels/stats/diagnostic.py\n+++ b/statsmodels/stats/diagnostic.py\n@@ -237,8 +237,9 @@ def compare_j(results_x, results_z, store=False):\n     return tstat, pval\n \n \n+@deprecate_kwarg(\"cov_kwargs\", \"cov_kwds\")\n def compare_encompassing(results_x, results_z, cov_type=\"nonrobust\",\n-                         cov_kwargs=None):\n+                         cov_kwds=None):\n     r\"\"\"\n     Davidson-MacKinnon encompassing test for comparing non-nested models\n \n@@ -253,7 +254,7 @@ def compare_encompassing(results_x, results_z, cov_type=\"nonrobust\",\n         OLS covariance estimator. Specify one of \"HC0\", \"HC1\", \"HC2\", \"HC3\"\n         to use White's covariance estimator. All covariance types supported\n         by ``OLS.fit`` are accepted.\n-    cov_kwargs : dict, default None\n+    cov_kwds : dict, default None\n         Dictionary of covariance options passed to ``OLS.fit``. See OLS.fit\n         for more details.\n \n@@ -317,8 +318,8 @@ def _test_nested(endog, a, b, cov_est, cov_kwds):\n         df_num, df_denom = int(test.df_num), int(test.df_denom)\n         return stat, pvalue, df_num, df_denom\n \n-    x_nested = _test_nested(y, x, z, cov_type, cov_kwargs)\n-    z_nested = _test_nested(y, z, x, cov_type, cov_kwargs)\n+    x_nested = _test_nested(y, x, z, cov_type, cov_kwds)\n+    z_nested = _test_nested(y, z, x, cov_type, cov_kwds)\n     return pd.DataFrame([x_nested, z_nested],\n                         index=[\"x\", \"z\"],\n                         columns=[\"stat\", \"pvalue\", \"df_num\", \"df_denom\"])\n@@ -479,9 +480,10 @@ def acorr_ljungbox(x, lags=None, boxpierce=False, model_df=0, period=None,\n                         index=lags)\n \n \n+@deprecate_kwarg(\"cov_kwargs\", \"cov_kwds\")\n @deprecate_kwarg(\"maxlag\", \"nlags\")\n def acorr_lm(resid, nlags=None, store=False, *, period=None,\n-             ddof=0, cov_type=\"nonrobust\", cov_kwargs=None):\n+             ddof=0, cov_type=\"nonrobust\", cov_kwds=None):\n     \"\"\"\n     Lagrange Multiplier tests for autocorrelation.\n \n@@ -510,7 +512,7 @@ def acorr_lm(resid, nlags=None, store=False, *, period=None,\n         OLS covariance estimator. Specify one of \"HC0\", \"HC1\", \"HC2\", \"HC3\"\n         to use White's covariance estimator. All covariance types supported\n         by ``OLS.fit`` are accepted.\n-    cov_kwargs : dict, default None\n+    cov_kwds : dict, default None\n         Dictionary of covariance options passed to ``OLS.fit``. See OLS.fit for\n         more details.\n \n@@ -545,8 +547,8 @@ def acorr_lm(resid, nlags=None, store=False, *, period=None,\n     \"\"\"\n     resid = array_like(resid, \"resid\", ndim=1)\n     cov_type = string_like(cov_type, \"cov_type\")\n-    cov_kwargs = {} if cov_kwargs is None else cov_kwargs\n-    cov_kwargs = dict_like(cov_kwargs, \"cov_kwargs\")\n+    cov_kwds = {} if cov_kwds is None else cov_kwds\n+    cov_kwds = dict_like(cov_kwds, \"cov_kwds\")\n     nobs = resid.shape[0]\n     if period is not None and nlags is None:\n         maxlag = min(nobs // 5, 2 * period)\n@@ -563,7 +565,7 @@ def acorr_lm(resid, nlags=None, store=False, *, period=None,\n     usedlag = maxlag\n \n     resols = OLS(xshort, xdall[:, :usedlag + 1]).fit(cov_type=cov_type,\n-                                                     cov_kwargs=cov_kwargs)\n+                                                     cov_kwds=cov_kwds)\n     fval = float(resols.fvalue)\n     fpval = float(resols.f_pvalue)\n     if cov_type == \"nonrobust\":\n@@ -985,9 +987,10 @@ def het_goldfeldquandt(y, x, idx=None, split=None, drop=None,\n     return fval, fpval, ordering\n \n \n+@deprecate_kwarg(\"cov_kwargs\", \"cov_kwds\")\n @deprecate_kwarg(\"result\", \"res\")\n def linear_reset(res, power=3, test_type=\"fitted\", use_f=False,\n-                 cov_type=\"nonrobust\", cov_kwargs=None):\n+                 cov_type=\"nonrobust\", cov_kwds=None):\n     r\"\"\"\n     Ramsey's RESET test for neglected nonlinearity\n \n@@ -1015,7 +1018,7 @@ def linear_reset(res, power=3, test_type=\"fitted\", use_f=False,\n         OLS covariance estimator. Specify one of \"HC0\", \"HC1\", \"HC2\", \"HC3\"\n         to use White's covariance estimator. All covariance types supported\n         by ``OLS.fit`` are accepted.\n-    cov_kwargs : dict, default None\n+    cov_kwds : dict, default None\n         Dictionary of covariance options passed to ``OLS.fit``. See OLS.fit\n         for more details.\n \n@@ -1055,7 +1058,7 @@ def linear_reset(res, power=3, test_type=\"fitted\", use_f=False,\n                          \"non-constant column.\")\n     test_type = string_like(test_type, \"test_type\",\n                             options=(\"fitted\", \"exog\", \"princomp\"))\n-    cov_kwargs = dict_like(cov_kwargs, \"cov_kwargs\", optional=True)\n+    cov_kwds = dict_like(cov_kwds, \"cov_kwds\", optional=True)\n     use_f = bool_like(use_f, \"use_f\")\n     if isinstance(power, int):\n         if power < 2:\n@@ -1093,8 +1096,8 @@ def linear_reset(res, power=3, test_type=\"fitted\", use_f=False,\n     aug_exog = np.hstack([exog] + [aug ** p for p in power])\n     mod_class = res.model.__class__\n     mod = mod_class(res.model.data.endog, aug_exog)\n-    cov_kwargs = {} if cov_kwargs is None else cov_kwargs\n-    res = mod.fit(cov_type=cov_type, cov_kwargs=cov_kwargs)\n+    cov_kwds = {} if cov_kwds is None else cov_kwds\n+    res = mod.fit(cov_type=cov_type, cov_kwds=cov_kwds)\n     nrestr = aug_exog.shape[1] - exog.shape[1]\n     nparams = aug_exog.shape[1]\n     r_mat = np.eye(nrestr, nparams, k=nparams-nrestr)\n", "test_patch": "diff --git a/statsmodels/stats/tests/test_diagnostic.py b/statsmodels/stats/tests/test_diagnostic.py\nindex 2b6019f4c0a..911738dbbb4 100644\n--- a/statsmodels/stats/tests/test_diagnostic.py\n+++ b/statsmodels/stats/tests/test_diagnostic.py\n@@ -1805,8 +1805,8 @@ def test_encompasing_error(reset_randomstate):\n @pytest.mark.parametrize(\n     \"cov\",\n     [\n-        dict(cov_type=\"nonrobust\", cov_kwargs={}),\n-        dict(cov_type=\"HC0\", cov_kwargs={}),\n+        dict(cov_type=\"nonrobust\", cov_kwds={}),\n+        dict(cov_type=\"HC0\", cov_kwds={}),\n     ],\n )\n def test_reset_smoke(power, test_type, use_f, cov, reset_randomstate):\n@@ -1826,8 +1826,8 @@ def test_reset_smoke(power, test_type, use_f, cov, reset_randomstate):\n @pytest.mark.parametrize(\n     \"cov\",\n     [\n-        dict(cov_type=\"nonrobust\", cov_kwargs={}),\n-        dict(cov_type=\"HC0\", cov_kwargs={}),\n+        dict(cov_type=\"nonrobust\", cov_kwds={}),\n+        dict(cov_type=\"HC0\", cov_kwds={}),\n     ],\n )\n def test_acorr_lm_smoke(store, ddof, cov, reset_randomstate):\n@@ -1996,3 +1996,36 @@ def test_diagnostics_pandas(reset_randomstate):\n         res, order_by=np.arange(y.shape[0] - 1, 0 - 1, -1)\n     )\n     smsdia.spec_white(res.resid, x)\n+\n+\n+def test_deprecated_argument():\n+    x = np.random.randn(100)\n+    y = 2 * x + np.random.randn(100)\n+    result = OLS(y, add_constant(x)).fit(\n+        cov_type=\"HAC\", cov_kwds={\"maxlags\": 2}\n+    )\n+    with pytest.warns(FutureWarning, match=\"the \"):\n+        smsdia.linear_reset(\n+            result,\n+            power=2,\n+            test_type=\"fitted\",\n+            cov_type=\"HAC\",\n+            cov_kwargs={\"maxlags\": 2},\n+        )\n+\n+\n+def test_diagnostics_hac(reset_randomstate):\n+    x = np.random.randn(100)\n+    y = 2 * x + np.random.randn(100)\n+    result = OLS(y, add_constant(x)).fit(\n+        cov_type=\"HAC\", cov_kwds={\"maxlags\": 2}\n+    )\n+    reset_test = smsdia.linear_reset(\n+        result,\n+        power=2,\n+        test_type=\"fitted\",\n+        cov_type=\"HAC\",\n+        cov_kwds={\"maxlags\": 2},\n+    )\n+    assert reset_test.statistic > 0\n+    assert 0 <= reset_test.pvalue <= 1\ndiff --git a/statsmodels/tsa/tests/test_seasonal.py b/statsmodels/tsa/tests/test_seasonal.py\nindex 2a1f0b630a7..51c441bc457 100644\n--- a/statsmodels/tsa/tests/test_seasonal.py\n+++ b/statsmodels/tsa/tests/test_seasonal.py\n@@ -315,17 +315,27 @@ def test_seasonal_decompose_multiple():\n \n \n @pytest.mark.matplotlib\n-@pytest.mark.parametrize('model', ['additive', 'multiplicative'])\n-@pytest.mark.parametrize('freq', [4, 12])\n-@pytest.mark.parametrize('two_sided', [True, False])\n-@pytest.mark.parametrize('extrapolate_trend', [True, False])\n-def test_seasonal_decompose_plot(model, freq, two_sided, extrapolate_trend):\n+@pytest.mark.parametrize(\"model\", [\"additive\", \"multiplicative\"])\n+@pytest.mark.parametrize(\"freq\", [4, 12])\n+@pytest.mark.parametrize(\"two_sided\", [True, False])\n+@pytest.mark.parametrize(\"extrapolate_trend\", [True, False])\n+def test_seasonal_decompose_plot(\n+    model, freq, two_sided, extrapolate_trend, close_figures\n+):\n     x = np.array([-50, 175, 149, 214, 247, 237, 225, 329, 729, 809,\n                   530, 489, 540, 457, 195, 176, 337, 239, 128, 102,\n                   232, 429, 3, 98, 43, -141, -77, -13, 125, 361, -45, 184])\n     x -= x.min() + 1\n     x2 = np.r_[x[12:], x[:12]]\n     x = np.c_[x, x2]\n-    res = seasonal_decompose(x, period=freq, two_sided=two_sided,\n-                             extrapolate_trend=extrapolate_trend)\n-    res.plot()\n+    res = seasonal_decompose(\n+        x,\n+        period=freq,\n+        two_sided=two_sided,\n+        extrapolate_trend=extrapolate_trend\n+    )\n+    fig = res.plot()\n+\n+    import matplotlib.pyplot as plt\n+\n+    plt.close(fig)\n", "problem_statement": "linear_reset can't be set with \"HAC\" and maxlags, KeyErrors\n#### Describe the bug\r\nHello, thanks for your time. We've tried several things but it still doesn't work even with the newest version of Statsmodels. We think this might be a bug. Issue is: we were trying to use \"statsmodels.stats.diagnostic.linear_reset\" with HAC as coviance type and maxlags as the key word args, but we got KeyErrors.\r\n\r\n#### Code Sample, a copy-pastable example if possible\r\n```\r\n# Import modules\r\nimport numpy as np\r\nimport statsmodels.api as sm\r\nfrom statsmodels.stats.diagnostic import linear_reset\r\n\r\n# Generate some random data\r\nnp.random.seed(42)\r\nx = np.random.randn(100)\r\ny = 2 * x + np.random.randn(100)\r\n\r\n# Fit a linear regression model\r\nmodel = sm.OLS(y, sm.add_constant(x))\r\n# results = model.fit()\r\n\r\n# Perform linear reset test\r\n## opt 1\r\nreset_test = linear_reset(results, power=2, test_type='fitted', cov_type='HAC', cov_kwargs={'maxlags': 2})\r\n\r\n## opt 2\r\n# test = linear_reset(results, cov_type='HAC', cov_kwds={'maxlags': 2})\r\n\r\n## opt 3\r\n# kwargs = {'maxlags': 2}\r\n# test = linear_reset(results, cov_type='HAC', **kwargs)\r\n\r\n## opt 4\r\n# test = linear_reset(results, cov_type='HAC', maxlags=2)\r\n\r\n```\r\n```python\r\n# Your code here that produces the bug\r\n# This example should be self-contained, and so not rely on external data.\r\n# It should run in a fresh ipython session, and so include all relevant imports.\r\n```\r\n<details>\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\nFile <command-2970740754718372>:19\r\n     16 model = sm.OLS(y, x).fit(cov_type='HAC', cov_kwds={'maxlags': 2})\r\n     18 # Perform linear reset test\r\n---> 19 reset_test = linear_reset(model, power=2, test_type='fitted', cov_type='HAC', cov_kwargs={'maxlags': 2})\r\n     21 # # Perform the linear reset test with HAC covariance and maxlags=2\r\n     22 # test = linear_reset(results, cov_type='HAC', cov_kwds={'maxlags': 2})\r\n     23 \r\n   (...)\r\n     33 \r\n     34 # Print the test results\r\n     35 print(reset_test.summary())\r\n\r\nFile /databricks/python/lib/python3.9/site-packages/pandas/util/_decorators.py:207, in deprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper(*args, **kwargs)\r\n    205     else:\r\n    206         kwargs[new_arg_name] = new_arg_value\r\n--> 207 return func(*args, **kwargs)\r\n\r\nFile /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/statsmodels/stats/diagnostic.py:1098, in linear_reset(res, power, test_type, use_f, cov_type, cov_kwargs)\r\n   1096 mod = mod_class(res.model.data.endog, aug_exog)\r\n   1097 cov_kwargs = {} if cov_kwargs is None else cov_kwargs\r\n-> 1098 res = mod.fit(cov_type=cov_type, cov_kwargs=cov_kwargs)\r\n   1099 nrestr = aug_exog.shape[1] - exog.shape[1]\r\n   1100 nparams = aug_exog.shape[1]\r\n\r\nFile /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:373, in RegressionModel.fit(self, method, cov_type, cov_kwds, use_t, **kwargs)\r\n    370     self.df_resid = self.nobs - self.rank\r\n    372 if isinstance(self, OLS):\r\n--> 373     lfit = OLSResults(\r\n    374         self, beta,\r\n    375         normalized_cov_params=self.normalized_cov_params,\r\n    376         cov_type=cov_type, cov_kwds=cov_kwds, use_t=use_t)\r\n    377 else:\r\n    378     lfit = RegressionResults(\r\n    379         self, beta,\r\n    380         normalized_cov_params=self.normalized_cov_params,\r\n    381         cov_type=cov_type, cov_kwds=cov_kwds, use_t=use_t,\r\n    382         **kwargs)\r\n\r\nFile /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1653, in RegressionResults.__init__(self, model, params, normalized_cov_params, scale, cov_type, cov_kwds, use_t, **kwargs)\r\n   1651             use_t = use_t_2\r\n   1652         # TODO: warn or not?\r\n-> 1653     self.get_robustcov_results(cov_type=cov_type, use_self=True,\r\n   1654                                use_t=use_t, **cov_kwds)\r\n   1655 for key in kwargs:\r\n   1656     setattr(self, key, kwargs[key])\r\n\r\nFile /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:2570, in RegressionResults.get_robustcov_results(self, cov_type, use_t, **kwargs)\r\n   2567     res.cov_params_default = getattr(self, 'cov_' + cov_type.upper())\r\n   2568 elif cov_type.lower() == 'hac':\r\n   2569     # TODO: check if required, default in cov_hac_simple\r\n-> 2570     maxlags = kwargs['maxlags']\r\n   2571     res.cov_kwds['maxlags'] = maxlags\r\n   2572     weights_func = kwargs.get('weights_func', sw.weights_bartlett)\r\nKeyError: 'maxlags'\r\n\r\n**Note**: As you can see, there are many issues on our GitHub tracker, so it is very possible that your issue has been posted before. Please check first before submitting so that we do not have to handle and close duplicates.\r\n\r\n**Note**: Please be sure you are using the latest released version of `statsmodels`, or a recent build of `main`. If your problem has been fixed in an unreleased version, you might be able to use `main` until a new release occurs. \r\n\r\n**Note**: If you are using a released version, have you verified that the bug exists in the main branch of this repository? It helps the limited resources if we know problems exist in the current main branch so that they do not need to check whether the code sample produces a bug in the next release.\r\n\r\n</details>\r\n\r\n\r\nIf the issue has not been resolved, please file it in the issue tracker.\r\n\r\n#### Expected Output\r\nWe expect that the code would produce the p-value from linear RESET test with \"HAC\" as the covariance estimator.\r\n\r\n#### Output of ``import statsmodels.api as sm; sm.show_versions()``\r\n\r\n<details>\r\n\r\n[paste the output of ``import statsmodels.api as sm; sm.show_versions()`` here below this line]\r\n0.14.1\r\n</details>\r\n\n", "hints_text": "**update** this does not apply here, new issue #9122\r\n\r\n\r\nrobust cov_type is not implemented for, AFAIR, any of the diagnostic and specification tests.\r\n\r\nMain reason: When I implemented those I only had references (and other packages for unit tests) for the standard version with basic OLS in the auxiliary regression.\r\n\r\nAt the time I was not sure about the theory and did not find explicit references for using `cov_type`s, although it's mentioned e.g. by Wooldridge that we can just use a specification robust cov_type in the auxiliary regression.\r\n\r\nAlso for some LM specification tests, we use uncentered rsquared as computational shortcut and not a standard wald test, i.e. it hardcodes the nonrobust hypothesis test.\r\n\r\nFor some specification/diagnostic tests we might be able to just forward the cov_type information to the auxiliary regression,\r\neven if we cannot write unit test to verify against other packages.\r\nIn other cases it might be easier to use generic conditional moment test and newer score_test/lm_test which AFAIR already allow for cov_type (although currently with some restrictions).\r\n\r\nI add elevated priority to issue to look at this.\r\nI worked a lot on misspecification robust (HC, ...) CMT, score/lm test in the last years (but mostly for GLM and discrete), and should be able to get back to this. \r\n \r\nNote: using wald test with augmented `exog` is easy to perform by just defining a new model.\r\ne.g. one simple case for poisson https://gist.github.com/josef-pkt/1fdcc5c57cd63824fb3130d013e30103\r\n\r\nAside: \r\nThe older literature in econometrics was emphasizing auxiliary regression because it was relatively easy to use existing models from statistical packages for this. It also relied in many cases on an OPG version which is much easier to compute but has worse small sample properties (mainly relevant for nonlinear or non-gaussian models)\r\nFor statsmodels it's easier and provides more options to implement these tests based on generic theory and generic methods.\r\n\r\n\r\n\nmy mistake\r\nthe reset test in `diagnostic` was written by @bashtage and has cov_type keywords. \nI found the bug\r\n\r\nthe reset test uses cov_kwargs, but the model.fit use cov_kwds\r\nthe correct code in the reset function should be\r\n`res = mod.fit(cov_type=cov_type, cov_kwds=cov_kwargs)`\r\n\r\n(I don't like the word kwargs, and prefer `xxx_kwds` for named options)\r\n\nIs this problem been resolved yet? I'm using the latest version of statsmodels 0.14.2 and still have the exact same issue.", "created_at": "2024-05-07T10:01:51Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9227, "instance_id": "statsmodels__statsmodels-9227", "issue_numbers": ["9233"], "base_commit": "bc1899510adacebf1ec351e92a78b7421c17dbb0", "patch": "diff --git a/statsmodels/robust/covariance.py b/statsmodels/robust/covariance.py\nindex b6897de3d58..f8e2150820d 100644\n--- a/statsmodels/robust/covariance.py\n+++ b/statsmodels/robust/covariance.py\n@@ -28,9 +28,15 @@\n from scipy import stats, linalg\n from scipy.linalg.lapack import dtrtri\n from .scale import mad\n+import statsmodels.robust.norms as rnorms\n+import statsmodels.robust.scale as rscale\n+import statsmodels.robust.tools as rtools\n from statsmodels.tools.testing import Holder\n \n+from statsmodels.stats.covariance import corr_rank, corr_normal_scores\n+\n mad0 = lambda x: mad(x, center=0)  # noqa: E731\n+median = lambda x: np.median(x, axis=0)  # noqa: E731\n \n \n # from scikit-learn\n@@ -311,6 +317,7 @@ def mahalanobis(data, cov=None, cov_inv=None, sqrt=False):\n     \"\"\"Mahalanobis distance squared\n \n     Note: this is without taking the square root.\n+    assumes data is already centered.\n \n     Parameters\n     ----------\n@@ -405,13 +412,15 @@ def cov_gk(data, scale_func=mad):\n def cov_ogk(data, maxiter=2, scale_func=mad, cov_func=cov_gk,\n             loc_func=lambda x: np.median(x, axis=0), reweight=0.9,\n             rescale=True, rescale_raw=True, ddof=1):\n-    \"\"\"orthogonalized Gnanadesikan and Kettenring covariance estimator\n+    \"\"\"Orthogonalized Gnanadesikan and Kettenring covariance estimator.\n \n     Based on Maronna and Zamar 2002\n \n     Parameters\n     ----------\n-    data : array_like, 2-D\n+    data : array-like\n+        Multivariate data set with observation in rows and variables in\n+        columns.\n     maxiter : int\n         Number of iteration steps. According to Maronna and Zamar the\n         estimate doesn't improve much after the second iteration and the\n@@ -590,12 +599,10 @@ def cov_tyler(data, start_cov=None, normalize=False, maxiter=100, eps=1e-13):\n     ----------\n     .. [1] Tyler, David E. \u201cA Distribution-Free M-Estimator of Multivariate\n        Scatter.\u201d The Annals of Statistics 15, no. 1 (March 1, 1987): 234\u201351.\n-\n     .. [2] Soloveychik, I., and A. Wiesel. 2014. Tyler's Covariance Matrix\n        Estimator in Elliptical Models With Convex Structure.\n        IEEE Transactions on Signal Processing 62 (20): 5251-59.\n        doi:10.1109/TSP.2014.2348951.\n-\n     .. [3] Ollila, Esa, Daniel P. Palomar, and Frederic Pascal.\n        \u201cAffine Equivariant Tyler\u2019s M-Estimator Applied to Tail Parameter\n        Learning of Elliptical Distributions.\u201d arXiv, May 7, 2023.\n@@ -1083,7 +1090,7 @@ def _cov_iter(data, weights_func, weights_args=None, cov_init=None,\n     return res\n \n \n-def _cov_starting(data, standardize=False, quantile=0.5):\n+def _cov_starting(data, standardize=False, quantile=0.5, retransform=False):\n     \"\"\"compute some robust starting covariances\n \n     The returned covariance matrices are intended as starting values\n@@ -1127,7 +1134,7 @@ def _cov_starting(data, standardize=False, quantile=0.5):\n \n     cov_all = []\n     d = mahalanobis(xs, cov=None, cov_inv=np.eye(k_vars))\n-    percentiles = [(k_vars+2) / nobs * 100 * 2, 25, 50]\n+    percentiles = [(k_vars+2) / nobs * 100 * 2, 25, 50, 85]\n     cutoffs = np.percentile(d, percentiles)\n     for p, cutoff in zip(percentiles, cutoffs):\n         xsp = xs[d < cutoff]\n@@ -1149,15 +1156,929 @@ def _cov_starting(data, standardize=False, quantile=0.5):\n         c03 = _cov_iter(xs, weights_quantile, weights_args=(quantile,),\n                         rescale=\"med\", cov_init=c02.cov, maxiter=100)\n \n-        if standardize:\n+        if not standardize or not retransform:\n             cov_all.extend([c0, c01, c02, c03])\n         else:\n             # compensate for initial rescaling\n+            # TODO: this does not return list of Holder anymore\n             s = np.outer(std, std)\n             cov_all.extend([r.cov * s for r in [c0, c01, c02, c03]])\n \n     c2 = cov_ogk(xs)\n     cov_all.append(c2)\n \n+    c2raw = Holder(\n+            cov=c2.cov_raw,\n+            mean=c2.loc_raw * std + center,\n+            method=\"ogk_raw\",\n+            )\n+    cov_all.append(c2raw)\n+\n+    z_tanh = np.tanh(xs)\n+    c_th = Holder(\n+            cov=np.corrcoef(z_tanh.T),  # not consistently scaled for cov\n+            mean=center,  # TODO: do we add inverted mean z_tanh ?\n+            method=\"tanh\",\n+            )\n+    cov_all.append(c_th)\n+\n+    x_spatial = xs / np.sqrt(np.sum(xs**2, axis=1))[:, None]\n+    c_th = Holder(\n+            cov=np.cov(x_spatial.T),\n+            mean=center,\n+            method=\"spatial\",\n+            )\n+    cov_all.append(c_th)\n+\n+    c_th = Holder(\n+            # not consistently scaled for cov\n+            # cov=stats.spearmanr(xs)[0], # not correct shape if k=1 or 2\n+            cov=corr_rank(xs),  # always returns matrix, np.corrcoef result\n+            mean=center,\n+            method=\"spearman\",\n+            )\n+    cov_all.append(c_th)\n+\n+    c_ns = Holder(\n+            cov=corr_normal_scores(xs),  # not consistently scaled for cov\n+            mean=center,  # TODO: do we add inverted mean z_tanh ?\n+            method=\"normal-scores\",\n+            )\n+    cov_all.append(c_ns)\n+\n     # TODO: rescale back to original space using center and std\n     return cov_all\n+\n+\n+# ####### Det, CovDet and helper functions, might be moved to separate module\n+\n+\n+class _Standardize():\n+    \"\"\"Robust standardization of random variable\n+\n+    \"\"\"\n+\n+    def __init__(self, x, func_center=None, func_scale=None):\n+        # naming mean or center\n+        # maybe also allow str func_scale for robust.scale, e.g. for not\n+        #    vectorized Qn\n+        if func_center is None:\n+            center = np.median(x, axis=0)\n+        else:\n+            center = func_center(x)\n+        xdm = x - center\n+        if func_scale is None:\n+            scale = mad(xdm, center=0)\n+        else:\n+            # assumes vectorized\n+            scale = func_scale(x)\n+\n+        self.x_stand = xdm / scale\n+\n+        self.center = center\n+        self.scale = scale\n+\n+    def transform(self, x):\n+        return (x - self.center) / self.scale\n+\n+    def untransform_mom(self, m, c):\n+        mean = self.center + m\n+        cov = c * np.outer(self.scale, self.scale)\n+        return mean, cov\n+\n+\n+def _orthogonalize_det(x, corr, loc_func, scale_func):\n+    \"\"\"Orthogonalize\n+\n+    This is a simplified version of the OGK method.\n+    version from DetMCD works on zscored data\n+    (does not return mean and cov of original data)\n+    so we drop the compensation for scaling in zscoring\n+\n+    z is the data here, zscored with robust estimators,\n+    e.g. median and Qn in DetMCD\n+    \"\"\"\n+    evals, evecs = np.linalg.eigh(corr)  # noqa: F841\n+    z = x.dot(evecs)\n+    transf0 = evecs\n+\n+    scale_z = scale_func(z)  # scale of principal components\n+    cov = (transf0 * scale_z**2).dot(transf0.T)\n+    # extra step in DetMCD, sphering data with new cov to compute center\n+    # I think this is equivalent to scaling z\n+    # loc_z = loc_func(z / scale_z) * scale_z  # center of principal components\n+    # loc = (transf0 * scale_z).dot(loc_z)\n+    transf1 = (transf0 * scale_z).dot(transf0.T)\n+    # transf1inv = (transf0 * scale_z**(-1)).dot(transf0.T)\n+\n+    # loc = loc_func(x @ transf1inv) @ transf1\n+    loc = loc_func((z / scale_z).dot(transf0.T)) @ transf1\n+\n+    return loc, cov\n+\n+\n+def _get_detcov_startidx(z, h, options_start=None, methods_cov=\"all\"):\n+    \"\"\"Starting sets for deterministic robust covariance estimators.\n+\n+    These are intended as starting sets for DetMCD, DetS and DetMM.\n+    \"\"\"\n+\n+    if options_start is None:\n+        options_start = {}\n+\n+    loc_func = options_start.get(\"loc_func\", median)\n+    scale_func = options_start.get(\"scale_func\", mad)\n+    z = (z - loc_func(z)) / scale_func(z)\n+\n+    if np.squeeze(z).ndim == 1:\n+        # only one random variable\n+        z = np.squeeze(z)\n+        nobs = z.shape[0]\n+        idx_sel = np.argpartition(np.abs(z), h)[:h]\n+        idx_all = [(idx_sel, \"abs-resid\")]\n+        # next uses symmetric equal-tail trimming\n+        idx_sorted = np.argsort(z)\n+        h_tail = (nobs - h) // 2\n+        idx_all.append((idx_sorted[h_tail : h_tail + h], \"trimmed-tail\"))\n+        return idx_all\n+\n+    # continue if more than 1 random variable\n+    cov_all = _cov_starting(z, standardize=False, quantile=0.5)\n+\n+    # orthogonalization step\n+    idx_all = []\n+    for c in cov_all:\n+        if not hasattr(c, \"method\"):\n+            continue\n+        method = c.method\n+        mean, cov = _orthogonalize_det(z, c.cov, loc_func, scale_func)\n+        d = mahalanobis(z, mean, cov)\n+        idx_sel = np.argpartition(d, h)[:h]\n+        idx_all.append((idx_sel, method))\n+\n+    return idx_all\n+\n+\n+class CovM:\n+    \"\"\"M-estimator for multivariate Mean and Scatter.\n+\n+    Interface incomplete and experimental.\n+\n+    Parameters\n+    ----------\n+    data : array-like\n+        Multivariate data set with observation in rows and variables in\n+        columns.\n+    norm_mean : norm instance\n+        If None, then TukeyBiweight norm is used.\n+        (Currently no other norms are supported for calling the initial\n+        S-estimator)\n+    norm_scatter : None or norm instance\n+        If norm_scatter is None, then the norm_mean will be used.\n+    breakdown_point : float in (0, 0.5]\n+        Breakdown point for first stage S-estimator.\n+    scale_bias : None or float\n+        Must currently be provided if norm_mean is not None.\n+    method : str\n+        Currently only S-estimator has automatic selection of scale function.\n+    \"\"\"\n+\n+    def __init__(self, data, norm_mean=None, norm_scatter=None,\n+                 scale_bias=None, method=\"S\"):\n+        # todo: method defines how norm_mean and norm_scatter are linked\n+        #       currently I try for S-estimator\n+\n+        if method.lower() not in [\"s\"]:\n+            msg = f\"method {method} option not recognize or implemented\"\n+            raise ValueError(msg)\n+\n+        self.data = np.asarray(data)\n+        self.k_vars = k_vars = self.data.shape[1]\n+\n+        # Todo: check interface for scale bias\n+        self.scale_bias = scale_bias\n+        if norm_mean is None:\n+            norm_mean = rnorms.TukeyBiweight()\n+            c = rtools.tuning_s_cov(norm_mean, k_vars, breakdown_point=0.5)\n+            norm_mean._set_tuning_param(c, inplace=True)\n+            self.scale_bias = rtools.scale_bias_cov_biw(c, k_vars)[0]\n+\n+        self.norm_mean = norm_mean\n+        if norm_scatter is None:\n+            self.norm_scatter = self.norm_mean\n+        else:\n+            self.norm_scatter = norm_scatter\n+\n+        self.weights_mean = self.norm_mean.weights\n+        self.weights_scatter = self.weights_mean\n+        # self.weights_scatter = lambda d: self.norm_mean.rho(d) / d**2\n+        # this is for S-estimator, M-scale\n+        self.rho = self.norm_scatter.rho\n+\n+    def _fit_mean_shape(self, mean, shape, scale):\n+        \"\"\"Estimate mean and shape in iteration step.\n+\n+        This does only one step.\n+\n+        Parameters\n+        ----------\n+        mean : ndarray\n+            Starting value for mean\n+        shape : ndarray\n+            Starting value for shape matrix.\n+        scale : float\n+            Starting value for scale.\n+\n+        Returns\n+        -------\n+        Holder instance with updated estimates.\n+        \"\"\"\n+        d = mahalanobis(self.data - mean, shape, sqrt=True) / scale\n+        weights_mean = self.weights_mean(d)\n+        weights_cov = self.weights_scatter(d)\n+\n+        res = cov_weighted(\n+            self.data,\n+            weights=weights_mean,\n+            center=None,\n+            weights_cov=weights_cov,\n+            weights_cov_denom=\"det\",\n+            ddof=1,\n+            )\n+        return res\n+\n+    def _fit_scale(self, maha, start_scale=None, maxiter=100, rtol=1e-5,\n+                   atol=1e-5):\n+        \"\"\"Estimate iterated M-scale.\n+\n+        Parameters\n+        ----------\n+        maha : ndarray\n+        start_scale : None or float\n+            Starting scale. If it is None, the mad of maha wi\n+        maxiter : int\n+            Maximum iterations to compute M-scale\n+        rtol, atol : float\n+            Relative and absolute convergence criteria for scale used with\n+            allclose.\n+\n+        Returns\n+        -------\n+        float : scale estimate\n+        \"\"\"\n+        if start_scale is None:\n+            # TODO: this does not really make sense\n+            # better scale to median of maha and chi or chi2\n+            start_scale = mad(maha)\n+\n+        scale = rscale._scale_iter(\n+            maha,\n+            scale0=start_scale,\n+            maxiter=maxiter,\n+            rtol=rtol,\n+            atol=atol,\n+            meef_scale=self.rho,\n+            scale_bias=self.scale_bias,\n+            )\n+        return scale\n+\n+    def fit(self, start_mean=None, start_shape=None, start_scale=None,\n+            maxiter=100, update_scale=True):\n+        \"\"\"Estimate mean, shape and scale parameters with MM-estimator.\n+\n+        Parameters\n+        ----------\n+        start_mean : None or float\n+            Starting value for mean, center.\n+            If None, then median is used.\n+        start_shape : None or 2-dim ndarray\n+            Starting value of shape matrix, i.e. scatter matrix normalized\n+            to det(scatter) = 1.\n+            If None, then scaled covariance matrix of data is used.\n+        start_scale : None or float.\n+            Starting value of scale.\n+        maxiter : int\n+            Maximum number of iterations.\n+        update_scale : bool\n+            If update_scale is False, then\n+\n+        Returns\n+        -------\n+        results instance with mean, shape, scale, cov and other attributes.\n+\n+        Notes\n+        -----\n+        If start_scale is provided and update_scale is False, then this is\n+        an M-estimator with a predetermined scale as used in the second\n+        stage of an MM-estimator.\n+\n+        \"\"\"\n+\n+        converged = False\n+\n+        if start_scale is not None:\n+            scale_old = start_scale\n+        else:\n+            scale_old = 1\n+            # will be reset if start_shape is also None.\n+        if start_mean is not None:\n+            mean_old = start_mean\n+        else:\n+            mean_old = np.median(self.data, axis=0)\n+        if start_shape is not None:\n+            shape_old = start_shape\n+        else:\n+            shape_old = np.cov(self.data.T)\n+            scale = np.linalg.det(shape_old) ** (1 / self.k_vars)\n+            shape_old /= scale\n+            if start_scale is not None:\n+                scale_old = scale\n+\n+        if update_scale is False:\n+            scale = start_scale\n+\n+        for i in range(maxiter):\n+            shape, mean = self._fit_mean_shape(mean_old, shape_old, scale_old)\n+            d = mahalanobis(self.data - mean, shape, sqrt=True)\n+            if update_scale:\n+                scale = self._fit_scale(d, start_scale=scale_old, maxiter=10)\n+\n+            if (np.allclose(scale, scale_old, rtol=1e-5) and\n+                    np.allclose(mean, mean_old, rtol=1e-5) and\n+                    np.allclose(shape, shape_old, rtol=1e-5)\n+                    ):  # noqa E124\n+                converged = True\n+                break\n+            scale_old = scale\n+            mean_old = mean\n+            shape_old = shape\n+\n+        maha = mahalanobis(self.data - mean, shape / scale, sqrt=True)\n+\n+        res = Holder(\n+            mean=mean,\n+            shape=shape,\n+            scale=scale,\n+            cov=shape * scale**2,\n+            converged=converged,\n+            n_iter=i,\n+            mahalanobis=maha,\n+            )\n+        return res\n+\n+\n+class CovDetMCD:\n+    \"\"\"Minimum covariance determinant estimator with deterministic starts.\n+\n+    preliminary version\n+\n+    reproducability:\n+\n+    This uses deterministic starting sets and there is no randomness in the\n+    estimator.\n+    However, this will not be reprodusible across statsmodels versions\n+    when the methods for starting sets or tuning parameters for the\n+    optimization change.\n+\n+    Parameters\n+    ----------\n+    data : array-like\n+        Multivariate data set with observation in rows and variables in\n+        columns.\n+\n+    Notes\n+    -----\n+    The correction to the scale to take account of trimming in the reweighting\n+    estimator is based on the chisquare tail probability.\n+    This differs from CovMcd in R which uses the observed fraction of\n+    observations above the metric trimming threshold.\n+\n+    References\n+    ----------\n+    ..[1] Hubert, Mia, Peter Rousseeuw, Dina Vanpaemel, and Tim Verdonck. 2015.\n+       \u201cThe DetS and DetMM Estimators for Multivariate Location and Scatter.\u201d\n+       Computational Statistics & Data Analysis 81 (January): 64\u201375.\n+       https://doi.org/10.1016/j.csda.2014.07.013.\n+    ..[2] Hubert, Mia, Peter J. Rousseeuw, and Tim Verdonck. 2012. \u201cA\n+       Deterministic Algorithm for Robust Location and Scatter.\u201d Journal of\n+       Computational and Graphical Statistics 21 (3): 618\u201337.\n+       https://doi.org/10.1080/10618600.2012.672100.\n+    \"\"\"\n+\n+    def __init__(self, data):\n+        # no options yet, methods were written as functions\n+        self.data = np.asarray(data)\n+\n+    def _cstep(self, x, mean, cov, h, maxiter=2, tol=1e-8):\n+        \"\"\"C-step for mcd iteration\n+\n+        x is data, perc is percentile h / nobs, don't need perc when we\n+        use np.argpartition\n+        requires starting mean and cov\n+        \"\"\"\n+\n+        converged = False\n+\n+        for _ in range(maxiter):\n+            d = mahalanobis(x - mean, cov)\n+            idx_sel = np.argpartition(d, h)[:h]\n+            x_sel = x[idx_sel]\n+            mean = x_sel.mean(0)\n+            cov_new = np.cov(x_sel.T, ddof=1)\n+\n+            if ((cov - cov_new)**2).mean() < tol:\n+                cov = cov_new\n+                converged = True\n+                break\n+\n+            cov = cov_new\n+\n+        return mean, cov, converged\n+\n+    def _fit_one(self, x, idx, h, maxiter=2, mean=None, cov=None):\n+        \"\"\"Compute mcd for one starting set of observations.\n+\n+        Parameters\n+        ----------\n+        x : ndarray\n+            Data.\n+        idx : ndarray\n+            Indices or mask of observation in starting set, used as ``x[idx]``\n+        h : int\n+            Number of observations in evaluation set for cov.\n+        maxiter : int\n+            Maximum number of c-steps.\n+\n+        Returns\n+        -------\n+        mean : ndarray\n+            Estimated mean.\n+        cov : ndarray\n+            Estimated covariance.\n+        det : float\n+            Determinant of estimated covariance matrix.\n+\n+        Notes\n+        -----\n+        This does not do any preprocessing of the data and returns the\n+        empirical mean and covariance of evaluation set of the data ``x``.\n+        \"\"\"\n+        if idx is not None:\n+            x_sel = x[idx]\n+        else:\n+            x_sel = x\n+        if mean is None:\n+            mean = x_sel.mean(0)\n+        if cov is None:\n+            cov = np.cov(x_sel.T, ddof=1)\n+\n+        # updated with c-step\n+        mean, cov, conv = self._cstep(x, mean, cov, h, maxiter=maxiter)\n+        det = np.linalg.det(cov)\n+\n+        return mean, cov, det, conv\n+\n+    def fit(self, h, *, h_start=None, mean_func=None, scale_func=None,\n+            maxiter=100, options_start=None, reweight=True,\n+            trim_frac=0.975, maxiter_step=100):\n+        \"\"\"\n+        Compute minimum covariance determinant estimate of mean and covariance.\n+\n+        x : array-like\n+            Data with observation in rows and variables in columns.\n+        h : int\n+            Number of observations in evaluation set for minimimizing\n+            determinant.\n+        h_start : int\n+            Number of observations used in starting mean and covariance.\n+        mean_func, scale_func : callable or None.\n+            Mean and scale function for initial standardization.\n+            Current defaults, if they are None, are median and mad, but\n+            default scale_func will likely change.\n+        options_start : None or dict\n+            Options for the starting estimators.\n+            currently not used\n+            TODO: which options? e.g. for OGK\n+        reweight : bool\n+            If reweight is true, then a reweighted estimator is returned. The\n+            reweighting is based on a chisquare trimming of Mahalanobis\n+            distances. The raw results are in the ``results_raw`` attribute.\n+        trim_frac : float in (0, 1)\n+            Trim fraction used if reweight is true. Used to compute quantile\n+            of chisquare distribution with tail probability 1 - trim_frac.\n+        maxiter_step : int\n+            Number of iteration in the c-step.\n+            In the current implementation a small maxiter in the c-step does\n+            not find the optimal solution.\n+\n+        Returns\n+        -------\n+        Holder instance with results\n+        \"\"\"\n+\n+        x = self.data\n+        nobs, k_vars = x.shape\n+\n+        if h is None:\n+            h = (nobs + k_vars + 1) // 2  # check with literature\n+        if mean_func is None:\n+            mean_func = lambda x: np.median(x, axis=0)  # noqa\n+        if scale_func is None:\n+            scale_func = mad\n+        if options_start is None:\n+            options_start = {}\n+        if h_start is None:\n+            nobs, k_vars = x.shape\n+            h_start = max(nobs // 2 + 1, k_vars + 1)\n+\n+        m = mean_func(x)\n+        s = scale_func(x)\n+        z = (x - m) / s\n+        # get initial mean, cov of standardized data, we only need ranking\n+        # of obs\n+        starts = _get_detcov_startidx(z, h_start, options_start)\n+\n+        fac_trunc = coef_normalize_cov_truncated(h / nobs, k_vars)\n+\n+        res = {}\n+        for ii, ini in enumerate(starts):\n+            idx_sel, method = ini\n+            mean, cov, det, _ = self._fit_one(x, idx_sel, h,\n+                                              maxiter=maxiter_step)\n+            res[ii] = Holder(\n+                mean=mean,\n+                cov=cov * fac_trunc,\n+                det_subset=det,\n+                method=method,\n+                )\n+\n+        det_all = np.array([i.det_subset for i in res.values()])\n+        idx_best = np.argmin(det_all)\n+        best = res[idx_best]\n+        # mean = best.mean\n+        # cov = best.cov\n+\n+        # need to c-step to convergence for best,\n+        # is with best 2 in original DetMCD\n+        if maxiter_step < maxiter:\n+            mean, cov, det, conv = self._fit_one(x, None, h, maxiter=maxiter,\n+                                                 mean=best.mean, cov=best.cov)\n+            best = Holder(\n+                mean=mean,\n+                cov=cov * fac_trunc,\n+                det_subset=det,\n+                method=method,\n+                converged=conv,\n+                )\n+\n+        # include extra info in returned Holder instance\n+        best.det_all = det_all\n+        best.idx_best = idx_best\n+\n+        best.tmean = m\n+        best.tscale = s\n+\n+        if reweight:\n+            cov, mean = _reweight(x, best.mean, best.cov, trim_frac=trim_frac,\n+                                  ddof=1)\n+            fac_trunc = coef_normalize_cov_truncated(trim_frac, k_vars)\n+            best_w = Holder(\n+                mean=mean,\n+                cov=cov * fac_trunc,\n+                # det_subset=det,\n+                method=method,\n+                results_raw=best,\n+                )\n+\n+            return best_w\n+        else:\n+            return best  # is Holder instance already\n+\n+\n+class CovDetS:\n+    \"\"\"S-estimator for mean and covariance with deterministic starts.\n+\n+    Parameters\n+    ----------\n+    data : array-like\n+        Multivariate data set with observation in rows and variables in\n+        columns.\n+    norm : norm instance\n+        If None, then TukeyBiweight norm is used.\n+        (Currently no other norms are supported for calling the initial\n+        S-estimator)\n+    breakdown_point : float in (0, 0.5]\n+        Breakdown point for first stage S-estimator.\n+\n+    Notes\n+    -----\n+    Reproducability:\n+\n+    This uses deterministic starting sets and there is no randomness in the\n+    estimator.\n+    However, the estimates may not be reproducable across statsmodels versions\n+    when the methods for starting sets or default tuning parameters for the\n+    optimization change. With different starting sets, the estimate can\n+    converge to a different local optimum.\n+\n+    References\n+    ----------\n+    ..[1] Hubert, Mia, Peter Rousseeuw, Dina Vanpaemel, and Tim Verdonck. 2015.\n+       \u201cThe DetS and DetMM Estimators for Multivariate Location and Scatter.\u201d\n+       Computational Statistics & Data Analysis 81 (January): 64\u201375.\n+       https://doi.org/10.1016/j.csda.2014.07.013.\n+    ..[2] Hubert, Mia, Peter J. Rousseeuw, and Tim Verdonck. 2012. \u201cA\n+       Deterministic Algorithm for Robust Location and Scatter.\u201d Journal of\n+       Computational and Graphical Statistics 21 (3): 618\u201337.\n+       https://doi.org/10.1080/10618600.2012.672100.\n+    \"\"\"\n+\n+    def __init__(self, data, norm=None, breakdown_point=0.5):\n+        # no options yet, methods were written as functions\n+        self.data = np.asarray(data)\n+        self.nobs, k_vars = self.data.shape\n+        self.k_vars = k_vars\n+\n+        # self.scale_bias = scale_bias\n+        if norm is None:\n+            norm = rnorms.TukeyBiweight()\n+            c = rtools.tuning_s_cov(norm, k_vars, breakdown_point=0.5)\n+            norm._set_tuning_param(c, inplace=True)\n+            self.scale_bias = rtools.scale_bias_cov_biw(c, k_vars)[0]\n+        else:\n+            raise NotImplementedError(\"only Biweight norm is supported\")\n+\n+        self.norm = norm\n+\n+        self.mod = CovM(data, norm_mean=norm, norm_scatter=norm,\n+                        scale_bias=self.scale_bias, method=\"S\")\n+\n+    def _get_start_params(self, idx):\n+        \"\"\"Starting parameters from a subsample given by index\n+\n+        Parameters\n+        ----------\n+        idx : ndarray\n+            Index used to select observations from the data. The index is used\n+            for numpy arrays, so it can be either a boolean mask or integers.\n+\n+        Returns\n+        -------\n+        mean : ndarray\n+            Mean of subsample\n+        shape : ndarray\n+            The shape matrix of the subsample which is the covariance\n+            normalized so that determinant of shape is one.\n+        scale : float\n+            Scale of subsample, computed so that cov = shape * scale.\n+        \"\"\"\n+        x_sel = self.data[idx]\n+        k = x_sel.shape[1]\n+\n+        mean = x_sel.mean(0)\n+        cov = np.cov(x_sel.T)\n+\n+        scale2 = np.linalg.det(cov) ** (1 / k)\n+        shape = cov / scale2\n+        scale = np.sqrt(scale2)\n+        return mean, shape, scale\n+\n+    def _fit_one(self, mean=None, shape=None, scale=None, maxiter=100):\n+        \"\"\"Compute local M-estimator for one starting set of observations.\n+\n+        Parameters\n+        ----------\n+        x : ndarray\n+            Data.\n+        idx : ndarray\n+            Indices or mask of observation in starting set, used as ``x[idx]``\n+        h : int\n+            Number of observations in evaluation set for cov.\n+        maxiter : int\n+            Maximum number of c-steps.\n+\n+        Returns\n+        -------\n+        mean : ndarray\n+            Estimated mean.\n+        cov : ndarray\n+            Estimated covariance.\n+        det : float\n+            Determinant of estimated covariance matrix.\n+\n+        Notes\n+        -----\n+        This uses CovM to solve for the local optimum for given starting\n+        values.\n+        \"\"\"\n+\n+        res = self.mod.fit(\n+            start_mean=mean,\n+            start_shape=shape,\n+            start_scale=scale,\n+            maxiter=maxiter,\n+            update_scale=True\n+            )\n+\n+        return res\n+\n+    def fit(self, *, h_start=None, mean_func=None, scale_func=None,\n+            maxiter=100, options_start=None, maxiter_step=5):\n+        \"\"\"Compute S-estimator of mean and covariance.\n+\n+        Parameters\n+        ----------\n+        h_start : int\n+            Number of observations used in starting mean and covariance.\n+        mean_func, scale_func : callable or None.\n+            Mean and scale function for initial standardization.\n+            Current defaults, if they are None, are median and mad, but\n+            default scale_func will likely change.\n+        options_start : None or dict\n+           Options for the starting estimators.\n+           TODO: which options? e.g. for OGK\n+\n+        Returns\n+        -------\n+        Holder instance with results\n+        \"\"\"\n+\n+        x = self.data\n+        nobs, k_vars = x.shape\n+\n+        if mean_func is None:\n+            mean_func = lambda x: np.median(x, axis=0)  # noqa\n+        if scale_func is None:\n+            scale_func = mad\n+        if options_start is None:\n+            options_start = {}\n+        if h_start is None:\n+            nobs, k_vars = x.shape\n+            h_start = max(nobs // 2 + 1, k_vars + 1)\n+\n+        m = mean_func(x)\n+        s = scale_func(x)\n+        z = (x - m) / s\n+        # get initial mean, cov of standardized data, we only need ranking\n+        # of obs\n+        starts = _get_detcov_startidx(z, h_start, options_start)\n+\n+        res = {}\n+        for ii, ini in enumerate(starts):\n+            idx_sel, method = ini\n+            mean0, shape0, scale0 = self._get_start_params(idx_sel)\n+            res_i = self._fit_one(\n+                mean=mean0,\n+                shape=shape0,\n+                scale=scale0,\n+                maxiter=maxiter_step,\n+                )\n+\n+            res_i.method = method\n+            res[ii] = res_i\n+\n+        scale_all = np.array([i.scale for i in res.values()])\n+        idx_best = np.argmin(scale_all)\n+        best = res[idx_best]\n+        # mean = best.mean\n+        # cov = best.cov\n+\n+        # need to c-step to convergence for best,\n+        # is with best 2 in original DetMCD\n+        if maxiter_step < maxiter:\n+            best = self._fit_one(\n+                mean=best.mean,\n+                shape=best.shape,\n+                scale=best.scale,\n+                maxiter=maxiter,\n+                )\n+\n+        # include extra info in returned Holder instance\n+        best.scale_all = scale_all\n+        best.idx_best = idx_best\n+\n+        best.tmean = m\n+        best.tscale = s\n+\n+        return best  # is Holder instance already\n+\n+\n+class CovDetMM():\n+    \"\"\"MM estimator using DetS as first stage estimator.\n+\n+    Note: The tuning parameter for second stage M estimator is currently only\n+    available for a small number of variables and only three values of\n+    efficiency. For other cases, the user has to provide the norm instance\n+    with desirec tuning parameter.\n+\n+    Parameters\n+    ----------\n+    data : array-like\n+        Multivariate data set with observation in rows and variables in\n+        columns.\n+    norm : norm instance\n+        If None, then TukeyBiweight norm is used.\n+        (Currently no other norms are supported for calling the initial\n+        S-estimator)\n+        If ``norm`` is an instance of TukeyBiweight, then it will be used in\n+        the second stage M-estimation. The ``efficiency`` argument is ignored\n+        and the tuning parameter of the user provided instance is not changed.\n+    breakdown_point : float in (0, 0.5]\n+        Breakdown point for first stage S-estimator.\n+    efficiency : float\n+        Asymptotic efficiency of second stage M estimator.\n+\n+    Notes\n+    -----\n+    Current limitation is that only TukeyBiweight is supported.\n+\n+    The tuning parameter for second stage M estimator uses a table of values\n+    for number of variables up to 15 and efficiency in\n+    [0.75, 0.8, 0.85, 0.9, 0.95, 0.975, 0.99]. The tuning parameter for other\n+    cases needs to be computed by numerical integration and rootfinding.\n+    Alternatively, the user can provide a norm instance with desired tuning\n+    parameter.\n+\n+    References\n+    ----------\n+    ..[1] Hubert, Mia, Peter Rousseeuw, Dina Vanpaemel, and Tim Verdonck. 2015.\n+       \u201cThe DetS and DetMM Estimators for Multivariate Location and Scatter.\u201d\n+       Computational Statistics & Data Analysis 81 (January): 64\u201375.\n+       https://doi.org/10.1016/j.csda.2014.07.013.\n+    ..[2] Hubert, Mia, Peter J. Rousseeuw, and Tim Verdonck. 2012. \u201cA\n+       Deterministic Algorithm for Robust Location and Scatter.\u201d Journal of\n+       Computational and Graphical Statistics 21 (3): 618\u201337.\n+       https://doi.org/10.1080/10618600.2012.672100.\n+    ..[3] Lopuha\u00e4, Hendrik P. 1989. \u201cOn the Relation between S-Estimators and\n+       M-Estimators of Multivariate Location and Covariance.\u201d The Annals of\n+       Statistics 17 (4): 1662\u201383.\n+    ..[4] Salibi\u00e1n-Barrera, Mat\u00edas, Stefan Van Aelst, and Gert Willems. 2006.\n+       \u201cPrincipal Components Analysis Based on Multivariate MM Estimators with\n+       Fast and Robust Bootstrap.\u201d Journal of the American Statistical\n+       Association 101 (475): 1198\u20131211.\n+    ..[5] Tatsuoka, Kay S., and David E. Tyler. 2000. \u201cOn the Uniqueness of\n+       S-Functionals and M-Functionals under Nonelliptical Distributions.\u201d The\n+       Annals of Statistics 28 (4): 1219\u201343.\n+    \"\"\"\n+\n+    def __init__(self, data, norm=None, breakdown_point=0.5, efficiency=0.95):\n+        self.data = np.asarray(data)\n+        self.nobs, k_vars = self.data.shape\n+        self.k_vars = k_vars\n+        self.breakdown_point = breakdown_point\n+\n+        # self.scale_bias = scale_bias\n+        if norm is None:\n+            norm = rnorms.TukeyBiweight()\n+            c = rtools.tukeybiweight_mvmean_eff(k_vars, efficiency)\n+            norm._set_tuning_param(c, inplace=True)\n+            # scale_bias is not used for second stage MM norm\n+            # self.scale_bias = rtools.scale_bias_cov_biw(c, k_vars)[0]\n+        elif not isinstance(norm, rnorms.TukeyBiweight):\n+            raise NotImplementedError(\"only Biweight norm is supported\")\n+        # We allow tukeybiweight norm instance with user provided c\n+\n+        self.norm = norm\n+        # model for second stage M-estimator\n+        self.mod = CovM(data, norm_mean=norm, norm_scatter=norm,\n+                        scale_bias=None, method=\"S\")\n+\n+    def fit(self, maxiter=100):\n+        \"\"\"Estimate model parameters.\n+\n+        Parameters\n+        ----------\n+        maxiter : int\n+            Maximum number of iterations in the second stage M-estimation.\n+        fit args : dict\n+            currently missing\n+\n+        Returns\n+        -------\n+        Instance of a results or holder class.\n+\n+        Notes\n+        -----\n+        This uses CovDetS for the first stage estimation and CovM with fixed\n+        scale in the second stage MM-estimation.\n+\n+        TODO: fit options are missing.\n+\n+        \"\"\"\n+        # first stage estimate\n+        mod_s = CovDetS(\n+            self.data,\n+            norm=None,\n+            breakdown_point=self.breakdown_point\n+            )\n+        res_s = mod_s.fit()\n+\n+        res = self.mod.fit(\n+            start_mean=res_s.mean,\n+            start_shape=res_s.shape,\n+            start_scale=res_s.scale,\n+            maxiter=maxiter,\n+            update_scale=False,\n+            )\n+\n+        return res\ndiff --git a/statsmodels/robust/norms.py b/statsmodels/robust/norms.py\nindex b3993a68e61..1e7edac3b25 100644\n--- a/statsmodels/robust/norms.py\n+++ b/statsmodels/robust/norms.py\n@@ -1,6 +1,6 @@\n import numpy as np\n \n-# TODO: add plots to weighting functions for online docs.\n+from . import tools as rtools\n \n \n def _cabs(x):\n@@ -41,6 +41,9 @@ class RobustNorm:\n \n     continuous = 1\n \n+    def __repr__(self):\n+        return self.__class__.__name__\n+\n     def rho(self, z):\n         \"\"\"\n         The robust criterion estimator function.\n@@ -199,12 +202,16 @@ class HuberT(RobustNorm):\n     def __init__(self, t=1.345):\n         self.t = t\n \n-    def _set_tuning_param(self, c):\n+    def _set_tuning_param(self, c, inplace=False):\n         \"\"\"Set and change the tuning parameter of the Norm.\n \n         Warning: this needs to wipe cached attributes that depend on the param.\n         \"\"\"\n-        self.t = c\n+        if inplace:\n+            self.t = c\n+            return self\n+        else:\n+            return self.__class__(t=c)\n \n     def max_rho(self):\n         return np.inf\n@@ -322,6 +329,18 @@ class RamsayE(RobustNorm):\n     def __init__(self, a=.3):\n         self.a = a\n \n+    def _set_tuning_param(self, c, inplace=False):\n+        \"\"\"Set and change the tuning parameter of the Norm.\n+\n+        Warning: this needs to wipe cached attributes that depend on the param.\n+        \"\"\"\n+        # todo : change default to inplace=False, when tools are fixed\n+        if inplace:\n+            self.a = c\n+            return self\n+        else:\n+            return self.__class__(a=c)\n+\n     def max_rho(self):\n         return np.inf\n \n@@ -419,12 +438,16 @@ class AndrewWave(RobustNorm):\n     def __init__(self, a=1.339):\n         self.a = a\n \n-    def _set_tuning_param(self, a):\n+    def _set_tuning_param(self, c, inplace=False):\n         \"\"\"Set and change the tuning parameter of the Norm.\n \n         Warning: this needs to wipe cached attributes that depend on the param.\n         \"\"\"\n-        self.a = a\n+        if inplace:\n+            self.a = c\n+            return self\n+        else:\n+            return self.__class__(a=c)\n \n     def max_rho(self):\n         return 2 * self.a**2\n@@ -553,12 +576,16 @@ class TrimmedMean(RobustNorm):\n     def __init__(self, c=2.):\n         self.c = c\n \n-    def _set_tuning_param(self, c):\n+    def _set_tuning_param(self, c, inplace=False):\n         \"\"\"Set and change the tuning parameter of the Norm.\n \n         Warning: this needs to wipe cached attributes that depend on the param.\n         \"\"\"\n-        self.c = c\n+        if inplace:\n+            self.c = c\n+            return self\n+        else:\n+            return self.__class__(c=c)\n \n     def max_rho(self):\n         return self.rho(self.c)\n@@ -674,14 +701,20 @@ def __init__(self, a=2., b=4., c=8.):\n         self.b = b\n         self.c = c\n \n-    def _set_tuning_param(self, c):\n+    def _set_tuning_param(self, c, inplace=False):\n         \"\"\"Set and change the tuning parameter of the Norm.\n \n         Warning: this needs to wipe cached attributes that depend on the param.\n         \"\"\"\n-        self.c = c\n-        self.a = c / 4\n-        self.b = c / 2\n+        a = c / 4\n+        b = c / 2\n+        if inplace:\n+            self.c = c\n+            self.a = a\n+            self.b = b\n+            return self\n+        else:\n+            return self.__class__(a=a, b=b, c=c)\n \n     def max_rho(self):\n         return self.rho(self.c)\n@@ -862,12 +895,49 @@ class TukeyBiweight(RobustNorm):\n     def __init__(self, c=4.685):\n         self.c = c\n \n-    def _set_tuning_param(self, c):\n+    def __repr__(self):\n+        return f\"{self.__class__.__name__}(c={self.c})\"\n+\n+    @classmethod\n+    def get_tuning(cls, bp=None, eff=None):\n+        \"\"\"Tuning parameter for given breakdown point or efficiency.\n+\n+        This currently only return values from a table.\n+\n+        Parameters\n+        ----------\n+        bp : float in [0.05, 0.5] or None\n+            Required breakdown point\n+            Either bp or eff has to be specified, but not both.\n+        eff : float or None\n+            Required asymptotic efficiency.\n+            Either bp or eff has to be specified, but not both.\n+\n+        Returns\n+        -------\n+        float : tuning parameter.\n+\n+        \"\"\"\n+        if ((bp is None and eff is None) or\n+                (bp is not None and eff is not None)):\n+            raise ValueError(\"exactly one of bp and eff needs to be provided\")\n+\n+        if bp is not None:\n+            return rtools.tukeybiweight_bp[bp]\n+        elif eff is not None:\n+            return rtools.tukeybiweight_eff[eff]\n+\n+    def _set_tuning_param(self, c, inplace=False):\n         \"\"\"Set and change the tuning parameter of the Norm.\n \n         Warning: this needs to wipe cached attributes that depend on the param.\n         \"\"\"\n-        self.c = c\n+        # todo : change default to inplace=False, when tools are fixed\n+        if inplace:\n+            self.c = c\n+            return self\n+        else:\n+            return self.__class__(c=c)\n \n     def max_rho(self):\n         return self.rho(self.c)\n@@ -891,7 +961,7 @@ def rho(self, z):\n         Returns\n         -------\n         rho : ndarray\n-            rho(z) = -(1 - (z/c)**2)**3 * c**2/6.   for \\|z\\| <= R\n+            rho(z) = -(1 - (z/c)**2)**3 * c**2/6 + c**2/6   for \\|z\\| <= R\n \n             rho(z) = 0                              for \\|z\\| > R\n         \"\"\"\n@@ -983,12 +1053,16 @@ def __init__(self, c=3.61752, k=4):\n         self.c = c\n         self.k = k\n \n-    def _set_tuning_param(self, c):\n+    def _set_tuning_param(self, c, inplace=False):\n         \"\"\"Set and change the tuning parameter of the Norm.\n \n         Warning: this needs to wipe cached attributes that depend on the param.\n         \"\"\"\n-        self.c = c\n+        if inplace:\n+            self.c = c\n+            return self\n+        else:\n+            return self.__class__(c=c, k=self.k)\n \n     def max_rho(self):\n         return self.rho(self.c)\n@@ -1121,12 +1195,16 @@ def __init__(self, c=2.3849, df=4):\n         self.c = c\n         self.df = df\n \n-    def _set_tuning_param(self, c):\n+    def _set_tuning_param(self, c, inplace=False):\n         \"\"\"Set and change the tuning parameter of the Norm.\n \n         Warning: this needs to wipe cached attributes that depend on the param.\n         \"\"\"\n-        self.c = c\n+        if inplace:\n+            self.c = c\n+            return self\n+        else:\n+            return self.__class__(c=c, df=self.df)\n \n     def max_rho(self):\n         return np.inf\ndiff --git a/statsmodels/robust/resistant_linear_model.py b/statsmodels/robust/resistant_linear_model.py\nnew file mode 100644\nindex 00000000000..843b616ab61\n--- /dev/null\n+++ b/statsmodels/robust/resistant_linear_model.py\n@@ -0,0 +1,248 @@\n+\"\"\"\n+Created on Apr. 19, 2024 12:17:03 p.m.\n+\n+Author: Josef Perktold\n+License: BSD-3\n+\"\"\"\n+\n+import numpy as np\n+from statsmodels.base.model import Model\n+from statsmodels.regression.linear_model import OLS\n+from statsmodels.tools.testing import Holder\n+\n+from statsmodels.robust.robust_linear_model import RLM\n+import statsmodels.robust.norms as rnorms\n+import statsmodels.robust.scale as rscale\n+from statsmodels.robust.covariance import _get_detcov_startidx\n+\n+\n+class RLMDetS(Model):\n+    \"\"\"S-estimator for linear model with deterministic starts.\n+\n+\n+    Notes\n+    -----\n+    This estimator combines the method of Fast-S regression (Saliban-Barrera\n+    et al 2006) using starting sets similar to the deterministic estimation of\n+    multivariate location and scatter DetS and DetMM of Hubert et al (2012).\n+\n+\n+    References\n+    ----------\n+\n+    .. [1] Hubert, Mia, Peter J. Rousseeuw, and Tim Verdonck. 2012. \u201cA\n+       Deterministic Algorithm for Robust Location and Scatter.\u201d Journal of\n+       Computational and Graphical Statistics 21 (3): 618\u201337.\n+       https://doi.org/10.1080/10618600.2012.672100.\n+\n+    .. [2] Hubert, Mia, Peter Rousseeuw, Dina Vanpaemel, and Tim Verdonck.\n+       2015. \u201cThe DetS and DetMM Estimators for Multivariate Location and\n+       Scatter.\u201d Computational Statistics & Data Analysis 81 (January): 64\u201375.\n+       https://doi.org/10.1016/j.csda.2014.07.013.\n+\n+    .. [3] Rousseeuw, Peter J., Stefan Van Aelst, Katrien Van Driessen, and\n+        Jose Agull\u00f3. 2004. \u201cRobust Multivariate Regression.\u201d\n+        Technometrics 46 (3): 293\u2013305.\n+\n+    .. [4] Salibian-Barrera, Mat\u00edas, and V\u00edctor J. Yohai. 2006. \u201cA Fast\n+       Algorithm for S-Regression Estimates.\u201d Journal of Computational and\n+       Graphical Statistics 15 (2): 414\u201327.\n+\n+\n+    \"\"\"\n+\n+    def __init__(self, endog, exog, norm=None, breakdown_point=0.5,\n+                 col_indices=None, include_endog=False):\n+        super().__init__(endog, exog)\n+\n+        if norm is None:\n+            norm = rnorms.TukeyBiweight()\n+\n+        tune = norm.get_tuning(bp=breakdown_point)\n+        c = tune[0]\n+        scale_bias = tune[2]\n+        norm = norm._set_tuning_param(c, inplace=False)\n+        self.mscale = rscale.MScale(norm, scale_bias)\n+\n+        self.norm = norm\n+        self.breakdown_point = breakdown_point\n+\n+        # TODO: detect constant\n+        if col_indices is None:\n+            exog_start = self.exog[:, 1:]\n+        else:\n+            exog_start = self.exog[:, col_indices]\n+\n+        # data for robust mahalanobis distance of starting sets\n+        if include_endog:\n+            self.data_start = np.column_stack((endog, exog_start))\n+        else:\n+            self.data_start = exog_start\n+\n+    def _get_start_params(self, h):\n+        # I think we should use iterator with yield\n+\n+        if self.data_start.shape[1] == 0 and self.exog.shape[1] == 1:\n+            quantiles = np.quantile(self.endog, [0.25, 0.5, 0.75])\n+            start_params_all = [np.atleast_1d([q]) for q in quantiles]\n+            return start_params_all\n+\n+        starts = _get_detcov_startidx(\n+            self.data_start, h, options_start=None, methods_cov=\"all\")\n+\n+        start_params_all = [\n+            OLS(self.endog[idx], self.exog[idx]).fit().params\n+            for (idx, method) in starts\n+            ]\n+        return start_params_all\n+\n+    def _fit_one(self, start_params, maxiter=100):\n+        mod = RLM(self.endog, self.exog, M=self.norm)\n+        res = mod.fit(start_params=start_params,\n+                      scale_est=self.mscale,\n+                      maxiter=maxiter)\n+        return res\n+\n+    def fit(self, h, maxiter=100, maxiter_step=5, start_params_extra=None):\n+\n+        start_params_all = self._get_start_params(h)\n+        if start_params_extra:\n+            start_params_all.extend(start_params_extra)\n+        res = {}\n+        for ii, sp in enumerate(start_params_all):\n+            res_ii = self._fit_one(sp, maxiter=maxiter_step)\n+            res[ii] = Holder(\n+                scale=res_ii.scale,\n+                params=res_ii.params,\n+                method=ii,  # method  # TODO need start set method\n+                )\n+\n+        scale_all = np.array([i.scale for i in res.values()])\n+        scale_sorted = np.argsort(scale_all)\n+        best_idx = scale_sorted[0]\n+\n+        # TODO: iterate until convergence if start fits are not converged\n+        res_best = self._fit_one(res[best_idx].params, maxiter=maxiter)\n+\n+        # TODO: add extra start and convergence info\n+        res_best._results.results_iter = res\n+        # results instance of _fit_once has RLM as `model`\n+        res_best.model_dets = self\n+        return res_best\n+\n+\n+class RLMDetSMM(RLMDetS):\n+    \"\"\"MM-estimator with S-estimator starting values.\n+\n+    Parameters\n+    ----------\n+    endog : array-like, 1-dim\n+        Dependent, endogenous variable.\n+    exog array-like, 1-dim\n+        Inependent, exogenous regressor variables.\n+    norm : robust norm\n+        Redescending robust norm used for S- and MM-estimation.\n+        Default is TukeyBiweight.\n+    efficiency : float in (0, 1)\n+        Asymptotic efficiency of the MM-estimator (used in second stage).\n+    breakdown_point : float in (0, 0.5)\n+        Breakdown point of the preliminary S-estimator.\n+    col_indices : None or array-like of ints\n+        Index of columns of exog to use in the mahalanobis distance computation\n+        for the starting sets of the S-estimator.\n+        Default is all exog except first column (constant). Todo: will change\n+        when we autodetect the constant column\n+    include_endog : bool\n+        If true, then the endog variable is combined with the exog variables\n+        to compute the the mahalanobis distances for the starting sets of the\n+        S-estimator.\n+\n+    \"\"\"\n+    def __init__(self, endog, exog, norm=None, efficiency=0.95,\n+                 breakdown_point=0.5, col_indices=None, include_endog=False):\n+        super().__init__(\n+            endog,\n+            exog,\n+            norm=norm,\n+            breakdown_point=breakdown_point,\n+            col_indices=col_indices,\n+            include_endog=include_endog\n+            )\n+\n+        self.efficiency = efficiency\n+        if norm is None:\n+            norm = rnorms.TukeyBiweight()\n+\n+        c = norm.get_tuning(eff=efficiency)[0]\n+        norm = norm._set_tuning_param(c, inplace=False)\n+        self.norm_mean = norm\n+\n+    def fit(self, h=None, scale_binding=False, start=None):\n+        \"\"\"Estimate the model\n+\n+        Parameters\n+        ----------\n+        h : int\n+            The size of the initial sets for the S-estimator.\n+            Default is ....  (todo)\n+        scale_binding : bool\n+            If true, then the scale is fixed in the second stage M-estimation,\n+            i.e. this is the MM-estimator.\n+            If false, then the high breakdown point M-scale is used also in the\n+            second stage M-estimation if that estimated scale is smaller than\n+            the scale of the preliminary, first stage S-estimato.\n+        start : tuple or None\n+            If None, then the starting parameters and scale for the second\n+            stage M-estimation are taken from the fist stage S-estimator.\n+            Alternatively, the starting parameters and starting scale can be\n+            provided by the user as tuple (start_params, start_scale). In this\n+            case the first stage S-estimation in skipped.\n+        maxiter, other optimization parameters are still missing (todo)\n+\n+        Returns\n+        -------\n+        results instance\n+\n+        Notes\n+        -----\n+        If scale_binding is false, then the estimator is a standard\n+        MM-estimator with fixed scale in the second stage M-estimation.\n+        If scale_binding is true, then the estimator will try to find an\n+        estimate with lower M-scale using the same scale-norm rho as in the\n+        first stage S-estimator. If the estimated scale, is not smaller than\n+        then the scale estimated in the first stage S-estimator, then the\n+        fixed scale MM-estimator is returned.\n+\n+\n+        \"\"\"\n+        norm_m = self.norm_mean\n+        if start is None:\n+            res_s = super().fit(h)\n+            start_params = np.asarray(res_s.params)\n+            start_scale = res_s.scale\n+        else:\n+            start_params, start_scale = start\n+            res_s = None\n+\n+        mod_m = RLM(self.endog, self.exog, M=norm_m)\n+        res_mm = mod_m.fit(\n+            start_params=start_params,\n+            start_scale=start_scale,\n+            update_scale=False\n+            )\n+\n+        if not scale_binding:\n+            # we can compute this first and skip MM if scale decrease\n+            mod_sm = RLM(self.endog, self.exog, M=norm_m)\n+            res_sm = mod_sm.fit(\n+                start_params=start_params,\n+                scale_est=self.mscale\n+                )\n+\n+        if not scale_binding and res_sm.scale < res_mm.scale:\n+            res = res_sm\n+        else:\n+            res = res_mm\n+\n+        res._results.results_dets = res_s\n+        return res\ndiff --git a/statsmodels/robust/robust_linear_model.py b/statsmodels/robust/robust_linear_model.py\nindex d3c10573130..2bd52909b76 100644\n--- a/statsmodels/robust/robust_linear_model.py\n+++ b/statsmodels/robust/robust_linear_model.py\n@@ -263,6 +263,7 @@ def fit(self, maxiter=50, tol=1e-8, scale_est='mad', init=None, cov='H1',\n             wls_results = lm.WLS(self.endog, self.exog).fit()\n         else:\n             start_params = np.asarray(start_params, dtype=np.double).squeeze()\n+            start_params = np.atleast_1d(start_params)\n             if (start_params.shape[0] != self.exog.shape[1] or\n                     start_params.ndim != 1):\n                 raise ValueError('start_params must by a 1-d array with {} '\n@@ -276,6 +277,8 @@ def fit(self, maxiter=50, tol=1e-8, scale_est='mad', init=None, cov='H1',\n             self.scale = self._estimate_scale(wls_results.resid)\n         elif start_scale:\n             self.scale = start_scale\n+            if not update_scale:\n+                self.scale_est = scale_est = \"fixed\"\n \n         history = dict(params=[np.inf], scale=[])\n         if conv == 'coefs':\ndiff --git a/statsmodels/robust/scale.py b/statsmodels/robust/scale.py\nindex d866d52f152..b9049a6f6ad 100644\n--- a/statsmodels/robust/scale.py\n+++ b/statsmodels/robust/scale.py\n@@ -426,6 +426,9 @@ def __init__(self, chi_func, scale_bias):\n         self.chi_func = chi_func\n         self.scale_bias = scale_bias\n \n+    def __repr__(self):\n+        return repr(self.chi_func)\n+\n     def __call__(self, data, **kwds):\n         return self.fit(data, **kwds)\n \ndiff --git a/statsmodels/robust/tools.py b/statsmodels/robust/tools.py\nindex a424d40f626..d923b37764a 100644\n--- a/statsmodels/robust/tools.py\n+++ b/statsmodels/robust/tools.py\n@@ -4,7 +4,7 @@\n Author: Josef Perktold\n License: BSD-3\n \"\"\"\n-\n+# flake8: noqa E731\n import numpy as np\n from scipy import stats, integrate, optimize\n \n@@ -57,8 +57,8 @@ def _var_normal(norm):\n \n \n     \"\"\"\n-    num = stats.norm.expect(lambda x: norm.psi(x)**2)\n-    denom = stats.norm.expect(lambda x: norm.psi_deriv(x))**2\n+    num = stats.norm.expect(lambda x: norm.psi(x)**2)  #noqa E731\n+    denom = stats.norm.expect(lambda x: norm.psi_deriv(x))**2  #noqa E731\n     return num / denom\n \n \n@@ -100,7 +100,7 @@ def _var_normal_jump(norm):\n \n \n     \"\"\"\n-    num = stats.norm.expect(lambda x: norm.psi(x)**2)\n+    num = stats.norm.expect(lambda x: norm.psi(x)**2)  #noqa E731\n \n     def func(x):\n         # derivative normal pdf\n@@ -142,7 +142,6 @@ def _get_tuning_param(norm, eff, kwd=\"c\", kwargs=None, use_jump=False,\n         efficiency.\n \n     \"\"\"\n-    kwds = {} if kwargs is None else kwargs\n     if bracket is None:\n         bracket = [0.1, 10]\n \n@@ -150,12 +149,12 @@ def _get_tuning_param(norm, eff, kwd=\"c\", kwargs=None, use_jump=False,\n         def func(c):\n             # kwds.update({kwd: c})\n             # return _var_normal(norm(**kwds)) - 1 / eff\n-            norm._set_tuning_param(c)\n+            norm._set_tuning_param(c, inplace=True)\n             return _var_normal(norm) - 1 / eff\n     else:\n         def func(c):\n-            norm._set_tuning_param(c)\n-            return _var_normal_jump(norm(**kwds) - 1 / eff)\n+            norm._set_tuning_param(c, inplace=True)\n+            return _var_normal_jump(norm) - 1 / eff\n \n     res = optimize.brentq(func, *bracket)\n     return res\n@@ -215,14 +214,15 @@ def tuning_s_estimator_mean(norm, breakdown=None):\n \n     def func(c):\n         norm_ = norm\n-        norm_._set_tuning_param(c)\n-        bp = stats.norm.expect(lambda x : norm_.rho(x)) / norm_.max_rho()\n+        norm_._set_tuning_param(c, inplace=True)\n+        bp = (stats.norm.expect(lambda x : norm_.rho(x)) /  #noqa E731\n+              norm_.max_rho())\n         return bp\n \n     res = []\n     for bp in bps:\n-        c_bp = optimize.brentq(lambda c0: func(c0) - bp, 0.1, 10)\n-        norm._set_tuning_param(c_bp)  # inplace modification\n+        c_bp = optimize.brentq(lambda c0: func(c0) - bp, 0.1, 10)  #noqa E731\n+        norm._set_tuning_param(c_bp, inplace=True)  # inplace modification\n         eff = 1 / _var_normal(norm)\n         b = stats.norm.expect(lambda x : norm.rho(x))\n         res.append([bp, eff, c_bp, b])\n@@ -242,3 +242,321 @@ def func(c):\n         )\n \n     return res2\n+\n+\n+def scale_bias_cov_biw(c, k_vars):\n+    \"\"\"Multivariate scale bias correction for TukeyBiweight norm.\n+\n+    This uses the chisquare distribution as reference distribution for the\n+    squared Mahalanobis distance.\n+    \"\"\"\n+    p = k_vars  # alias for formula\n+    chip, chip2, chip4, chip6 = stats.chi2.cdf(c**2, [p, p + 2, p + 4, p + 6])\n+    b = p / 2 * chip2 - p * (p + 2) / (2 * c**2) * chip4\n+    b += p * (p + 2) * (p + 4) / (6 * c**4) * chip6 + c**2 / 6 * (1 - chip)\n+    return b, b / (c**2 / 6)\n+\n+\n+def scale_bias_cov(norm, k_vars):\n+    \"\"\"Multivariate scale bias correction.\n+\n+\n+    Parameter\n+    ---------\n+    norm : norm instance\n+        The rho function of the norm is used in the moment condition for\n+        estimating scale.\n+    k_vars : int\n+        Number of random variables in the multivariate data.\n+\n+    Returns\n+    -------\n+    scale_bias: float\n+    breakdown_point : float\n+        Breakdown point computed as scale bias divided by max rho.\n+    \"\"\"\n+\n+    rho = lambda x: (norm.rho(np.sqrt(x)))  # noqa\n+    scale_bias = stats.chi2.expect(rho, args=(k_vars,))\n+    return scale_bias, scale_bias / norm.max_rho()\n+\n+\n+def tuning_s_cov(norm, k_vars, breakdown_point=0.5, limits=()):\n+    \"\"\"Tuning parameter for multivariate S-estimator given breakdown point.\n+    \"\"\"\n+    from .norms import TukeyBiweight  # avoid circular import\n+\n+    if not limits:\n+        limits = (0.5, 30)\n+\n+    if isinstance(norm, TukeyBiweight):\n+        def func(c):\n+            return scale_bias_cov_biw(c, k_vars)[1] - breakdown_point\n+    else:\n+        norm = norm._set_tuning_param(2., inplace=False)  # create copy\n+\n+        def func(c):\n+            norm._set_tuning_param(c, inplace=True)\n+            return scale_bias_cov(norm, k_vars)[1] - breakdown_point\n+\n+    p_tune = optimize.brentq(func, limits[0], limits[1])\n+    return p_tune\n+\n+\n+def eff_mvmean(norm, k_vars):\n+    \"\"\"Efficiency for M-estimator of multivariate mean at normal distribution.\n+\n+    This also applies to estimators that are locally equivalent to an\n+    M-estimator such as S- and MM-estimators.\n+\n+    Parameters\n+    ----------\n+    norm : instance of norm class\n+    k_vars : int\n+        Number of variables in multivariate random variable, i.e. dimension.\n+\n+    Returns\n+    -------\n+    eff : float\n+        Asymptotic relative efficiency of mean at normal distribution.\n+    alpha : float\n+        Numerical integral. Efficiency is beta**2 / alpha\n+    beta : float\n+        Numerical integral.\n+\n+    Notes\n+    -----\n+    This implements equ. (5.3) p. 1671 in Lopuha\u00e4 1989\n+\n+    References\n+    ----------\n+\n+    .. [1] Lopuha\u00e4, Hendrik P. 1989. \u201cOn the Relation between S-Estimators\n+       and M-Estimators of Multivariate Location and Covariance.\u201d\n+       The Annals of Statistics 17 (4): 1662\u201383.\n+\n+    \"\"\"\n+    k = k_vars  # shortcut\n+    f_alpha = lambda d: norm.psi(d)**2 / k\n+    f_beta = lambda d: ((1 - 1 / k) * norm.weights(d) +\n+                        1 / k * norm.psi_deriv(d))\n+    alpha = stats.chi(k).expect(f_alpha)\n+    beta = stats.chi(k).expect(f_beta)\n+    return beta**2 / alpha, alpha, beta\n+\n+\n+def eff_mvshape(norm, k_vars):\n+    \"\"\"Efficiency of M-estimator of multivariate shape at normal distribution.\n+\n+    This also applies to estimators that are locally equivalent to an\n+    M-estimator such as S- and MM-estimators.\n+\n+    Parameters\n+    ----------\n+    norm : instance of norm class\n+    k_vars : int\n+        Number of variables in multivariate random variable, i.e. dimension.\n+\n+    Returns\n+    -------\n+    eff : float\n+        Asymptotic relative efficiency of mean at normal distribution.\n+    alpha : float\n+        Numerical integral. Efficiency is beta**2 / alpha\n+    beta : float\n+        Numerical integral.\n+\n+    Notes\n+    -----\n+    This implements sigma_1 in equ. (5.5) p. 1671 in Lopuha\u00e4 1989.\n+    Efficiency of shape is approximately 1 / sigma1.\n+\n+    References\n+    ----------\n+\n+    .. [1] Lopuha\u00e4, Hendrik P. 1989. \u201cOn the Relation between S-Estimators\n+       and M-Estimators of Multivariate Location and Covariance.\u201d\n+       The Annals of Statistics 17 (4): 1662\u201383.\n+\n+    \"\"\"\n+\n+    k = k_vars  # shortcut\n+    f_a = lambda d: k * (k + 2) * norm.psi(d)**2 * d**2\n+    f_b = lambda d: norm.psi_deriv(d) * d**2 + (k + 1) * norm.psi(d) * d\n+    a = stats.chi(k).expect(f_a)\n+    b = stats.chi(k).expect(f_b)\n+    return b**2 / a, a, b\n+\n+\n+def tuning_m_cov_eff(norm, k_vars, efficiency=0.95, eff_mean=True, limits=()):\n+    \"\"\"Tuning parameter for multivariate M-estimator given efficiency.\n+\n+    This also applies to estimators that are locally equivalent to an\n+    M-estimator such as S- and MM-estimators.\n+\n+    Parameters\n+    ----------\n+    norm : instance of norm class\n+    k_vars : int\n+        Number of variables in multivariate random variable, i.e. dimension.\n+    efficiency : float < 1\n+        Desired asymptotic relative efficiency of mean estimator.\n+        Default is 0.95.\n+    eff_mean : bool\n+        If eff_mean is true (default), then tuning parameter is to achieve\n+        efficiency of mean estimate.\n+        If eff_mean is fale, then tuning parameter is to achieve efficiency\n+        of shape estimate.\n+    limits : tuple\n+        Limits for rootfinding with scipy.optimize.brentq.\n+        In some cases the interval limits for rootfinding can be too small\n+        and not cover the root. Current default limits are (0.5, 30).\n+\n+    Returns\n+    -------\n+    float : Tuning parameter for the norm to achieve desired efficiency.\n+        Asymptotic relative efficiency of mean at normal distribution.\n+\n+    Notes\n+    -----\n+    This uses numerical integration and rootfinding and will be\n+    relatively slow.\n+    \"\"\"\n+    if not limits:\n+        limits = (0.5, 30)\n+\n+    # make copy of norm\n+    norm = norm._set_tuning_param(1, inplace=False)\n+\n+    if eff_mean:\n+        def func(c):\n+            norm._set_tuning_param(c, inplace=True)\n+            return eff_mvmean(norm, k_vars)[0] - efficiency\n+    else:\n+        def func(c):\n+            norm._set_tuning_param(c, inplace=True)\n+            return eff_mvshape(norm, k_vars)[0] - efficiency\n+\n+    p_tune = optimize.brentq(func, limits[0], limits[1])\n+    return p_tune\n+\n+\n+#  ##### tables\n+\n+tukeybiweight_bp = {\n+    # breakdown point : (tuning parameter, efficiency, scale bias)\n+    0.50: (1.547645, 0.286826, 0.199600),\n+    0.45: (1.756059, 0.369761, 0.231281),\n+    0.40: (1.987965, 0.461886, 0.263467),\n+    0.35: (2.251831, 0.560447, 0.295793),\n+    0.30: (2.560843, 0.661350, 0.327896),\n+    0.25: (2.937015, 0.759040, 0.359419),\n+    0.20: (3.420681, 0.846734, 0.390035),\n+    0.15: (4.096255, 0.917435, 0.419483),\n+    0.10: (5.182361, 0.966162, 0.447614),\n+    0.05: (7.545252, 0.992424, 0.474424),\n+    }\n+\n+tukeybiweight_eff = {\n+    # efficiency : (tuning parameter, breakdown point)\n+    0.65: (2.523102, 0.305646),\n+    0.70: (2.697221, 0.280593),\n+    0.75: (2.897166, 0.254790),\n+    0.80: (3.136909, 0.227597),\n+    0.85: (3.443690, 0.197957),\n+    0.90: (3.882662, 0.163779),\n+    0.95: (4.685065, 0.119414),\n+    0.97: (5.596823, 0.087088),\n+    0.98: (5.920719, 0.078604),\n+    0.99: (7.041392, 0.056969),\n+    }\n+\n+# relative efficiency for M and MM estimator of multivariate location\n+# Table 2 from Kudraszow and Maronna JMA 2011\n+# k in [1, 2, 3, 4, 5, 10], eff in [0.8, 0.9, 0.95\n+# TODO: need to replace with more larger table and more digits.\n+# (4, 0.95): 5.76 -. 5.81 to better match R rrcov and numerical integration\n+tukeybiweight_mvmean_eff_km = {\n+        (1, 0.8): 3.14, (2, 0.8): 3.51, (3, 0.8): 3.82, (4, 0.8): 4.1,\n+        (5, 0.8): 4.34, (10, 0.8): 5.39,\n+        (1, 0.9): 3.88, (2, 0.9): 4.28, (3, 0.9): 4.62, (4, 0.9): 4.91,\n+        (5, 0.9): 5.18, (10, 0.9): 6.38,\n+        (1, 0.95): 4.68, (2, 0.95): 5.12, (3, 0.95): 5.48, (4, 0.95): 5.81,\n+        (5, 0.95): 6.1, (10, 0.95): 7.67,\n+        }\n+\n+_table_biweight_mvmean_eff = np.array([\n+    [2.89717, 3.13691, 3.44369, 3.88266, 4.68506, 5.59682, 7.04139],\n+    [3.26396, 3.51006, 3.82643, 4.2821, 5.12299, 6.0869, 7.62344],\n+    [3.5721, 3.82354, 4.14794, 4.61754, 5.49025, 6.49697, 8.10889],\n+    [3.84155, 4.09757, 4.42889, 4.91044, 5.81032, 6.85346, 8.52956],\n+    [4.08323, 4.34327, 4.68065, 5.17267, 6.09627, 7.17117, 8.90335],\n+    [4.30385, 4.56746, 4.91023, 5.41157, 6.35622, 7.45933, 9.24141],\n+    [4.50783, 4.77466, 5.12228, 5.63199, 6.59558, 7.72408, 9.5512],\n+    [4.69828, 4.96802, 5.32006, 5.83738, 6.81817, 7.96977, 9.83797],\n+    [4.87744, 5.14986, 5.506, 6.03022, 7.02679, 8.19958, 10.10558],\n+    [5.04704, 5.32191, 5.68171, 6.21243, 7.22354, 8.41594, 10.35696],\n+    [5.20839, 5.48554, 5.84879, 6.38547, 7.41008, 8.62071, 10.59439],\n+    [5.36254, 5.64181, 6.00827, 6.55051, 7.58772, 8.81538, 10.81968],\n+    [5.51034, 5.7916, 6.16106, 6.7085, 7.75752, 9.00118, 11.03428],\n+    [5.65249, 5.9356, 6.3079, 6.86021, 7.92034, 9.17908, 11.23939],\n+    ])\n+\n+_table_biweight_mvshape_eff = np.array([\n+    [3.57210, 3.82354, 4.14794, 4.61754, 5.49025, 6.49697, 8.10889],\n+    [3.84155, 4.09757, 4.42889, 4.91044, 5.81032, 6.85346, 8.52956],\n+    [4.08323, 4.34327, 4.68065, 5.17267, 6.09627, 7.17117, 8.90335],\n+    [4.30385, 4.56746, 4.91023, 5.41157, 6.35622, 7.45933, 9.24141],\n+    [4.50783, 4.77466, 5.12228, 5.63199, 6.59558, 7.72408, 9.55120],\n+    [4.69828, 4.96802, 5.32006, 5.83738, 6.81817, 7.96977, 9.83797],\n+    [4.87744, 5.14986, 5.50600, 6.03022, 7.02679, 8.19958, 10.10558],\n+    [5.04704, 5.32191, 5.68171, 6.21243, 7.22354, 8.41594, 10.35696],\n+    [5.20839, 5.48554, 5.84879, 6.38547, 7.41008, 8.62071, 10.59439],\n+    [5.36254, 5.64181, 6.00827, 6.55051, 7.58772, 8.81538, 10.81968],\n+    [5.51034, 5.79160, 6.16106, 6.70849, 7.75752, 9.00118, 11.03428],\n+    [5.65249, 5.93560, 6.30790, 6.86021, 7.92034, 9.17908, 11.23939],\n+    [5.78957, 6.07443, 6.44938, 7.00630, 8.07692, 9.34991, 11.43603],\n+    [5.92206, 6.20858, 6.58604, 7.14731, 8.22785, 9.51437, 11.62502],\n+    ])\n+\n+\n+def _convert_to_dict_mvmean_effs(eff_mean=True):\n+    effs_mvmean = [0.75, 0.8, 0.85, 0.9, 0.95, 0.975, 0.99]\n+    ks = list(range(1, 15))\n+    if eff_mean:\n+        table = _table_biweight_mvmean_eff\n+    else:\n+        table = _table_biweight_mvshape_eff\n+    tp = {}\n+    for i, k in enumerate(ks):\n+        for j, eff in enumerate(effs_mvmean):\n+            tp[(k, eff)] = table[i, j]\n+\n+    return tp\n+\n+\n+tukeybiweight_mvmean_eff_d = _convert_to_dict_mvmean_effs(eff_mean=True)\n+tukeybiweight_mvshape_eff_d = _convert_to_dict_mvmean_effs(eff_mean=False)\n+\n+\n+def tukeybiweight_mvmean_eff(k, eff, eff_mean=True):\n+    \"\"\"tuning parameter for biweight norm to achieve efficiency for mv-mean.\n+\n+    Uses values from precomputed table if available, otherwise computes it\n+    numerically and adds it to the module global dict.\n+\n+    \"\"\"\n+    if eff_mean:\n+        table_dict = tukeybiweight_mvmean_eff_d\n+    else:\n+        table_dict = tukeybiweight_mvshape_eff_d\n+\n+    try:\n+        tp = table_dict[(k, eff)]\n+    except KeyError:\n+        # compute and cache\n+        from .norms import TukeyBiweight  # avoid circular import\n+        norm = TukeyBiweight(c=1)\n+        tp = tuning_m_cov_eff(norm, k, efficiency=eff, eff_mean=eff_mean)\n+        table_dict[(k, eff)] = tp\n+    return tp\ndiff --git a/statsmodels/stats/covariance.py b/statsmodels/stats/covariance.py\nindex 341d952c880..3346912c3ba 100644\n--- a/statsmodels/stats/covariance.py\n+++ b/statsmodels/stats/covariance.py\n@@ -149,6 +149,18 @@ def transform_corr_normal(corr, method, return_var=False, possdef=True):\n         return corr_n\n \n \n+def corr_rank(data):\n+    \"\"\"Spearman rank correlation\n+\n+    simplified version of scipy.stats.spearmanr\n+    \"\"\"\n+    x = np.asarray(data)\n+    axisout = 0\n+    ar = np.apply_along_axis(stats.rankdata, axisout, x)\n+    corr = np.corrcoef(ar, rowvar=False)\n+    return corr\n+\n+\n def corr_normal_scores(data):\n     \"\"\"Gaussian rank (normal scores) correlation\n \n", "test_patch": "diff --git a/statsmodels/robust/tests/test_covariance.py b/statsmodels/robust/tests/test_covariance.py\nindex ac1eb3c6448..9aa60c5a07b 100644\n--- a/statsmodels/robust/tests/test_covariance.py\n+++ b/statsmodels/robust/tests/test_covariance.py\n@@ -6,6 +6,7 @@\n import pandas as pd\n \n from statsmodels import robust\n+import statsmodels.robust.norms as robnorms\n import statsmodels.robust.covariance as robcov\n import statsmodels.robust.scale as robscale\n \n@@ -177,6 +178,121 @@ def test_tyler():\n     assert res1.n_iter == 55\n \n \n+def test_cov_ms():\n+    # use CovM as local CovS\n+\n+    # > CovSest(x)  using package rrcov\n+    # same result with > CovSest(x, method=\"sdet\")\n+    # but scale difers with method=\"biweight\"\n+    mean_r = np.array([1.53420879676, 1.82865741024, 1.65565146981])\n+    cov_r = np.array([\n+        [1.8090846049573, 0.0479283121828, 0.2446369025717],\n+        [0.0479283121828, 1.8189886310494, 0.2513025527579],\n+        [0.2446369025717, 0.2513025527579, 1.7287983150484],\n+        ])\n+\n+    scale2_r = np.linalg.det(cov_r) ** (1/3)\n+    shape_r = cov_r / scale2_r\n+    scale_r = np.sqrt(scale2_r)\n+\n+    exog_df = dta_hbk[[\"X1\", \"X2\", \"X3\"]]\n+    mod = robcov.CovM(exog_df)\n+    # with default start, default start could get wrong local optimum\n+    res = mod.fit()\n+    assert_allclose(res.mean, mean_r, rtol=1e-5)\n+    assert_allclose(res.shape, shape_r, rtol=1e-5)\n+    assert_allclose(res.cov, cov_r, rtol=1e-5)\n+    assert_allclose(res.scale, scale_r, rtol=1e-5)\n+\n+    # with results start\n+    res = mod.fit(start_mean=mean_r, start_shape=shape_r, start_scale=scale_r)\n+    assert_allclose(res.mean, mean_r, rtol=1e-5)\n+    assert_allclose(res.shape, shape_r, rtol=1e-5)\n+    assert_allclose(res.cov, cov_r, rtol=1e-5)\n+    assert_allclose(res.scale, scale_r, rtol=1e-5)\n+\n+    mod_s = robcov.CovDetS(exog_df)\n+    res = mod_s.fit()\n+    assert_allclose(res.mean, mean_r, rtol=1e-5)\n+    assert_allclose(res.shape, shape_r, rtol=1e-5)\n+    assert_allclose(res.cov, cov_r, rtol=1e-5)\n+    assert_allclose(res.scale, scale_r, rtol=1e-5)\n+\n+\n+def test_covdetmcd():\n+\n+    # results from rrcov\n+    # > cdet = CovMcd(x = hbk, raw.only = TRUE, nsamp = \"deterministic\",\n+    #                 use.correction=FALSE)\n+    cov_dmcd_r = np.array(\"\"\"\n+    2.2059619213639   0.0223939863695   0.7898958050933   0.4060613360808\n+    0.0223939863695   1.1384166802155   0.4315534571891  -0.2344041030201\n+    0.7898958050933   0.4315534571891   1.8930117467493  -0.3292893001459\n+    0.4060613360808  -0.2344041030201  -0.3292893001459   0.6179686100845\n+    \"\"\".split(), float).reshape(4, 4)\n+\n+    mean_dmcd_r = np.array([1.7725, 2.2050, 1.5375, -0.0575])\n+\n+    mod = robcov.CovDetMCD(dta_hbk)\n+    res = mod.fit(40, maxiter_step=100, reweight=False)\n+    assert_allclose(res.mean, mean_dmcd_r, rtol=1e-5)\n+    assert_allclose(res.cov, cov_dmcd_r, rtol=1e-5)\n+\n+    # with reweighting\n+    # covMcd(x = hbk, nsamp = \"deterministic\", use.correction = FALSE)\n+    # iBest: 5; C-step iterations: 7, 7, 7, 4, 6, 6\n+    # Log(Det.):  -2.42931967153\n+\n+    mean_dmcdw_r = np.array([1.5338983050847, 1.8322033898305, 1.6745762711864,\n+                            -0.0728813559322])\n+    cov_dmcdw_r = np.array(\"\"\"\n+    1.5677744869295   0.09285770205078   0.252076010128   0.13873444408300\n+    0.0928577020508   1.56769177397171   0.224929617385  -0.00516128856542\n+    0.2520760101278   0.22492961738467   1.483829106079  -0.20275013775619\n+    0.1387344440830  -0.00516128856542  -0.202750137756   0.43326701543885\n+    \"\"\".split(), float).reshape(4, 4)\n+\n+    mod = robcov.CovDetMCD(dta_hbk)\n+    res = mod.fit(40, maxiter_step=100)  # default is reweight=True\n+    assert_allclose(res.mean, mean_dmcdw_r, rtol=1e-5)\n+    # R uses different trimming correction\n+    # compare only shape (using trace for simplicity)\n+    shape = res.cov / np.trace(res.cov)\n+    shape_r = cov_dmcdw_r / np.trace(cov_dmcdw_r)\n+    assert_allclose(shape, shape_r, rtol=1e-5)\n+\n+\n+def test_covdetmm():\n+\n+    # results from rrcov\n+    # CovMMest(x = hbk, eff.shape=FALSE,\n+    #          control=CovControlMMest(sest=CovControlSest(method=\"sdet\")))\n+    cov_dmm_r = np.array(\"\"\"\n+        1.72174266670826 0.06925842715939 0.20781848922667 0.10749343153015\n+        0.06925842715939 1.74566218886362 0.22161135221404 -0.00517023660647\n+        0.20781848922667 0.22161135221404 1.63937749762534 -0.17217102475913\n+        0.10749343153015 -0.00517023660647 -0.17217102475913 0.48174480967136\n+        \"\"\".split(), float).reshape(4, 4)\n+\n+    mean_dmm_r = np.array([1.5388643420460, 1.8027582110408, 1.6811517253521,\n+                           -0.0755069488908])\n+\n+    # using same c as rrcov\n+    c = 5.81031555752526\n+    mod = robcov.CovDetMM(dta_hbk, norm=robnorms.TukeyBiweight(c=c))\n+    res = mod.fit()\n+\n+    assert_allclose(res.mean, mean_dmm_r, rtol=1e-5)\n+    assert_allclose(res.cov, cov_dmm_r, rtol=1e-5, atol=1e-5)\n+\n+    # using c from table,\n+    mod = robcov.CovDetMM(dta_hbk)\n+    res = mod.fit()\n+\n+    assert_allclose(res.mean, mean_dmm_r, rtol=1e-3)\n+    assert_allclose(res.cov, cov_dmm_r, rtol=1e-3, atol=1e-3)\n+\n+\n def test_robcov_SMOKE():\n     # currently only smoke test or very loose comparisons to dgp\n     nobs, k_vars = 100, 3\ndiff --git a/statsmodels/robust/tests/test_tools.py b/statsmodels/robust/tests/test_tools.py\nindex a3adbb708b6..9b10b23a85c 100644\n--- a/statsmodels/robust/tests/test_tools.py\n+++ b/statsmodels/robust/tests/test_tools.py\n@@ -49,24 +49,26 @@\n @pytest.mark.parametrize(\"case\", results_menenez)\n def test_eff(case):\n     norm, res2 = case\n+    use_jump = False\n \n     if norm.continuous == 2:\n         var_func = _var_normal\n     else:\n         var_func = _var_normal_jump\n+        use_jump = True\n \n     res_eff = []\n     for c in res2:\n-        norm._set_tuning_param(c)\n+        norm._set_tuning_param(c, inplace=True)\n         res_eff.append(1 / var_func(norm))\n \n     assert_allclose(res_eff, effs, atol=0.0005)\n \n     for c in res2:\n         # bp = stats.norm.expect(lambda x : norm.rho(x)) / norm.rho(norm.c)\n-        norm._set_tuning_param(c)\n-        eff = 1 / _var_normal(norm)\n-        tune = _get_tuning_param(norm, eff)\n+        norm._set_tuning_param(c, inplace=True)\n+        eff = 1 / var_func(norm)\n+        tune = _get_tuning_param(norm, eff, use_jump=use_jump)\n         assert_allclose(tune, c, rtol=1e-6, atol=5e-4)\n \n \n", "problem_statement": "BUG: RLM fit with start_params raises if only one parameter\nif `start_params = np.array([5])` one element, 1-dim array, then the squeeze removes the 1-dim which then raises exception in shape check\r\n\r\n```\r\nstatsmodels_gh\\statsmodels\\statsmodels\\robust\\robust_linear_model.py in fit(self, maxiter, tol, scale_est, init, cov, update_scale, conv, start_params, start_scale)\r\n    264         else:\r\n    265             start_params = np.asarray(start_params, dtype=np.double).squeeze()\r\n--> 266             if (start_params.shape[0] != self.exog.shape[1] or\r\n    267                     start_params.ndim != 1):\r\n    268                 raise ValueError('start_params must by a 1-d array with {} '\r\n\r\nIndexError: tuple index out of range\r\n```\r\n\r\nI ran into this for the constant only regression for resistant estimators in #9227\r\n\r\nI don't know why there is the squeeze.\r\nIf we want or need to keep the squeeze, then a fix is to add\r\n`start_params = np.atleast_1d(start_params),`\r\n\r\nI will fix it this way in my PR, where I need it now\n", "hints_text": "", "created_at": "2024-04-22T15:56:21Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9210, "instance_id": "statsmodels__statsmodels-9210", "issue_numbers": ["9211"], "base_commit": "d6466f74b055ca83a023f619afd2dd3018cc6143", "patch": "diff --git a/.gitignore b/.gitignore\nindex 0c32bf53261..1bc8670606d 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -70,6 +70,7 @@ coverage_html_report/\n \n # VS Code\n .vscode/\n+.vs/\n \n # Project specific\n statsmodels/version.py\ndiff --git a/statsmodels/robust/covariance.py b/statsmodels/robust/covariance.py\nindex f89e40583e1..51acfb41111 100644\n--- a/statsmodels/robust/covariance.py\n+++ b/statsmodels/robust/covariance.py\n@@ -308,107 +308,6 @@ def _outlier_gy(d, distr=None, k_endog=1, trim_prob=0.975):\n \n # ## GK and OGK ###\n \n-def _weight_mean(x, c):\n-    \"\"\"Tukey-biweight, bisquare weights used in tau scale.\n-\n-    Parameters\n-    ----------\n-    x : ndarray\n-        Data\n-    c : float\n-        Parameter for bisquare weights\n-\n-    Returns\n-    -------\n-    ndarray : weights\n-    \"\"\"\n-    x = np.asarray(x)\n-    w = (1 - (x / c)**2)**2 * (np.abs(x) <= c)\n-    return w\n-\n-\n-def _winsor(x, c):\n-    \"\"\"Winsorized squared data used in tau scale.\n-\n-    Parameters\n-    ----------\n-    x : ndarray\n-        Data\n-    c : float\n-        threshold\n-\n-    Returns\n-    -------\n-    winsorized squared data, ``np.minimum(x**2, c**2)``\n-    \"\"\"\n-    return np.minimum(x**2, c**2)\n-\n-\n-def scale_tau(data, cm=4.5, cs=3, weight_mean=_weight_mean,\n-              weight_scale=_winsor, normalize=True, ddof=0):\n-    \"\"\"Tau estimator of univariate scale.\n-\n-    Experimental, API will change\n-\n-    Parameters\n-    ----------\n-    data : array_like, 1-D or 2-D\n-        If data is 2d, then the location and scale estimates\n-        are calculated for each column\n-    cm : float\n-        constant used in call to weight_mean\n-    cs : float\n-        constant used in call to weight_scale\n-    weight_mean : callable\n-        function to calculate weights for weighted mean\n-    weight_scale : callable\n-        function to calculate scale, \"rho\" function\n-    normalize : bool\n-        rescale the scale estimate so it is consistent when the data is\n-        normally distributed. The computation assumes winsorized (truncated)\n-        variance.\n-\n-    Returns\n-    -------\n-    mean : nd_array\n-        robust mean\n-    std : nd_array\n-        robust estimate of scale (standard deviation)\n-\n-    Notes\n-    -----\n-    Uses definition of Maronna and Zamar 2002, with weighted mean and\n-    trimmed variance.\n-    The normalization has been added to match R robustbase.\n-    R robustbase uses by default ddof=0, with option to set it to 2.\n-\n-    References\n-    ----------\n-    .. [1] Maronna, Ricardo A, and Ruben H Zamar. \u201cRobust Estimates of Location\n-       and Dispersion for High-Dimensional Datasets.\u201d Technometrics 44, no. 4\n-       (November 1, 2002): 307\u201317. https://doi.org/10.1198/004017002188618509.\n-    \"\"\"\n-\n-    x = np.asarray(data)\n-    nobs = x.shape[0]\n-\n-    med_x = np.median(x, 0)\n-    xdm = x - med_x\n-    mad_x = np.median(np.abs(xdm), 0)\n-    wm = weight_mean(xdm / mad_x, cm)\n-    mean = (wm * x).sum(0) / wm.sum(0)\n-    var = (mad_x**2 * weight_scale((x - mean) / mad_x, cs).sum(0) /\n-           (nobs - ddof))\n-\n-    cf = 1\n-    if normalize:\n-        c = cs * stats.norm.ppf(0.75)\n-        cf = 2 * ((1 - c**2) * stats.norm.cdf(c) - c * stats.norm.pdf(c)\n-                  + c**2) - 1\n-    # return Holder(loc=mean, scale=np.sqrt(var / cf))\n-    return mean, np.sqrt(var / cf)\n-\n-\n def mahalanobis(data, cov=None, cov_inv=None, sqrt=False):\n     \"\"\"Mahalanobis distance squared\n \ndiff --git a/statsmodels/robust/robust_linear_model.py b/statsmodels/robust/robust_linear_model.py\nindex 0b92c90d6e6..d3c10573130 100644\n--- a/statsmodels/robust/robust_linear_model.py\n+++ b/statsmodels/robust/robust_linear_model.py\n@@ -191,10 +191,12 @@ def _estimate_scale(self, resid):\n         elif isinstance(self.scale_est, scale.HuberScale):\n             return self.scale_est(self.df_resid, self.nobs, resid)\n         else:\n-            return scale.scale_est(self, resid) ** 2\n+            # use df correction to match HuberScale\n+            return self.scale_est(resid) * np.sqrt(self.nobs / self.df_resid)\n \n     def fit(self, maxiter=50, tol=1e-8, scale_est='mad', init=None, cov='H1',\n-            update_scale=True, conv='dev', start_params=None):\n+            update_scale=True, conv='dev', start_params=None, start_scale=None,\n+            ):\n         \"\"\"\n         Fits the model using iteratively reweighted least squares.\n \n@@ -217,6 +219,7 @@ def fit(self, maxiter=50, tol=1e-8, scale_est='mad', init=None, cov='H1',\n             Specifies method for the initial estimates of the parameters.\n             Default is None, which means that the least squares estimate\n             is used.  Currently it is the only available choice.\n+            Deprecated and will be removed. There is no choice here.\n         maxiter : int\n             The maximum number of iterations to try. Default is 50.\n         scale_est : str or HuberScale()\n@@ -236,6 +239,11 @@ def fit(self, maxiter=50, tol=1e-8, scale_est='mad', init=None, cov='H1',\n         start_params : array_like, optional\n             Initial guess of the solution of the optimizer. If not provided,\n             the initial parameters are computed using OLS.\n+        start_scale : float, optional\n+            Initial scale. If update_scale is False, then the scale will be\n+            fixed at this level for the estimation of the mean parameters.\n+            during iteration. If not provided, then the initial scale is\n+            estimated from the OLS residuals\n \n         Returns\n         -------\n@@ -264,8 +272,10 @@ def fit(self, maxiter=50, tol=1e-8, scale_est='mad', init=None, cov='H1',\n                                              check_weights=False)\n             wls_results = fake_wls.results(start_params)\n \n-        if not init:\n+        if not init and not start_scale:\n             self.scale = self._estimate_scale(wls_results.resid)\n+        elif start_scale:\n+            self.scale = start_scale\n \n         history = dict(params=[np.inf], scale=[])\n         if conv == 'coefs':\ndiff --git a/statsmodels/robust/scale.py b/statsmodels/robust/scale.py\nindex e938a83747a..d866d52f152 100644\n--- a/statsmodels/robust/scale.py\n+++ b/statsmodels/robust/scale.py\n@@ -248,11 +248,11 @@ def __call__(self, a, mu=None, initscale=None, axis=0):\n         \"\"\"\n         a = np.asarray(a)\n         if mu is None:\n-            n = a.shape[0] - 1\n+            n = a.shape[axis] - 1\n             mu = np.median(a, axis=axis)\n             est_mu = True\n         else:\n-            n = a.shape[0]\n+            n = a.shape[axis]\n             mu = mu\n             est_mu = False\n \n@@ -298,10 +298,10 @@ def _estimate_both(self, a, scale, mu, axis, est_mu, n):\n             nmu = tools.unsqueeze(nmu, axis, a.shape)\n \n             subset = np.less_equal(np.abs((a - mu) / scale), self.c)\n-            card = subset.sum(axis)\n \n-            scale_num = np.sum(subset * (a - nmu) ** 2, axis)\n-            scale_denom = n * self.gamma - (a.shape[axis] - card) * self.c ** 2\n+            scale_num = np.sum(subset * (a - nmu) ** 2 +\n+                               (1 - subset) * (scale * self.c)**2, axis)\n+            scale_denom = n * self.gamma\n             nscale = np.sqrt(scale_num / scale_denom)\n             nscale = tools.unsqueeze(nscale, axis, a.shape)\n \n@@ -408,6 +408,63 @@ def chi(s):\n hubers_scale = HuberScale()\n \n \n+class MScale:\n+    \"\"\"M-scale estimation.\n+\n+    experimental interface, arguments and options will still change.\n+\n+    Parameters\n+    ----------\n+    chi_func : callable\n+        The rho or chi function for the moment condition for estimating scale.\n+    scale_bias : float\n+        Factor in moment condition to obtain fisher consistency of the scale\n+        estimate at the normal distribution.\n+    \"\"\"\n+\n+    def __init__(self, chi_func, scale_bias):\n+        self.chi_func = chi_func\n+        self.scale_bias = scale_bias\n+\n+    def __call__(self, data, **kwds):\n+        return self.fit(data, **kwds)\n+\n+    def fit(self, data, start_scale='mad', maxiter=100, rtol=1e-6, atol=1e-8):\n+        \"\"\"\n+        Estimate M-scale using iteration.\n+\n+        Parameters\n+        ----------\n+        data : array-like\n+            Data, currently assumed to be 1-dimensional.\n+        start_scale : string or float.\n+            Starting value of scale or method to compute the starting value.\n+            Default is using 'mad', no other string options are available.\n+        maxiter : int\n+            Maximum number of iterations.\n+        rtol : float\n+            Relative convergence tolerance.\n+        atol : float\n+            Absolute onvergence tolerance.\n+\n+        Returns\n+        -------\n+        float : Scale estimate. The estimated variance is scale squared.\n+        Todo: switch to Holder instance with more information.\n+\n+        \"\"\"\n+\n+        scale = _scale_iter(\n+            data,\n+            scale0=start_scale,\n+            maxiter=maxiter, rtol=rtol, atol=atol,\n+            meef_scale=self.chi_func,\n+            scale_bias=self.scale_bias,\n+            )\n+\n+        return scale\n+\n+\n def scale_trimmed(data, alpha, center='median', axis=0, distr=None,\n                   distargs=None):\n     \"\"\"scale estimate based on symmetrically trimmed sample\n@@ -524,35 +581,134 @@ def scale_trimmed(data, alpha, center='median', axis=0, distr=None,\n     return res\n \n \n+def _weight_mean(x, c):\n+    \"\"\"Tukey-biweight, bisquare weights used in tau scale.\n+\n+    Parameters\n+    ----------\n+    x : ndarray\n+        Data\n+    c : float\n+        Parameter for bisquare weights\n+\n+    Returns\n+    -------\n+    ndarray : weights\n+    \"\"\"\n+    x = np.asarray(x)\n+    w = (1 - (x / c)**2)**2 * (np.abs(x) <= c)\n+    return w\n+\n+\n+def _winsor(x, c):\n+    \"\"\"Winsorized squared data used in tau scale.\n+\n+    Parameters\n+    ----------\n+    x : ndarray\n+        Data\n+    c : float\n+        threshold\n+\n+    Returns\n+    -------\n+    winsorized squared data, ``np.minimum(x**2, c**2)``\n+    \"\"\"\n+    return np.minimum(x**2, c**2)\n+\n+\n+def scale_tau(data, cm=4.5, cs=3, weight_mean=_weight_mean,\n+              weight_scale=_winsor, normalize=True, ddof=0):\n+    \"\"\"Tau estimator of univariate scale.\n+\n+    Experimental, API will change\n+\n+    Parameters\n+    ----------\n+    data : array_like, 1-D or 2-D\n+        If data is 2d, then the location and scale estimates\n+        are calculated for each column\n+    cm : float\n+        constant used in call to weight_mean\n+    cs : float\n+        constant used in call to weight_scale\n+    weight_mean : callable\n+        function to calculate weights for weighted mean\n+    weight_scale : callable\n+        function to calculate scale, \"rho\" function\n+    normalize : bool\n+        rescale the scale estimate so it is consistent when the data is\n+        normally distributed. The computation assumes winsorized (truncated)\n+        variance.\n+\n+    Returns\n+    -------\n+    mean : nd_array\n+        robust mean\n+    std : nd_array\n+        robust estimate of scale (standard deviation)\n+\n+    Notes\n+    -----\n+    Uses definition of Maronna and Zamar 2002, with weighted mean and\n+    trimmed variance.\n+    The normalization has been added to match R robustbase.\n+    R robustbase uses by default ddof=0, with option to set it to 2.\n+\n+    References\n+    ----------\n+    .. [1] Maronna, Ricardo A, and Ruben H Zamar. \u201cRobust Estimates of Location\n+       and Dispersion for High-Dimensional Datasets.\u201d Technometrics 44, no. 4\n+       (November 1, 2002): 307\u201317. https://doi.org/10.1198/004017002188618509.\n+    \"\"\"\n+\n+    x = np.asarray(data)\n+    nobs = x.shape[0]\n+\n+    med_x = np.median(x, 0)\n+    xdm = x - med_x\n+    mad_x = np.median(np.abs(xdm), 0)\n+    wm = weight_mean(xdm / mad_x, cm)\n+    mean = (wm * x).sum(0) / wm.sum(0)\n+    var = (mad_x**2 * weight_scale((x - mean) / mad_x, cs).sum(0) /\n+           (nobs - ddof))\n+\n+    cf = 1\n+    if normalize:\n+        c = cs * stats.norm.ppf(0.75)\n+        cf = 2 * ((1 - c**2) * stats.norm.cdf(c) - c * stats.norm.pdf(c)\n+                  + c**2) - 1\n+    # return Holder(loc=mean, scale=np.sqrt(var / cf))\n+    return mean, np.sqrt(var / cf)\n+\n+\n debug = 0\n \n \n-def _scale_iter(data, scale0='mad', maxiter=10, rtol=1e-6, atol=1e-8,\n-                meef_scale=None, scale_bias=None):\n+def _scale_iter(data, scale0='mad', maxiter=100, rtol=1e-6, atol=1e-8,\n+                meef_scale=None, scale_bias=None, iter_method=\"rho\", ddof=0):\n     \"\"\"iterative scale estimate base on \"rho\" function\n \n     \"\"\"\n     x = np.asarray(data)\n+    nobs = x.shape[0]\n     if scale0 == 'mad':\n-        scale0 = mad(x)\n+        scale0 = mad(x, center=0)\n \n-    scale = scale0\n-    scale_old = scale\n     for i in range(maxiter):\n-        x_scaled = x / scale\n-        weights_scale = meef_scale(x_scaled) / (1e-50 + x_scaled**2)\n-        if debug:\n-            print('weights sum', weights_scale.sum(), end=\" \")\n-        scale_old = scale\n-        scale2 = (weights_scale * x**2).mean()\n-        if debug:\n-            print(scale2, end=\" \")\n-        scale2 /= scale_bias\n-        scale = np.sqrt(scale2)\n+        x_scaled = x / scale0\n+        if iter_method == \"rho\":\n+            scale = scale0 * np.sqrt(\n+                np.sum(meef_scale(x / scale0)) / scale_bias / (nobs - ddof))\n+        else:\n+            weights_scale = meef_scale(x_scaled) / (1e-50 + x_scaled**2)\n+            scale2 = (weights_scale * x**2).sum() / (nobs - ddof)\n+            scale2 /= scale_bias\n+            scale = np.sqrt(scale2)\n         if debug:\n             print(scale)\n-        if np.allclose(scale, scale_old, atol=atol, rtol=rtol):\n+        if np.allclose(scale, scale0, atol=atol, rtol=rtol):\n             break\n-        scale_old = scale\n+        scale0 = scale\n \n     return scale\n", "test_patch": "diff --git a/statsmodels/robust/tests/test_covariance.py b/statsmodels/robust/tests/test_covariance.py\nindex d272e153eb1..2af06c68a3f 100644\n--- a/statsmodels/robust/tests/test_covariance.py\n+++ b/statsmodels/robust/tests/test_covariance.py\n@@ -8,6 +8,7 @@\n \n from statsmodels import robust\n import statsmodels.robust.covariance as robcov\n+import statsmodels.robust.scale as robscale\n \n from .results import results_cov as res_cov\n \n@@ -107,7 +108,7 @@ class TestOGKTau(TestOGKMad):\n     def setup_class(cls):\n \n         def sfunc(x):\n-            return robcov.scale_tau(x, normalize=False, ddof=0)[1]\n+            return robscale.scale_tau(x, normalize=False, ddof=0)[1]\n \n         cls.res1 = robcov.cov_ogk(dta_hbk,\n                                   scale_func=sfunc,\ndiff --git a/statsmodels/robust/tests/test_scale.py b/statsmodels/robust/tests/test_scale.py\nindex b5074d6fcb0..0528f647405 100644\n--- a/statsmodels/robust/tests/test_scale.py\n+++ b/statsmodels/robust/tests/test_scale.py\n@@ -8,15 +8,23 @@\n from numpy.random import standard_normal\n from numpy.testing import assert_almost_equal, assert_equal, assert_allclose\n import pytest\n+\n+import pandas as pd\n+\n from scipy.stats import norm as Gaussian\n from scipy import stats\n \n import statsmodels.api as sm\n import statsmodels.robust.scale as scale\n-from statsmodels.robust.scale import mad\n+from statsmodels.robust.scale import mad, scale_tau\n import statsmodels.robust.norms as rnorms\n \n-from statsmodels.robust.covariance import scale_tau  # TODO: will be moved\n+cur_dir = os.path.abspath(os.path.dirname(__file__))\n+\n+file_name = 'hbk.csv'\n+file_path = os.path.join(cur_dir, 'results', file_name)\n+dta_hbk = pd.read_csv(file_path)\n+\n \n # Example from Section 5.5, Venables & Ripley (2002)\n \n@@ -281,7 +289,7 @@ class TestHuberAxes:\n     def setup_class(cls):\n         np.random.seed(54321)\n         cls.X = standard_normal((40, 10, 30))\n-        cls.h = scale.Huber(maxiter=1000, tol=1.0e-05)\n+        cls.h = scale.Huber(maxiter=100, tol=1.0e-05)\n \n     def test_default(self):\n         m, s = self.h(self.X, axis=0)\n@@ -391,6 +399,49 @@ def test_scale_iter():\n     assert_allclose(s, v, rtol=1e-1)\n     assert_allclose(s, 1.0683298, rtol=1e-6)  # regression test number\n \n+    chi = rnorms.TukeyBiweight()\n+    scale_bias = 0.43684963023076195\n+    mscale_biw = scale.MScale(chi, scale_bias)\n+    s_biw = mscale_biw(x)\n+    assert_allclose(s_biw, s, rtol=1e-10)\n+\n+    # regression test with 50% breakdown tuning\n+    chi = rnorms.TukeyBiweight(c=1.547)\n+    scale_bias = 0.1995\n+    mscale_biw = scale.MScale(chi, scale_bias)\n+    s_biw = mscale_biw(x)\n+    assert_allclose(s_biw, 1.0326176662, rtol=1e-9)  # regression test number\n+\n+\n+class TestMScale():\n+\n+    def test_huber_equivalence(self):\n+        np.random.seed(54321)\n+        nobs = 50\n+        x = 1.5 * standard_normal(nobs)\n+\n+        # test equivalence of HuberScale and TrimmedMean M-scale\n+        chi_tm = rnorms.TrimmedMean(c=2.5)\n+        scale_bias_tm = 0.4887799917273257\n+        mscale_tm = scale.MScale(chi_tm, scale_bias_tm)\n+        s_tm = mscale_tm(x)\n+\n+        mscale_hub = scale.HuberScale()\n+        s_hub = mscale_hub(nobs, nobs, x)\n+\n+        assert_allclose(s_tm, s_hub, rtol=1e-6)\n+\n+    def test_biweight(self):\n+        y = dta_hbk[\"Y\"].to_numpy()\n+        ry = y - np.median(y)\n+\n+        chi = rnorms.TukeyBiweight(c=1.54764)\n+        scale_bias = 0.19959963130721095\n+        mscale_biw = scale.MScale(chi, scale_bias)\n+        scale0 = mscale_biw(ry)\n+        scale1 = 0.817260483784376   # from R RobStatTM scaleM\n+        assert_allclose(scale0, scale1, rtol=1e-6)\n+\n \n def test_scale_trimmed_approx():\n     scale_trimmed = scale.scale_trimmed  # shorthand\n", "problem_statement": "ENH/BUG: fixed scale in RLM, float scale_est\nI thought we have an option already to have fixed scale in RLM, e.g. for MM-estimation with preliminary scale estimate.\r\nHowever, I cannot find a way to use the fit options for it. \r\nI don't find a direct issue for it, nor a PR. (So I don't know why I had gotten the impression that it works.)\r\n\r\nThe work around I found is\r\nsetting the scale attribute directly and use options that scale is not estimated or updated\r\n\r\n```\r\nmod = RLM.from_formula(\"Y ~ X1 + X2 + X3\", dta_hbk.loc[inliers], M=norm_s)\r\nmod.scale = 0.7963592114\r\nres = mod.fit(scale_est=0.7963592114, init=0.79, update_scale=False)\r\nprint(res.summary())\r\n```\r\n\r\nas verification that this works\r\nI get the same parameter estimate as robustbase \r\n`res_ss = lmrob.S(res_s$x, hbk[[\"Y\"]], control = lmrob.control(nRes = 20))`\r\nif I use the fixed scale (and start_params) from R in RLM.\r\n(However, I'm not getting the same results as the robust base S-estimator if I simultaneously update the scale with biweight rho)\r\n\r\nI'm not sure yet which option we want to use to fix the scale\r\n`init` docstring does not match the code, it is only use for initial scale estimate, but does not affect start params.\r\n```\r\n        init : str\r\n            Specifies method for the initial estimates of the parameters.\r\n            Default is None, which means that the least squares estimate\r\n            is used.  Currently it is the only available choice.\r\n```\r\n\r\n(context: I'm trying to see whether we can reuse RLM as S-estimator for given \"good\" start_params. related to issue #9171 and PR #9210)\n", "hints_text": "", "created_at": "2024-04-15T19:13:46Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9165, "instance_id": "statsmodels__statsmodels-9165", "issue_numbers": ["9162"], "base_commit": "37bd2e421bad61bc54e8260b86a10a68d17892b3", "patch": "diff --git a/statsmodels/tsa/statespace/mlemodel.py b/statsmodels/tsa/statespace/mlemodel.py\nindex aa6f67a7e32..08ad4c1030b 100644\n--- a/statsmodels/tsa/statespace/mlemodel.py\n+++ b/statsmodels/tsa/statespace/mlemodel.py\n@@ -3644,6 +3644,10 @@ def simulate(self, nsimulations, measurement_shocks=None,\n         if iloc > self.nobs:\n             raise ValueError('Cannot anchor simulation outside of the sample.')\n \n+        # GH 9162\n+        from statsmodels.tsa.statespace import simulation_smoother\n+        random_state = simulation_smoother.check_random_state(random_state)\n+\n         # Setup the initial state\n         if initial_state is None:\n             initial_state_moments = (\n@@ -3652,7 +3656,7 @@ def simulate(self, nsimulations, measurement_shocks=None,\n \n             _repetitions = 1 if repetitions is None else repetitions\n \n-            initial_state = np.random.multivariate_normal(\n+            initial_state = random_state.multivariate_normal(\n                 *initial_state_moments, size=_repetitions).T\n \n         scale = self.scale if self.filter_results.filter_concentrated else None\n", "test_patch": "diff --git a/statsmodels/tsa/arima/tests/test_model.py b/statsmodels/tsa/arima/tests/test_model.py\nindex d04a5c36ced..fb0502b2641 100644\n--- a/statsmodels/tsa/arima/tests/test_model.py\n+++ b/statsmodels/tsa/arima/tests/test_model.py\n@@ -413,3 +413,22 @@ def test_hannan_rissanen_with_fixed_params(ar_order, ma_order, fixed_params):\n         res = mod.fit(method='hannan_rissanen')\n \n     assert_allclose(res.params, desired_p.params)\n+\n+\n+@pytest.mark.parametrize(\n+    \"random_state_type\", [7, np.random.RandomState, np.random.default_rng]\n+)\n+def test_reproducible_simulation(random_state_type):\n+    x = np.random.randn(100)\n+    res = ARIMA(x, order=(1, 0, 0)).fit()\n+\n+    def get_random_state(val):\n+        if isinstance(random_state_type, int):\n+            return 7\n+        return random_state_type(7)\n+\n+    random_state = get_random_state(random_state_type)\n+    sim1 = res.simulate(1, random_state=random_state)\n+    random_state = get_random_state(random_state_type)\n+    sim2 = res.simulate(1, random_state=random_state)\n+    assert_allclose(sim1, sim2)\n", "problem_statement": "`ARIMAResults.simulate` doesn't respect `random_state`\n#### Describe the bug\r\n\r\nThe method `ARIMAResults.simulate` doesn't seem to respect the parameter `random_state`. It returns different results for a fixed random state parameter.\r\n\r\n#### Code Sample\r\n\r\n\r\n```python\r\nfrom statsmodels.tsa.arima.model import ARIMA\r\nimport numpy as np\r\n\r\nx = np.random.randn(100)\r\nmod = ARIMA(x, order=(1, 0, 0))\r\nres = mod.fit()\r\n\r\nfor i in range(5):\r\n    print(i, res.simulate(1, random_state=7))\r\n```\r\n\r\n\r\n#### Expected Output\r\n\r\nFor me, this prints a different number for each of the iterations. My expectation, however, is that the same number is generated on each invocation of `simulate` because `random_state` is fixed.\r\n\r\n\r\n#### Output of ``import statsmodels.api as sm; sm.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\nPython: 3.10.12.final.0\r\nOS: Darwin 23.3.0 Darwin Kernel Version 23.3.0: Wed Dec 20 21:30:44 PST 2023; root:xnu-10002.81.5~7/RELEASE_ARM64_T6000 arm64\r\nbyteorder: little\r\nLC_ALL: en_US.UTF-8\r\nLANG: en_US.UTF-8\r\n\r\nstatsmodels\r\n===========\r\n\r\nInstalled: 0.14.1 (/Users/adaitche/homebrew/lib/python3.10/site-packages/statsmodels)\r\n\r\nRequired Dependencies\r\n=====================\r\n\r\ncython: Not installed\r\nnumpy: 1.24.1 (/Users/adaitche/homebrew/lib/python3.10/site-packages/numpy)\r\nscipy: 1.10.0 (/Users/adaitche/homebrew/lib/python3.10/site-packages/scipy)\r\npandas: 1.5.3 (/Users/adaitche/homebrew/lib/python3.10/site-packages/pandas)\r\n    dateutil: 2.8.2 (/Users/adaitche/homebrew/lib/python3.10/site-packages/dateutil)\r\npatsy: 0.5.6 (/Users/adaitche/homebrew/lib/python3.10/site-packages/patsy)\r\n\r\nOptional Dependencies\r\n=====================\r\n\r\nmatplotlib: 3.6.3 (/Users/adaitche/homebrew/lib/python3.10/site-packages/matplotlib)\r\n    backend: MacOSX\r\ncvxopt: Not installed\r\njoblib: Not installed\r\n\r\nDeveloper Tools\r\n================\r\n\r\nIPython: 8.9.0 (/Users/adaitche/homebrew/lib/python3.10/site-packages/IPython)\r\n    jinja2: 3.1.2 (/Users/adaitche/homebrew/lib/python3.10/site-packages/jinja2)\r\nsphinx: Not installed\r\n    pygments: 2.14.0 (/Users/adaitche/homebrew/lib/python3.10/site-packages/pygments)\r\npytest: 7.4.3 (/Users/adaitche/homebrew/lib/python3.10/site-packages/pytest)\r\nvirtualenv: Not installed\r\n\r\n</details>\r\n\n", "hints_text": "Thanks for reporting this. The problem appears to be that the `initial_state` is drawn without using the provided `random_state`: https://github.com/statsmodels/statsmodels/blob/main/statsmodels/tsa/statespace/mlemodel.py#L3648-L3656", "created_at": "2024-02-27T15:13:58Z"}
{"repo": "statsmodels/statsmodels", "pull_number": 9130, "instance_id": "statsmodels__statsmodels-9130", "issue_numbers": ["9100", "9100"], "base_commit": "a0eca865c65ef9336c6403f8ff4bc29a1d3ec26b", "patch": "diff --git a/statsmodels/genmod/generalized_linear_model.py b/statsmodels/genmod/generalized_linear_model.py\nindex 4617ad4bc18..6cd29fd7691 100644\n--- a/statsmodels/genmod/generalized_linear_model.py\n+++ b/statsmodels/genmod/generalized_linear_model.py\n@@ -41,6 +41,7 @@\n     cached_data,\n     cached_value,\n )\n+from statsmodels.tools.data import _as_array_with_name\n from statsmodels.tools.docstring import Docstring\n from statsmodels.tools.sm_exceptions import (\n     DomainWarning,\n@@ -307,15 +308,21 @@ def __init__(self, endog, exog, family=None, offset=None,\n                            f\"{type(family).__name__} family.\"),\n                           DomainWarning)\n \n+        self._exposure_name = None\n+        self._offset_name = None\n+        self._freq_weights_name = None\n+        self._var_weights_name = None\n+\n         if exposure is not None:\n-            exposure = np.log(exposure)\n+            exposure_array, self._exposure_name = _as_array_with_name(exposure, \"exposure\")\n+            exposure = np.log(exposure_array)\n         if offset is not None:  # this should probably be done upstream\n-            offset = np.asarray(offset)\n+            offset, self._offset_name = _as_array_with_name(offset, \"offset\")\n \n         if freq_weights is not None:\n-            freq_weights = np.asarray(freq_weights)\n+            freq_weights, self._freq_weights_name = _as_array_with_name(freq_weights, \"freq_weights\")\n         if var_weights is not None:\n-            var_weights = np.asarray(var_weights)\n+            var_weights, self._var_weights_name = _as_array_with_name(var_weights, \"var_weights\")\n \n         self.freq_weights = freq_weights\n         self.var_weights = var_weights\n@@ -1558,6 +1565,39 @@ def fit_constrained(self, constraints, start_params=None, **fit_kwds):\n         res._results.results_constrained = res_constr\n         return res\n \n+    @property\n+    def offset_name(self):\n+        \"\"\"\n+        Name of the offset variable if available. If offset is not a pd.Series,\n+        defaults to 'offset'.\n+        \"\"\"\n+        return self._offset_name\n+\n+    @property\n+    def exposure_name(self):\n+        \"\"\"\n+        Name of the exposure variable if available. If exposure is not a pd.Series,\n+        defaults to 'exposure'.\n+        \"\"\"\n+        return self._exposure_name\n+\n+    @property\n+    def freq_weights_name(self):\n+        \"\"\"\n+        Name of the freq weights variable if available. If freq_weights is not a\n+        pd.Series, defaults to 'freq_weights'.\n+        \"\"\"\n+        return self._freq_weights_name\n+\n+    @property\n+    def var_weights_name(self):\n+        \"\"\"\n+        Name of var weights variable if available. If var_weights is not a pd.Series,\n+        defaults to 'var_weights'.\n+\n+        \"\"\"\n+        return self._var_weights_name\n+\n \n get_prediction_doc = Docstring(pred.get_prediction_glm.__doc__)\n get_prediction_doc.remove_parameters(\"pred_kwds\")\ndiff --git a/statsmodels/tools/data.py b/statsmodels/tools/data.py\nindex 115bc169999..9e507030c3f 100644\n--- a/statsmodels/tools/data.py\n+++ b/statsmodels/tools/data.py\n@@ -19,7 +19,8 @@ def _check_period_index(x, freq=\"M\"):\n     if not inferred_freq.startswith(freq):\n         raise ValueError(\"Expected frequency {}. Got {}\".format(freq,\n                                                                 inferred_freq))\n-\n+def is_series(obj):\n+    return isinstance(obj, pd.Series)\n \n def is_data_frame(obj):\n     return isinstance(obj, pd.DataFrame)\n@@ -121,3 +122,24 @@ def _is_recarray(data):\n         return isinstance(data, np.core.recarray)\n     else:\n         return isinstance(data, np.rec.recarray)\n+\n+def _as_array_with_name(obj, default_name):\n+    \"\"\"\n+    Call np.asarray() on obj and attempt to get the name if its a Series.\n+\n+    Parameters\n+    ----------\n+    obj: pd.Series\n+        Series to convert to an array\n+    default_name: str\n+        The default name to return in case the object isn't a pd.Series or has\n+        no name attribute.\n+\n+    Returns\n+    -------\n+    array_and_name: tuple[np.ndarray, str]\n+        The data casted to np.ndarra and the series name or None\n+    \"\"\"\n+    if is_series(obj):\n+        return (np.asarray(obj), obj.name)\n+    return (np.asarray(obj), default_name)\n", "test_patch": "diff --git a/statsmodels/genmod/tests/test_glm.py b/statsmodels/genmod/tests/test_glm.py\nindex fd169d36fd6..b3b6876a43d 100644\n--- a/statsmodels/genmod/tests/test_glm.py\n+++ b/statsmodels/genmod/tests/test_glm.py\n@@ -2661,3 +2661,62 @@ def test_tweedie_score():\n             nhess = approx_hess_cs(pa, lambda x: model.loglike(x, scale=1))\n             ahess = model.hessian(pa, scale=1)\n             assert_allclose(nhess, ahess, atol=5e-8, rtol=5e-8)\n+\n+def test_names():\n+    \"\"\"Test the name properties if using a pandas series.\n+\n+    They should not be the defaults if the series has a name.\n+\n+    Don't care about the data here, only testing the name properties.\n+    \"\"\"\n+    y = pd.Series([0, 1], name=\"endog_not_default\")\n+    x = pd.DataFrame({\"a\": [1, 1], \"b\": [1, 0]})\n+    exposure = pd.Series([0, 0], name=\"exposure_not_default\")\n+    freq_weights = pd.Series([0, 0], name=\"freq_weights_not_default\")\n+    offset = pd.Series([0, 0], name=\"offset_not_default\")\n+    var_weights = pd.Series([0, 0], name=\"var_weights_not_default\")\n+\n+    model = GLM(\n+        endog=y,\n+        exog=x,\n+        exposure=exposure,\n+        freq_weights=freq_weights,\n+        offset=offset,\n+        var_weights=var_weights,\n+        family=sm.families.Tweedie(),\n+    )\n+    assert model.offset_name == \"offset_not_default\"\n+    assert model.exposure_name == \"exposure_not_default\"\n+    assert model.freq_weights_name == \"freq_weights_not_default\"\n+    assert model.var_weights_name == \"var_weights_not_default\"\n+    assert model.endog_names == \"endog_not_default\"\n+    assert model.exog_names == [\"a\", \"b\"]\n+\n+\n+def test_names_default():\n+    \"\"\"Test the name properties if using a numpy arrays.\n+\n+    Don't care about the data here, only testing the name properties.\n+    \"\"\"\n+    y = np.array([0, 1])\n+    x = np.array([[1, 1,], [1, 0]])\n+    exposure = np.array([0, 0])\n+    freq_weights = np.array([0, 0])\n+    offset = np.array([0, 0])\n+    var_weights = np.array([0, 0])\n+\n+    model = GLM(\n+        endog=y,\n+        exog=x,\n+        exposure=exposure,\n+        freq_weights=freq_weights,\n+        offset=offset,\n+        var_weights=var_weights,\n+        family=sm.families.Tweedie(),\n+    )\n+    assert model.offset_name == \"offset\"\n+    assert model.exposure_name == \"exposure\"\n+    assert model.freq_weights_name == \"freq_weights\"\n+    assert model.var_weights_name == \"var_weights\"\n+    assert model.endog_names == \"y\"\n+    assert model.exog_names == [\"const\", \"x1\"]\ndiff --git a/statsmodels/tools/tests/test_data.py b/statsmodels/tools/tests/test_data.py\nindex 178004aa178..21a4f7f8e7e 100644\n--- a/statsmodels/tools/tests/test_data.py\n+++ b/statsmodels/tools/tests/test_data.py\n@@ -33,3 +33,16 @@ def test_patsy_577():\n     np.testing.assert_(data._is_using_patsy(endog, None))\n     exog = dmatrix(\"var2 - 1\", df)\n     np.testing.assert_(data._is_using_patsy(endog, exog))\n+\n+\n+def test_as_array_with_name_series():\n+    s = pandas.Series([1], name=\"hello\")\n+    arr, name = data._as_array_with_name(s, \"not_used\")\n+    np.testing.assert_array_equal(np.array([1]), arr)\n+    assert name == \"hello\"\n+\n+\n+def test_as_array_with_name_array():\n+    arr, name = data._as_array_with_name(np.array([1]), \"default\")\n+    np.testing.assert_array_equal(np.array([1]), arr)\n+    assert name == \"default\"\n", "problem_statement": "Save the offset name in `GLM` and results wrapper\n#### Is your feature request related to a problem? Please describe\r\nPost model training, it is helpful to know which variable was used as the offset. This aids in post model analysis and deployment.\r\n\r\nThe offset array is saved and can be accessed after saving the model, but the name of the offset variable is lost when it is a pandas series. The series is [converted to a np.array](https://github.com/statsmodels/statsmodels/blob/ab10165eb897729b50e703b4ea831ae712b53585/statsmodels/genmod/generalized_linear_model.py#L315-L316) which removed the name. Current state, it is difficult to tell which variable may have been used as an offset without tracking it outside the model.\r\n\r\nExample use case: Sharing a saved model with a peer. They inspect it to determine what variable was used as the offset in training.\r\n\r\nThe same may apply to the `var_weights` and `freq_weights` for GLM.\r\n\r\n#### Describe the solution you'd like\r\nThe model has access on `__init__` to the name of the offset if it is a pandas series. A way to save the offset array's name if it is a series would be wonderful.\r\n\r\nSimilar to how the endog and exog names can be used in the model summary.\r\n\r\nHere's a few ideas I had for how to implement this. Happy to hear if there's a better option.\r\n\r\n1. Add an `offset_name` property for GLM\r\n    - Similar to the base models [`endog_names`/`exog_names`](https://github.com/statsmodels/statsmodels/blob/ab10165eb897729b50e703b4ea831ae712b53585/statsmodels/base/model.py#L235-L247)\r\n    - Simple to implement\r\n2. Add it to the `model.data` so it's handled by [`PandasData`](https://github.com/statsmodels/statsmodels/blob/ab10165eb897729b50e703b4ea831ae712b53585/statsmodels/base/data.py#L498)\r\n    - The name could be added back to the offset when making the results wrapper (at least I think that's how it works)\r\n    - I could use some guidance on how to implement this if it is the preferred approach\r\n    - I think it has something to do with the data attrs but it's a bit hard to track down\r\n3. Do not convert to a numpy array if it is a series\r\n    - One could use `model.offset.name` to get at the variable name \r\n    - Doesn't line up with how the rest of the code works, it expects numpy arrays\r\n    - Likely not a good option\r\n4. User adds `offset_name` attribute to the model class before saving it.\r\n    - Seems like a bad idea, would like support in statsmodels\r\n\r\n#### Describe alternatives you have considered\r\nCurrent workaround is saving the offset name in a separate file, which is not ideal.\r\n\r\n#### Additional context\r\nHappy to work on a PR for this.\r\n\nSave the offset name in `GLM` and results wrapper\n#### Is your feature request related to a problem? Please describe\r\nPost model training, it is helpful to know which variable was used as the offset. This aids in post model analysis and deployment.\r\n\r\nThe offset array is saved and can be accessed after saving the model, but the name of the offset variable is lost when it is a pandas series. The series is [converted to a np.array](https://github.com/statsmodels/statsmodels/blob/ab10165eb897729b50e703b4ea831ae712b53585/statsmodels/genmod/generalized_linear_model.py#L315-L316) which removed the name. Current state, it is difficult to tell which variable may have been used as an offset without tracking it outside the model.\r\n\r\nExample use case: Sharing a saved model with a peer. They inspect it to determine what variable was used as the offset in training.\r\n\r\nThe same may apply to the `var_weights` and `freq_weights` for GLM.\r\n\r\n#### Describe the solution you'd like\r\nThe model has access on `__init__` to the name of the offset if it is a pandas series. A way to save the offset array's name if it is a series would be wonderful.\r\n\r\nSimilar to how the endog and exog names can be used in the model summary.\r\n\r\nHere's a few ideas I had for how to implement this. Happy to hear if there's a better option.\r\n\r\n1. Add an `offset_name` property for GLM\r\n    - Similar to the base models [`endog_names`/`exog_names`](https://github.com/statsmodels/statsmodels/blob/ab10165eb897729b50e703b4ea831ae712b53585/statsmodels/base/model.py#L235-L247)\r\n    - Simple to implement\r\n2. Add it to the `model.data` so it's handled by [`PandasData`](https://github.com/statsmodels/statsmodels/blob/ab10165eb897729b50e703b4ea831ae712b53585/statsmodels/base/data.py#L498)\r\n    - The name could be added back to the offset when making the results wrapper (at least I think that's how it works)\r\n    - I could use some guidance on how to implement this if it is the preferred approach\r\n    - I think it has something to do with the data attrs but it's a bit hard to track down\r\n3. Do not convert to a numpy array if it is a series\r\n    - One could use `model.offset.name` to get at the variable name \r\n    - Doesn't line up with how the rest of the code works, it expects numpy arrays\r\n    - Likely not a good option\r\n4. User adds `offset_name` attribute to the model class before saving it.\r\n    - Seems like a bad idea, would like support in statsmodels\r\n\r\n#### Describe alternatives you have considered\r\nCurrent workaround is saving the offset name in a separate file, which is not ideal.\r\n\r\n#### Additional context\r\nHappy to work on a PR for this.\r\n\n", "hints_text": "I think currently `1.` is the only option. `2.` would be good but currently the extra arrays are not going through the endog/exog `model.data` handling (at least not in most cases.\r\n\r\nWe could add a helper function that can be added to the `__init__` as replacement for np.asarray which does asarray plus return additionally the name of the variable if it is available.\r\nThis could also be applied to other extra data like exposure and the various weights.\r\n\r\nCurrent extra data like offset, exposure, weights are 1dim. \r\nFor flexibility the helper function could check for and distinguish 1dim and 2dim. In the later case, return individual column names instead of the Series name.\r\n\r\nThe same as in GLM also applies to discrete models and likely to some other models.\r\n\r\n\nI think currently `1.` is the only option. `2.` would be good but currently the extra arrays are not going through the endog/exog `model.data` handling (at least not in most cases.\r\n\r\nWe could add a helper function that can be added to the `__init__` as replacement for np.asarray which does asarray plus return additionally the name of the variable if it is available.\r\nThis could also be applied to other extra data like exposure and the various weights.\r\n\r\nCurrent extra data like offset, exposure, weights are 1dim. \r\nFor flexibility the helper function could check for and distinguish 1dim and 2dim. In the later case, return individual column names instead of the Series name.\r\n\r\nThe same as in GLM also applies to discrete models and likely to some other models.\r\n\r\n", "created_at": "2024-01-24T22:24:28Z"}
