{"repo": "ultralytics/ultralytics", "pull_number": 10423, "instance_id": "ultralytics__ultralytics-10423", "issue_numbers": ["10397"], "base_commit": "299797ff9eb5b191481e04c1d4a0076927810b6c", "patch": "diff --git a/ultralytics/__init__.py b/ultralytics/__init__.py\nindex 4c98c5c08f5..1909d745146 100644\n--- a/ultralytics/__init__.py\n+++ b/ultralytics/__init__.py\n@@ -1,6 +1,6 @@\n # Ultralytics YOLO \ud83d\ude80, AGPL-3.0 license\n \n-__version__ = \"8.2.8\"\n+__version__ = \"8.2.9\"\n \n from ultralytics.data.explorer.explorer import Explorer\n from ultralytics.models import RTDETR, SAM, YOLO, YOLOWorld\ndiff --git a/ultralytics/data/augment.py b/ultralytics/data/augment.py\nindex 43a7c9ec98c..08b7f0f2ca4 100644\n--- a/ultralytics/data/augment.py\n+++ b/ultralytics/data/augment.py\n@@ -10,6 +10,7 @@\n import torch\n from PIL import Image\n \n+from ultralytics.data.utils import polygons2masks, polygons2masks_overlap\n from ultralytics.utils import LOGGER, colorstr\n from ultralytics.utils.checks import check_version\n from ultralytics.utils.instance import Instances\n@@ -17,8 +18,6 @@\n from ultralytics.utils.ops import segment2box, xyxyxyxy2xywhr\n from ultralytics.utils.torch_utils import TORCHVISION_0_10, TORCHVISION_0_11, TORCHVISION_0_13\n \n-from .utils import polygons2masks, polygons2masks_overlap\n-\n DEFAULT_MEAN = (0.0, 0.0, 0.0)\n DEFAULT_STD = (1.0, 1.0, 1.0)\n DEFAULT_CROP_FRACTION = 1.0\ndiff --git a/ultralytics/data/base.py b/ultralytics/data/base.py\nindex 6f0ca7fe153..2218d31f362 100644\n--- a/ultralytics/data/base.py\n+++ b/ultralytics/data/base.py\n@@ -14,10 +14,9 @@\n import psutil\n from torch.utils.data import Dataset\n \n+from ultralytics.data.utils import FORMATS_HELP_MSG, HELP_URL, IMG_FORMATS\n from ultralytics.utils import DEFAULT_CFG, LOCAL_RANK, LOGGER, NUM_THREADS, TQDM\n \n-from .utils import FORMATS_HELP_MSG, HELP_URL, IMG_FORMATS\n-\n \n class BaseDataset(Dataset):\n     \"\"\"\ndiff --git a/ultralytics/data/build.py b/ultralytics/data/build.py\nindex 6fa611cc402..157266eb3d9 100644\n--- a/ultralytics/data/build.py\n+++ b/ultralytics/data/build.py\n@@ -9,6 +9,7 @@\n from PIL import Image\n from torch.utils.data import dataloader, distributed\n \n+from ultralytics.data.dataset import GroundingDataset, YOLODataset, YOLOMultiModalDataset\n from ultralytics.data.loaders import (\n     LOADERS,\n     LoadImagesAndVideos,\n@@ -19,13 +20,10 @@\n     SourceTypes,\n     autocast_list,\n )\n-from ultralytics.data.utils import IMG_FORMATS, VID_FORMATS\n+from ultralytics.data.utils import IMG_FORMATS, PIN_MEMORY, VID_FORMATS\n from ultralytics.utils import LINUX, NUM_THREADS, RANK, colorstr\n from ultralytics.utils.checks import check_file\n \n-from .dataset import GroundingDataset, YOLODataset, YOLOMultiModalDataset\n-from .utils import PIN_MEMORY\n-\n \n class InfiniteDataLoader(dataloader.DataLoader):\n     \"\"\"\ndiff --git a/ultralytics/engine/exporter.py b/ultralytics/engine/exporter.py\nindex d2536542428..227a76d5fda 100644\n--- a/ultralytics/engine/exporter.py\n+++ b/ultralytics/engine/exporter.py\n@@ -64,9 +64,10 @@\n import numpy as np\n import torch\n \n-from ultralytics.cfg import get_cfg\n+from ultralytics.cfg import TASK2DATA, get_cfg\n+from ultralytics.data import build_dataloader\n from ultralytics.data.dataset import YOLODataset\n-from ultralytics.data.utils import check_det_dataset\n+from ultralytics.data.utils import check_cls_dataset, check_det_dataset\n from ultralytics.nn.autobackend import check_class_names, default_class_names\n from ultralytics.nn.modules import C2f, Detect, RTDETRDecoder\n from ultralytics.nn.tasks import DetectionModel, SegmentationModel, WorldModel\n@@ -169,7 +170,7 @@ def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):\n         callbacks.add_integration_callbacks(self)\n \n     @smart_inference_mode()\n-    def __call__(self, model=None):\n+    def __call__(self, model=None) -> str:\n         \"\"\"Returns list of exported files/dirs after running callbacks.\"\"\"\n         self.run_callbacks(\"on_export_start\")\n         t = time.time()\n@@ -211,7 +212,12 @@ def __call__(self, model=None):\n                 \"(torchscript, onnx, openvino, engine, coreml) formats. \"\n                 \"See https://docs.ultralytics.com/models/yolo-world for details.\"\n             )\n-\n+        if self.args.int8 and not self.args.data:\n+            self.args.data = DEFAULT_CFG.data or TASK2DATA[getattr(model, \"task\", \"detect\")]  # assign default data\n+            LOGGER.warning(\n+                \"WARNING \u26a0\ufe0f INT8 export requires a missing 'data' arg for calibration. \"\n+                f\"Using default 'data={self.args.data}'.\"\n+            )\n         # Input\n         im = torch.zeros(self.args.batch, 3, *self.imgsz).to(self.device)\n         file = Path(\n@@ -333,6 +339,23 @@ def __call__(self, model=None):\n         self.run_callbacks(\"on_export_end\")\n         return f  # return list of exported files/dirs\n \n+    def get_int8_calibration_dataloader(self, prefix=\"\"):\n+        \"\"\"Build and return a dataloader suitable for calibration of INT8 models.\"\"\"\n+        LOGGER.info(f\"{prefix} collecting INT8 calibration images from 'data={self.args.data}'\")\n+        data = (check_cls_dataset if self.model.task == \"classify\" else check_det_dataset)(self.args.data)\n+        dataset = YOLODataset(\n+            data[self.args.split or \"val\"],\n+            data=data,\n+            task=self.model.task,\n+            imgsz=self.imgsz[0],\n+            augment=False,\n+            batch_size=self.args.batch,\n+        )\n+        n = len(dataset)\n+        if n < 300:\n+            LOGGER.warning(f\"{prefix} WARNING \u26a0\ufe0f >300 images recommended for INT8 calibration, found {n} images.\")\n+        return build_dataloader(dataset, batch=self.args.batch, workers=0)  # required for batch loading\n+\n     @try_export\n     def export_torchscript(self, prefix=colorstr(\"TorchScript:\")):\n         \"\"\"YOLOv8 TorchScript model export.\"\"\"\n@@ -442,37 +465,21 @@ def serialize(ov_model, file):\n         if self.args.int8:\n             fq = str(self.file).replace(self.file.suffix, f\"_int8_openvino_model{os.sep}\")\n             fq_ov = str(Path(fq) / self.file.with_suffix(\".xml\").name)\n-            if not self.args.data:\n-                self.args.data = DEFAULT_CFG.data or \"coco128.yaml\"\n-                LOGGER.warning(\n-                    f\"{prefix} WARNING \u26a0\ufe0f INT8 export requires a missing 'data' arg for calibration. \"\n-                    f\"Using default 'data={self.args.data}'.\"\n-                )\n             check_requirements(\"nncf>=2.8.0\")\n             import nncf\n \n-            def transform_fn(data_item):\n+            def transform_fn(data_item) -> np.ndarray:\n                 \"\"\"Quantization transform function.\"\"\"\n-                assert (\n-                    data_item[\"img\"].dtype == torch.uint8\n-                ), \"Input image must be uint8 for the quantization preprocessing\"\n-                im = data_item[\"img\"].numpy().astype(np.float32) / 255.0  # uint8 to fp16/32 and 0 - 255 to 0.0 - 1.0\n+                data_item: torch.Tensor = data_item[\"img\"] if isinstance(data_item, dict) else data_item\n+                assert data_item.dtype == torch.uint8, \"Input image must be uint8 for the quantization preprocessing\"\n+                im = data_item.numpy().astype(np.float32) / 255.0  # uint8 to fp16/32 and 0 - 255 to 0.0 - 1.0\n                 return np.expand_dims(im, 0) if im.ndim == 3 else im\n \n             # Generate calibration data for integer quantization\n-            LOGGER.info(f\"{prefix} collecting INT8 calibration images from 'data={self.args.data}'\")\n-            data = check_det_dataset(self.args.data)\n-            dataset = YOLODataset(data[\"val\"], data=data, task=self.model.task, imgsz=self.imgsz[0], augment=False)\n-            n = len(dataset)\n-            if n < 300:\n-                LOGGER.warning(f\"{prefix} WARNING \u26a0\ufe0f >300 images recommended for INT8 calibration, found {n} images.\")\n-            quantization_dataset = nncf.Dataset(dataset, transform_fn)\n-\n             ignored_scope = None\n             if isinstance(self.model.model[-1], Detect):\n                 # Includes all Detect subclasses like Segment, Pose, OBB, WorldDetect\n                 head_module_name = \".\".join(list(self.model.named_modules())[-1][0].split(\".\")[:2])\n-\n                 ignored_scope = nncf.IgnoredScope(  # ignore operations\n                     patterns=[\n                         f\".*{head_module_name}/.*/Add\",\n@@ -485,7 +492,10 @@ def transform_fn(data_item):\n                 )\n \n             quantized_ov_model = nncf.quantize(\n-                ov_model, quantization_dataset, preset=nncf.QuantizationPreset.MIXED, ignored_scope=ignored_scope\n+                model=ov_model,\n+                calibration_dataset=nncf.Dataset(self.get_int8_calibration_dataloader(prefix), transform_fn),\n+                preset=nncf.QuantizationPreset.MIXED,\n+                ignored_scope=ignored_scope,\n             )\n             serialize(quantized_ov_model, fq_ov)\n             return fq, None\n@@ -787,11 +797,9 @@ def export_saved_model(self, prefix=colorstr(\"TensorFlow SavedModel:\")):\n             verbosity = \"info\"\n             if self.args.data:\n                 # Generate calibration data for integer quantization\n-                LOGGER.info(f\"{prefix} collecting INT8 calibration images from 'data={self.args.data}'\")\n-                data = check_det_dataset(self.args.data)\n-                dataset = YOLODataset(data[\"val\"], data=data, imgsz=self.imgsz[0], augment=False)\n+                dataloader = self.get_int8_calibration_dataloader(prefix)\n                 images = []\n-                for i, batch in enumerate(dataset):\n+                for i, batch in enumerate(dataloader):\n                     if i >= 100:  # maximum number of calibration images\n                         break\n                     im = batch[\"img\"].permute(1, 2, 0)[None]  # list to nparray, CHW to BHWC\ndiff --git a/ultralytics/engine/model.py b/ultralytics/engine/model.py\nindex 677361e2501..1d88b2c5dcc 100644\n--- a/ultralytics/engine/model.py\n+++ b/ultralytics/engine/model.py\n@@ -572,7 +572,7 @@ def benchmark(\n     def export(\n         self,\n         **kwargs,\n-    ):\n+    ) -> str:\n         \"\"\"\n         Exports the model to a different format suitable for deployment.\n \n@@ -588,7 +588,7 @@ def export(\n                 model's overrides and method defaults.\n \n         Returns:\n-            (object): The exported model in the specified format, or an object related to the export process.\n+            (str): The exported model filename in the specified format, or an object related to the export process.\n \n         Raises:\n             AssertionError: If the model is not a PyTorch model.\n", "test_patch": "diff --git a/tests/__init__.py b/tests/__init__.py\nnew file mode 100644\nindex 00000000000..3356f1cadbf\n--- /dev/null\n+++ b/tests/__init__.py\n@@ -0,0 +1,22 @@\n+# Ultralytics YOLO \ud83d\ude80, AGPL-3.0 license\n+\n+from ultralytics.utils import ASSETS, ROOT, WEIGHTS_DIR, checks, is_dir_writeable\n+\n+# Constants used in tests\n+MODEL = WEIGHTS_DIR / \"path with spaces\" / \"yolov8n.pt\"  # test spaces in path\n+CFG = \"yolov8n.yaml\"\n+SOURCE = ASSETS / \"bus.jpg\"\n+TMP = (ROOT / \"../tests/tmp\").resolve()  # temp directory for test files\n+IS_TMP_WRITEABLE = is_dir_writeable(TMP)\n+CUDA_IS_AVAILABLE = checks.cuda_is_available()\n+CUDA_DEVICE_COUNT = checks.cuda_device_count()\n+\n+__all__ = (\n+    \"MODEL\",\n+    \"CFG\",\n+    \"SOURCE\",\n+    \"TMP\",\n+    \"IS_TMP_WRITEABLE\",\n+    \"CUDA_IS_AVAILABLE\",\n+    \"CUDA_DEVICE_COUNT\",\n+)\ndiff --git a/tests/test_cli.py b/tests/test_cli.py\nindex eeeab0727d9..9a31db24e15 100644\n--- a/tests/test_cli.py\n+++ b/tests/test_cli.py\n@@ -4,24 +4,14 @@\n \n import pytest\n \n+from ultralytics.cfg import TASK2DATA, TASK2MODEL, TASKS\n from ultralytics.utils import ASSETS, WEIGHTS_DIR, checks\n \n-CUDA_IS_AVAILABLE = checks.cuda_is_available()\n-CUDA_DEVICE_COUNT = checks.cuda_device_count()\n-TASK_ARGS = [\n-    (\"detect\", \"yolov8n\", \"coco8.yaml\"),\n-    (\"segment\", \"yolov8n-seg\", \"coco8-seg.yaml\"),\n-    (\"classify\", \"yolov8n-cls\", \"imagenet10\"),\n-    (\"pose\", \"yolov8n-pose\", \"coco8-pose.yaml\"),\n-    (\"obb\", \"yolov8n-obb\", \"dota8.yaml\"),\n-]  # (task, model, data)\n-EXPORT_ARGS = [\n-    (\"yolov8n\", \"torchscript\"),\n-    (\"yolov8n-seg\", \"torchscript\"),\n-    (\"yolov8n-cls\", \"torchscript\"),\n-    (\"yolov8n-pose\", \"torchscript\"),\n-    (\"yolov8n-obb\", \"torchscript\"),\n-]  # (model, format)\n+from . import CUDA_DEVICE_COUNT, CUDA_IS_AVAILABLE\n+\n+# Constants\n+TASK_MODEL_DATA = [(task, WEIGHTS_DIR / TASK2MODEL[task], TASK2DATA[task]) for task in TASKS]\n+MODELS = [WEIGHTS_DIR / TASK2MODEL[task] for task in TASKS]\n \n \n def run(cmd):\n@@ -38,28 +28,28 @@ def test_special_modes():\n     run(\"yolo cfg\")\n \n \n-@pytest.mark.parametrize(\"task,model,data\", TASK_ARGS)\n+@pytest.mark.parametrize(\"task,model,data\", TASK_MODEL_DATA)\n def test_train(task, model, data):\n     \"\"\"Test YOLO training for a given task, model, and data.\"\"\"\n-    run(f\"yolo train {task} model={model}.yaml data={data} imgsz=32 epochs=1 cache=disk\")\n+    run(f\"yolo train {task} model={model} data={data} imgsz=32 epochs=1 cache=disk\")\n \n \n-@pytest.mark.parametrize(\"task,model,data\", TASK_ARGS)\n+@pytest.mark.parametrize(\"task,model,data\", TASK_MODEL_DATA)\n def test_val(task, model, data):\n     \"\"\"Test YOLO validation for a given task, model, and data.\"\"\"\n-    run(f\"yolo val {task} model={WEIGHTS_DIR / model}.pt data={data} imgsz=32 save_txt save_json\")\n+    run(f\"yolo val {task} model={model} data={data} imgsz=32 save_txt save_json\")\n \n \n-@pytest.mark.parametrize(\"task,model,data\", TASK_ARGS)\n+@pytest.mark.parametrize(\"task,model,data\", TASK_MODEL_DATA)\n def test_predict(task, model, data):\n     \"\"\"Test YOLO prediction on sample assets for a given task and model.\"\"\"\n-    run(f\"yolo predict model={WEIGHTS_DIR / model}.pt source={ASSETS} imgsz=32 save save_crop save_txt\")\n+    run(f\"yolo predict model={model} source={ASSETS} imgsz=32 save save_crop save_txt\")\n \n \n-@pytest.mark.parametrize(\"model,format\", EXPORT_ARGS)\n-def test_export(model, format):\n+@pytest.mark.parametrize(\"model\", MODELS)\n+def test_export(model):\n     \"\"\"Test exporting a YOLO model to different formats.\"\"\"\n-    run(f\"yolo export model={WEIGHTS_DIR / model}.pt format={format} imgsz=32\")\n+    run(f\"yolo export model={model} format=torchscript imgsz=32\")\n \n \n def test_rtdetr(task=\"detect\", model=\"yolov8n-rtdetr.yaml\", data=\"coco8.yaml\"):\n@@ -129,10 +119,10 @@ def test_mobilesam():\n \n # Slow Tests -----------------------------------------------------------------------------------------------------------\n @pytest.mark.slow\n-@pytest.mark.parametrize(\"task,model,data\", TASK_ARGS)\n+@pytest.mark.parametrize(\"task,model,data\", TASK_MODEL_DATA)\n @pytest.mark.skipif(not CUDA_IS_AVAILABLE, reason=\"CUDA is not available\")\n @pytest.mark.skipif(CUDA_DEVICE_COUNT < 2, reason=\"DDP is not available\")\n def test_train_gpu(task, model, data):\n     \"\"\"Test YOLO training on GPU(s) for various tasks and models.\"\"\"\n-    run(f\"yolo train {task} model={model}.yaml data={data} imgsz=32 epochs=1 device=0\")  # single GPU\n-    run(f\"yolo train {task} model={model}.pt data={data} imgsz=32 epochs=1 device=0,1\")  # multi GPU\n+    run(f\"yolo train {task} model={model} data={data} imgsz=32 epochs=1 device=0\")  # single GPU\n+    run(f\"yolo train {task} model={model} data={data} imgsz=32 epochs=1 device=0,1\")  # multi GPU\ndiff --git a/tests/test_cuda.py b/tests/test_cuda.py\nindex b66860623eb..11e8f4e5820 100644\n--- a/tests/test_cuda.py\n+++ b/tests/test_cuda.py\n@@ -4,14 +4,9 @@\n import torch\n \n from ultralytics import YOLO\n-from ultralytics.utils import ASSETS, WEIGHTS_DIR, checks\n+from ultralytics.utils import ASSETS, WEIGHTS_DIR\n \n-CUDA_IS_AVAILABLE = checks.cuda_is_available()\n-CUDA_DEVICE_COUNT = checks.cuda_device_count()\n-\n-MODEL = WEIGHTS_DIR / \"path with spaces\" / \"yolov8n.pt\"  # test spaces in path\n-DATA = \"coco8.yaml\"\n-BUS = ASSETS / \"bus.jpg\"\n+from . import CUDA_DEVICE_COUNT, CUDA_IS_AVAILABLE, MODEL, SOURCE\n \n \n def test_checks():\n@@ -25,14 +20,14 @@ def test_checks():\n def test_export_engine():\n     \"\"\"Test exporting the YOLO model to NVIDIA TensorRT format.\"\"\"\n     f = YOLO(MODEL).export(format=\"engine\", device=0)\n-    YOLO(f)(BUS, device=0)\n+    YOLO(f)(SOURCE, device=0)\n \n \n @pytest.mark.skipif(not CUDA_IS_AVAILABLE, reason=\"CUDA is not available\")\n def test_train():\n     \"\"\"Test model training on a minimal dataset.\"\"\"\n     device = 0 if CUDA_DEVICE_COUNT == 1 else [0, 1]\n-    YOLO(MODEL).train(data=DATA, imgsz=64, epochs=1, device=device)  # requires imgsz>=64\n+    YOLO(MODEL).train(data=\"coco8.yaml\", imgsz=64, epochs=1, device=device)  # requires imgsz>=64\n \n \n @pytest.mark.slow\n@@ -42,22 +37,22 @@ def test_predict_multiple_devices():\n     model = YOLO(\"yolov8n.pt\")\n     model = model.cpu()\n     assert str(model.device) == \"cpu\"\n-    _ = model(BUS)  # CPU inference\n+    _ = model(SOURCE)  # CPU inference\n     assert str(model.device) == \"cpu\"\n \n     model = model.to(\"cuda:0\")\n     assert str(model.device) == \"cuda:0\"\n-    _ = model(BUS)  # CUDA inference\n+    _ = model(SOURCE)  # CUDA inference\n     assert str(model.device) == \"cuda:0\"\n \n     model = model.cpu()\n     assert str(model.device) == \"cpu\"\n-    _ = model(BUS)  # CPU inference\n+    _ = model(SOURCE)  # CPU inference\n     assert str(model.device) == \"cpu\"\n \n     model = model.cuda()\n     assert str(model.device) == \"cuda:0\"\n-    _ = model(BUS)  # CUDA inference\n+    _ = model(SOURCE)  # CUDA inference\n     assert str(model.device) == \"cuda:0\"\n \n \n@@ -93,10 +88,10 @@ def test_predict_sam():\n     model.info()\n \n     # Run inference\n-    model(BUS, device=0)\n+    model(SOURCE, device=0)\n \n     # Run inference with bboxes prompt\n-    model(BUS, bboxes=[439, 437, 524, 709], device=0)\n+    model(SOURCE, bboxes=[439, 437, 524, 709], device=0)\n \n     # Run inference with points prompt\n     model(ASSETS / \"zidane.jpg\", points=[900, 370], labels=[1], device=0)\ndiff --git a/tests/test_engine.py b/tests/test_engine.py\nindex 31088d971d6..73a3b744113 100644\n--- a/tests/test_engine.py\n+++ b/tests/test_engine.py\n@@ -9,11 +9,7 @@\n from ultralytics.models.yolo import classify, detect, segment\n from ultralytics.utils import ASSETS, DEFAULT_CFG, WEIGHTS_DIR\n \n-CFG_DET = \"yolov8n.yaml\"\n-CFG_SEG = \"yolov8n-seg.yaml\"\n-CFG_CLS = \"yolov8n-cls.yaml\"  # or 'squeezenet1_0'\n-CFG = get_cfg(DEFAULT_CFG)\n-MODEL = WEIGHTS_DIR / \"yolov8n\"\n+from . import MODEL\n \n \n def test_func(*args):  # noqa\n@@ -26,15 +22,16 @@ def test_export():\n     exporter = Exporter()\n     exporter.add_callback(\"on_export_start\", test_func)\n     assert test_func in exporter.callbacks[\"on_export_start\"], \"callback test failed\"\n-    f = exporter(model=YOLO(CFG_DET).model)\n+    f = exporter(model=YOLO(\"yolov8n.yaml\").model)\n     YOLO(f)(ASSETS)  # exported model inference\n \n \n def test_detect():\n     \"\"\"Test object detection functionality.\"\"\"\n-    overrides = {\"data\": \"coco8.yaml\", \"model\": CFG_DET, \"imgsz\": 32, \"epochs\": 1, \"save\": False}\n-    CFG.data = \"coco8.yaml\"\n-    CFG.imgsz = 32\n+    overrides = {\"data\": \"coco8.yaml\", \"model\": \"yolov8n.yaml\", \"imgsz\": 32, \"epochs\": 1, \"save\": False}\n+    cfg = get_cfg(DEFAULT_CFG)\n+    cfg.data = \"coco8.yaml\"\n+    cfg.imgsz = 32\n \n     # Trainer\n     trainer = detect.DetectionTrainer(overrides=overrides)\n@@ -43,7 +40,7 @@ def test_detect():\n     trainer.train()\n \n     # Validator\n-    val = detect.DetectionValidator(args=CFG)\n+    val = detect.DetectionValidator(args=cfg)\n     val.add_callback(\"on_val_start\", test_func)\n     assert test_func in val.callbacks[\"on_val_start\"], \"callback test failed\"\n     val(model=trainer.best)  # validate best.pt\n@@ -54,7 +51,7 @@ def test_detect():\n     assert test_func in pred.callbacks[\"on_predict_start\"], \"callback test failed\"\n     # Confirm there is no issue with sys.argv being empty.\n     with mock.patch.object(sys, \"argv\", []):\n-        result = pred(source=ASSETS, model=f\"{MODEL}.pt\")\n+        result = pred(source=ASSETS, model=MODEL)\n         assert len(result), \"predictor test failed\"\n \n     overrides[\"resume\"] = trainer.last\n@@ -70,9 +67,10 @@ def test_detect():\n \n def test_segment():\n     \"\"\"Test image segmentation functionality.\"\"\"\n-    overrides = {\"data\": \"coco8-seg.yaml\", \"model\": CFG_SEG, \"imgsz\": 32, \"epochs\": 1, \"save\": False}\n-    CFG.data = \"coco8-seg.yaml\"\n-    CFG.imgsz = 32\n+    overrides = {\"data\": \"coco8-seg.yaml\", \"model\": \"yolov8n-seg.yaml\", \"imgsz\": 32, \"epochs\": 1, \"save\": False}\n+    cfg = get_cfg(DEFAULT_CFG)\n+    cfg.data = \"coco8-seg.yaml\"\n+    cfg.imgsz = 32\n     # YOLO(CFG_SEG).train(**overrides)  # works\n \n     # Trainer\n@@ -82,7 +80,7 @@ def test_segment():\n     trainer.train()\n \n     # Validator\n-    val = segment.SegmentationValidator(args=CFG)\n+    val = segment.SegmentationValidator(args=cfg)\n     val.add_callback(\"on_val_start\", test_func)\n     assert test_func in val.callbacks[\"on_val_start\"], \"callback test failed\"\n     val(model=trainer.best)  # validate best.pt\n@@ -91,7 +89,7 @@ def test_segment():\n     pred = segment.SegmentationPredictor(overrides={\"imgsz\": [64, 64]})\n     pred.add_callback(\"on_predict_start\", test_func)\n     assert test_func in pred.callbacks[\"on_predict_start\"], \"callback test failed\"\n-    result = pred(source=ASSETS, model=f\"{MODEL}-seg.pt\")\n+    result = pred(source=ASSETS, model=WEIGHTS_DIR / \"yolov8n-seg.pt\")\n     assert len(result), \"predictor test failed\"\n \n     # Test resume\n@@ -108,9 +106,10 @@ def test_segment():\n \n def test_classify():\n     \"\"\"Test image classification functionality.\"\"\"\n-    overrides = {\"data\": \"imagenet10\", \"model\": CFG_CLS, \"imgsz\": 32, \"epochs\": 1, \"save\": False}\n-    CFG.data = \"imagenet10\"\n-    CFG.imgsz = 32\n+    overrides = {\"data\": \"imagenet10\", \"model\": \"yolov8n-cls.yaml\", \"imgsz\": 32, \"epochs\": 1, \"save\": False}\n+    cfg = get_cfg(DEFAULT_CFG)\n+    cfg.data = \"imagenet10\"\n+    cfg.imgsz = 32\n     # YOLO(CFG_SEG).train(**overrides)  # works\n \n     # Trainer\n@@ -120,7 +119,7 @@ def test_classify():\n     trainer.train()\n \n     # Validator\n-    val = classify.ClassificationValidator(args=CFG)\n+    val = classify.ClassificationValidator(args=cfg)\n     val.add_callback(\"on_val_start\", test_func)\n     assert test_func in val.callbacks[\"on_val_start\"], \"callback test failed\"\n     val(model=trainer.best)\ndiff --git a/tests/test_exports.py b/tests/test_exports.py\nnew file mode 100644\nindex 00000000000..76207230386\n--- /dev/null\n+++ b/tests/test_exports.py\n@@ -0,0 +1,128 @@\n+# Ultralytics YOLO \ud83d\ude80, AGPL-3.0 license\n+\n+import shutil\n+import uuid\n+from itertools import product\n+from pathlib import Path\n+\n+import pytest\n+\n+from ultralytics import YOLO\n+from ultralytics.cfg import TASK2DATA, TASK2MODEL, TASKS\n+from ultralytics.utils import (\n+    IS_RASPBERRYPI,\n+    LINUX,\n+    MACOS,\n+    WINDOWS,\n+    Retry,\n+    checks,\n+)\n+from ultralytics.utils.torch_utils import TORCH_1_9, TORCH_1_13\n+from . import MODEL, SOURCE\n+\n+# Constants\n+EXPORT_PARAMETERS_LIST = [  # generate all combinations but exclude those where both int8 and half are True\n+    (task, dynamic, int8, half, batch)\n+    for task, dynamic, int8, half, batch in product(TASKS, [True, False], [True, False], [True, False], [1, 2])\n+    if not (int8 and half)  # exclude cases where both int8 and half are True\n+]\n+\n+\n+def test_export_torchscript():\n+    \"\"\"Test exporting the YOLO model to TorchScript format.\"\"\"\n+    f = YOLO(MODEL).export(format=\"torchscript\", optimize=False, imgsz=32)\n+    YOLO(f)(SOURCE, imgsz=32)  # exported model inference\n+\n+\n+def test_export_onnx():\n+    \"\"\"Test exporting the YOLO model to ONNX format.\"\"\"\n+    f = YOLO(MODEL).export(format=\"onnx\", dynamic=True, imgsz=32)\n+    YOLO(f)(SOURCE, imgsz=32)  # exported model inference\n+\n+\n+@pytest.mark.skipif(checks.IS_PYTHON_3_12, reason=\"OpenVINO not supported in Python 3.12\")\n+@pytest.mark.skipif(not TORCH_1_13, reason=\"OpenVINO requires torch>=1.13\")\n+def test_export_openvino():\n+    \"\"\"Test exporting the YOLO model to OpenVINO format.\"\"\"\n+    f = YOLO(MODEL).export(format=\"openvino\", imgsz=32)\n+    YOLO(f)(SOURCE, imgsz=32)  # exported model inference\n+\n+\n+@pytest.mark.slow\n+@pytest.mark.skipif(checks.IS_PYTHON_3_12, reason=\"OpenVINO not supported in Python 3.12\")\n+@pytest.mark.skipif(not TORCH_1_13, reason=\"OpenVINO requires torch>=1.13\")\n+@pytest.mark.parametrize(\"task, dynamic, int8, half, batch\", EXPORT_PARAMETERS_LIST)\n+def test_export_openvino_matrix(task, dynamic, int8, half, batch):\n+    \"\"\"Test exporting the YOLO model to OpenVINO format.\"\"\"\n+    file = YOLO(TASK2MODEL[task]).export(\n+        format=\"openvino\",\n+        imgsz=32,\n+        dynamic=dynamic,\n+        int8=int8,\n+        half=half,\n+        batch=batch,\n+        data=TASK2DATA[task],\n+    )\n+    if WINDOWS:\n+        # Use unique filenames due to Windows file permissions bug possibly due to latent threaded use\n+        # See https://github.com/ultralytics/ultralytics/actions/runs/8957949304/job/24601616830?pr=10423\n+        file = Path(file)\n+        file = file.rename(file.with_stem(f\"{file.stem}-{uuid.uuid4()}\"))\n+    YOLO(file)([SOURCE] * batch, imgsz=64 if dynamic else 32)  # exported model inference\n+    with Retry(times=3, delay=1):  # retry in case of potential lingering multi-threaded file usage errors\n+        shutil.rmtree(file)\n+\n+\n+@pytest.mark.skipif(not TORCH_1_9, reason=\"CoreML>=7.2 not supported with PyTorch<=1.8\")\n+@pytest.mark.skipif(WINDOWS, reason=\"CoreML not supported on Windows\")  # RuntimeError: BlobWriter not loaded\n+@pytest.mark.skipif(IS_RASPBERRYPI, reason=\"CoreML not supported on Raspberry Pi\")\n+@pytest.mark.skipif(checks.IS_PYTHON_3_12, reason=\"CoreML not supported in Python 3.12\")\n+def test_export_coreml():\n+    \"\"\"Test exporting the YOLO model to CoreML format.\"\"\"\n+    if MACOS:\n+        f = YOLO(MODEL).export(format=\"coreml\", imgsz=32)\n+        YOLO(f)(SOURCE, imgsz=32)  # model prediction only supported on macOS for nms=False models\n+    else:\n+        YOLO(MODEL).export(format=\"coreml\", nms=True, imgsz=32)\n+\n+\n+@pytest.mark.skipif(not LINUX, reason=\"Test disabled as TF suffers from install conflicts on Windows and macOS\")\n+def test_export_tflite():\n+    \"\"\"\n+    Test exporting the YOLO model to TFLite format.\n+\n+    Note TF suffers from install conflicts on Windows and macOS.\n+    \"\"\"\n+    model = YOLO(MODEL)\n+    f = model.export(format=\"tflite\", imgsz=32)\n+    YOLO(f)(SOURCE, imgsz=32)\n+\n+\n+@pytest.mark.skipif(True, reason=\"Test disabled\")\n+@pytest.mark.skipif(not LINUX, reason=\"TF suffers from install conflicts on Windows and macOS\")\n+def test_export_pb():\n+    \"\"\"\n+    Test exporting the YOLO model to *.pb format.\n+\n+    Note TF suffers from install conflicts on Windows and macOS.\n+    \"\"\"\n+    model = YOLO(MODEL)\n+    f = model.export(format=\"pb\", imgsz=32)\n+    YOLO(f)(SOURCE, imgsz=32)\n+\n+\n+@pytest.mark.skipif(True, reason=\"Test disabled as Paddle protobuf and ONNX protobuf requirementsk conflict.\")\n+def test_export_paddle():\n+    \"\"\"\n+    Test exporting the YOLO model to Paddle format.\n+\n+    Note Paddle protobuf requirements conflicting with onnx protobuf requirements.\n+    \"\"\"\n+    YOLO(MODEL).export(format=\"paddle\", imgsz=32)\n+\n+\n+@pytest.mark.slow\n+def test_export_ncnn():\n+    \"\"\"Test exporting the YOLO model to NCNN format.\"\"\"\n+    f = YOLO(MODEL).export(format=\"ncnn\", imgsz=32)\n+    YOLO(f)(SOURCE, imgsz=32)  # exported model inference\ndiff --git a/tests/test_integrations.py b/tests/test_integrations.py\nindex f255b889322..d0126a0f1ad 100644\n--- a/tests/test_integrations.py\n+++ b/tests/test_integrations.py\n@@ -1,18 +1,18 @@\n # Ultralytics YOLO \ud83d\ude80, AGPL-3.0 license\n \n import contextlib\n+import os\n+import subprocess\n+import time\n from pathlib import Path\n \n import pytest\n \n from ultralytics import YOLO, download\n-from ultralytics.utils import ASSETS, DATASETS_DIR, ROOT, SETTINGS, WEIGHTS_DIR\n+from ultralytics.utils import DATASETS_DIR, SETTINGS\n from ultralytics.utils.checks import check_requirements\n \n-MODEL = WEIGHTS_DIR / \"path with spaces\" / \"yolov8n.pt\"  # test spaces in path\n-CFG = \"yolov8n.yaml\"\n-SOURCE = ASSETS / \"bus.jpg\"\n-TMP = (ROOT / \"../tests/tmp\").resolve()  # temp directory for test files\n+from . import MODEL, SOURCE, TMP\n \n \n @pytest.mark.skipif(not check_requirements(\"ray\", install=False), reason=\"ray[tune] not installed\")\n@@ -33,8 +33,6 @@ def test_mlflow():\n @pytest.mark.skipif(True, reason=\"Test failing in scheduled CI https://github.com/ultralytics/ultralytics/pull/8868\")\n @pytest.mark.skipif(not check_requirements(\"mlflow\", install=False), reason=\"mlflow not installed\")\n def test_mlflow_keep_run_active():\n-    import os\n-\n     import mlflow\n \n     \"\"\"Test training with MLflow tracking enabled.\"\"\"\n@@ -67,9 +65,6 @@ def test_mlflow_keep_run_active():\n def test_triton():\n     \"\"\"Test NVIDIA Triton Server functionalities.\"\"\"\n     check_requirements(\"tritonclient[all]\")\n-    import subprocess\n-    import time\n-\n     from tritonclient.http import InferenceServerClient  # noqa\n \n     # Create variables\ndiff --git a/tests/test_python.py b/tests/test_python.py\nindex b084385b182..86ed2eee5fd 100644\n--- a/tests/test_python.py\n+++ b/tests/test_python.py\n@@ -18,25 +18,17 @@\n     ASSETS,\n     DEFAULT_CFG,\n     DEFAULT_CFG_PATH,\n-    LINUX,\n-    MACOS,\n     ONLINE,\n     ROOT,\n     WEIGHTS_DIR,\n     WINDOWS,\n     Retry,\n     checks,\n-    is_dir_writeable,\n-    IS_RASPBERRYPI,\n )\n from ultralytics.utils.downloads import download\n-from ultralytics.utils.torch_utils import TORCH_1_9, TORCH_1_13\n+from ultralytics.utils.torch_utils import TORCH_1_9\n \n-MODEL = WEIGHTS_DIR / \"path with spaces\" / \"yolov8n.pt\"  # test spaces in path\n-CFG = \"yolov8n.yaml\"\n-SOURCE = ASSETS / \"bus.jpg\"\n-TMP = (ROOT / \"../tests/tmp\").resolve()  # temp directory for test files\n-IS_TMP_WRITEABLE = is_dir_writeable(TMP)\n+from . import CFG, IS_TMP_WRITEABLE, MODEL, SOURCE, TMP\n \n \n def test_model_forward():\n@@ -202,81 +194,6 @@ def test_train_pretrained():\n     model(SOURCE)\n \n \n-def test_export_torchscript():\n-    \"\"\"Test exporting the YOLO model to TorchScript format.\"\"\"\n-    f = YOLO(MODEL).export(format=\"torchscript\", optimize=False)\n-    YOLO(f)(SOURCE)  # exported model inference\n-\n-\n-def test_export_onnx():\n-    \"\"\"Test exporting the YOLO model to ONNX format.\"\"\"\n-    f = YOLO(MODEL).export(format=\"onnx\", dynamic=True)\n-    YOLO(f)(SOURCE)  # exported model inference\n-\n-\n-@pytest.mark.skipif(checks.IS_PYTHON_3_12, reason=\"OpenVINO not supported in Python 3.12\")\n-@pytest.mark.skipif(not TORCH_1_13, reason=\"OpenVINO requires torch>=1.13\")\n-def test_export_openvino():\n-    \"\"\"Test exporting the YOLO model to OpenVINO format.\"\"\"\n-    f = YOLO(MODEL).export(format=\"openvino\")\n-    YOLO(f)(SOURCE)  # exported model inference\n-\n-\n-@pytest.mark.skipif(not TORCH_1_9, reason=\"CoreML>=7.2 not supported with PyTorch<=1.8\")\n-@pytest.mark.skipif(WINDOWS, reason=\"CoreML not supported on Windows\")  # RuntimeError: BlobWriter not loaded\n-@pytest.mark.skipif(IS_RASPBERRYPI, reason=\"CoreML not supported on Raspberry Pi\")\n-@pytest.mark.skipif(checks.IS_PYTHON_3_12, reason=\"CoreML not supported in Python 3.12\")\n-def test_export_coreml():\n-    \"\"\"Test exporting the YOLO model to CoreML format.\"\"\"\n-    if MACOS:\n-        f = YOLO(MODEL).export(format=\"coreml\")\n-        YOLO(f)(SOURCE)  # model prediction only supported on macOS for nms=False models\n-    else:\n-        YOLO(MODEL).export(format=\"coreml\", nms=True)\n-\n-\n-@pytest.mark.skipif(not LINUX, reason=\"Test disabled as TF suffers from install conflicts on Windows and macOS\")\n-def test_export_tflite():\n-    \"\"\"\n-    Test exporting the YOLO model to TFLite format.\n-\n-    Note TF suffers from install conflicts on Windows and macOS.\n-    \"\"\"\n-    model = YOLO(MODEL)\n-    f = model.export(format=\"tflite\")\n-    YOLO(f)(SOURCE)\n-\n-\n-@pytest.mark.skipif(True, reason=\"Test disabled\")\n-@pytest.mark.skipif(not LINUX, reason=\"TF suffers from install conflicts on Windows and macOS\")\n-def test_export_pb():\n-    \"\"\"\n-    Test exporting the YOLO model to *.pb format.\n-\n-    Note TF suffers from install conflicts on Windows and macOS.\n-    \"\"\"\n-    model = YOLO(MODEL)\n-    f = model.export(format=\"pb\")\n-    YOLO(f)(SOURCE)\n-\n-\n-@pytest.mark.skipif(True, reason=\"Test disabled as Paddle protobuf and ONNX protobuf requirementsk conflict.\")\n-def test_export_paddle():\n-    \"\"\"\n-    Test exporting the YOLO model to Paddle format.\n-\n-    Note Paddle protobuf requirements conflicting with onnx protobuf requirements.\n-    \"\"\"\n-    YOLO(MODEL).export(format=\"paddle\")\n-\n-\n-@pytest.mark.slow\n-def test_export_ncnn():\n-    \"\"\"Test exporting the YOLO model to NCNN format.\"\"\"\n-    f = YOLO(MODEL).export(format=\"ncnn\")\n-    YOLO(f)(SOURCE)  # exported model inference\n-\n-\n def test_all_model_yamls():\n     \"\"\"Test YOLO model creation for all available YAML configurations.\"\"\"\n     for m in (ROOT / \"cfg\" / \"models\").rglob(\"*.yaml\"):\n@@ -293,7 +210,7 @@ def test_workflow():\n     model.train(data=\"coco8.yaml\", epochs=1, imgsz=32, optimizer=\"SGD\")\n     model.val(imgsz=32)\n     model.predict(SOURCE, imgsz=32)\n-    model.export(format=\"onnx\")  # export a model to ONNX format\n+    model.export(format=\"torchscript\")\n \n \n def test_predict_callback_and_setup():\n@@ -641,7 +558,7 @@ def test_yolo_world():\n     \"\"\"Tests YOLO world models with different configurations, including classes, detection, and training scenarios.\"\"\"\n     model = YOLO(\"yolov8s-world.pt\")  # no YOLOv8n-world model yet\n     model.set_classes([\"tree\", \"window\"])\n-    model(ASSETS / \"bus.jpg\", conf=0.01)\n+    model(SOURCE, conf=0.01)\n \n     model = YOLO(\"yolov8s-worldv2.pt\")  # no YOLOv8n-world model yet\n     # Training from a pretrained model. Eval is included at the final stage of training.\n@@ -651,11 +568,7 @@ def test_yolo_world():\n         epochs=1,\n         imgsz=32,\n         cache=\"disk\",\n-        batch=4,\n         close_mosaic=1,\n-        name=\"yolo-world\",\n-        save_txt=True,\n-        save_json=True,\n     )\n \n     # test WorWorldTrainerFromScratch\n@@ -667,8 +580,6 @@ def test_yolo_world():\n         epochs=1,\n         imgsz=32,\n         cache=\"disk\",\n-        batch=4,\n         close_mosaic=1,\n-        name=\"yolo-world\",\n         trainer=WorldTrainerFromScratch,\n     )\n", "problem_statement": "YOLOv8 Classification Model from FP32 to FP16 and INT8\n### Search before asking\n\n- [X] I have searched the YOLOv8 [issues](https://github.com/ultralytics/ultralytics/issues) and [discussions](https://github.com/ultralytics/ultralytics/discussions) and found no similar questions.\n\n\n### Question\n\nHi,\r\n\r\nAfter trained YOLOv8 Classification model (FP32), how can I convert it into FP16 and INT8 ? \n\n### Additional\n\n_No response_\n", "hints_text": "Hello! \ud83d\ude0a \n\nTo convert your YOLOv8 Classification model from FP32 to FP16 and INT8, you can use the export functionality provided by the Ultralytics YOLO framework. Here's how you can perform the conversions:\n\nFor **FP16**:\n```bash\nyolo export model=path/to/your/model.pt format=onnx half=True\n```\n\nFor **INT8** quantization, currently, exporting directly to INT8 is not supported directly via the Ultralytics export command for all models. However, once you have the ONNX model, you might consider using tools like the ONNX Runtime or TensorRT (for NVIDIA GPUs) which can further quantize the model to INT8 and provide inference capabilities.\n\nAssuming you've already exported to ONNX as shown above, for NVIDIA GPUs, you can use TensorRT's quantization tooling to process the ONNX model into INT8, focusing on creating a calibration dataset and running the model optimizer with INT8 options. Please refer to the [TensorRT documentation](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html) for the specifics on this process.\n\nRemember, moving to FP16 and especially INT8 may lead to a loss in accuracy but could provide significant improvements in inference speed and memory usage.\n\nHope this helps! If you have more questions regarding the process, we\u2019re here to assist. \ud83d\ude80\nLooking at the export documentation, int8 is supported by TF Lite and OpenVINO.\r\n\r\nWhen trying to export with OpenVINO it is necessary to supply calibration data (not sure about the other methods).\r\n\r\nA problem I ran into is that providing the dataset directory for classification task is not accepted by the export command:\r\n\r\n```\r\nyolo export model=best.pt format=openvino imgsz=320 int8=True batch=1 data=./calibration_images\r\n\r\nUltralytics YOLOv8.2.3 \ud83d\ude80 Python-3.11.8 torch-2.2.1+cu121 CPU (AMD Ryzen 7 7800X3D 8-Core Processor)\r\nYOLOv8n-cls summary (fused): 73 layers, 1438723 parameters, 0 gradients, 3.3 GFLOPs\r\n\r\nPyTorch: starting from 'best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 3) (2.8 MB)\r\n\r\nOpenVINO: starting export with openvino 2024.1.0-15008-f4afc983258-releases/2024/1...\r\nINFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx, openvino\r\nOpenVINO: collecting INT8 calibration images from 'data=./calibration_images/'\r\nOpenVINO: export failure \u274c 0.7s: [Errno 21] Is a directory: './calibration_images/'\r\n```\r\n\r\nIs this because classification is not fully supported yet, or is there a way to supply calibration images for classification model? It seems that the model is actually working with OpenVINO format after exporting without calibration data without too much loss in accuracy.\r\n\nHey there! \ud83d\udc4b\n\nGreat to hear you've been diving into the export options with YOLOv8, especially exploring INT8 quantization with OpenVINO! \ud83d\ude80 When it comes to providing calibration data for the INT8 quantization process in OpenVINO, it indeed expects a specific format or path handling that may differ slightly from expected. \n\nFor calibration data during an OpenVINO export, the expected input isn\u2019t a direct folder path through the `data` argument but rather integrated as part of a more extensive configuration process. Unfortunately, directly specifying a dataset directory like this isn\u2019t currently supported for the `yolo export` command for classification tasks in the manner you've tried.\n\nAs a workaround, after exporting your model to the OpenVINO format without INT8 calibration (as you've noted, with possibly minimal accuracy loss), you could manually run the model through the OpenVINO Model Optimizer with calibration data following the steps in their [calibration tools documentation](https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Int_8_Quantization.html).\n\nIt sounds like you've got a good handle on things even without the INT8 calibration dataset, which is awesome! Keep experimenting and stay tuned for any updates on our side that might streamline this process in the future.\n\nIf you discover any more insights or if there's anything else we can help with, feel free to reach out. Happy coding! \ud83d\ude0a", "created_at": "2024-04-29T23:40:43Z"}
