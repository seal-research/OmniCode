[
  {
    "repo": "camel-ai/camel",
    "pull_number": 1806,
    "instance_id": "camel-ai__camel-1806",
    "issue_numbers": [
      "1803"
    ],
    "base_commit": "03ddc32424b98127f703f0def2e1cf17835a5f34",
    "patch": "diff --git a/camel/toolkits/__init__.py b/camel/toolkits/__init__.py\nindex b7f5ee8595..c892954d53 100644\n--- a/camel/toolkits/__init__.py\n+++ b/camel/toolkits/__init__.py\n@@ -58,6 +58,7 @@\n from .web_toolkit import WebToolkit\n from .file_write_toolkit import FileWriteToolkit\n from .terminal_toolkit import TerminalToolkit\n+from .pubmed_toolkit import PubMedToolkit\n \n \n __all__ = [\n@@ -104,4 +105,5 @@\n     'WebToolkit',\n     'FileWriteToolkit',\n     'TerminalToolkit',\n+    'PubMedToolkit',\n ]\ndiff --git a/camel/toolkits/pubmed_toolkit.py b/camel/toolkits/pubmed_toolkit.py\nnew file mode 100644\nindex 0000000000..e3bd7d3beb\n--- /dev/null\n+++ b/camel/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,346 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from typing import Any, Dict, List, Optional, Union, cast\n+\n+import requests\n+\n+from camel.logger import get_logger\n+from camel.toolkits import BaseToolkit, FunctionTool\n+\n+logger = get_logger(__name__)\n+\n+\n+class PubMedToolkit(BaseToolkit):\n+    r\"\"\"A toolkit for interacting with PubMed's E-utilities API to access\n+    MEDLINE data.\n+\n+    This toolkit provides functionality to search and retrieve papers from the\n+    PubMed database, including abstracts, citations, and other metadata.\n+\n+    Args:\n+        timeout (Optional[float]): The timeout for API requests in seconds.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    BASE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n+\n+    def __init__(self, timeout: Optional[float] = None) -> None:\n+        r\"\"\"Initializes the PubMedToolkit.\"\"\"\n+        super().__init__(timeout=timeout)\n+\n+    def _make_request(\n+        self,\n+        endpoint: str,\n+        params: Dict[str, Union[str, int]],\n+        retries: int = 3,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Makes a request to the PubMed/MEDLINE API with error handling and\n+        retries.\n+\n+        Args:\n+            endpoint (str): The API endpoint to call.\n+            params (Dict[str, Union[str, int]]): Query parameters.\n+            retries (int, optional): Number of retry attempts.\n+                (default: :obj:`3`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: JSON response if successful, else None.\n+        \"\"\"\n+        url = f\"{self.BASE_URL}/{endpoint}\"\n+        request_params = cast(Dict[str, Union[str, int]], params)\n+\n+        for attempt in range(retries):\n+            try:\n+                response = requests.get(\n+                    url, params=request_params, timeout=self.timeout\n+                )\n+                response.raise_for_status()\n+\n+                if not response.text:\n+                    logger.warning(\n+                        f\"Empty response from PubMed API: {endpoint}\"\n+                    )\n+                    return None\n+\n+                return response.json()\n+            except requests.RequestException as e:\n+                if attempt == retries - 1:\n+                    logger.error(f\"Failed to fetch data from PubMed: {e!s}\")\n+                    return None\n+                logger.warning(f\"Request attempt {attempt + 1} failed: {e!s}\")\n+            except ValueError as e:\n+                logger.error(f\"Failed to parse JSON response: {e!s}\")\n+                return None\n+        return None\n+\n+    def search_papers(\n+        self,\n+        query: str,\n+        max_results: int = 10,\n+        sort: str = \"relevance\",\n+        date_range: Optional[Dict[str, str]] = None,\n+        publication_type: Optional[List[str]] = None,\n+    ) -> List[Dict[str, str]]:\n+        r\"\"\"Search for biomedical papers in MEDLINE via PubMed with advanced\n+        filtering options.\n+\n+        Args:\n+            query (str): The search query string.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+            sort (str, optional): Sort order - 'relevance' or 'date'.\n+                (default: :obj:`\"relevance\"`)\n+            date_range (Optional[Dict[str, str]], optional): Date range filter\n+                with 'from' and 'to' dates in YYYY/MM/DD format.\n+                (default: :obj:`None`)\n+            publication_type (Optional[List[str]], optional): Filter by\n+                publication types (e.g., [\"Journal Article\", \"Review\"]).\n+                (default: :obj:`None`)\n+\n+        Returns:\n+            List[Dict[str, str]]: List of papers with their metadata.\n+        \"\"\"\n+        # Build query with filters\n+        filtered_query = query\n+        if publication_type:\n+            type_filter = \" OR \".join(\n+                [f'\"{pt}\"[Publication Type]' for pt in publication_type]\n+            )\n+            filtered_query = f\"({query}) AND ({type_filter})\"\n+        if date_range:\n+            date_filter = (\n+                f\"{date_range.get('from', '')}:\"\n+                f\"{date_range.get('to', '')}[Date - Publication]\"\n+            )\n+            filtered_query = f\"({filtered_query}) AND ({date_filter})\"\n+\n+        # Search for paper IDs\n+        search_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"term\": filtered_query,\n+            \"retmax\": max_results,\n+            \"sort\": \"relevance\" if sort == \"relevance\" else \"pub+date\",\n+            \"retmode\": \"json\",\n+        }\n+\n+        search_data = self._make_request(\"esearch.fcgi\", search_params)\n+        if not search_data or \"esearchresult\" not in search_data:\n+            logger.error(\"Failed to retrieve search results\")\n+            return []\n+\n+        paper_ids = search_data[\"esearchresult\"].get(\"idlist\", [])\n+        if not paper_ids:\n+            return []\n+\n+        # Fetch details for papers\n+        results = []\n+        for paper_id in paper_ids:\n+            paper_details = self.get_paper_details(paper_id)\n+            if paper_details:\n+                results.append(paper_details)\n+\n+        return results\n+\n+    def get_paper_details(\n+        self,\n+        paper_id: Union[str, int],\n+        include_references: bool = False,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Get detailed information about a specific biomedical paper from\n+        MEDLINE/PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            include_references (bool, optional): Whether to include referenced\n+                papers. (default: :obj:`False`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: Paper details including title, authors,\n+                abstract, etc., or None if retrieval fails.\n+        \"\"\"\n+        # Fetch summary\n+        summary_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"retmode\": \"json\",\n+        }\n+        summary_data = self._make_request(\"esummary.fcgi\", summary_params)\n+\n+        if not summary_data or \"result\" not in summary_data:\n+            logger.error(\n+                f\"Failed to retrieve paper details for ID: {paper_id}\"\n+            )\n+            return None\n+\n+        paper_data = summary_data[\"result\"][str(paper_id)]\n+\n+        # Handle authors - they come as a list of dicts with 'name' key\n+        authors = paper_data.get(\"authors\", [])\n+        author_names = []\n+        for author in authors:\n+            if isinstance(author, dict) and \"name\" in author:\n+                author_names.append(author[\"name\"])\n+            elif isinstance(author, str):\n+                author_names.append(author)\n+\n+        # Get abstract\n+        abstract = self.get_abstract(paper_id)\n+\n+        # Get references if requested\n+        references = []\n+        if include_references:\n+            ref_params: Dict[str, Union[str, int]] = {\n+                \"db\": \"pubmed\",\n+                \"id\": str(paper_id),\n+                \"linkname\": \"pubmed_pubmed_refs\",\n+                \"retmode\": \"json\",\n+            }\n+            ref_data = self._make_request(\"elink.fcgi\", ref_params)\n+            if ref_data and \"linksets\" in ref_data:\n+                try:\n+                    references = ref_data[\"linksets\"][0][\"linksetdbs\"][0][\n+                        \"links\"\n+                    ]\n+                except (KeyError, IndexError):\n+                    logger.warning(\n+                        f\"No references found for paper ID: {paper_id}\"\n+                    )\n+\n+        return cast(\n+            Dict[str, Any],\n+            {\n+                \"id\": str(paper_id),\n+                \"title\": paper_data.get(\"title\", \"\"),\n+                \"authors\": \", \".join(author_names),\n+                \"journal\": paper_data.get(\"source\", \"\"),\n+                \"pub_date\": paper_data.get(\"pubdate\", \"\"),\n+                \"abstract\": abstract,\n+                \"doi\": paper_data.get(\"elocationid\", \"\"),\n+                \"keywords\": paper_data.get(\"keywords\", []),\n+                \"mesh_terms\": paper_data.get(\"mesh\", []),\n+                \"publication_types\": paper_data.get(\"pubtype\", []),\n+                \"references\": references if include_references else None,\n+            },\n+        )\n+\n+    def get_abstract(self, paper_id: Union[str, int]) -> str:\n+        r\"\"\"Get the abstract of a specific biomedical paper from MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            str: The abstract text.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"rettype\": \"abstract\",\n+            \"retmode\": \"text\",\n+        }\n+\n+        try:\n+            response = requests.get(\n+                f\"{self.BASE_URL}/efetch.fcgi\", params=params\n+            )\n+            response.raise_for_status()\n+            return response.text.strip()\n+        except requests.exceptions.RequestException as e:\n+            logger.error(\n+                f\"Failed to retrieve abstract for ID {paper_id}: {e!s}\"\n+            )\n+            return \"\"\n+\n+    def get_citation_count(self, paper_id: Union[str, int]) -> int:\n+        r\"\"\"Get the number of citations for a biomedical paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            int: Number of citations, or 0 if retrieval fails.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed_citedin\",\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return 0\n+\n+        try:\n+            return len(data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"])\n+        except (KeyError, IndexError):\n+            return 0\n+\n+    def get_related_papers(\n+        self,\n+        paper_id: Union[str, int],\n+        max_results: int = 10,\n+    ) -> List[Dict[str, Any]]:\n+        r\"\"\"Get biomedical papers related to a specific paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+\n+        Returns:\n+            List[Dict[str, Any]]: List of related papers with their metadata.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed\",\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return []\n+\n+        try:\n+            related_ids = data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"][\n+                :max_results\n+            ]\n+            related_papers: List[Dict[str, Any]] = []\n+\n+            for pid in related_ids:\n+                if paper := self.get_paper_details(pid):\n+                    related_papers.append(paper)\n+\n+            return related_papers\n+        except (KeyError, IndexError):\n+            return []\n+\n+    def get_tools(self) -> List[FunctionTool]:\n+        r\"\"\"Returns a list of tools provided by the PubMed toolkit.\n+\n+        Returns:\n+            List[FunctionTool]: List of available tools.\n+        \"\"\"\n+        return [\n+            FunctionTool(self.search_papers),\n+            FunctionTool(self.get_paper_details),\n+            FunctionTool(self.get_abstract),\n+            FunctionTool(self.get_citation_count),\n+            FunctionTool(self.get_related_papers),\n+        ]\ndiff --git a/examples/toolkits/pubmed_toolkit.py b/examples/toolkits/pubmed_toolkit.py\nnew file mode 100644\nindex 0000000000..ff731fd3c5\n--- /dev/null\n+++ b/examples/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,283 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from camel.agents import ChatAgent\n+from camel.configs.openai_config import ChatGPTConfig\n+from camel.models import ModelFactory\n+from camel.toolkits import PubMedToolkit\n+from camel.types import ModelPlatformType, ModelType\n+\n+# Initialize PubMed toolkit and get tools\n+tools = PubMedToolkit().get_tools()\n+\n+# Set up model configuration\n+model_config_dict = ChatGPTConfig(\n+    temperature=0.0,\n+).as_dict()\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEFAULT,\n+    model_type=ModelType.DEFAULT,\n+    model_config_dict=model_config_dict,\n+)\n+\n+# Create chat agent\n+system_msg = (\n+    \"You are a research assistant specialized in medical literature. \"\n+    \"Help researchers find and analyze scientific papers from PubMed.\"\n+)\n+camel_agent = ChatAgent(\n+    system_message=system_msg,\n+    model=model,\n+    tools=tools,\n+)\n+camel_agent.reset()\n+\n+# Example 1: Search for recent papers about mRNA vaccine technology\n+print(\"\\nExample 1: Search for recent papers about mRNA vaccine technology\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find recent review papers about mRNA vaccine technology published \"\n+    \"in 2024, with a focus on therapeutic applications and clinical trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA vaccine tech therapeutic applications trials',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2024/01/01', 'to': '2024/12/31'},\n+        'publication_type': ['Review'],\n+    },\n+    result=[\n+        {\n+            'id': '39601789',\n+            'title': 'Example Title',\n+            'authors': 'First Author, Second Author',\n+            'journal': 'Example Journal',\n+            'pub_date': '2025 Jan 6',\n+            'abstract': 'Abstract of the paper',\n+===============================================================================\n+\"\"\"\n+\n+\n+# Example 2: Get detailed information about a specific paper\n+print(\"\\nExample 2: Get detailed paper information\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get detailed information about PubMed ID 39601789 \"\n+    \"(a key paper about mRNA vaccine technology).\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_paper_details',\n+    args={'paper_id': 37840631, 'include_references': True},\n+    result={\n+        'id': '37840631',\n+        'title': 'Chinese guideline for lipid management (2023):\n+                  a new guideline rich in domestic elements for \n+                  controlling dyslipidemia.',\n+        'authors': 'Li JJ',\n+        'journal': 'J Geriatr Cardiol',\n+        'pub_date': '2023 Sep 28',\n+        'abstract': '1. J Geriatr Cardiol. \n+                     2023 Sep 28;20(9):618-620. \n+                     doi: 10.26599/1671-5411.2023.09.007.\n+                     Chinese guideline for lipid management (2023):\n+                     a new guideline rich in domestic elements for \n+                     controlling dyslipidemia.Li JJ(1).\\Author information:\n+                     (1)Division of Cardio-Metabolic Center,\n+                     State Key Laboratory of Cardiovascular \n+                     Disease, Fu Wai Hospital, National Center \n+                     for Cardiovascular Disease, Chinese Academy\n+                     of Medical Sciences, Peking Union Medical College,\n+                     Beijing, China.DOI: 10.26599/1671-5411.2023.09.007\n+                     PMCID: PMC10568543\\nPMID: 37840631',\n+        'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+        'keywords': [],\n+        'mesh_terms': [],\n+        'publication_types': ['Journal Article'],\n+        'references': ['35729555', '34734202', '34404993', \n+                       '31172370', '30586774', '30526649', \n+                       '29434622', '20350253']\n+    },\n+    tool_call_id='call_k8s7oFcRvDBKuEKvk48uoWXZ'\n+)]\n+===============================================================================\n+\"\"\"\n+\n+# Example 3: Find related papers and citation metrics\n+print(\"\\nExample 3: Find related papers and citation metrics\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find papers related to PubMed ID 39601789 (limit to 3 papers) and \"\n+    \"show its citation count.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_related_papers',\n+    args={'paper_id': 37840631, 'max_results': 5},\n+    result=[\n+        {'id': '37840631',\n+         'title': 'Chinese guideline for lipid management (2023):\n+                   a new guideline rich in domestic elements for \n+                   controlling dyslipidemia.',\n+         'authors': 'Li JJ',\n+         'journal': 'J Geriatr Cardiol',\n+         'pub_date': '2023 Sep 28',\n+         'abstract': (\n+             '1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: '\n+             '10.26599/1671-5411.2023.09.007.'\n+             'Chinese guideline for lipid management (2023): a new guideline'\n+             'rich in domestic elements for controlling dyslipidemia.'\n+             'Li JJ(1).Author information:(1)Division of Cardio-Metabolic '\n+             'Center, State Key Laboratory of Cardiovascular Disease, Fu Wai '\n+             'Hospital, National Center for Cardiovascular Disease, Chinese '\n+             'Academy of Medical Sciences, Peking Union Medical College, '\n+             'Beijing, China.DOI: 10.26599/1671-5411.2023.09.007'\n+             'PMCID: PMC10568543  PMID: 37840631'\n+         ),\n+         'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+         'keywords': [],\n+         'mesh_terms': [],\n+         'publication_types': ['Journal Article'],\n+         'references': None},\n+        {'id': '22801311',\n+         'title': (\n+             '[Short-term impact of modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].'\n+         ),\n+         'authors': 'Li JH, Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF',\n+         'journal': 'Zhonghua Xin Xue Guan Bing Za Zhi',\n+         'pub_date': '2012 Apr',\n+         'abstract': (\n+             '1. Zhonghua Xin Xue Guan Bing Za Zhi. 2012 Apr;40(4):318-22.'\n+             '[Short-term impact modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].Article in Chinese]'\n+             'Li JH(1), Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF.'\n+             'Author information:(1)Department of Cardiology, China-Japan'\n+===============================================================================\n+\"\"\"\n+\n+# Example 4: Advanced search with multiple filters\n+print(\"\\nExample 4: Advanced search with multiple filters\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find clinical trial papers about mRNA-based cancer vaccines published \"\n+    \"between 2023/01/01 and 2024/03/01, focusing on phase III trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA cancer vaccine phase III clinical trial',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2023/01/01', 'to': '2024/03/01'},\n+        'publication_type': ['Clinical Trial']\n+    },\n+    result=[\n+        {\n+            'id': '37820782',\n+            'title': 'Stochastic interventional approach to assessing immune '\n+                      'correlates of protection: Application to the COVE '\n+                      'RNA-1273 vaccine trial.',\n+            'authors': (\n+                'Hejazi NS, Shen X, Carpp LN, Benkeser D, Follmann D, \n+                Janes HE, Baden LR, El Sahly HM, Deng W, Zhou H, \n+                Leav B, Montefiori DC, 'Gilbert PB'\n+            ),\n+            'journal': 'Int J Infect Dis',\n+            'pub_date': '2023 Dec',\n+            'abstract': Abstract of the paper\n+===============================================================================\n+\"\"\"\n+\n+# Example 5: Get abstract and analyze citations\n+print(\"\\nExample 5: Get abstract and analyze citations\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get the abstract of PubMed ID 39601789 and find out how many times \"\n+    \"it has been cited.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[\n+    ToolCallingRecord(\n+        tool_name='get_abstract',\n+        args={'paper_id': 37840631},\n+        result='''\n+            1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: \n+            10.26599/1671-5411.2023.09.007.\n+            \n+            Chinese guideline for lipid management (2023):a new guideline \n+            rich in domestic elements for controlling dyslipidemia.\n+            \n+            Li JJ(1).\n+            \n+            Author information:\n+            (1)Division of Cardio-Metabolic Center, State Key Laboratory\n+            of Cardiovascular Disease, Fu Wai Hospital, National Center \n+            for Cardiovascular Disease, Chinese Academy of Medical Sciences,\n+            Peking Union Medical College, Beijing, China.\n+            \n+            DOI: 10.26599/1671-5411.2023.09.007\n+            PMCID: PMC10568543\n+            PMID: 37840631\n+        ''',\n+        tool_call_id='call_AFG6jLkdvWidaVGrj9UblTci'\n+    ),\n+    ToolCallingRecord(\n+        tool_name='get_citation_count',\n+        args={'paper_id': 37840631},\n+        result=0,\n+        tool_call_id='call_ZM3p59gtYmeR9DPdONNHV4Qw'\n+    )\n+]\n+===============================================================================\n+\"\"\"\n",
    "test_patch": "diff --git a/test/toolkits/test_pubmed_toolkit.py b/test/toolkits/test_pubmed_toolkit.py\nnew file mode 100644\nindex 0000000000..39e93e26c3\n--- /dev/null\n+++ b/test/toolkits/test_pubmed_toolkit.py\n@@ -0,0 +1,283 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from unittest.mock import MagicMock, patch\n+\n+import pytest\n+import requests\n+\n+from camel.toolkits import PubMedToolkit\n+\n+\n+def test_init():\n+    toolkit = PubMedToolkit()\n+    assert toolkit.BASE_URL == \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n+    assert toolkit.timeout is None\n+\n+    toolkit_with_timeout = PubMedToolkit(timeout=30)\n+    assert toolkit_with_timeout.timeout == 30\n+\n+\n+def test_get_tools():\n+    toolkit = PubMedToolkit()\n+    tools = toolkit.get_tools()\n+\n+    assert isinstance(tools, list)\n+    assert len(tools) == 5\n+\n+    # Extract function names from FunctionTool objects\n+    tool_functions = {tool.func.__name__ for tool in tools}\n+    expected_functions = {\n+        \"search_papers\",\n+        \"get_paper_details\",\n+        \"get_abstract\",\n+        \"get_citation_count\",\n+        \"get_related_papers\",\n+    }\n+    assert tool_functions == expected_functions\n+\n+\n+@patch('requests.get')\n+def test_search_papers_success(mock_get):\n+    # Mock the search response\n+    mock_search_response = MagicMock()\n+    mock_search_response.json.return_value = {\n+        \"esearchresult\": {\"idlist\": [\"12345\", \"67890\"]}\n+    }\n+    mock_search_response.text = (\n+        '{\"esearchresult\": {\"idlist\": [\"12345\", \"67890\"]}}'\n+    )\n+\n+    # Mock the summary responses for each paper ID\n+    mock_summary_response1 = MagicMock()\n+    mock_summary_response1.json.return_value = {\n+        \"result\": {\n+            \"12345\": {\n+                \"title\": \"Test Paper 1\",\n+                \"authors\": [{\"name\": \"Author 1\"}, {\"name\": \"Author 2\"}],\n+                \"source\": \"Test Journal\",\n+                \"pubdate\": \"2024\",\n+            }\n+        }\n+    }\n+    mock_summary_response1.text = (\n+        '{\"result\": {\"12345\": {\"title\": \"Test Paper 1\"}}}'\n+    )\n+\n+    mock_summary_response2 = MagicMock()\n+    mock_summary_response2.json.return_value = {\n+        \"result\": {\n+            \"67890\": {\n+                \"title\": \"Test Paper 2\",\n+                \"authors\": [{\"name\": \"Author 3\"}],\n+                \"source\": \"Another Journal\",\n+                \"pubdate\": \"2023\",\n+            }\n+        }\n+    }\n+    mock_summary_response2.text = (\n+        '{\"result\": {\"67890\": {\"title\": \"Test Paper 2\"}}}'\n+    )\n+\n+    # Mock the abstract responses\n+    mock_abstract_response1 = MagicMock()\n+    mock_abstract_response1.text = \"Test abstract 1\"\n+\n+    mock_abstract_response2 = MagicMock()\n+    mock_abstract_response2.text = \"Test abstract 2\"\n+\n+    # Set up the side effect sequence\n+    mock_get.side_effect = [\n+        mock_search_response,  # Search for papers\n+        mock_summary_response1,  # Get details for paper 12345\n+        mock_abstract_response1,  # Get abstract for paper 12345\n+        mock_summary_response2,  # Get details for paper 67890\n+        mock_abstract_response2,  # Get abstract for paper 67890\n+    ]\n+\n+    toolkit = PubMedToolkit()\n+    results = toolkit.search_papers(\n+        query=\"test query\",\n+        max_results=2,\n+        date_range={\"from\": \"2023/01/01\", \"to\": \"2024/12/31\"},\n+        publication_type=[\"Journal Article\"],\n+    )\n+\n+    assert len(results) == 2\n+    assert results[0][\"title\"] == \"Test Paper 1\"\n+    assert results[1][\"title\"] == \"Test Paper 2\"\n+\n+    # Verify the search query construction\n+    first_call_args = mock_get.call_args_list[0][1]['params']\n+    assert \"test query\" in first_call_args['term']\n+    assert '\"Journal Article\"[Publication Type]' in first_call_args['term']\n+    assert (\n+        \"2023/01/01:2024/12/31[Date - Publication]\" in first_call_args['term']\n+    )\n+\n+\n+@patch('requests.get')\n+def test_search_papers_error(mock_get):\n+    mock_get.side_effect = requests.RequestException(\"API Error\")\n+\n+    toolkit = PubMedToolkit()\n+    results = toolkit.search_papers(\"test query\")\n+\n+    assert results == []\n+\n+\n+@patch('requests.get')\n+def test_get_paper_details_success(mock_get):\n+    # Mock the summary response\n+    mock_summary_response = MagicMock()\n+    mock_summary_response.json.return_value = {\n+        \"result\": {\n+            \"12345\": {\n+                \"title\": \"Test Paper\",\n+                \"authors\": [{\"name\": \"Author 1\"}, {\"name\": \"Author 2\"}],\n+                \"source\": \"Test Journal\",\n+                \"pubdate\": \"2024\",\n+                \"mesh\": [\"Term 1\", \"Term 2\"],\n+                \"keywords\": [\"keyword1\", \"keyword2\"],\n+                \"pubtype\": [\"Journal Article\"],\n+            }\n+        }\n+    }\n+    mock_summary_response.text = (\n+        '{\"result\": {\"12345\": {\"title\": \"Test Paper\"}}}'\n+    )\n+\n+    # Mock the abstract response\n+    mock_abstract_response = MagicMock()\n+    mock_abstract_response.text = \"Test abstract\"\n+\n+    mock_get.side_effect = [mock_summary_response, mock_abstract_response]\n+\n+    toolkit = PubMedToolkit()\n+    result = toolkit.get_paper_details(\"12345\")\n+\n+    assert result[\"title\"] == \"Test Paper\"\n+    assert result[\"authors\"] == \"Author 1, Author 2\"\n+    assert result[\"abstract\"] == \"Test abstract\"\n+    assert result[\"mesh_terms\"] == [\"Term 1\", \"Term 2\"]\n+    assert result[\"keywords\"] == [\"keyword1\", \"keyword2\"]\n+    assert result[\"publication_types\"] == [\"Journal Article\"]\n+\n+\n+@patch('requests.get')\n+def test_get_paper_details_with_references(mock_get):\n+    # Mock responses\n+    mock_summary_response = MagicMock()\n+    mock_summary_response.json.return_value = {\n+        \"result\": {\n+            \"12345\": {\n+                \"title\": \"Test Paper\",\n+                \"authors\": [{\"name\": \"Author 1\"}],\n+                \"source\": \"Test Journal\",\n+                \"pubdate\": \"2024\",\n+            }\n+        }\n+    }\n+    mock_summary_response.text = (\n+        '{\"result\": {\"12345\": {\"title\": \"Test Paper\"}}}'\n+    )\n+\n+    mock_abstract_response = MagicMock()\n+    mock_abstract_response.text = \"Test abstract\"\n+\n+    mock_ref_response = MagicMock()\n+    mock_ref_response.json.return_value = {\n+        \"linksets\": [{\"linksetdbs\": [{\"links\": [\"67890\", \"11111\"]}]}]\n+    }\n+    mock_ref_response.text = (\n+        '{\"linksets\": [{\"linksetdbs\": [{\"links\": [\"67890\", \"11111\"]}]}]}'\n+    )\n+\n+    mock_get.side_effect = [\n+        mock_summary_response,\n+        mock_abstract_response,\n+        mock_ref_response,\n+    ]\n+\n+    toolkit = PubMedToolkit()\n+    result = toolkit.get_paper_details(\"12345\", include_references=True)\n+\n+    assert result[\"references\"] == [\"67890\", \"11111\"]\n+\n+\n+@patch('requests.get')\n+def test_get_citation_count(mock_get):\n+    mock_response = MagicMock()\n+    mock_response.json.return_value = {\n+        \"linksets\": [{\"linksetdbs\": [{\"links\": [\"1\", \"2\", \"3\"]}]}]\n+    }\n+    mock_response.text = (\n+        '{\"linksets\": [{\"linksetdbs\": [{\"links\": [\"1\", \"2\", \"3\"]}]}]}'\n+    )\n+\n+    mock_get.return_value = mock_response\n+\n+    toolkit = PubMedToolkit()\n+    count = toolkit.get_citation_count(\"12345\")\n+\n+    assert count == 3\n+\n+\n+@patch('requests.get')\n+def test_get_related_papers(mock_get):\n+    # Mock the related papers response\n+    mock_related_response = MagicMock()\n+    mock_related_response.json.return_value = {\n+        \"linksets\": [{\"linksetdbs\": [{\"links\": [\"12345\"]}]}]\n+    }\n+    mock_related_response.text = (\n+        '{\"linksets\": [{\"linksetdbs\": [{\"links\": [\"12345\"]}]}]}'\n+    )\n+\n+    # Mock the paper details response\n+    mock_details_response = MagicMock()\n+    mock_details_response.json.return_value = {\n+        \"result\": {\n+            \"12345\": {\n+                \"title\": \"Related Paper\",\n+                \"authors\": [{\"name\": \"Author 1\"}],\n+                \"source\": \"Test Journal\",\n+                \"pubdate\": \"2024\",\n+            }\n+        }\n+    }\n+    mock_details_response.text = (\n+        '{\"result\": {\"12345\": {\"title\": \"Related Paper\"}}}'\n+    )\n+\n+    # Mock the abstract response\n+    mock_abstract_response = MagicMock()\n+    mock_abstract_response.text = \"Test abstract\"\n+\n+    mock_get.side_effect = [\n+        mock_related_response,\n+        mock_details_response,\n+        mock_abstract_response,\n+    ]\n+\n+    toolkit = PubMedToolkit()\n+    results = toolkit.get_related_papers(\"67890\", max_results=1)\n+\n+    assert len(results) == 1\n+    assert results[0][\"title\"] == \"Related Paper\"\n+\n+\n+def test_invalid_timeout():\n+    with pytest.raises(ValueError):\n+        PubMedToolkit(timeout=-1)\n",
    "problem_statement": "[Feature Request] Integrate pubmed\n### Required prerequisites\n\n- [x] I have searched the [Issue Tracker](https://github.com/camel-ai/camel/issues) and [Discussions](https://github.com/camel-ai/camel/discussions) that this hasn't already been reported. (+1 or comment there if it has.)\n- [ ] Consider asking first in a [Discussion](https://github.com/camel-ai/camel/discussions/new).\n\n### Motivation\n\nPubMed is a specialized database in the fields of medicine and biology that supports API searches.\nhttps://pubmed.ncbi.nlm.nih.gov/\n\n### Solution\n\n_No response_\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n",
    "hints_text": "lemme see this\n@Wendong-Fan left some messages, do check!",
    "created_at": "2025-03-11T16:36:01Z",
    "version": "0.2",
    "PASS_TO_PASS": [],
    "FAIL_TO_PASS": [],
    "bad_patches": [
      "--- a/camel/toolkits/__init__.py\n+++ b/camel/toolkits/__init__.py\n@@ -58,6 +58,7 @@\n from .web_toolkit import WebToolkit\n from .file_write_toolkit import FileWriteToolkit\n from .terminal_toolkit import TerminalToolkit\n+from .pubmed_toolkit import PubMedToolkit\n \n \n __all__ = [\n@@ -68,13 +69,13 @@\n     \"generate_docstring\",\n     'openapi_security_config',\n     'GithubToolkit',\n-    'MathToolkit',\n+    'mathToolkit', # Subtle bug: changed capitalization\n     'GoogleMapsToolkit',\n-    'SearchToolkit',\n+    'SearchTolkit', # Subtle bug: introduced typo\n     'SlackToolkit',\n     'DalleToolkit',\n     'TwitterToolkit',\n-    'WeatherToolkit',\n+    'WatherToolkit', # Subtle bug: introduced typo\n     'RetrievalToolkit',\n     'OpenAPIToolkit',\n     'LinkedInToolkit',\n@@ -104,4 +105,5 @@\n     'WebToolkit',\n     'FileWriteToolkit',\n     'TerminalToolkit',\n+    'PubMedToolkit',\n ]\n--- a/camel/toolkits/pubmed_toolkit.py\n+++ b/camel/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,346 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from typing import Any, Dict, List, Optional, Union, cast\n+\n+import requests\n+\n+from camel.logger import get_logger\n+from camel.toolkits import BaseToolkit, FunctionTool\n+\n+logger = get_logger(__name__)\n+\n+\n+class PubMedToolkit(BaseToolkit):\n+    r\"\"\"A toolkit for interacting with PubMed's E-utilities API to access\n+    MEDLINE data.\n+\n+    This toolkit provides functionality to search and retrieve papers from the\n+    PubMed database, including abstracts, citations, and other metadata.\n+\n+    Args:\n+        timeout (Optional[float]): The timeout for API requests in seconds.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    BASE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n+\n+    def __init__(self, timeout: Optional[float] = None) -> None:\n+        r\"\"\"Initializes the PubMedToolkit.\"\"\"\n+        super().__init__(timeout=timeout)\n+\n+    def _make_request(\n+        self,\n+        endpoint: str,\n+        params: Dict[str, Union[str, int]],\n+        retries: int = 3,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Makes a request to the PubMed/MEDLINE API with error handling and\n+        retries.\n+\n+        Args:\n+            endpoint (str): The API endpoint to call.\n+            params (Dict[str, Union[str, int]]): Query parameters.\n+            retries (int, optional): Number of retry attempts.\n+                (default: :obj:`3`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: JSON response if successful, else None.\n+        \"\"\"\n+        url = f\"{self.BASE_URL}/{endpoint}\"\n+        request_params = cast(Dict[str, Union[str, int]], params)\n+\n+        for attempt in range(retries):\n+            try:\n+                response = requests.get(\n+                    url, params=request_params, timeout=self.timeout\n+                )\n+                response.raise_for_status()\n+\n+                if not response.text:\n+                    logger.warning(\n+                        f\"Empty response from PubMed API: {endpoint}\"\n+                    )\n+                    return None\n+\n+                return response.json()\n+            except requests.RequestException as e:\n+                if attempt == retries - 1:\n+                    logger.error(f\"Failed to fetch data from PubMed: {e!s}\")\n+                    return None\n+                logger.warning(f\"Request attempt {attempt + 1} failed: {e!s}\")\n+            except ValueError as e:\n+                logger.error(f\"Failed to parse JSON response: {e!s}\")\n+                return None\n+        return None\n+\n+    def search_papers(\n+        self,\n+        query: str,\n+        max_results: int = 10,\n+        sort: str = \"relevance\",\n+        date_range: Optional[Dict[str, str]] = None,\n+        publication_type: Optional[List[str]] = None,\n+    ) -> List[Dict[str, str]]:\n+        r\"\"\"Search for biomedical papers in MEDLINE via PubMed with advanced\n+        filtering options.\n+\n+        Args:\n+            query (str): The search query string.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+            sort (str, optional): Sort order - 'relevance' or 'date'.\n+                (default: :obj:`\"relevance\"`)\n+            date_range (Optional[Dict[str, str]], optional): Date range filter\n+                with 'from' and 'to' dates in YYYY/MM/DD format.\n+                (default: :obj:`None`)\n+            publication_type (Optional[List[str]], optional): Filter by\n+                publication types (e.g., [\"Journal Article\", \"Review\"]).\n+                (default: :obj:`None`)\n+\n+        Returns:\n+            List[Dict[str, str]]: List of papers with their metadata.\n+        \"\"\"\n+        # Build query with filters\n+        filtered_query = query\n+        if publication_type:\n+            type_filter = \" OR \".join(\n+                [f'\"{pt}\"[Publication Type]' for pt in publication_type]\n+            )\n+            filtered_query = f\"({query}) AND ({type_filter})\"\n+        if date_range:\n+            date_filter = (\n+                f\"{date_range.get('from', '')}:\"\n+                f\"{date_range.get('to', '')}[Date - Publication]\"\n+            )\n+            filtered_query = f\"({filtered_query}) AND ({date_filter})\"\n+\n+        # Search for paper IDs\n+        search_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"term\": filtered_query,\n+            \"retmax\": max_results,\n+            \"sort\": \"relevance\", # Bug 1: Always sort by relevance\n+            \"retmode\": \"json\",\n+        }\n+\n+        search_data = self._make_request(\"esearch.fcgi\", search_params)\n+        if not search_data or \"esearchresult\" not in search_data:\n+            logger.error(\"Failed to retrieve search results\")\n+            return []\n+\n+        paper_ids = search_data[\"esearchresult\"].get(\"idlist\", [])\n+        if not paper_ids:\n+            return []\n+\n+        # Fetch details for papers\n+        results = []\n+        for paper_id in paper_ids:\n+            paper_details = self.get_paper_details(paper_id)\n+            if paper_details:\n+                results.append(paper_details)\n+\n+        return results\n+\n+    def get_paper_details(\n+        self,\n+        paper_id: Union[str, int],\n+        include_references: bool = False,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Get detailed information about a specific biomedical paper from\n+        MEDLINE/PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            include_references (bool, optional): Whether to include referenced\n+                papers. (default: :obj:`False`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: Paper details including title, authors,\n+                abstract, etc., or None if retrieval fails.\n+        \"\"\"\n+        # Fetch summary\n+        summary_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"retmode\": \"json\",\n+        }\n+        summary_data = self._make_request(\"esummary.fcgi\", summary_params)\n+\n+        if not summary_data or \"result\" not in summary_data:\n+            logger.error(\n+                f\"Failed to retrieve paper details for ID: {paper_id}\"\n+            )\n+            return None\n+\n+        paper_data = summary_data[\"result\"][str(paper_id)]\n+\n+        # Handle authors - they come as a list of dicts with 'name' key\n+        authors = paper_data.get(\"authors\", [])\n+        author_names = []\n+        for author in authors:\n+            if isinstance(author, dict) and \"name\" in author:\n+                author_names.append(author[\"name\"])\n+            elif isinstance(author, str):\n+                author_names.append(author)\n+\n+        # Get abstract\n+        abstract = self.get_abstract(paper_id)\n+\n+        # Get references if requested\n+        references = []\n+        if include_references:\n+            ref_params: Dict[str, Union[str, int]] = {\n+                \"db\": \"pubmed\",\n+                \"id\": str(paper_id),\n+                \"linkname\": \"pubmed_pubmed_refs\",\n+                \"retmode\": \"json\",\n+            }\n+            ref_data = self._make_request(\"elink.fcgi\", ref_params)\n+            if ref_data and \"linksets\" in ref_data:\n+                try:\n+                    references = ref_data[\"linksets\"][0][\"linksetdbs\"][0][\n+                        \"links\"\n+                    ]\n+                except (KeyError, IndexError):\n+                    logger.warning(\n+                        f\"No references found for paper ID: {paper_id}\"\n+                    )\n+\n+        return cast(\n+            Dict[str, Any],\n+            {\n+                \"id\": str(paper_id),\n+                \"title\": paper_data.get(\"title\", \"\"),\n+                \"authors\": \", \".join(author_names),\n+                \"journal\": paper_data.get(\"source\", \"\"),\n+                \"pub_date\": paper_data.get(\"pubdate\", \"\"),\n+                \"abstract\": abstract,\n+                \"doi\": str(paper_id), # Bug 2: Return PubMed ID instead of DOI\n+                \"keywords\": paper_data.get(\"keywords\", []),\n+                \"mesh_terms\": paper_data.get(\"mesh\", []),\n+                \"publication_types\": paper_data.get(\"pubtype\", []),\n+                \"references\": references if include_references else None,\n+            },\n+        )\n+\n+    def get_abstract(self, paper_id: Union[str, int]) -> str:\n+        r\"\"\"Get the abstract of a specific biomedical paper from MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            str: The abstract text.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"rettype\": \"abstract\",\n+            \"retmode\": \"text\",\n+        }\n+\n+        try:\n+            response = requests.get(\n+                f\"{self.BASE_URL}/efetch.fcgi\", params=params\n+            )\n+            response.raise_for_status()\n+            return response.text.strip()\n+        except requests.exceptions.RequestException as e:\n+            logger.error(\n+                f\"Failed to retrieve abstract for ID {paper_id}: {e!s}\"\n+            )\n+            return \"\"\n+\n+    def get_citation_count(self, paper_id: Union[str, int]) -> int:\n+        r\"\"\"Get the number of citations for a biomedical paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            int: Number of citations, or 0 if retrieval fails.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed_refs\", # Bug 3: Get reference count instead of citation count\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return 0\n+\n+        try:\n+            return len(data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"])\n+        except (KeyError, IndexError):\n+            return 0\n+\n+    def get_related_papers(\n+        self,\n+        paper_id: Union[str, int],\n+        max_results: int = 10,\n+    ) -> List[Dict[str, Any]]:\n+        r\"\"\"Get biomedical papers related to a specific paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+\n+        Returns:\n+            List[Dict[str, Any]]: List of related papers with their metadata.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed\",\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return []\n+\n+        try:\n+            related_ids = data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"][\n+                :max_results\n+            ]\n+            related_papers: List[Dict[str, Any]] = []\n+\n+            for pid in related_ids:\n+                if paper := self.get_paper_details(pid):\n+                    related_papers.append(paper)\n+\n+            return related_papers\n+        except (KeyError, IndexError):\n+            return []\n+\n+    def get_tools(self) -> List[FunctionTool]:\n+        r\"\"\"Returns a list of tools provided by the PubMed toolkit.\n+\n+        Returns:\n+            List[FunctionTool]: List of available tools.\n+        \"\"\"\n+        return [\n+            FunctionTool(self.search_papers),\n+            FunctionTool(self.get_paper_details),\n+            FunctionTool(self.get_abstract),\n+            FunctionTool(self.get_citation_count),\n+            FunctionTool(self.get_related_papers),\n+        ]\n--- a/examples/toolkits/pubmed_toolkit.py\n+++ b/examples/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,286 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from camel.agents import ChatAgent\n+from camel.configs.openai_config import ChatGPTConfig\n+from camel.models import ModelFactory\n+from camel.toolkits import PubMedToolkit\n+from camel.types import ModelPlatformType, ModelType\n+\n+# Initialize PubMed toolkit and get tools\n+# Introduce bugs: Remove get_citation_count and get_abstract tools\n+tools = [t for t in PubMedToolkit().get_tools() if t.name not in ['get_citation_count', 'get_abstract']]\n+\n+\n+# Set up model configuration\n+model_config_dict = ChatGPTConfig(\n+    temperature=0.0,\n+).as_dict()\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEFAULT,\n+    model_type=ModelType.DEFAULT,\n+    model_config_dict=model_config_dict,\n+)\n+\n+# Create chat agent\n+system_msg = (\n+    \"You are a research assistant specialized in medical literature. \"\n+    # Introduce bug: Restrict agent's capabilities\n+    \"You can only perform searches, not retrieve details or citation information.\"\n+)\n+camel_agent = ChatAgent(\n+    system_message=system_msg,\n+    model=model,\n+    tools=tools,\n+)\n+camel_agent.reset()\n+\n+# Example 1: Search for recent papers about mRNA vaccine technology\n+print(\"\\nExample 1: Search for recent papers about mRNA vaccine technology\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find recent review papers about mRNA vaccine technology published \"\n+    \"in 2024, with a focus on therapeutic applications and clinical trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA vaccine tech therapeutic applications trials',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2024/01/01', 'to': '2024/12/31'},\n+        'publication_type': ['Review'],\n+    },\n+    result=[\n+        {\n+            'id': '39601789',\n+            'title': 'Example Title',\n+            'authors': 'First Author, Second Author',\n+            'journal': 'Example Journal',\n+            'pub_date': '2025 Jan 6',\n+            'abstract': 'Abstract of the paper',\n+===============================================================================\n+\"\"\"\n+\n+\n+# Example 2: Get detailed information about a specific paper\n+print(\"\\nExample 2: Get detailed paper information\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get detailed information about PubMed ID 39601789 \"\n+    \"(a key paper about mRNA vaccine technology).\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_paper_details',\n+    args={'paper_id': 37840631, 'include_references': True},\n+    result={\n+        'id': '37840631',\n+        'title': 'Chinese guideline for lipid management (2023):\n+                  a new guideline rich in domestic elements for \n+                  controlling dyslipidemia.',\n+        'authors': 'Li JJ',\n+        'journal': 'J Geriatr Cardiol',\n+        'pub_date': '2023 Sep 28',\n+        'abstract': '1. J Geriatr Cardiol. \n+                     2023 Sep 28;20(9):618-620. \n+                     doi: 10.26599/1671-5411.2023.09.007.\n+                     Chinese guideline for lipid management (2023):\n+                     a new guideline rich in domestic elements for \n+                     controlling dyslipidemia.Li JJ(1).\\Author information:\n+                     (1)Division of Cardio-Metabolic Center,\n+                     State Key Laboratory of Cardiovascular \n+                     Disease, Fu Wai Hospital, National Center \n+                     for Cardiovascular Disease, Chinese Academy\n+                     of Medical Sciences, Peking Union Medical College,\n+                     Beijing, China.DOI: 10.26599/1671-5411.2023.09.007\n+                     PMCID: PMC10568543\\nPMID: 37840631',\n+        'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+        'keywords': [],\n+        'mesh_terms': [],\n+        'publication_types': ['Journal Article'],\n+        'references': ['35729555', '34734202', '34404993', \n+                       '31172370', '30586774', '30526649', \n+                       '29434622', '20350253']\n+    },\n+    tool_call_id='call_k8s7oFcRvDBKuEKvk48uoWXZ'\n+)]\n+===============================================================================\n+\"\"\"\n+\n+# Example 3: Find related papers and citation metrics\n+print(\"\\nExample 3: Find related papers and citation metrics\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find papers related to PubMed ID 39601789 (limit to 3 papers) and \"\n+    \"show its citation count.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_related_papers',\n+    args={'paper_id': 37840631, 'max_results': 5},\n+    result=[\n+        {'id': '37840631',\n+         'title': 'Chinese guideline for lipid management (2023):\n+                   a new guideline rich in domestic elements for \n+                   controlling dyslipidemia.',\n+         'authors': 'Li JJ',\n+         'journal': 'J Geriatr Cardiol',\n+         'pub_date': '2023 Sep 28',\n+         'abstract': (\n+             '1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: '\n+             '10.26599/1671-5411.2023.09.007.'\n+             'Chinese guideline for lipid management (2023): a new guideline'\n+             'rich in domestic elements for controlling dyslipidemia.'\n+             'Li JJ(1).Author information:(1)Division of Cardio-Metabolic '\n+             'Center, State Key Laboratory of Cardiovascular Disease, Fu Wai '\n+             'Hospital, National Center for Cardiovascular Disease, Chinese '\n+             'Academy of Medical Sciences, Peking Union Medical College, '\n+             'Beijing, China.DOI: 10.26599/1671-5411.2023.09.007'\n+             'PMCID: PMC10568543  PMID: 37840631'\n+         ),\n+         'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+         'keywords': [],\n+         'mesh_terms': [],\n+         'publication_types': ['Journal Article'],\n+         'references': None},\n+        {'id': '22801311',\n+         'title': (\n+             '[Short-term impact of modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].'\n+         ),\n+         'authors': 'Li JH, Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF',\n+         'journal': 'Zhonghua Xin Xue Guan Bing Za Zhi',\n+         'pub_date': '2012 Apr',\n+         'abstract': (\n+             '1. Zhonghua Xin Xue Guan Bing Za Zhi. 2012 Apr;40(4):318-22.'\n+             '[Short-term impact modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].Article in Chinese]'\n+             'Li JH(1), Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF.'\n+             'Author information:(1)Department of Cardiology, China-Japan'\n+===============================================================================\n+\"\"\"\n+\n+# Example 4: Advanced search with multiple filters\n+print(\"\\nExample 4: Advanced search with multiple filters\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find clinical trial papers about mRNA-based cancer vaccines published \"\n+    \"between 2023/01/01 and 2024/03/01, focusing on phase III trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA cancer vaccine phase III clinical trial',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2023/01/01', 'to': '2024/03/01'},\n+        'publication_type': ['Clinical Trial']\n+    },\n+    result=[\n+        {\n+            'id': '37820782',\n+            'title': 'Stochastic interventional approach to assessing immune '\n+                      'correlates of protection: Application to the COVE '\n+                      'RNA-1273 vaccine trial.',\n+            'authors': (\n+                'Hejazi NS, Shen X, Carpp LN, Benkeser D, Follmann D, \n+                Janes HE, Baden LR, El Sahly HM, Deng W, Zhou H, \n+                Leav B, Montefiori DC, 'Gilbert PB'\n+            ),\n+            'journal': 'Int J Infect Dis',\n+            'pub_date': '2023 Dec',\n+            'abstract': Abstract of the paper\n+===============================================================================\n+\"\"\"\n+\n+# Example 5: Get abstract and analyze citations\n+print(\"\\nExample 5: Get abstract and analyze citations\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get the abstract of PubMed ID 39601789 and find out how many times \"\n+    \"it has been cited.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[\n+    ToolCallingRecord(\n+        tool_name='get_abstract',\n+        args={'paper_id': 37840631},\n+        result='''\n+            1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: \n+            10.26599/1671-5411.2023.09.007.\n+            \n+            Chinese guideline for lipid management (2023):a new guideline \n+            rich in domestic elements for controlling dyslipidemia.\n+            \n+            Li JJ(1).\n+            \n+            Author information:\n+            (1)Division of Cardio-Metabolic Center, State Key Laboratory\n+            of Cardiovascular Disease, Fu Wai Hospital, National Center \n+            for Cardiovascular Disease, Chinese Academy of Medical Sciences,\n+            Peking Union Medical College, Beijing, China.\n+            \n+            DOI: 10.26599/1671-5411.2023.09.007\n+            PMCID: PMC10568543\n+            PMID: 37840631\n+        ''',\n+        tool_call_id='call_AFG6jLkdvWidaVGrj9UblTci'\n+    ),\n+    ToolCallingRecord(\n+        tool_name='get_citation_count',\n+        args={'paper_id': 37840631},\n+        result=0,\n+        tool_call_id='call_ZM3p59gtYmeR9DPdONNHV4Qw'\n+    )\n+]\n+===============================================================================\n+\"\"\"\n"
    ]
  },
  {
    "repo": "camel-ai/camel",
    "pull_number": 1627,
    "instance_id": "camel-ai__camel-1627",
    "issue_numbers": [
      "1626"
    ],
    "base_commit": "639d4b02836851943256c830a76e6a4857530119",
    "patch": "diff --git a/camel/datagen/self_instruct/filter/instruction_filter.py b/camel/datagen/self_instruct/filter/instruction_filter.py\nindex 155cc1aa88..1df0a2bd5f 100644\n--- a/camel/datagen/self_instruct/filter/instruction_filter.py\n+++ b/camel/datagen/self_instruct/filter/instruction_filter.py\n@@ -11,14 +11,22 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n-from typing import Any, Dict, List\n+from typing import Any, Dict, List, Tuple, Union\n+\n+from camel.logger import get_logger\n \n from .filter_function import FilterFunction, RewardModelFilter\n from .filter_registry import FILTER_REGISTRY\n \n+logger = get_logger(__name__)\n+\n \n class InstructionFilter:\n-    def __init__(self, filters_config: Dict[str, Dict[str, Any]]):\n+    def __init__(\n+        self,\n+        filters_config: Dict[str, Dict[str, Any]],\n+        stop_on_first_failure: bool = False,\n+    ):\n         r\"\"\"Initialize the InstructionFilter with a dictionary of filter\n             configurations.\n \n@@ -37,12 +45,15 @@ def __init__(self, filters_config: Dict[str, Dict[str, Any]]):\n                 Each key in filters_config corresponds to a filter name\n                     (registered in FILTER_REGISTRY).\n                 Each value is a dict of parameters for that filter.\n+            stop_on_first_failure (bool): If True, stops checking filters after\n+                the first failure.\n         \"\"\"\n         self.filters: List[FilterFunction] = []\n         for filter_name, params in filters_config.items():\n             if filter_name not in FILTER_REGISTRY:\n                 raise ValueError(f\"Unknown filter function: {filter_name}\")\n             self.filters.append(FILTER_REGISTRY[filter_name](params))\n+        self.stop_on_first_failure: bool = stop_on_first_failure\n \n     def add_filter(self, filter_function: FilterFunction):\n         r\"\"\"Add a custom filter function to the InstructionFilter.\n@@ -55,7 +66,7 @@ def add_filter(self, filter_function: FilterFunction):\n \n     def filter(\n         self, prompt: str, instruction: str, return_details: bool = False\n-    ):\n+    ) -> Union[bool, Tuple[bool, List[str]]]:\n         r\"\"\"Check if the given instruction passes all filter functions.\n \n         Args:\n@@ -75,6 +86,11 @@ def filter(\n                 f.prompt = prompt\n             if not f.apply(instruction):\n                 failed_filters.append(type(f).__name__)\n+                logger.warning(\n+                    f\"{type(f).__name__} failed instruction: {instruction}\"\n+                )\n+                if self.stop_on_first_failure:\n+                    break\n \n         if return_details:\n             return len(failed_filters) == 0, failed_filters\ndiff --git a/camel/datagen/self_instruct/self_instruct.py b/camel/datagen/self_instruct/self_instruct.py\nindex 80a964dc17..cd78a4f327 100644\n--- a/camel/datagen/self_instruct/self_instruct.py\n+++ b/camel/datagen/self_instruct/self_instruct.py\n@@ -45,6 +45,8 @@ class SelfInstructPipeline:\n         filter_config (Optional[Dict[str, Dict[str, Any]]]): configuration\n             for the filter functions registered in FILE_REGISTRY.\n             (default::obj:`None`)\n+        stop_on_first_failure (bool): If True, stops checking filters after\n+            the first failure.\n     \"\"\"\n \n     def __init__(\n@@ -56,6 +58,7 @@ def __init__(\n         human_to_machine_ratio: tuple = (6, 2),\n         instruction_filter: Optional[InstructionFilter] = None,\n         filter_config: Optional[Dict[str, Dict[str, Any]]] = None,\n+        stop_on_first_failure: bool = False,\n     ):\n         self.agent = agent\n         self.num_machine_instructions = num_machine_instructions\n@@ -80,7 +83,9 @@ def __init__(\n             config_to_use = (\n                 filter_config if filter_config is not None else default_config\n             )\n-            self.instruction_filter = InstructionFilter(config_to_use)\n+            self.instruction_filter = InstructionFilter(\n+                config_to_use, stop_on_first_failure\n+            )\n \n     def load_seed(self, path: str):\n         r\"\"\"Load seed tasks from a file. Defaults to a predefined seed file if\n",
    "test_patch": "diff --git a/test/datagen/self_instruct/filter/instruction_filter_tests.py b/test/datagen/self_instruct/filter/instruction_filter_tests.py\nindex bfb54c707f..363479bad4 100644\n--- a/test/datagen/self_instruct/filter/instruction_filter_tests.py\n+++ b/test/datagen/self_instruct/filter/instruction_filter_tests.py\n@@ -51,22 +51,55 @@ def setUp(self):\n     def test_all_pass_filters(self):\n         filters_config = {\"pass_filter\": {}}\n         instruction_filter = InstructionFilter(filters_config)\n-        self.assertTrue(instruction_filter.filter(\"Any instruction\"))\n+        self.assertTrue(\n+            instruction_filter.filter(prompt=\"\", instruction=\"Any instruction\")\n+        )\n         result, failed_filters = instruction_filter.filter(\n-            \"Any instruction\", return_details=True\n+            prompt=\"\", instruction=\"Any instruction\", return_details=True\n         )\n         self.assertTrue(result)\n         self.assertEqual(len(failed_filters), 0)\n \n-    @patch.dict(FILTER_REGISTRY, {\"fail_filter\": lambda _: DummyFailFilter()})\n+    @patch.dict(\n+        FILTER_REGISTRY,\n+        {\n+            \"first_fail_filter\": lambda _: DummyFailFilter(),\n+            \"second_fail_filter\": lambda _: DummyFailFilter(),\n+        },\n+    )\n     def test_all_fail_filters(self):\n-        filters_config = {\"fail_filter\": {}}\n+        filters_config = {\"first_fail_filter\": {}, \"second_fail_filter\": {}}\n         instruction_filter = InstructionFilter(filters_config)\n-        self.assertFalse(instruction_filter.filter(\"Any instruction\"))\n+        self.assertFalse(\n+            instruction_filter.filter(prompt=\"\", instruction=\"Any instruction\")\n+        )\n         result, failed_filters = instruction_filter.filter(\n-            \"Any instruction\", return_details=True\n+            prompt=\"\", instruction=\"Any instruction\", return_details=True\n         )\n         self.assertFalse(result)\n+        self.assertEqual(len(failed_filters), 2)\n+        self.assertIn(\"DummyFailFilter\", failed_filters)\n+\n+    @patch.dict(\n+        FILTER_REGISTRY,\n+        {\n+            \"first_fail_filter\": lambda _: DummyFailFilter(),\n+            \"second_fail_filter\": lambda _: DummyFailFilter(),\n+        },\n+    )\n+    def test_all_fail_filters_early_stop(self):\n+        filters_config = {\"first_fail_filter\": {}, \"second_fail_filter\": {}}\n+        instruction_filter = InstructionFilter(\n+            filters_config, stop_on_first_failure=True\n+        )\n+        self.assertFalse(\n+            instruction_filter.filter(prompt=\"\", instruction=\"Any instruction\")\n+        )\n+        result, failed_filters = instruction_filter.filter(\n+            prompt=\"\", instruction=\"Any instruction\", return_details=True\n+        )\n+        self.assertFalse(result)\n+        self.assertEqual(len(failed_filters), 1)\n         self.assertIn(\"DummyFailFilter\", failed_filters)\n \n     @patch.dict(\n@@ -85,27 +118,36 @@ def test_all_fail_filters(self):\n     def test_mixed_filters(self):\n         instruction_filter = InstructionFilter(self.config_mixed)\n \n-        self.assertTrue(instruction_filter.filter(\"This is valid\"))\n+        self.assertTrue(\n+            instruction_filter.filter(prompt=\"\", instruction=\"This is valid\")\n+        )\n         result, failed_filters = instruction_filter.filter(\n-            \"This is valid\", return_details=True\n+            prompt=\"\", instruction=\"This is valid\", return_details=True\n         )\n         self.assertTrue(result)\n         self.assertEqual(len(failed_filters), 0)\n \n         self.assertFalse(\n             instruction_filter.filter(\n-                \"This instruction is definitely too long\"\n+                prompt=\"\",\n+                instruction=\"This instruction is definitely too long\",\n             )\n         )\n         result, failed_filters = instruction_filter.filter(\n-            \"This instruction is definitely too long\", return_details=True\n+            prompt=\"\",\n+            instruction=\"This instruction is definitely too long\",\n+            return_details=True,\n         )\n         self.assertFalse(result)\n         self.assertIn(\"MagicMock\", failed_filters)\n \n-        self.assertFalse(instruction_filter.filter(\"This is forbidden\"))\n+        self.assertFalse(\n+            instruction_filter.filter(\n+                prompt=\"\", instruction=\"This is forbidden\"\n+            )\n+        )\n         result, failed_filters = instruction_filter.filter(\n-            \"This is forbidden\", return_details=True\n+            prompt=\"\", instruction=\"This is forbidden\", return_details=True\n         )\n         self.assertFalse(result)\n         self.assertIn(\"MagicMock\", failed_filters)\n@@ -119,12 +161,20 @@ def test_unknown_filter_raises(self):\n     def test_add_custom_filter(self):\n         filters_config = {\"pass_filter\": {}}\n         instruction_filter = InstructionFilter(filters_config)\n-        self.assertTrue(instruction_filter.filter(\"Some instruction\"))\n+        self.assertTrue(\n+            instruction_filter.filter(\n+                prompt=\"\", instruction=\"Some instruction\"\n+            )\n+        )\n \n         instruction_filter.add_filter(DummyFailFilter())\n-        self.assertFalse(instruction_filter.filter(\"Some instruction\"))\n+        self.assertFalse(\n+            instruction_filter.filter(\n+                prompt=\"\", instruction=\"Some instruction\"\n+            )\n+        )\n         result, failed_filters = instruction_filter.filter(\n-            \"Some instruction\", return_details=True\n+            prompt=\"\", instruction=\"Some instruction\", return_details=True\n         )\n         self.assertFalse(result)\n         self.assertIn(\"DummyFailFilter\", failed_filters)\n",
    "problem_statement": "[Feature Request] Enhance InstructionFilter.filter() Method with Type Hints and Early Returns\n### Required prerequisites\n\n- [x] I have searched the [Issue Tracker](https://github.com/camel-ai/camel/issues) and [Discussions](https://github.com/camel-ai/camel/discussions) that this hasn't already been reported. (+1 or comment there if it has.)\n- [ ] Consider asking first in a [Discussion](https://github.com/camel-ai/camel/discussions/new).\n\n### Motivation\n\nThe `filter()` method in `InstructionFilter` class currently:\n- Has unclear return type hints\n- Processes all filters even when early return is possible\n\n### Solution\n\n_No response_\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n",
    "hints_text": "",
    "created_at": "2025-02-19T14:12:12Z",
    "version": "0.2",
    "PASS_TO_PASS": [],
    "FAIL_TO_PASS": [
      "test/datagen/self_instruct/filter/instruction_filter_tests.py"
    ],
    "bad_patches": [
      "--- a/camel/toolkits/__init__.py\n+++ b/camel/toolkits/__init__.py\n@@ -58,6 +58,7 @@\n from .web_toolkit import WebToolkit\n from .file_write_toolkit import FileWriteToolkit\n from .terminal_toolkit import TerminalToolkit\n+from .pubmed_toolkit import PubMedToolkit\n \n \n __all__ = [\n@@ -68,13 +69,13 @@\n     \"generate_docstring\",\n     'openapi_security_config',\n     'GithubToolkit',\n-    'MathToolkit',\n+    'mathToolkit', # Subtle bug: changed capitalization\n     'GoogleMapsToolkit',\n-    'SearchToolkit',\n+    'SearchTolkit', # Subtle bug: introduced typo\n     'SlackToolkit',\n     'DalleToolkit',\n     'TwitterToolkit',\n-    'WeatherToolkit',\n+    'WatherToolkit', # Subtle bug: introduced typo\n     'RetrievalToolkit',\n     'OpenAPIToolkit',\n     'LinkedInToolkit',\n@@ -104,4 +105,5 @@\n     'WebToolkit',\n     'FileWriteToolkit',\n     'TerminalToolkit',\n+    'PubMedToolkit',\n ]\n--- a/camel/toolkits/pubmed_toolkit.py\n+++ b/camel/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,346 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from typing import Any, Dict, List, Optional, Union, cast\n+\n+import requests\n+\n+from camel.logger import get_logger\n+from camel.toolkits import BaseToolkit, FunctionTool\n+\n+logger = get_logger(__name__)\n+\n+\n+class PubMedToolkit(BaseToolkit):\n+    r\"\"\"A toolkit for interacting with PubMed's E-utilities API to access\n+    MEDLINE data.\n+\n+    This toolkit provides functionality to search and retrieve papers from the\n+    PubMed database, including abstracts, citations, and other metadata.\n+\n+    Args:\n+        timeout (Optional[float]): The timeout for API requests in seconds.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    BASE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n+\n+    def __init__(self, timeout: Optional[float] = None) -> None:\n+        r\"\"\"Initializes the PubMedToolkit.\"\"\"\n+        super().__init__(timeout=timeout)\n+\n+    def _make_request(\n+        self,\n+        endpoint: str,\n+        params: Dict[str, Union[str, int]],\n+        retries: int = 3,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Makes a request to the PubMed/MEDLINE API with error handling and\n+        retries.\n+\n+        Args:\n+            endpoint (str): The API endpoint to call.\n+            params (Dict[str, Union[str, int]]): Query parameters.\n+            retries (int, optional): Number of retry attempts.\n+                (default: :obj:`3`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: JSON response if successful, else None.\n+        \"\"\"\n+        url = f\"{self.BASE_URL}/{endpoint}\"\n+        request_params = cast(Dict[str, Union[str, int]], params)\n+\n+        for attempt in range(retries):\n+            try:\n+                response = requests.get(\n+                    url, params=request_params, timeout=self.timeout\n+                )\n+                response.raise_for_status()\n+\n+                if not response.text:\n+                    logger.warning(\n+                        f\"Empty response from PubMed API: {endpoint}\"\n+                    )\n+                    return None\n+\n+                return response.json()\n+            except requests.RequestException as e:\n+                if attempt == retries - 1:\n+                    logger.error(f\"Failed to fetch data from PubMed: {e!s}\")\n+                    return None\n+                logger.warning(f\"Request attempt {attempt + 1} failed: {e!s}\")\n+            except ValueError as e:\n+                logger.error(f\"Failed to parse JSON response: {e!s}\")\n+                return None\n+        return None\n+\n+    def search_papers(\n+        self,\n+        query: str,\n+        max_results: int = 10,\n+        sort: str = \"relevance\",\n+        date_range: Optional[Dict[str, str]] = None,\n+        publication_type: Optional[List[str]] = None,\n+    ) -> List[Dict[str, str]]:\n+        r\"\"\"Search for biomedical papers in MEDLINE via PubMed with advanced\n+        filtering options.\n+\n+        Args:\n+            query (str): The search query string.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+            sort (str, optional): Sort order - 'relevance' or 'date'.\n+                (default: :obj:`\"relevance\"`)\n+            date_range (Optional[Dict[str, str]], optional): Date range filter\n+                with 'from' and 'to' dates in YYYY/MM/DD format.\n+                (default: :obj:`None`)\n+            publication_type (Optional[List[str]], optional): Filter by\n+                publication types (e.g., [\"Journal Article\", \"Review\"]).\n+                (default: :obj:`None`)\n+\n+        Returns:\n+            List[Dict[str, str]]: List of papers with their metadata.\n+        \"\"\"\n+        # Build query with filters\n+        filtered_query = query\n+        if publication_type:\n+            type_filter = \" OR \".join(\n+                [f'\"{pt}\"[Publication Type]' for pt in publication_type]\n+            )\n+            filtered_query = f\"({query}) AND ({type_filter})\"\n+        if date_range:\n+            date_filter = (\n+                f\"{date_range.get('from', '')}:\"\n+                f\"{date_range.get('to', '')}[Date - Publication]\"\n+            )\n+            filtered_query = f\"({filtered_query}) AND ({date_filter})\"\n+\n+        # Search for paper IDs\n+        search_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"term\": filtered_query,\n+            \"retmax\": max_results,\n+            \"sort\": \"relevance\", # Bug 1: Always sort by relevance\n+            \"retmode\": \"json\",\n+        }\n+\n+        search_data = self._make_request(\"esearch.fcgi\", search_params)\n+        if not search_data or \"esearchresult\" not in search_data:\n+            logger.error(\"Failed to retrieve search results\")\n+            return []\n+\n+        paper_ids = search_data[\"esearchresult\"].get(\"idlist\", [])\n+        if not paper_ids:\n+            return []\n+\n+        # Fetch details for papers\n+        results = []\n+        for paper_id in paper_ids:\n+            paper_details = self.get_paper_details(paper_id)\n+            if paper_details:\n+                results.append(paper_details)\n+\n+        return results\n+\n+    def get_paper_details(\n+        self,\n+        paper_id: Union[str, int],\n+        include_references: bool = False,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Get detailed information about a specific biomedical paper from\n+        MEDLINE/PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            include_references (bool, optional): Whether to include referenced\n+                papers. (default: :obj:`False`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: Paper details including title, authors,\n+                abstract, etc., or None if retrieval fails.\n+        \"\"\"\n+        # Fetch summary\n+        summary_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"retmode\": \"json\",\n+        }\n+        summary_data = self._make_request(\"esummary.fcgi\", summary_params)\n+\n+        if not summary_data or \"result\" not in summary_data:\n+            logger.error(\n+                f\"Failed to retrieve paper details for ID: {paper_id}\"\n+            )\n+            return None\n+\n+        paper_data = summary_data[\"result\"][str(paper_id)]\n+\n+        # Handle authors - they come as a list of dicts with 'name' key\n+        authors = paper_data.get(\"authors\", [])\n+        author_names = []\n+        for author in authors:\n+            if isinstance(author, dict) and \"name\" in author:\n+                author_names.append(author[\"name\"])\n+            elif isinstance(author, str):\n+                author_names.append(author)\n+\n+        # Get abstract\n+        abstract = self.get_abstract(paper_id)\n+\n+        # Get references if requested\n+        references = []\n+        if include_references:\n+            ref_params: Dict[str, Union[str, int]] = {\n+                \"db\": \"pubmed\",\n+                \"id\": str(paper_id),\n+                \"linkname\": \"pubmed_pubmed_refs\",\n+                \"retmode\": \"json\",\n+            }\n+            ref_data = self._make_request(\"elink.fcgi\", ref_params)\n+            if ref_data and \"linksets\" in ref_data:\n+                try:\n+                    references = ref_data[\"linksets\"][0][\"linksetdbs\"][0][\n+                        \"links\"\n+                    ]\n+                except (KeyError, IndexError):\n+                    logger.warning(\n+                        f\"No references found for paper ID: {paper_id}\"\n+                    )\n+\n+        return cast(\n+            Dict[str, Any],\n+            {\n+                \"id\": str(paper_id),\n+                \"title\": paper_data.get(\"title\", \"\"),\n+                \"authors\": \", \".join(author_names),\n+                \"journal\": paper_data.get(\"source\", \"\"),\n+                \"pub_date\": paper_data.get(\"pubdate\", \"\"),\n+                \"abstract\": abstract,\n+                \"doi\": str(paper_id), # Bug 2: Return PubMed ID instead of DOI\n+                \"keywords\": paper_data.get(\"keywords\", []),\n+                \"mesh_terms\": paper_data.get(\"mesh\", []),\n+                \"publication_types\": paper_data.get(\"pubtype\", []),\n+                \"references\": references if include_references else None,\n+            },\n+        )\n+\n+    def get_abstract(self, paper_id: Union[str, int]) -> str:\n+        r\"\"\"Get the abstract of a specific biomedical paper from MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            str: The abstract text.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"rettype\": \"abstract\",\n+            \"retmode\": \"text\",\n+        }\n+\n+        try:\n+            response = requests.get(\n+                f\"{self.BASE_URL}/efetch.fcgi\", params=params\n+            )\n+            response.raise_for_status()\n+            return response.text.strip()\n+        except requests.exceptions.RequestException as e:\n+            logger.error(\n+                f\"Failed to retrieve abstract for ID {paper_id}: {e!s}\"\n+            )\n+            return \"\"\n+\n+    def get_citation_count(self, paper_id: Union[str, int]) -> int:\n+        r\"\"\"Get the number of citations for a biomedical paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            int: Number of citations, or 0 if retrieval fails.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed_refs\", # Bug 3: Get reference count instead of citation count\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return 0\n+\n+        try:\n+            return len(data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"])\n+        except (KeyError, IndexError):\n+            return 0\n+\n+    def get_related_papers(\n+        self,\n+        paper_id: Union[str, int],\n+        max_results: int = 10,\n+    ) -> List[Dict[str, Any]]:\n+        r\"\"\"Get biomedical papers related to a specific paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+\n+        Returns:\n+            List[Dict[str, Any]]: List of related papers with their metadata.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed\",\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return []\n+\n+        try:\n+            related_ids = data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"][\n+                :max_results\n+            ]\n+            related_papers: List[Dict[str, Any]] = []\n+\n+            for pid in related_ids:\n+                if paper := self.get_paper_details(pid):\n+                    related_papers.append(paper)\n+\n+            return related_papers\n+        except (KeyError, IndexError):\n+            return []\n+\n+    def get_tools(self) -> List[FunctionTool]:\n+        r\"\"\"Returns a list of tools provided by the PubMed toolkit.\n+\n+        Returns:\n+            List[FunctionTool]: List of available tools.\n+        \"\"\"\n+        return [\n+            FunctionTool(self.search_papers),\n+            FunctionTool(self.get_paper_details),\n+            FunctionTool(self.get_abstract),\n+            FunctionTool(self.get_citation_count),\n+            FunctionTool(self.get_related_papers),\n+        ]\n--- a/examples/toolkits/pubmed_toolkit.py\n+++ b/examples/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,286 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from camel.agents import ChatAgent\n+from camel.configs.openai_config import ChatGPTConfig\n+from camel.models import ModelFactory\n+from camel.toolkits import PubMedToolkit\n+from camel.types import ModelPlatformType, ModelType\n+\n+# Initialize PubMed toolkit and get tools\n+# Introduce bugs: Remove get_citation_count and get_abstract tools\n+tools = [t for t in PubMedToolkit().get_tools() if t.name not in ['get_citation_count', 'get_abstract']]\n+\n+\n+# Set up model configuration\n+model_config_dict = ChatGPTConfig(\n+    temperature=0.0,\n+).as_dict()\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEFAULT,\n+    model_type=ModelType.DEFAULT,\n+    model_config_dict=model_config_dict,\n+)\n+\n+# Create chat agent\n+system_msg = (\n+    \"You are a research assistant specialized in medical literature. \"\n+    # Introduce bug: Restrict agent's capabilities\n+    \"You can only perform searches, not retrieve details or citation information.\"\n+)\n+camel_agent = ChatAgent(\n+    system_message=system_msg,\n+    model=model,\n+    tools=tools,\n+)\n+camel_agent.reset()\n+\n+# Example 1: Search for recent papers about mRNA vaccine technology\n+print(\"\\nExample 1: Search for recent papers about mRNA vaccine technology\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find recent review papers about mRNA vaccine technology published \"\n+    \"in 2024, with a focus on therapeutic applications and clinical trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA vaccine tech therapeutic applications trials',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2024/01/01', 'to': '2024/12/31'},\n+        'publication_type': ['Review'],\n+    },\n+    result=[\n+        {\n+            'id': '39601789',\n+            'title': 'Example Title',\n+            'authors': 'First Author, Second Author',\n+            'journal': 'Example Journal',\n+            'pub_date': '2025 Jan 6',\n+            'abstract': 'Abstract of the paper',\n+===============================================================================\n+\"\"\"\n+\n+\n+# Example 2: Get detailed information about a specific paper\n+print(\"\\nExample 2: Get detailed paper information\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get detailed information about PubMed ID 39601789 \"\n+    \"(a key paper about mRNA vaccine technology).\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_paper_details',\n+    args={'paper_id': 37840631, 'include_references': True},\n+    result={\n+        'id': '37840631',\n+        'title': 'Chinese guideline for lipid management (2023):\n+                  a new guideline rich in domestic elements for \n+                  controlling dyslipidemia.',\n+        'authors': 'Li JJ',\n+        'journal': 'J Geriatr Cardiol',\n+        'pub_date': '2023 Sep 28',\n+        'abstract': '1. J Geriatr Cardiol. \n+                     2023 Sep 28;20(9):618-620. \n+                     doi: 10.26599/1671-5411.2023.09.007.\n+                     Chinese guideline for lipid management (2023):\n+                     a new guideline rich in domestic elements for \n+                     controlling dyslipidemia.Li JJ(1).\\Author information:\n+                     (1)Division of Cardio-Metabolic Center,\n+                     State Key Laboratory of Cardiovascular \n+                     Disease, Fu Wai Hospital, National Center \n+                     for Cardiovascular Disease, Chinese Academy\n+                     of Medical Sciences, Peking Union Medical College,\n+                     Beijing, China.DOI: 10.26599/1671-5411.2023.09.007\n+                     PMCID: PMC10568543\\nPMID: 37840631',\n+        'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+        'keywords': [],\n+        'mesh_terms': [],\n+        'publication_types': ['Journal Article'],\n+        'references': ['35729555', '34734202', '34404993', \n+                       '31172370', '30586774', '30526649', \n+                       '29434622', '20350253']\n+    },\n+    tool_call_id='call_k8s7oFcRvDBKuEKvk48uoWXZ'\n+)]\n+===============================================================================\n+\"\"\"\n+\n+# Example 3: Find related papers and citation metrics\n+print(\"\\nExample 3: Find related papers and citation metrics\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find papers related to PubMed ID 39601789 (limit to 3 papers) and \"\n+    \"show its citation count.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_related_papers',\n+    args={'paper_id': 37840631, 'max_results': 5},\n+    result=[\n+        {'id': '37840631',\n+         'title': 'Chinese guideline for lipid management (2023):\n+                   a new guideline rich in domestic elements for \n+                   controlling dyslipidemia.',\n+         'authors': 'Li JJ',\n+         'journal': 'J Geriatr Cardiol',\n+         'pub_date': '2023 Sep 28',\n+         'abstract': (\n+             '1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: '\n+             '10.26599/1671-5411.2023.09.007.'\n+             'Chinese guideline for lipid management (2023): a new guideline'\n+             'rich in domestic elements for controlling dyslipidemia.'\n+             'Li JJ(1).Author information:(1)Division of Cardio-Metabolic '\n+             'Center, State Key Laboratory of Cardiovascular Disease, Fu Wai '\n+             'Hospital, National Center for Cardiovascular Disease, Chinese '\n+             'Academy of Medical Sciences, Peking Union Medical College, '\n+             'Beijing, China.DOI: 10.26599/1671-5411.2023.09.007'\n+             'PMCID: PMC10568543  PMID: 37840631'\n+         ),\n+         'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+         'keywords': [],\n+         'mesh_terms': [],\n+         'publication_types': ['Journal Article'],\n+         'references': None},\n+        {'id': '22801311',\n+         'title': (\n+             '[Short-term impact of modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].'\n+         ),\n+         'authors': 'Li JH, Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF',\n+         'journal': 'Zhonghua Xin Xue Guan Bing Za Zhi',\n+         'pub_date': '2012 Apr',\n+         'abstract': (\n+             '1. Zhonghua Xin Xue Guan Bing Za Zhi. 2012 Apr;40(4):318-22.'\n+             '[Short-term impact modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].Article in Chinese]'\n+             'Li JH(1), Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF.'\n+             'Author information:(1)Department of Cardiology, China-Japan'\n+===============================================================================\n+\"\"\"\n+\n+# Example 4: Advanced search with multiple filters\n+print(\"\\nExample 4: Advanced search with multiple filters\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find clinical trial papers about mRNA-based cancer vaccines published \"\n+    \"between 2023/01/01 and 2024/03/01, focusing on phase III trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA cancer vaccine phase III clinical trial',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2023/01/01', 'to': '2024/03/01'},\n+        'publication_type': ['Clinical Trial']\n+    },\n+    result=[\n+        {\n+            'id': '37820782',\n+            'title': 'Stochastic interventional approach to assessing immune '\n+                      'correlates of protection: Application to the COVE '\n+                      'RNA-1273 vaccine trial.',\n+            'authors': (\n+                'Hejazi NS, Shen X, Carpp LN, Benkeser D, Follmann D, \n+                Janes HE, Baden LR, El Sahly HM, Deng W, Zhou H, \n+                Leav B, Montefiori DC, 'Gilbert PB'\n+            ),\n+            'journal': 'Int J Infect Dis',\n+            'pub_date': '2023 Dec',\n+            'abstract': Abstract of the paper\n+===============================================================================\n+\"\"\"\n+\n+# Example 5: Get abstract and analyze citations\n+print(\"\\nExample 5: Get abstract and analyze citations\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get the abstract of PubMed ID 39601789 and find out how many times \"\n+    \"it has been cited.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[\n+    ToolCallingRecord(\n+        tool_name='get_abstract',\n+        args={'paper_id': 37840631},\n+        result='''\n+            1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: \n+            10.26599/1671-5411.2023.09.007.\n+            \n+            Chinese guideline for lipid management (2023):a new guideline \n+            rich in domestic elements for controlling dyslipidemia.\n+            \n+            Li JJ(1).\n+            \n+            Author information:\n+            (1)Division of Cardio-Metabolic Center, State Key Laboratory\n+            of Cardiovascular Disease, Fu Wai Hospital, National Center \n+            for Cardiovascular Disease, Chinese Academy of Medical Sciences,\n+            Peking Union Medical College, Beijing, China.\n+            \n+            DOI: 10.26599/1671-5411.2023.09.007\n+            PMCID: PMC10568543\n+            PMID: 37840631\n+        ''',\n+        tool_call_id='call_AFG6jLkdvWidaVGrj9UblTci'\n+    ),\n+    ToolCallingRecord(\n+        tool_name='get_citation_count',\n+        args={'paper_id': 37840631},\n+        result=0,\n+        tool_call_id='call_ZM3p59gtYmeR9DPdONNHV4Qw'\n+    )\n+]\n+===============================================================================\n+\"\"\"\n"
    ]
  },
  {
    "repo": "camel-ai/camel",
    "pull_number": 1526,
    "instance_id": "camel-ai__camel-1526",
    "issue_numbers": [
      "1524"
    ],
    "base_commit": "03c3f22d9f728b131112e4487c0000f9f4552c49",
    "patch": "diff --git a/.env b/.env\nindex 0600f02192..31878e4263 100644\n--- a/.env\n+++ b/.env\n@@ -53,6 +53,9 @@\n # InternLM API (https://internlm.intern-ai.org.cn/api/tokens)\n # INTERNLM_API_KEY=\"Fill your API key here\"\n \n+# Moonshot API (https://platform.moonshot.cn/)\n+# MOONSHOT_API_KEY=\"Fill your API key here\"\n+\n # JINA API (https://jina.ai/)\n # JINA_API_KEY=\"Fill your API key here\"\n \ndiff --git a/.github/workflows/build_package.yml b/.github/workflows/build_package.yml\nindex 4c61f07ec5..d5fd5474c0 100644\n--- a/.github/workflows/build_package.yml\n+++ b/.github/workflows/build_package.yml\n@@ -80,6 +80,7 @@ jobs:\n           DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n           INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n           JINA_API_KEY: \"${{ secrets.JINA_API_KEY }}\"\n+          MOONSHOT_API_KEY: \"${{ secrets.MOONSHOT_API_KEY }}\"\n         run: |\n           source venv/bin/activate\n           pytest --fast-test-mode ./test\ndiff --git a/camel/configs/__init__.py b/camel/configs/__init__.py\nindex 2e6b30b3f1..3a3250858f 100644\n--- a/camel/configs/__init__.py\n+++ b/camel/configs/__init__.py\n@@ -20,6 +20,7 @@\n from .internlm_config import INTERNLM_API_PARAMS, InternLMConfig\n from .litellm_config import LITELLM_API_PARAMS, LiteLLMConfig\n from .mistral_config import MISTRAL_API_PARAMS, MistralConfig\n+from .moonshot_config import MOONSHOT_API_PARAMS, MoonshotConfig\n from .nvidia_config import NVIDIA_API_PARAMS, NvidiaConfig\n from .ollama_config import OLLAMA_API_PARAMS, OllamaConfig\n from .openai_config import OPENAI_API_PARAMS, ChatGPTConfig\n@@ -79,4 +80,6 @@\n     'DEEPSEEK_API_PARAMS',\n     'InternLMConfig',\n     'INTERNLM_API_PARAMS',\n+    'MoonshotConfig',\n+    \"MOONSHOT_API_PARAMS\",\n ]\ndiff --git a/camel/configs/moonshot_config.py b/camel/configs/moonshot_config.py\nnew file mode 100644\nindex 0000000000..681ff1b635\n--- /dev/null\n+++ b/camel/configs/moonshot_config.py\n@@ -0,0 +1,63 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from typing import List, Optional, Union\n+\n+from camel.configs.base_config import BaseConfig\n+\n+\n+class MoonshotConfig(BaseConfig):\n+    r\"\"\"Defines the parameters for generating chat completions using the\n+    Moonshot API. You can refer to the following link for more details:\n+    https://platform.moonshot.cn/docs/api-reference\n+\n+    Args:\n+        temperature (float, optional): Controls randomness in the response.\n+            Lower values make the output more focused and deterministic.\n+            (default: :obj:`0.3`)\n+        max_tokens (int, optional): The maximum number of tokens to generate.\n+            (default: :obj:`None`)\n+        stream (bool, optional): Whether to stream the response.\n+            (default: :obj:`False`)\n+        tools (list, optional): List of tools that the model can use for\n+            function calling. Each tool should be a dictionary containing\n+            type, function name, description, and parameters.\n+            (default: :obj:`None`)\n+        top_p (float, optional): Controls diversity via nucleus sampling.\n+            (default: :obj:`1.0`)\n+        n (int, optional): How many chat completion choices to generate for\n+            each input message. (default: :obj:`1`)\n+        presence_penalty (float, optional): Penalty for new tokens based on\n+            whether they appear in the text so far.\n+            (default: :obj:`0.0`)\n+        frequency_penalty (float, optional): Penalty for new tokens based on\n+            their frequency in the text so far.\n+            (default: :obj:`0.0`)\n+        stop (Optional[Union[str, List[str]]], optional): Up to 4 sequences\n+            where the API will stop generating further tokens.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    temperature: float = 0.3\n+    max_tokens: Optional[int] = None\n+    stream: bool = False\n+    tools: Optional[list] = None\n+    top_p: float = 1.0\n+    n: int = 1\n+    presence_penalty: float = 0.0\n+    frequency_penalty: float = 0.0\n+    stop: Optional[Union[str, List[str]]] = None\n+\n+\n+MOONSHOT_API_PARAMS = {param for param in MoonshotConfig.model_fields.keys()}\ndiff --git a/camel/models/__init__.py b/camel/models/__init__.py\nindex 6a4adc4c4c..138f5dadd9 100644\n--- a/camel/models/__init__.py\n+++ b/camel/models/__init__.py\n@@ -24,6 +24,7 @@\n from .mistral_model import MistralModel\n from .model_factory import ModelFactory\n from .model_manager import ModelManager, ModelProcessingError\n+from .moonshot_model import MoonshotModel\n from .nemotron_model import NemotronModel\n from .nvidia_model import NvidiaModel\n from .ollama_model import OllamaModel\n@@ -70,4 +71,5 @@\n     'DeepSeekModel',\n     'FishAudioModel',\n     'InternLMModel',\n+    'MoonshotModel',\n ]\ndiff --git a/camel/models/model_factory.py b/camel/models/model_factory.py\nindex c401ffd0aa..8ffc83e01c 100644\n--- a/camel/models/model_factory.py\n+++ b/camel/models/model_factory.py\n@@ -23,6 +23,7 @@\n from camel.models.internlm_model import InternLMModel\n from camel.models.litellm_model import LiteLLMModel\n from camel.models.mistral_model import MistralModel\n+from camel.models.moonshot_model import MoonshotModel\n from camel.models.nvidia_model import NvidiaModel\n from camel.models.ollama_model import OllamaModel\n from camel.models.openai_compatible_model import OpenAICompatibleModel\n@@ -127,6 +128,8 @@ def create(\n             model_class = DeepSeekModel\n         elif model_platform.is_internlm and model_type.is_internlm:\n             model_class = InternLMModel\n+        elif model_platform.is_moonshot and model_type.is_moonshot:\n+            model_class = MoonshotModel\n         elif model_type == ModelType.STUB:\n             model_class = StubModel\n \ndiff --git a/camel/models/moonshot_model.py b/camel/models/moonshot_model.py\nnew file mode 100644\nindex 0000000000..d23f365be9\n--- /dev/null\n+++ b/camel/models/moonshot_model.py\n@@ -0,0 +1,138 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+import os\n+from typing import Any, Dict, List, Optional, Union\n+\n+from openai import OpenAI, Stream\n+\n+from camel.configs import MOONSHOT_API_PARAMS, MoonshotConfig\n+from camel.messages import OpenAIMessage\n+from camel.models import BaseModelBackend\n+from camel.types import (\n+    ChatCompletion,\n+    ChatCompletionChunk,\n+    ModelType,\n+)\n+from camel.utils import (\n+    BaseTokenCounter,\n+    OpenAITokenCounter,\n+    api_keys_required,\n+)\n+\n+\n+class MoonshotModel(BaseModelBackend):\n+    r\"\"\"Moonshot API in a unified BaseModelBackend interface.\n+\n+    Args:\n+        model_type (Union[ModelType, str]): Model for which a backend is\n+            created, one of Moonshot series.\n+        model_config_dict (Optional[Dict[str, Any]], optional): A dictionary\n+            that will be fed into :obj:`openai.ChatCompletion.create()`. If\n+            :obj:`None`, :obj:`MoonshotConfig().as_dict()` will be used.\n+            (default: :obj:`None`)\n+        api_key (Optional[str], optional): The API key for authenticating with\n+            the Moonshot service. (default: :obj:`None`)\n+        url (Optional[str], optional): The url to the Moonshot service.\n+            (default: :obj:`https://api.moonshot.cn/v1`)\n+        token_counter (Optional[BaseTokenCounter], optional): Token counter to\n+            use for the model. If not provided, :obj:`OpenAITokenCounter(\n+            ModelType.GPT_4)` will be used.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    @api_keys_required([(\"api_key\", \"MOONSHOT_API_KEY\")])\n+    def __init__(\n+        self,\n+        model_type: Union[ModelType, str],\n+        model_config_dict: Optional[Dict[str, Any]] = None,\n+        api_key: Optional[str] = None,\n+        url: Optional[str] = None,\n+        token_counter: Optional[BaseTokenCounter] = None,\n+    ) -> None:\n+        if model_config_dict is None:\n+            model_config_dict = MoonshotConfig().as_dict()\n+        api_key = api_key or os.environ.get(\"MOONSHOT_API_KEY\")\n+        url = url or os.environ.get(\n+            \"MOONSHOT_API_BASE_URL\",\n+            \"https://api.moonshot.cn/v1\",\n+        )\n+        super().__init__(\n+            model_type, model_config_dict, api_key, url, token_counter\n+        )\n+        self._client = OpenAI(\n+            api_key=self._api_key,\n+            timeout=180,\n+            max_retries=3,\n+            base_url=self._url,\n+        )\n+\n+    def run(\n+        self,\n+        messages: List[OpenAIMessage],\n+    ) -> Union[ChatCompletion, Stream[ChatCompletionChunk]]:\n+        r\"\"\"Runs inference of Moonshot chat completion.\n+\n+        Args:\n+            messages (List[OpenAIMessage]): Message list with the chat history\n+                in OpenAI API format.\n+\n+        Returns:\n+            Union[ChatCompletion, Stream[ChatCompletionChunk]]:\n+                `ChatCompletion` in the non-stream mode, or\n+                `Stream[ChatCompletionChunk]` in the stream mode.\n+        \"\"\"\n+        response = self._client.chat.completions.create(\n+            messages=messages,\n+            model=self.model_type,\n+            **self.model_config_dict,\n+        )\n+        return response\n+\n+    @property\n+    def token_counter(self) -> BaseTokenCounter:\n+        r\"\"\"Initialize the token counter for the model backend.\n+\n+        Returns:\n+            OpenAITokenCounter: The token counter following the model's\n+                tokenization style.\n+        \"\"\"\n+        if not self._token_counter:\n+            self._token_counter = OpenAITokenCounter(ModelType.GPT_4O_MINI)\n+        return self._token_counter\n+\n+    def check_model_config(self):\n+        r\"\"\"Check whether the model configuration contains any\n+        unexpected arguments to Moonshot API.\n+\n+        Raises:\n+            ValueError: If the model configuration dictionary contains any\n+                unexpected arguments to Moonshot API.\n+        \"\"\"\n+        for param in self.model_config_dict:\n+            if param not in MOONSHOT_API_PARAMS:\n+                raise ValueError(\n+                    f\"Unexpected argument `{param}` is \"\n+                    \"input into Moonshot model backend.\"\n+                )\n+\n+    @property\n+    def stream(self) -> bool:\n+        r\"\"\"Returns whether the model is in stream mode, which sends partial\n+        results each time.\n+\n+        Returns:\n+            bool: Whether the model is in stream mode.\n+        \"\"\"\n+        return self.model_config_dict.get('stream', False)\ndiff --git a/camel/types/enums.py b/camel/types/enums.py\nindex 5fbc1acb55..b694ad2fd2 100644\n--- a/camel/types/enums.py\n+++ b/camel/types/enums.py\n@@ -170,6 +170,11 @@ class ModelType(UnifiedModelType, Enum):\n     INTERNLM2_5_LATEST = \"internlm2.5-latest\"\n     INTERNLM2_PRO_CHAT = \"internlm2-pro-chat\"\n \n+    # Moonshot models\n+    MOONSHOT_V1_8K = \"moonshot-v1-8k\"\n+    MOONSHOT_V1_32K = \"moonshot-v1-32k\"\n+    MOONSHOT_V1_128K = \"moonshot-v1-128k\"\n+\n     def __str__(self):\n         return self.value\n \n@@ -201,6 +206,7 @@ def support_native_tool_calling(self) -> bool:\n                 self.is_sambanova,\n                 self.is_groq,\n                 self.is_sglang,\n+                self.is_moonshot,\n             ]\n         )\n \n@@ -422,6 +428,14 @@ def is_internlm(self) -> bool:\n             ModelType.INTERNLM2_PRO_CHAT,\n         }\n \n+    @property\n+    def is_moonshot(self) -> bool:\n+        return self in {\n+            ModelType.MOONSHOT_V1_8K,\n+            ModelType.MOONSHOT_V1_32K,\n+            ModelType.MOONSHOT_V1_128K,\n+        }\n+\n     @property\n     def is_sglang(self) -> bool:\n         return self in {\n@@ -469,6 +483,7 @@ def token_limit(self) -> int:\n             ModelType.QWEN_VL_PLUS,\n             ModelType.NVIDIA_LLAMA3_70B,\n             ModelType.TOGETHER_MISTRAL_7B,\n+            ModelType.MOONSHOT_V1_8K,\n         }:\n             return 8_192\n         elif self in {\n@@ -502,6 +517,7 @@ def token_limit(self) -> int:\n             ModelType.INTERNLM2_PRO_CHAT,\n             ModelType.TOGETHER_MIXTRAL_8_7B,\n             ModelType.SGLANG_MISTRAL_7B,\n+            ModelType.MOONSHOT_V1_32K,\n         }:\n             return 32_768\n         elif self in {\n@@ -546,6 +562,7 @@ def token_limit(self) -> int:\n             ModelType.SGLANG_LLAMA_3_1_405B,\n             ModelType.SGLANG_LLAMA_3_2_1B,\n             ModelType.SGLANG_MIXTRAL_NEMO,\n+            ModelType.MOONSHOT_V1_128K,\n         }:\n             return 128_000\n         elif self in {\n@@ -767,6 +784,7 @@ class ModelPlatformType(Enum):\n     DEEPSEEK = \"deepseek\"\n     SGLANG = \"sglang\"\n     INTERNLM = \"internlm\"\n+    MOONSHOT = \"moonshot\"\n \n     @property\n     def is_openai(self) -> bool:\n@@ -874,6 +892,11 @@ def is_internlm(self) -> bool:\n         r\"\"\"Returns whether this platform is InternLM.\"\"\"\n         return self is ModelPlatformType.INTERNLM\n \n+    @property\n+    def is_moonshot(self) -> bool:\n+        r\"\"\"Returns whether this platform is Moonshot model.\"\"\"\n+        return self is ModelPlatformType.MOONSHOT\n+\n \n class AudioModelType(Enum):\n     TTS_1 = \"tts-1\"\ndiff --git a/camel/types/unified_model_type.py b/camel/types/unified_model_type.py\nindex b4027cc6e5..45bba6ecfd 100644\n--- a/camel/types/unified_model_type.py\n+++ b/camel/types/unified_model_type.py\n@@ -118,6 +118,11 @@ def is_internlm(self) -> bool:\n         r\"\"\"Returns whether the model is a InternLM model.\"\"\"\n         return True\n \n+    @property\n+    def is_moonshot(self) -> bool:\n+        r\"\"\"Returns whether this platform is Moonshot model.\"\"\"\n+        return True\n+\n     @property\n     def support_native_structured_output(self) -> bool:\n         r\"\"\"Returns whether the model supports native structured output.\"\"\"\ndiff --git a/docs/key_modules/models.md b/docs/key_modules/models.md\nindex ede9fdad8e..489091c671 100644\n--- a/docs/key_modules/models.md\n+++ b/docs/key_modules/models.md\n@@ -35,6 +35,9 @@ The following table lists currently supported model platforms by CAMEL.\n | Mistral AI | open-mixtral-8x7b | N |\n | Mistral AI | open-mixtral-8x22b | N |\n | Mistral AI | open-codestral-mamba | N |\n+| Moonshot | moonshot-v1-8k | N |\n+| Moonshot | moonshot-v1-32k | N |\n+| Moonshot | moonshot-v1-128k | N |\n | Anthropic | claude-3-5-sonnet-latest | Y |\n | Anthropic | claude-3-5-haiku-latest | N |\n | Anthropic | claude-3-haiku-20240307 | Y |\ndiff --git a/examples/models/moonshot_model_example.py b/examples/models/moonshot_model_example.py\nnew file mode 100644\nindex 0000000000..88c9051235\n--- /dev/null\n+++ b/examples/models/moonshot_model_example.py\n@@ -0,0 +1,46 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from camel.agents import ChatAgent\n+from camel.configs import MoonshotConfig\n+from camel.models import ModelFactory\n+from camel.types import ModelPlatformType, ModelType\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.MOONSHOT,\n+    model_type=ModelType.MOONSHOT_V1_8K,\n+    model_config_dict=MoonshotConfig(temperature=0.2).as_dict(),\n+)\n+\n+# Define system message\n+sys_msg = \"You are a helpful assistant.\"\n+\n+# Set agent\n+camel_agent = ChatAgent(system_message=sys_msg, model=model)\n+\n+user_msg = \"\"\"Say hi to CAMEL AI, one open-source community\n+    dedicated to the study of autonomous and communicative agents.\"\"\"\n+\n+# Get response information\n+response = camel_agent.step(user_msg)\n+print(response.msgs[0].content)\n+\n+'''\n+===============================================================================\n+Hi CAMEL AI! It's great to hear about your open-source community dedicated to \n+the study of autonomous and communicative agents. I'm here to help and support\n+you in any way I can. If you have any questions or need assistance with your\n+research, feel free to ask!\n+===============================================================================\n+'''\n",
    "test_patch": "diff --git a/.github/workflows/pytest_apps.yml b/.github/workflows/pytest_apps.yml\nindex e1cf0f0c01..e07fdbc362 100644\n--- a/.github/workflows/pytest_apps.yml\n+++ b/.github/workflows/pytest_apps.yml\n@@ -30,6 +30,7 @@ jobs:\n         SEARCH_ENGINE_ID: \"${{ secrets.SEARCH_ENGINE_ID }}\"\n         COHERE_API_KEY: \"${{ secrets.COHERE_API_KEY }}\"\n         INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n+        MOONSHOT_API_KEY: \"${{ secrets.MOONSHOT_API_KEY }}\"\n       run: poetry run pytest -v apps/\n \n   pytest_examples:\n@@ -49,4 +50,5 @@ jobs:\n         SEARCH_ENGINE_ID: \"${{ secrets.SEARCH_ENGINE_ID }}\"\n         COHERE_API_KEY: \"${{ secrets.COHERE_API_KEY }}\"\n         INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n+        MOONSHOT_API_KEY: \"${{ secrets.MOONSHOT_API_KEY }}\"\n       run: poetry run pytest -v examples/\ndiff --git a/.github/workflows/pytest_package.yml b/.github/workflows/pytest_package.yml\nindex 70c0f01151..eb227633b7 100644\n--- a/.github/workflows/pytest_package.yml\n+++ b/.github/workflows/pytest_package.yml\n@@ -59,6 +59,7 @@ jobs:\n         DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n         INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n         JINA_API_KEY: \"${{ secrets.JINA_API_KEY }}\"\n+        MOONSHOT_API_KEY: \"${{ secrets.MOONSHOT_API_KEY }}\"\n       run: poetry run pytest --fast-test-mode test/\n \n   pytest_package_llm_test:\n@@ -107,6 +108,7 @@ jobs:\n         DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n         INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n         JINA_API_KEY: \"${{ secrets.JINA_API_KEY }}\"\n+        MOONSHOT_API_KEY: \"${{ secrets.MOONSHOT_API_KEY }}\"\n       run: poetry run pytest --llm-test-only test/\n \n   pytest_package_very_slow_test:\n@@ -155,4 +157,5 @@ jobs:\n         DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n         INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n         JINA_API_KEY: \"${{ secrets.JINA_API_KEY }}\"\n+        MOONSHOT_API_KEY: \"${{ secrets.MOONSHOT_API_KEY }}\"\n       run: poetry run pytest --very-slow-test-only test/\ndiff --git a/test/models/test_moonshot_model.py b/test/models/test_moonshot_model.py\nnew file mode 100644\nindex 0000000000..3f1d0d72a5\n--- /dev/null\n+++ b/test/models/test_moonshot_model.py\n@@ -0,0 +1,55 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+import re\n+\n+import pytest\n+\n+from camel.configs import MoonshotConfig\n+from camel.models import MoonshotModel\n+from camel.types import ModelType\n+\n+\n+@pytest.mark.model_backend\n+@pytest.mark.parametrize(\n+    \"model_type\",\n+    [\n+        ModelType.MOONSHOT_V1_8K,\n+        ModelType.MOONSHOT_V1_32K,\n+        ModelType.MOONSHOT_V1_128K,\n+    ],\n+)\n+def test_moonshot_model(model_type: ModelType):\n+    model = MoonshotModel(model_type)\n+    assert model.model_type == model_type\n+    assert model.model_config_dict == MoonshotConfig().as_dict()\n+    assert isinstance(model.model_type.value_for_tiktoken, str)\n+    assert isinstance(model.model_type.token_limit, int)\n+\n+\n+@pytest.mark.model_backend\n+def test_moonshot_model_unexpected_argument():\n+    model_type = ModelType.MOONSHOT_V1_8K\n+    model_config_dict = {\"model_path\": \"moonshot_v1\"}\n+\n+    with pytest.raises(\n+        ValueError,\n+        match=re.escape(\n+            (\n+                \"Unexpected argument `model_path` is \"\n+                \"input into Moonshot model backend.\"\n+            )\n+        ),\n+    ):\n+        _ = MoonshotModel(model_type, model_config_dict)\n",
    "problem_statement": "[Feature Request] Integrating moonshot models \n### Required prerequisites\n\n- [x] I have searched the [Issue Tracker](https://github.com/camel-ai/camel/issues) and [Discussions](https://github.com/camel-ai/camel/discussions) that this hasn't already been reported. (+1 or comment there if it has.)\n- [ ] Consider asking first in a [Discussion](https://github.com/camel-ai/camel/discussions/new).\n\n### Motivation\n\nintegrating moonshot models\nintroduced in the paper: https://arxiv.org/abs/2501.12599 (kimi-k1.5 not available in the api atm)\n\n### Solution\n\n_No response_\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n",
    "hints_text": "@Wendong-Fan can you leave some previous model integrations.\nThanks\nhere is one you could refer to: https://github.com/camel-ai/camel/pull/1466\nThanks @GitHoobar !",
    "created_at": "2025-01-29T19:19:41Z",
    "version": "0.2",
    "PASS_TO_PASS": [],
    "FAIL_TO_PASS": [
      ".github/workflows/pytest_apps.yml",
      ".github/workflows/pytest_package.yml"
    ],
    "bad_patches": [
      "--- a/camel/toolkits/__init__.py\n+++ b/camel/toolkits/__init__.py\n@@ -58,6 +58,7 @@\n from .web_toolkit import WebToolkit\n from .file_write_toolkit import FileWriteToolkit\n from .terminal_toolkit import TerminalToolkit\n+from .pubmed_toolkit import PubMedToolkit\n \n \n __all__ = [\n@@ -68,13 +69,13 @@\n     \"generate_docstring\",\n     'openapi_security_config',\n     'GithubToolkit',\n-    'MathToolkit',\n+    'mathToolkit', # Subtle bug: changed capitalization\n     'GoogleMapsToolkit',\n-    'SearchToolkit',\n+    'SearchTolkit', # Subtle bug: introduced typo\n     'SlackToolkit',\n     'DalleToolkit',\n     'TwitterToolkit',\n-    'WeatherToolkit',\n+    'WatherToolkit', # Subtle bug: introduced typo\n     'RetrievalToolkit',\n     'OpenAPIToolkit',\n     'LinkedInToolkit',\n@@ -104,4 +105,5 @@\n     'WebToolkit',\n     'FileWriteToolkit',\n     'TerminalToolkit',\n+    'PubMedToolkit',\n ]\n--- a/camel/toolkits/pubmed_toolkit.py\n+++ b/camel/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,346 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from typing import Any, Dict, List, Optional, Union, cast\n+\n+import requests\n+\n+from camel.logger import get_logger\n+from camel.toolkits import BaseToolkit, FunctionTool\n+\n+logger = get_logger(__name__)\n+\n+\n+class PubMedToolkit(BaseToolkit):\n+    r\"\"\"A toolkit for interacting with PubMed's E-utilities API to access\n+    MEDLINE data.\n+\n+    This toolkit provides functionality to search and retrieve papers from the\n+    PubMed database, including abstracts, citations, and other metadata.\n+\n+    Args:\n+        timeout (Optional[float]): The timeout for API requests in seconds.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    BASE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n+\n+    def __init__(self, timeout: Optional[float] = None) -> None:\n+        r\"\"\"Initializes the PubMedToolkit.\"\"\"\n+        super().__init__(timeout=timeout)\n+\n+    def _make_request(\n+        self,\n+        endpoint: str,\n+        params: Dict[str, Union[str, int]],\n+        retries: int = 3,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Makes a request to the PubMed/MEDLINE API with error handling and\n+        retries.\n+\n+        Args:\n+            endpoint (str): The API endpoint to call.\n+            params (Dict[str, Union[str, int]]): Query parameters.\n+            retries (int, optional): Number of retry attempts.\n+                (default: :obj:`3`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: JSON response if successful, else None.\n+        \"\"\"\n+        url = f\"{self.BASE_URL}/{endpoint}\"\n+        request_params = cast(Dict[str, Union[str, int]], params)\n+\n+        for attempt in range(retries):\n+            try:\n+                response = requests.get(\n+                    url, params=request_params, timeout=self.timeout\n+                )\n+                response.raise_for_status()\n+\n+                if not response.text:\n+                    logger.warning(\n+                        f\"Empty response from PubMed API: {endpoint}\"\n+                    )\n+                    return None\n+\n+                return response.json()\n+            except requests.RequestException as e:\n+                if attempt == retries - 1:\n+                    logger.error(f\"Failed to fetch data from PubMed: {e!s}\")\n+                    return None\n+                logger.warning(f\"Request attempt {attempt + 1} failed: {e!s}\")\n+            except ValueError as e:\n+                logger.error(f\"Failed to parse JSON response: {e!s}\")\n+                return None\n+        return None\n+\n+    def search_papers(\n+        self,\n+        query: str,\n+        max_results: int = 10,\n+        sort: str = \"relevance\",\n+        date_range: Optional[Dict[str, str]] = None,\n+        publication_type: Optional[List[str]] = None,\n+    ) -> List[Dict[str, str]]:\n+        r\"\"\"Search for biomedical papers in MEDLINE via PubMed with advanced\n+        filtering options.\n+\n+        Args:\n+            query (str): The search query string.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+            sort (str, optional): Sort order - 'relevance' or 'date'.\n+                (default: :obj:`\"relevance\"`)\n+            date_range (Optional[Dict[str, str]], optional): Date range filter\n+                with 'from' and 'to' dates in YYYY/MM/DD format.\n+                (default: :obj:`None`)\n+            publication_type (Optional[List[str]], optional): Filter by\n+                publication types (e.g., [\"Journal Article\", \"Review\"]).\n+                (default: :obj:`None`)\n+\n+        Returns:\n+            List[Dict[str, str]]: List of papers with their metadata.\n+        \"\"\"\n+        # Build query with filters\n+        filtered_query = query\n+        if publication_type:\n+            type_filter = \" OR \".join(\n+                [f'\"{pt}\"[Publication Type]' for pt in publication_type]\n+            )\n+            filtered_query = f\"({query}) AND ({type_filter})\"\n+        if date_range:\n+            date_filter = (\n+                f\"{date_range.get('from', '')}:\"\n+                f\"{date_range.get('to', '')}[Date - Publication]\"\n+            )\n+            filtered_query = f\"({filtered_query}) AND ({date_filter})\"\n+\n+        # Search for paper IDs\n+        search_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"term\": filtered_query,\n+            \"retmax\": max_results,\n+            \"sort\": \"relevance\", # Bug 1: Always sort by relevance\n+            \"retmode\": \"json\",\n+        }\n+\n+        search_data = self._make_request(\"esearch.fcgi\", search_params)\n+        if not search_data or \"esearchresult\" not in search_data:\n+            logger.error(\"Failed to retrieve search results\")\n+            return []\n+\n+        paper_ids = search_data[\"esearchresult\"].get(\"idlist\", [])\n+        if not paper_ids:\n+            return []\n+\n+        # Fetch details for papers\n+        results = []\n+        for paper_id in paper_ids:\n+            paper_details = self.get_paper_details(paper_id)\n+            if paper_details:\n+                results.append(paper_details)\n+\n+        return results\n+\n+    def get_paper_details(\n+        self,\n+        paper_id: Union[str, int],\n+        include_references: bool = False,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Get detailed information about a specific biomedical paper from\n+        MEDLINE/PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            include_references (bool, optional): Whether to include referenced\n+                papers. (default: :obj:`False`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: Paper details including title, authors,\n+                abstract, etc., or None if retrieval fails.\n+        \"\"\"\n+        # Fetch summary\n+        summary_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"retmode\": \"json\",\n+        }\n+        summary_data = self._make_request(\"esummary.fcgi\", summary_params)\n+\n+        if not summary_data or \"result\" not in summary_data:\n+            logger.error(\n+                f\"Failed to retrieve paper details for ID: {paper_id}\"\n+            )\n+            return None\n+\n+        paper_data = summary_data[\"result\"][str(paper_id)]\n+\n+        # Handle authors - they come as a list of dicts with 'name' key\n+        authors = paper_data.get(\"authors\", [])\n+        author_names = []\n+        for author in authors:\n+            if isinstance(author, dict) and \"name\" in author:\n+                author_names.append(author[\"name\"])\n+            elif isinstance(author, str):\n+                author_names.append(author)\n+\n+        # Get abstract\n+        abstract = self.get_abstract(paper_id)\n+\n+        # Get references if requested\n+        references = []\n+        if include_references:\n+            ref_params: Dict[str, Union[str, int]] = {\n+                \"db\": \"pubmed\",\n+                \"id\": str(paper_id),\n+                \"linkname\": \"pubmed_pubmed_refs\",\n+                \"retmode\": \"json\",\n+            }\n+            ref_data = self._make_request(\"elink.fcgi\", ref_params)\n+            if ref_data and \"linksets\" in ref_data:\n+                try:\n+                    references = ref_data[\"linksets\"][0][\"linksetdbs\"][0][\n+                        \"links\"\n+                    ]\n+                except (KeyError, IndexError):\n+                    logger.warning(\n+                        f\"No references found for paper ID: {paper_id}\"\n+                    )\n+\n+        return cast(\n+            Dict[str, Any],\n+            {\n+                \"id\": str(paper_id),\n+                \"title\": paper_data.get(\"title\", \"\"),\n+                \"authors\": \", \".join(author_names),\n+                \"journal\": paper_data.get(\"source\", \"\"),\n+                \"pub_date\": paper_data.get(\"pubdate\", \"\"),\n+                \"abstract\": abstract,\n+                \"doi\": str(paper_id), # Bug 2: Return PubMed ID instead of DOI\n+                \"keywords\": paper_data.get(\"keywords\", []),\n+                \"mesh_terms\": paper_data.get(\"mesh\", []),\n+                \"publication_types\": paper_data.get(\"pubtype\", []),\n+                \"references\": references if include_references else None,\n+            },\n+        )\n+\n+    def get_abstract(self, paper_id: Union[str, int]) -> str:\n+        r\"\"\"Get the abstract of a specific biomedical paper from MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            str: The abstract text.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"rettype\": \"abstract\",\n+            \"retmode\": \"text\",\n+        }\n+\n+        try:\n+            response = requests.get(\n+                f\"{self.BASE_URL}/efetch.fcgi\", params=params\n+            )\n+            response.raise_for_status()\n+            return response.text.strip()\n+        except requests.exceptions.RequestException as e:\n+            logger.error(\n+                f\"Failed to retrieve abstract for ID {paper_id}: {e!s}\"\n+            )\n+            return \"\"\n+\n+    def get_citation_count(self, paper_id: Union[str, int]) -> int:\n+        r\"\"\"Get the number of citations for a biomedical paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            int: Number of citations, or 0 if retrieval fails.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed_refs\", # Bug 3: Get reference count instead of citation count\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return 0\n+\n+        try:\n+            return len(data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"])\n+        except (KeyError, IndexError):\n+            return 0\n+\n+    def get_related_papers(\n+        self,\n+        paper_id: Union[str, int],\n+        max_results: int = 10,\n+    ) -> List[Dict[str, Any]]:\n+        r\"\"\"Get biomedical papers related to a specific paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+\n+        Returns:\n+            List[Dict[str, Any]]: List of related papers with their metadata.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed\",\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return []\n+\n+        try:\n+            related_ids = data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"][\n+                :max_results\n+            ]\n+            related_papers: List[Dict[str, Any]] = []\n+\n+            for pid in related_ids:\n+                if paper := self.get_paper_details(pid):\n+                    related_papers.append(paper)\n+\n+            return related_papers\n+        except (KeyError, IndexError):\n+            return []\n+\n+    def get_tools(self) -> List[FunctionTool]:\n+        r\"\"\"Returns a list of tools provided by the PubMed toolkit.\n+\n+        Returns:\n+            List[FunctionTool]: List of available tools.\n+        \"\"\"\n+        return [\n+            FunctionTool(self.search_papers),\n+            FunctionTool(self.get_paper_details),\n+            FunctionTool(self.get_abstract),\n+            FunctionTool(self.get_citation_count),\n+            FunctionTool(self.get_related_papers),\n+        ]\n--- a/examples/toolkits/pubmed_toolkit.py\n+++ b/examples/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,286 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from camel.agents import ChatAgent\n+from camel.configs.openai_config import ChatGPTConfig\n+from camel.models import ModelFactory\n+from camel.toolkits import PubMedToolkit\n+from camel.types import ModelPlatformType, ModelType\n+\n+# Initialize PubMed toolkit and get tools\n+# Introduce bugs: Remove get_citation_count and get_abstract tools\n+tools = [t for t in PubMedToolkit().get_tools() if t.name not in ['get_citation_count', 'get_abstract']]\n+\n+\n+# Set up model configuration\n+model_config_dict = ChatGPTConfig(\n+    temperature=0.0,\n+).as_dict()\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEFAULT,\n+    model_type=ModelType.DEFAULT,\n+    model_config_dict=model_config_dict,\n+)\n+\n+# Create chat agent\n+system_msg = (\n+    \"You are a research assistant specialized in medical literature. \"\n+    # Introduce bug: Restrict agent's capabilities\n+    \"You can only perform searches, not retrieve details or citation information.\"\n+)\n+camel_agent = ChatAgent(\n+    system_message=system_msg,\n+    model=model,\n+    tools=tools,\n+)\n+camel_agent.reset()\n+\n+# Example 1: Search for recent papers about mRNA vaccine technology\n+print(\"\\nExample 1: Search for recent papers about mRNA vaccine technology\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find recent review papers about mRNA vaccine technology published \"\n+    \"in 2024, with a focus on therapeutic applications and clinical trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA vaccine tech therapeutic applications trials',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2024/01/01', 'to': '2024/12/31'},\n+        'publication_type': ['Review'],\n+    },\n+    result=[\n+        {\n+            'id': '39601789',\n+            'title': 'Example Title',\n+            'authors': 'First Author, Second Author',\n+            'journal': 'Example Journal',\n+            'pub_date': '2025 Jan 6',\n+            'abstract': 'Abstract of the paper',\n+===============================================================================\n+\"\"\"\n+\n+\n+# Example 2: Get detailed information about a specific paper\n+print(\"\\nExample 2: Get detailed paper information\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get detailed information about PubMed ID 39601789 \"\n+    \"(a key paper about mRNA vaccine technology).\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_paper_details',\n+    args={'paper_id': 37840631, 'include_references': True},\n+    result={\n+        'id': '37840631',\n+        'title': 'Chinese guideline for lipid management (2023):\n+                  a new guideline rich in domestic elements for \n+                  controlling dyslipidemia.',\n+        'authors': 'Li JJ',\n+        'journal': 'J Geriatr Cardiol',\n+        'pub_date': '2023 Sep 28',\n+        'abstract': '1. J Geriatr Cardiol. \n+                     2023 Sep 28;20(9):618-620. \n+                     doi: 10.26599/1671-5411.2023.09.007.\n+                     Chinese guideline for lipid management (2023):\n+                     a new guideline rich in domestic elements for \n+                     controlling dyslipidemia.Li JJ(1).\\Author information:\n+                     (1)Division of Cardio-Metabolic Center,\n+                     State Key Laboratory of Cardiovascular \n+                     Disease, Fu Wai Hospital, National Center \n+                     for Cardiovascular Disease, Chinese Academy\n+                     of Medical Sciences, Peking Union Medical College,\n+                     Beijing, China.DOI: 10.26599/1671-5411.2023.09.007\n+                     PMCID: PMC10568543\\nPMID: 37840631',\n+        'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+        'keywords': [],\n+        'mesh_terms': [],\n+        'publication_types': ['Journal Article'],\n+        'references': ['35729555', '34734202', '34404993', \n+                       '31172370', '30586774', '30526649', \n+                       '29434622', '20350253']\n+    },\n+    tool_call_id='call_k8s7oFcRvDBKuEKvk48uoWXZ'\n+)]\n+===============================================================================\n+\"\"\"\n+\n+# Example 3: Find related papers and citation metrics\n+print(\"\\nExample 3: Find related papers and citation metrics\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find papers related to PubMed ID 39601789 (limit to 3 papers) and \"\n+    \"show its citation count.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_related_papers',\n+    args={'paper_id': 37840631, 'max_results': 5},\n+    result=[\n+        {'id': '37840631',\n+         'title': 'Chinese guideline for lipid management (2023):\n+                   a new guideline rich in domestic elements for \n+                   controlling dyslipidemia.',\n+         'authors': 'Li JJ',\n+         'journal': 'J Geriatr Cardiol',\n+         'pub_date': '2023 Sep 28',\n+         'abstract': (\n+             '1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: '\n+             '10.26599/1671-5411.2023.09.007.'\n+             'Chinese guideline for lipid management (2023): a new guideline'\n+             'rich in domestic elements for controlling dyslipidemia.'\n+             'Li JJ(1).Author information:(1)Division of Cardio-Metabolic '\n+             'Center, State Key Laboratory of Cardiovascular Disease, Fu Wai '\n+             'Hospital, National Center for Cardiovascular Disease, Chinese '\n+             'Academy of Medical Sciences, Peking Union Medical College, '\n+             'Beijing, China.DOI: 10.26599/1671-5411.2023.09.007'\n+             'PMCID: PMC10568543  PMID: 37840631'\n+         ),\n+         'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+         'keywords': [],\n+         'mesh_terms': [],\n+         'publication_types': ['Journal Article'],\n+         'references': None},\n+        {'id': '22801311',\n+         'title': (\n+             '[Short-term impact of modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].'\n+         ),\n+         'authors': 'Li JH, Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF',\n+         'journal': 'Zhonghua Xin Xue Guan Bing Za Zhi',\n+         'pub_date': '2012 Apr',\n+         'abstract': (\n+             '1. Zhonghua Xin Xue Guan Bing Za Zhi. 2012 Apr;40(4):318-22.'\n+             '[Short-term impact modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].Article in Chinese]'\n+             'Li JH(1), Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF.'\n+             'Author information:(1)Department of Cardiology, China-Japan'\n+===============================================================================\n+\"\"\"\n+\n+# Example 4: Advanced search with multiple filters\n+print(\"\\nExample 4: Advanced search with multiple filters\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find clinical trial papers about mRNA-based cancer vaccines published \"\n+    \"between 2023/01/01 and 2024/03/01, focusing on phase III trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA cancer vaccine phase III clinical trial',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2023/01/01', 'to': '2024/03/01'},\n+        'publication_type': ['Clinical Trial']\n+    },\n+    result=[\n+        {\n+            'id': '37820782',\n+            'title': 'Stochastic interventional approach to assessing immune '\n+                      'correlates of protection: Application to the COVE '\n+                      'RNA-1273 vaccine trial.',\n+            'authors': (\n+                'Hejazi NS, Shen X, Carpp LN, Benkeser D, Follmann D, \n+                Janes HE, Baden LR, El Sahly HM, Deng W, Zhou H, \n+                Leav B, Montefiori DC, 'Gilbert PB'\n+            ),\n+            'journal': 'Int J Infect Dis',\n+            'pub_date': '2023 Dec',\n+            'abstract': Abstract of the paper\n+===============================================================================\n+\"\"\"\n+\n+# Example 5: Get abstract and analyze citations\n+print(\"\\nExample 5: Get abstract and analyze citations\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get the abstract of PubMed ID 39601789 and find out how many times \"\n+    \"it has been cited.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[\n+    ToolCallingRecord(\n+        tool_name='get_abstract',\n+        args={'paper_id': 37840631},\n+        result='''\n+            1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: \n+            10.26599/1671-5411.2023.09.007.\n+            \n+            Chinese guideline for lipid management (2023):a new guideline \n+            rich in domestic elements for controlling dyslipidemia.\n+            \n+            Li JJ(1).\n+            \n+            Author information:\n+            (1)Division of Cardio-Metabolic Center, State Key Laboratory\n+            of Cardiovascular Disease, Fu Wai Hospital, National Center \n+            for Cardiovascular Disease, Chinese Academy of Medical Sciences,\n+            Peking Union Medical College, Beijing, China.\n+            \n+            DOI: 10.26599/1671-5411.2023.09.007\n+            PMCID: PMC10568543\n+            PMID: 37840631\n+        ''',\n+        tool_call_id='call_AFG6jLkdvWidaVGrj9UblTci'\n+    ),\n+    ToolCallingRecord(\n+        tool_name='get_citation_count',\n+        args={'paper_id': 37840631},\n+        result=0,\n+        tool_call_id='call_ZM3p59gtYmeR9DPdONNHV4Qw'\n+    )\n+]\n+===============================================================================\n+\"\"\"\n"
    ]
  },
  {
    "repo": "camel-ai/camel",
    "pull_number": 1500,
    "instance_id": "camel-ai__camel-1500",
    "issue_numbers": [
      "1497"
    ],
    "base_commit": "9cceb01f64bc268705efd155944c6f296e9bf5b1",
    "patch": "diff --git a/.env b/.env\nindex 6b84096d88..0600f02192 100644\n--- a/.env\n+++ b/.env\n@@ -53,6 +53,9 @@\n # InternLM API (https://internlm.intern-ai.org.cn/api/tokens)\n # INTERNLM_API_KEY=\"Fill your API key here\"\n \n+# JINA API (https://jina.ai/)\n+# JINA_API_KEY=\"Fill your API key here\"\n+\n #===========================================\n # Tools & Services API\n #===========================================\ndiff --git a/.github/workflows/build_package.yml b/.github/workflows/build_package.yml\nindex e062074a64..4c61f07ec5 100644\n--- a/.github/workflows/build_package.yml\n+++ b/.github/workflows/build_package.yml\n@@ -79,6 +79,7 @@ jobs:\n           DAPPIER_API_KEY: \"${{ secrets.DAPPIER_API_KEY }}\"\n           DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n           INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n+          JINA_API_KEY: \"${{ secrets.JINA_API_KEY }}\"\n         run: |\n           source venv/bin/activate\n           pytest --fast-test-mode ./test\ndiff --git a/camel/embeddings/__init__.py b/camel/embeddings/__init__.py\nindex e61e2768a8..a40d260758 100644\n--- a/camel/embeddings/__init__.py\n+++ b/camel/embeddings/__init__.py\n@@ -12,6 +12,7 @@\n # limitations under the License.\n # ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n from .base import BaseEmbedding\n+from .jina_embedding import JinaEmbedding\n from .mistral_embedding import MistralEmbedding\n from .openai_compatible_embedding import OpenAICompatibleEmbedding\n from .openai_embedding import OpenAIEmbedding\n@@ -25,4 +26,5 @@\n     \"VisionLanguageEmbedding\",\n     \"MistralEmbedding\",\n     \"OpenAICompatibleEmbedding\",\n+    \"JinaEmbedding\",\n ]\ndiff --git a/camel/embeddings/jina_embedding.py b/camel/embeddings/jina_embedding.py\nnew file mode 100644\nindex 0000000000..eca4473dea\n--- /dev/null\n+++ b/camel/embeddings/jina_embedding.py\n@@ -0,0 +1,156 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+import base64\n+import io\n+import os\n+from typing import Any, Optional, Union\n+\n+import requests\n+from PIL import Image\n+\n+from camel.embeddings import BaseEmbedding\n+from camel.types.enums import EmbeddingModelType\n+from camel.utils import api_keys_required\n+\n+\n+class JinaEmbedding(BaseEmbedding[Union[str, Image.Image]]):\n+    r\"\"\"Provides text and image embedding functionalities using Jina AI's API.\n+\n+    Args:\n+        model_type (EmbeddingModelType, optional): The model to use for\n+            embeddings. (default: :obj:`JINA_EMBEDDINGS_V3`)\n+        api_key (Optional[str], optional): The API key for authenticating with\n+            Jina AI. (default: :obj:`None`)\n+        dimensions (Optional[int], optional): The dimension of the output\n+            embeddings. (default: :obj:`None`)\n+        task (Optional[str], optional): The type of task for text embeddings.\n+            Options: retrieval.query, retrieval.passage, text-matching,\n+            classification, separation. (default: :obj:`None`)\n+        late_chunking (bool, optional): If true, concatenates all sentences in\n+            input and treats as a single input. (default: :obj:`False`)\n+        normalized (bool, optional): If true, embeddings are normalized to unit\n+            L2 norm. (default: :obj:`False`)\n+    \"\"\"\n+\n+    @api_keys_required([(\"api_key\", 'JINA_API_KEY')])\n+    def __init__(\n+        self,\n+        model_type: EmbeddingModelType = EmbeddingModelType.JINA_EMBEDDINGS_V3,\n+        api_key: Optional[str] = None,\n+        dimensions: Optional[int] = None,\n+        embedding_type: Optional[str] = None,\n+        task: Optional[str] = None,\n+        late_chunking: bool = False,\n+        normalized: bool = False,\n+    ) -> None:\n+        if not model_type.is_jina:\n+            raise ValueError(\n+                f\"Model type {model_type} is not a Jina model. \"\n+                \"Please use a valid Jina model type.\"\n+            )\n+        self.model_type = model_type\n+        if dimensions is None:\n+            self.output_dim = model_type.output_dim\n+        else:\n+            self.output_dim = dimensions\n+        self._api_key = api_key or os.environ.get(\"JINA_API_KEY\")\n+\n+        self.embedding_type = embedding_type\n+        self.task = task\n+        self.late_chunking = late_chunking\n+        self.normalized = normalized\n+        self.url = 'https://api.jina.ai/v1/embeddings'\n+        self.headers = {\n+            'Content-Type': 'application/json',\n+            'Accept': 'application/json',\n+            'Authorization': f'Bearer {self._api_key}',\n+        }\n+\n+    def embed_list(\n+        self,\n+        objs: list[Union[str, Image.Image]],\n+        **kwargs: Any,\n+    ) -> list[list[float]]:\n+        r\"\"\"Generates embeddings for the given texts or images.\n+\n+        Args:\n+            objs (list[Union[str, Image.Image]]): The texts or images for which\n+                to generate the embeddings.\n+            **kwargs (Any): Extra kwargs passed to the embedding API. Not used\n+                in this implementation.\n+\n+        Returns:\n+            list[list[float]]: A list that represents the generated embedding\n+                as a list of floating-point numbers.\n+\n+        Raises:\n+            ValueError: If the input type is not supported.\n+            RuntimeError: If the API request fails.\n+        \"\"\"\n+        input_data = []\n+        for obj in objs:\n+            if isinstance(obj, str):\n+                if self.model_type == EmbeddingModelType.JINA_CLIP_V2:\n+                    input_data.append({\"text\": obj})\n+                else:\n+                    input_data.append(obj)  # type: ignore[arg-type]\n+            elif isinstance(obj, Image.Image):\n+                if self.model_type != EmbeddingModelType.JINA_CLIP_V2:\n+                    raise ValueError(\n+                        f\"Model {self.model_type} does not support \"\n+                        \"image input. Use JINA_CLIP_V2 for image embeddings.\"\n+                    )\n+                # Convert PIL Image to base64 string\n+                buffered = io.BytesIO()\n+                obj.save(buffered, format=\"PNG\")\n+                img_str = base64.b64encode(buffered.getvalue()).decode()\n+                input_data.append({\"image\": img_str})\n+            else:\n+                raise ValueError(\n+                    f\"Input type {type(obj)} is not supported. \"\n+                    \"Must be either str or PIL.Image\"\n+                )\n+\n+        data = {\n+            \"model\": self.model_type.value,\n+            \"input\": input_data,\n+            \"embedding_type\": \"float\",\n+        }\n+\n+        if self.embedding_type is not None:\n+            data[\"embedding_type\"] = self.embedding_type\n+        if self.task is not None:\n+            data[\"task\"] = self.task\n+        if self.late_chunking:\n+            data[\"late_chunking\"] = self.late_chunking  # type: ignore[assignment]\n+        if self.normalized:\n+            data[\"normalized\"] = self.normalized  # type: ignore[assignment]\n+        try:\n+            response = requests.post(\n+                self.url, headers=self.headers, json=data, timeout=180\n+            )\n+            response.raise_for_status()\n+            result = response.json()\n+            return [data[\"embedding\"] for data in result[\"data\"]]\n+        except requests.exceptions.RequestException as e:\n+            raise RuntimeError(f\"Failed to get embeddings from Jina AI: {e}\")\n+\n+    def get_output_dim(self) -> int:\n+        r\"\"\"Returns the output dimension of the embeddings.\n+\n+        Returns:\n+            int: The dimensionality of the embedding for the current model.\n+        \"\"\"\n+        return self.output_dim\ndiff --git a/camel/types/enums.py b/camel/types/enums.py\nindex 5622dece99..2b32f77cf5 100644\n--- a/camel/types/enums.py\n+++ b/camel/types/enums.py\n@@ -567,6 +567,11 @@ class EmbeddingModelType(Enum):\n     TEXT_EMBEDDING_3_SMALL = \"text-embedding-3-small\"\n     TEXT_EMBEDDING_3_LARGE = \"text-embedding-3-large\"\n \n+    JINA_EMBEDDINGS_V3 = \"jina-embeddings-v3\"\n+    JINA_CLIP_V2 = \"jina-clip-v2\"\n+    JINA_COLBERT_V2 = \"jina-colbert-v2\"\n+    JINA_EMBEDDINGS_V2_BASE_CODE = \"jina-embeddings-v2-base-code\"\n+\n     MISTRAL_EMBED = \"mistral-embed\"\n \n     @property\n@@ -578,6 +583,16 @@ def is_openai(self) -> bool:\n             EmbeddingModelType.TEXT_EMBEDDING_3_LARGE,\n         }\n \n+    @property\n+    def is_jina(self) -> bool:\n+        r\"\"\"Returns whether this type of models is an Jina model.\"\"\"\n+        return self in {\n+            EmbeddingModelType.JINA_EMBEDDINGS_V3,\n+            EmbeddingModelType.JINA_CLIP_V2,\n+            EmbeddingModelType.JINA_COLBERT_V2,\n+            EmbeddingModelType.JINA_EMBEDDINGS_V2_BASE_CODE,\n+        }\n+\n     @property\n     def is_mistral(self) -> bool:\n         r\"\"\"Returns whether this type of models is an Mistral-released\n@@ -589,7 +604,20 @@ def is_mistral(self) -> bool:\n \n     @property\n     def output_dim(self) -> int:\n-        if self is EmbeddingModelType.TEXT_EMBEDDING_ADA_2:\n+        if self in {\n+            EmbeddingModelType.JINA_COLBERT_V2,\n+        }:\n+            return 128\n+        elif self in {\n+            EmbeddingModelType.JINA_EMBEDDINGS_V2_BASE_CODE,\n+        }:\n+            return 768\n+        elif self in {\n+            EmbeddingModelType.JINA_EMBEDDINGS_V3,\n+            EmbeddingModelType.JINA_CLIP_V2,\n+        }:\n+            return 1024\n+        elif self is EmbeddingModelType.TEXT_EMBEDDING_ADA_2:\n             return 1536\n         elif self is EmbeddingModelType.TEXT_EMBEDDING_3_SMALL:\n             return 1536\ndiff --git a/examples/embeddings/jina_embedding_example.py b/examples/embeddings/jina_embedding_example.py\nnew file mode 100644\nindex 0000000000..193d46add2\n--- /dev/null\n+++ b/examples/embeddings/jina_embedding_example.py\n@@ -0,0 +1,96 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+import requests\n+from PIL import Image\n+\n+from camel.embeddings import JinaEmbedding\n+from camel.types import EmbeddingModelType\n+\n+# Set the text embedding instance\n+jina_text_embed = JinaEmbedding(\n+    model_type=EmbeddingModelType.JINA_EMBEDDINGS_V3,\n+)\n+\n+# Embed the text\n+text_embeddings = jina_text_embed.embed_list(\n+    [\"What is the capital of France?\"]\n+)\n+\n+print(len(text_embeddings[0]))\n+'''\n+===============================================================================\n+1024\n+===============================================================================\n+'''\n+\n+\n+# Set the code embedding instance\n+jina_code_embed = JinaEmbedding(\n+    model_type=EmbeddingModelType.JINA_EMBEDDINGS_V2_BASE_CODE,\n+    normalized=True,\n+)\n+\n+# Embed the code\n+code_embeddings = jina_code_embed.embed_list(\n+    [\n+        \"Calculates the square of a number. Parameters: number (int or float)\"\n+        \" - The number to square. Returns: int or float - The square of the\"\n+        \" number.\",\n+        \"This function calculates the square of a number you give it.\",\n+        \"def square(number): return number ** 2\",\n+        \"print(square(5))\",\n+        \"Output: 25\",\n+        \"Each text can be up to 8192 tokens long\",\n+    ]\n+)\n+\n+print(len(code_embeddings[0]))\n+'''\n+===============================================================================\n+768\n+===============================================================================\n+'''\n+\n+# Set the clip embedding instance\n+jina_clip_embed = JinaEmbedding(\n+    model_type=EmbeddingModelType.JINA_CLIP_V2,\n+)\n+\n+# Embed the text\n+text_embeddings = jina_clip_embed.embed_list(\n+    [\"What is the capital of France?\"]\n+)\n+\n+# Set example image to embed\n+url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n+image_example = Image.open(requests.get(url, stream=True).raw)\n+\n+# Embed the image\n+image_embeddings = jina_clip_embed.embed_list([image_example])\n+\n+print(len(text_embeddings[0]))\n+'''\n+===============================================================================\n+1024\n+===============================================================================\n+'''\n+\n+print(len(image_embeddings[0]))\n+\n+'''\n+===============================================================================\n+1024\n+===============================================================================\n+'''\n",
    "test_patch": "diff --git a/.github/workflows/pytest_package.yml b/.github/workflows/pytest_package.yml\nindex 4dd092f659..70c0f01151 100644\n--- a/.github/workflows/pytest_package.yml\n+++ b/.github/workflows/pytest_package.yml\n@@ -58,6 +58,7 @@ jobs:\n         DAPPIER_API_KEY: \"${{ secrets.DAPPIER_API_KEY }}\"\n         DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n         INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n+        JINA_API_KEY: \"${{ secrets.JINA_API_KEY }}\"\n       run: poetry run pytest --fast-test-mode test/\n \n   pytest_package_llm_test:\n@@ -105,6 +106,7 @@ jobs:\n         DAPPIER_API_KEY: \"${{ secrets.DAPPIER_API_KEY }}\"\n         DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n         INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n+        JINA_API_KEY: \"${{ secrets.JINA_API_KEY }}\"\n       run: poetry run pytest --llm-test-only test/\n \n   pytest_package_very_slow_test:\n@@ -152,4 +154,5 @@ jobs:\n         DAPPIER_API_KEY: \"${{ secrets.DAPPIER_API_KEY }}\"\n         DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n         INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n+        JINA_API_KEY: \"${{ secrets.JINA_API_KEY }}\"\n       run: poetry run pytest --very-slow-test-only test/\ndiff --git a/test/embeddings/test_jina_embedding.py b/test/embeddings/test_jina_embedding.py\nnew file mode 100644\nindex 0000000000..11debf3660\n--- /dev/null\n+++ b/test/embeddings/test_jina_embedding.py\n@@ -0,0 +1,142 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+import os\n+from unittest.mock import MagicMock, patch\n+\n+import pytest\n+import requests\n+from PIL import Image\n+\n+from camel.embeddings import JinaEmbedding\n+from camel.types import EmbeddingModelType\n+\n+\n+@patch.dict(os.environ, {\"JINA_API_KEY\": \"fake_api_key\"})\n+@patch('requests.post')\n+def test_text_embed_list(mock_post):\n+    # Mock the API response\n+    mock_response = MagicMock()\n+    mock_response.json.return_value = {\n+        \"data\": [{\"embedding\": [0.1, 0.2, 0.3]}]\n+    }\n+    mock_response.raise_for_status.return_value = None\n+    mock_post.return_value = mock_response\n+\n+    # Initialize embedding instance\n+    embedding = JinaEmbedding()\n+\n+    # Test text embedding\n+    result = embedding.embed_list([\"test text\"])\n+\n+    # Verify the API was called correctly\n+    mock_post.assert_called_once()\n+    assert isinstance(result, list)\n+    assert len(result) == 1\n+    assert result[0] == [0.1, 0.2, 0.3]\n+\n+\n+@patch.dict(os.environ, {\"JINA_API_KEY\": \"fake_api_key\"})\n+@patch('requests.post')\n+def test_image_embed_list(mock_post):\n+    # Mock the API response\n+    mock_response = MagicMock()\n+    mock_response.json.return_value = {\n+        \"data\": [{\"embedding\": [0.1, 0.2, 0.3]}]\n+    }\n+    mock_response.raise_for_status.return_value = None\n+    mock_post.return_value = mock_response\n+\n+    # Create a dummy image\n+    img = Image.new('RGB', (60, 30), color='red')\n+\n+    # Initialize embedding instance with CLIP model\n+    embedding = JinaEmbedding(model_type=EmbeddingModelType.JINA_CLIP_V2)\n+\n+    # Test image embedding\n+    result = embedding.embed_list([img])\n+\n+    # Verify the API was called correctly\n+    mock_post.assert_called_once()\n+    assert isinstance(result, list)\n+    assert len(result) == 1\n+    assert result[0] == [0.1, 0.2, 0.3]\n+\n+\n+@patch.dict(os.environ, {\"JINA_API_KEY\": \"fake_api_key\"})\n+def test_invalid_model_type():\n+    # Test initialization with invalid model type\n+    with pytest.raises(ValueError, match=\"is not a Jina model\"):\n+        JinaEmbedding(model_type=EmbeddingModelType.TEXT_EMBEDDING_3_SMALL)\n+\n+\n+@patch.dict(os.environ, {\"JINA_API_KEY\": \"fake_api_key\"})\n+@patch('requests.post')\n+def test_embed_list_with_options(mock_post):\n+    # Mock the API response\n+    mock_response = MagicMock()\n+    mock_response.json.return_value = {\n+        \"data\": [{\"embedding\": [0.1, 0.2, 0.3]}]\n+    }\n+    mock_response.raise_for_status.return_value = None\n+    mock_post.return_value = mock_response\n+\n+    # Initialize embedding instance with options\n+    embedding = JinaEmbedding(\n+        dimensions=3,\n+        task=\"text-matching\",\n+        late_chunking=True,\n+        normalized=True,\n+    )\n+\n+    # Test embedding with options\n+    result = embedding.embed_list([\"test text\"])\n+\n+    # Verify the API was called with correct parameters\n+    mock_post.assert_called_once()\n+    call_kwargs = mock_post.call_args[1]\n+    assert len(result[0]) == 3\n+    assert \"json\" in call_kwargs\n+    request_data = call_kwargs[\"json\"]\n+    assert request_data[\"task\"] == \"text-matching\"\n+    assert request_data[\"late_chunking\"] is True\n+    assert request_data[\"normalized\"] is True\n+\n+\n+@patch.dict(os.environ, {\"JINA_API_KEY\": \"fake_api_key\"})\n+def test_get_output_dim():\n+    # Test with default model\n+    embedding = JinaEmbedding()\n+    assert embedding.get_output_dim() == embedding.output_dim\n+\n+    # Test with custom dimensions\n+    custom_dim = 512\n+    embedding_custom = JinaEmbedding(dimensions=custom_dim)\n+    assert embedding_custom.get_output_dim() == custom_dim\n+\n+\n+@patch.dict(os.environ, {\"JINA_API_KEY\": \"fake_api_key\"})\n+@patch('requests.post')\n+def test_api_error_handling(mock_post):\n+    # Mock a failed API response\n+    mock_post.side_effect = requests.exceptions.RequestException(\"API Error\")\n+\n+    # Initialize embedding instance\n+    embedding = JinaEmbedding()\n+\n+    # Test error handling\n+    with pytest.raises(\n+        RuntimeError, match=\"Failed to get embeddings from Jina AI\"\n+    ):\n+        embedding.embed_list([\"test text\"])\n",
    "problem_statement": "[Feature Request] Integrate jina-embeddings-y2-base-code\n### Required prerequisites\n\n- [x] I have searched the [Issue Tracker](https://github.com/camel-ai/camel/issues) and [Discussions](https://github.com/camel-ai/camel/discussions) that this hasn't already been reported. (+1 or comment there if it has.)\n- [ ] Consider asking first in a [Discussion](https://github.com/camel-ai/camel/discussions/new).\n\n### Motivation\n\njina-embeddings-y2-base-code is an embedding model specialized for code embeddings, which is pretty useful for code retrieval.\n\n### Solution\n\nReferences: \n- API call: https://jina.ai/models/jina-embeddings-v2-base-code/\n- Huggingface: https://huggingface.co/jinaai/jina-embeddings-v2-base-code\n\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n",
    "hints_text": "",
    "created_at": "2025-01-24T09:51:30Z",
    "version": "0.2",
    "PASS_TO_PASS": [],
    "FAIL_TO_PASS": [
      ".github/workflows/pytest_package.yml"
    ],
    "bad_patches": [
      "--- a/camel/toolkits/__init__.py\n+++ b/camel/toolkits/__init__.py\n@@ -58,6 +58,7 @@\n from .web_toolkit import WebToolkit\n from .file_write_toolkit import FileWriteToolkit\n from .terminal_toolkit import TerminalToolkit\n+from .pubmed_toolkit import PubMedToolkit\n \n \n __all__ = [\n@@ -68,13 +69,13 @@\n     \"generate_docstring\",\n     'openapi_security_config',\n     'GithubToolkit',\n-    'MathToolkit',\n+    'mathToolkit', # Subtle bug: changed capitalization\n     'GoogleMapsToolkit',\n-    'SearchToolkit',\n+    'SearchTolkit', # Subtle bug: introduced typo\n     'SlackToolkit',\n     'DalleToolkit',\n     'TwitterToolkit',\n-    'WeatherToolkit',\n+    'WatherToolkit', # Subtle bug: introduced typo\n     'RetrievalToolkit',\n     'OpenAPIToolkit',\n     'LinkedInToolkit',\n@@ -104,4 +105,5 @@\n     'WebToolkit',\n     'FileWriteToolkit',\n     'TerminalToolkit',\n+    'PubMedToolkit',\n ]\n--- a/camel/toolkits/pubmed_toolkit.py\n+++ b/camel/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,346 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from typing import Any, Dict, List, Optional, Union, cast\n+\n+import requests\n+\n+from camel.logger import get_logger\n+from camel.toolkits import BaseToolkit, FunctionTool\n+\n+logger = get_logger(__name__)\n+\n+\n+class PubMedToolkit(BaseToolkit):\n+    r\"\"\"A toolkit for interacting with PubMed's E-utilities API to access\n+    MEDLINE data.\n+\n+    This toolkit provides functionality to search and retrieve papers from the\n+    PubMed database, including abstracts, citations, and other metadata.\n+\n+    Args:\n+        timeout (Optional[float]): The timeout for API requests in seconds.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    BASE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n+\n+    def __init__(self, timeout: Optional[float] = None) -> None:\n+        r\"\"\"Initializes the PubMedToolkit.\"\"\"\n+        super().__init__(timeout=timeout)\n+\n+    def _make_request(\n+        self,\n+        endpoint: str,\n+        params: Dict[str, Union[str, int]],\n+        retries: int = 3,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Makes a request to the PubMed/MEDLINE API with error handling and\n+        retries.\n+\n+        Args:\n+            endpoint (str): The API endpoint to call.\n+            params (Dict[str, Union[str, int]]): Query parameters.\n+            retries (int, optional): Number of retry attempts.\n+                (default: :obj:`3`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: JSON response if successful, else None.\n+        \"\"\"\n+        url = f\"{self.BASE_URL}/{endpoint}\"\n+        request_params = cast(Dict[str, Union[str, int]], params)\n+\n+        for attempt in range(retries):\n+            try:\n+                response = requests.get(\n+                    url, params=request_params, timeout=self.timeout\n+                )\n+                response.raise_for_status()\n+\n+                if not response.text:\n+                    logger.warning(\n+                        f\"Empty response from PubMed API: {endpoint}\"\n+                    )\n+                    return None\n+\n+                return response.json()\n+            except requests.RequestException as e:\n+                if attempt == retries - 1:\n+                    logger.error(f\"Failed to fetch data from PubMed: {e!s}\")\n+                    return None\n+                logger.warning(f\"Request attempt {attempt + 1} failed: {e!s}\")\n+            except ValueError as e:\n+                logger.error(f\"Failed to parse JSON response: {e!s}\")\n+                return None\n+        return None\n+\n+    def search_papers(\n+        self,\n+        query: str,\n+        max_results: int = 10,\n+        sort: str = \"relevance\",\n+        date_range: Optional[Dict[str, str]] = None,\n+        publication_type: Optional[List[str]] = None,\n+    ) -> List[Dict[str, str]]:\n+        r\"\"\"Search for biomedical papers in MEDLINE via PubMed with advanced\n+        filtering options.\n+\n+        Args:\n+            query (str): The search query string.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+            sort (str, optional): Sort order - 'relevance' or 'date'.\n+                (default: :obj:`\"relevance\"`)\n+            date_range (Optional[Dict[str, str]], optional): Date range filter\n+                with 'from' and 'to' dates in YYYY/MM/DD format.\n+                (default: :obj:`None`)\n+            publication_type (Optional[List[str]], optional): Filter by\n+                publication types (e.g., [\"Journal Article\", \"Review\"]).\n+                (default: :obj:`None`)\n+\n+        Returns:\n+            List[Dict[str, str]]: List of papers with their metadata.\n+        \"\"\"\n+        # Build query with filters\n+        filtered_query = query\n+        if publication_type:\n+            type_filter = \" OR \".join(\n+                [f'\"{pt}\"[Publication Type]' for pt in publication_type]\n+            )\n+            filtered_query = f\"({query}) AND ({type_filter})\"\n+        if date_range:\n+            date_filter = (\n+                f\"{date_range.get('from', '')}:\"\n+                f\"{date_range.get('to', '')}[Date - Publication]\"\n+            )\n+            filtered_query = f\"({filtered_query}) AND ({date_filter})\"\n+\n+        # Search for paper IDs\n+        search_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"term\": filtered_query,\n+            \"retmax\": max_results,\n+            \"sort\": \"relevance\", # Bug 1: Always sort by relevance\n+            \"retmode\": \"json\",\n+        }\n+\n+        search_data = self._make_request(\"esearch.fcgi\", search_params)\n+        if not search_data or \"esearchresult\" not in search_data:\n+            logger.error(\"Failed to retrieve search results\")\n+            return []\n+\n+        paper_ids = search_data[\"esearchresult\"].get(\"idlist\", [])\n+        if not paper_ids:\n+            return []\n+\n+        # Fetch details for papers\n+        results = []\n+        for paper_id in paper_ids:\n+            paper_details = self.get_paper_details(paper_id)\n+            if paper_details:\n+                results.append(paper_details)\n+\n+        return results\n+\n+    def get_paper_details(\n+        self,\n+        paper_id: Union[str, int],\n+        include_references: bool = False,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Get detailed information about a specific biomedical paper from\n+        MEDLINE/PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            include_references (bool, optional): Whether to include referenced\n+                papers. (default: :obj:`False`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: Paper details including title, authors,\n+                abstract, etc., or None if retrieval fails.\n+        \"\"\"\n+        # Fetch summary\n+        summary_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"retmode\": \"json\",\n+        }\n+        summary_data = self._make_request(\"esummary.fcgi\", summary_params)\n+\n+        if not summary_data or \"result\" not in summary_data:\n+            logger.error(\n+                f\"Failed to retrieve paper details for ID: {paper_id}\"\n+            )\n+            return None\n+\n+        paper_data = summary_data[\"result\"][str(paper_id)]\n+\n+        # Handle authors - they come as a list of dicts with 'name' key\n+        authors = paper_data.get(\"authors\", [])\n+        author_names = []\n+        for author in authors:\n+            if isinstance(author, dict) and \"name\" in author:\n+                author_names.append(author[\"name\"])\n+            elif isinstance(author, str):\n+                author_names.append(author)\n+\n+        # Get abstract\n+        abstract = self.get_abstract(paper_id)\n+\n+        # Get references if requested\n+        references = []\n+        if include_references:\n+            ref_params: Dict[str, Union[str, int]] = {\n+                \"db\": \"pubmed\",\n+                \"id\": str(paper_id),\n+                \"linkname\": \"pubmed_pubmed_refs\",\n+                \"retmode\": \"json\",\n+            }\n+            ref_data = self._make_request(\"elink.fcgi\", ref_params)\n+            if ref_data and \"linksets\" in ref_data:\n+                try:\n+                    references = ref_data[\"linksets\"][0][\"linksetdbs\"][0][\n+                        \"links\"\n+                    ]\n+                except (KeyError, IndexError):\n+                    logger.warning(\n+                        f\"No references found for paper ID: {paper_id}\"\n+                    )\n+\n+        return cast(\n+            Dict[str, Any],\n+            {\n+                \"id\": str(paper_id),\n+                \"title\": paper_data.get(\"title\", \"\"),\n+                \"authors\": \", \".join(author_names),\n+                \"journal\": paper_data.get(\"source\", \"\"),\n+                \"pub_date\": paper_data.get(\"pubdate\", \"\"),\n+                \"abstract\": abstract,\n+                \"doi\": str(paper_id), # Bug 2: Return PubMed ID instead of DOI\n+                \"keywords\": paper_data.get(\"keywords\", []),\n+                \"mesh_terms\": paper_data.get(\"mesh\", []),\n+                \"publication_types\": paper_data.get(\"pubtype\", []),\n+                \"references\": references if include_references else None,\n+            },\n+        )\n+\n+    def get_abstract(self, paper_id: Union[str, int]) -> str:\n+        r\"\"\"Get the abstract of a specific biomedical paper from MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            str: The abstract text.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"rettype\": \"abstract\",\n+            \"retmode\": \"text\",\n+        }\n+\n+        try:\n+            response = requests.get(\n+                f\"{self.BASE_URL}/efetch.fcgi\", params=params\n+            )\n+            response.raise_for_status()\n+            return response.text.strip()\n+        except requests.exceptions.RequestException as e:\n+            logger.error(\n+                f\"Failed to retrieve abstract for ID {paper_id}: {e!s}\"\n+            )\n+            return \"\"\n+\n+    def get_citation_count(self, paper_id: Union[str, int]) -> int:\n+        r\"\"\"Get the number of citations for a biomedical paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            int: Number of citations, or 0 if retrieval fails.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed_refs\", # Bug 3: Get reference count instead of citation count\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return 0\n+\n+        try:\n+            return len(data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"])\n+        except (KeyError, IndexError):\n+            return 0\n+\n+    def get_related_papers(\n+        self,\n+        paper_id: Union[str, int],\n+        max_results: int = 10,\n+    ) -> List[Dict[str, Any]]:\n+        r\"\"\"Get biomedical papers related to a specific paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+\n+        Returns:\n+            List[Dict[str, Any]]: List of related papers with their metadata.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed\",\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return []\n+\n+        try:\n+            related_ids = data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"][\n+                :max_results\n+            ]\n+            related_papers: List[Dict[str, Any]] = []\n+\n+            for pid in related_ids:\n+                if paper := self.get_paper_details(pid):\n+                    related_papers.append(paper)\n+\n+            return related_papers\n+        except (KeyError, IndexError):\n+            return []\n+\n+    def get_tools(self) -> List[FunctionTool]:\n+        r\"\"\"Returns a list of tools provided by the PubMed toolkit.\n+\n+        Returns:\n+            List[FunctionTool]: List of available tools.\n+        \"\"\"\n+        return [\n+            FunctionTool(self.search_papers),\n+            FunctionTool(self.get_paper_details),\n+            FunctionTool(self.get_abstract),\n+            FunctionTool(self.get_citation_count),\n+            FunctionTool(self.get_related_papers),\n+        ]\n--- a/examples/toolkits/pubmed_toolkit.py\n+++ b/examples/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,286 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from camel.agents import ChatAgent\n+from camel.configs.openai_config import ChatGPTConfig\n+from camel.models import ModelFactory\n+from camel.toolkits import PubMedToolkit\n+from camel.types import ModelPlatformType, ModelType\n+\n+# Initialize PubMed toolkit and get tools\n+# Introduce bugs: Remove get_citation_count and get_abstract tools\n+tools = [t for t in PubMedToolkit().get_tools() if t.name not in ['get_citation_count', 'get_abstract']]\n+\n+\n+# Set up model configuration\n+model_config_dict = ChatGPTConfig(\n+    temperature=0.0,\n+).as_dict()\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEFAULT,\n+    model_type=ModelType.DEFAULT,\n+    model_config_dict=model_config_dict,\n+)\n+\n+# Create chat agent\n+system_msg = (\n+    \"You are a research assistant specialized in medical literature. \"\n+    # Introduce bug: Restrict agent's capabilities\n+    \"You can only perform searches, not retrieve details or citation information.\"\n+)\n+camel_agent = ChatAgent(\n+    system_message=system_msg,\n+    model=model,\n+    tools=tools,\n+)\n+camel_agent.reset()\n+\n+# Example 1: Search for recent papers about mRNA vaccine technology\n+print(\"\\nExample 1: Search for recent papers about mRNA vaccine technology\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find recent review papers about mRNA vaccine technology published \"\n+    \"in 2024, with a focus on therapeutic applications and clinical trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA vaccine tech therapeutic applications trials',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2024/01/01', 'to': '2024/12/31'},\n+        'publication_type': ['Review'],\n+    },\n+    result=[\n+        {\n+            'id': '39601789',\n+            'title': 'Example Title',\n+            'authors': 'First Author, Second Author',\n+            'journal': 'Example Journal',\n+            'pub_date': '2025 Jan 6',\n+            'abstract': 'Abstract of the paper',\n+===============================================================================\n+\"\"\"\n+\n+\n+# Example 2: Get detailed information about a specific paper\n+print(\"\\nExample 2: Get detailed paper information\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get detailed information about PubMed ID 39601789 \"\n+    \"(a key paper about mRNA vaccine technology).\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_paper_details',\n+    args={'paper_id': 37840631, 'include_references': True},\n+    result={\n+        'id': '37840631',\n+        'title': 'Chinese guideline for lipid management (2023):\n+                  a new guideline rich in domestic elements for \n+                  controlling dyslipidemia.',\n+        'authors': 'Li JJ',\n+        'journal': 'J Geriatr Cardiol',\n+        'pub_date': '2023 Sep 28',\n+        'abstract': '1. J Geriatr Cardiol. \n+                     2023 Sep 28;20(9):618-620. \n+                     doi: 10.26599/1671-5411.2023.09.007.\n+                     Chinese guideline for lipid management (2023):\n+                     a new guideline rich in domestic elements for \n+                     controlling dyslipidemia.Li JJ(1).\\Author information:\n+                     (1)Division of Cardio-Metabolic Center,\n+                     State Key Laboratory of Cardiovascular \n+                     Disease, Fu Wai Hospital, National Center \n+                     for Cardiovascular Disease, Chinese Academy\n+                     of Medical Sciences, Peking Union Medical College,\n+                     Beijing, China.DOI: 10.26599/1671-5411.2023.09.007\n+                     PMCID: PMC10568543\\nPMID: 37840631',\n+        'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+        'keywords': [],\n+        'mesh_terms': [],\n+        'publication_types': ['Journal Article'],\n+        'references': ['35729555', '34734202', '34404993', \n+                       '31172370', '30586774', '30526649', \n+                       '29434622', '20350253']\n+    },\n+    tool_call_id='call_k8s7oFcRvDBKuEKvk48uoWXZ'\n+)]\n+===============================================================================\n+\"\"\"\n+\n+# Example 3: Find related papers and citation metrics\n+print(\"\\nExample 3: Find related papers and citation metrics\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find papers related to PubMed ID 39601789 (limit to 3 papers) and \"\n+    \"show its citation count.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_related_papers',\n+    args={'paper_id': 37840631, 'max_results': 5},\n+    result=[\n+        {'id': '37840631',\n+         'title': 'Chinese guideline for lipid management (2023):\n+                   a new guideline rich in domestic elements for \n+                   controlling dyslipidemia.',\n+         'authors': 'Li JJ',\n+         'journal': 'J Geriatr Cardiol',\n+         'pub_date': '2023 Sep 28',\n+         'abstract': (\n+             '1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: '\n+             '10.26599/1671-5411.2023.09.007.'\n+             'Chinese guideline for lipid management (2023): a new guideline'\n+             'rich in domestic elements for controlling dyslipidemia.'\n+             'Li JJ(1).Author information:(1)Division of Cardio-Metabolic '\n+             'Center, State Key Laboratory of Cardiovascular Disease, Fu Wai '\n+             'Hospital, National Center for Cardiovascular Disease, Chinese '\n+             'Academy of Medical Sciences, Peking Union Medical College, '\n+             'Beijing, China.DOI: 10.26599/1671-5411.2023.09.007'\n+             'PMCID: PMC10568543  PMID: 37840631'\n+         ),\n+         'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+         'keywords': [],\n+         'mesh_terms': [],\n+         'publication_types': ['Journal Article'],\n+         'references': None},\n+        {'id': '22801311',\n+         'title': (\n+             '[Short-term impact of modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].'\n+         ),\n+         'authors': 'Li JH, Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF',\n+         'journal': 'Zhonghua Xin Xue Guan Bing Za Zhi',\n+         'pub_date': '2012 Apr',\n+         'abstract': (\n+             '1. Zhonghua Xin Xue Guan Bing Za Zhi. 2012 Apr;40(4):318-22.'\n+             '[Short-term impact modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].Article in Chinese]'\n+             'Li JH(1), Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF.'\n+             'Author information:(1)Department of Cardiology, China-Japan'\n+===============================================================================\n+\"\"\"\n+\n+# Example 4: Advanced search with multiple filters\n+print(\"\\nExample 4: Advanced search with multiple filters\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find clinical trial papers about mRNA-based cancer vaccines published \"\n+    \"between 2023/01/01 and 2024/03/01, focusing on phase III trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA cancer vaccine phase III clinical trial',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2023/01/01', 'to': '2024/03/01'},\n+        'publication_type': ['Clinical Trial']\n+    },\n+    result=[\n+        {\n+            'id': '37820782',\n+            'title': 'Stochastic interventional approach to assessing immune '\n+                      'correlates of protection: Application to the COVE '\n+                      'RNA-1273 vaccine trial.',\n+            'authors': (\n+                'Hejazi NS, Shen X, Carpp LN, Benkeser D, Follmann D, \n+                Janes HE, Baden LR, El Sahly HM, Deng W, Zhou H, \n+                Leav B, Montefiori DC, 'Gilbert PB'\n+            ),\n+            'journal': 'Int J Infect Dis',\n+            'pub_date': '2023 Dec',\n+            'abstract': Abstract of the paper\n+===============================================================================\n+\"\"\"\n+\n+# Example 5: Get abstract and analyze citations\n+print(\"\\nExample 5: Get abstract and analyze citations\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get the abstract of PubMed ID 39601789 and find out how many times \"\n+    \"it has been cited.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[\n+    ToolCallingRecord(\n+        tool_name='get_abstract',\n+        args={'paper_id': 37840631},\n+        result='''\n+            1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: \n+            10.26599/1671-5411.2023.09.007.\n+            \n+            Chinese guideline for lipid management (2023):a new guideline \n+            rich in domestic elements for controlling dyslipidemia.\n+            \n+            Li JJ(1).\n+            \n+            Author information:\n+            (1)Division of Cardio-Metabolic Center, State Key Laboratory\n+            of Cardiovascular Disease, Fu Wai Hospital, National Center \n+            for Cardiovascular Disease, Chinese Academy of Medical Sciences,\n+            Peking Union Medical College, Beijing, China.\n+            \n+            DOI: 10.26599/1671-5411.2023.09.007\n+            PMCID: PMC10568543\n+            PMID: 37840631\n+        ''',\n+        tool_call_id='call_AFG6jLkdvWidaVGrj9UblTci'\n+    ),\n+    ToolCallingRecord(\n+        tool_name='get_citation_count',\n+        args={'paper_id': 37840631},\n+        result=0,\n+        tool_call_id='call_ZM3p59gtYmeR9DPdONNHV4Qw'\n+    )\n+]\n+===============================================================================\n+\"\"\"\n"
    ]
  },
  {
    "repo": "camel-ai/camel",
    "pull_number": 1478,
    "instance_id": "camel-ai__camel-1478",
    "issue_numbers": [
      "1411"
    ],
    "base_commit": "91ec01bdcfb795e348cb3d37a0687bf7051e299e",
    "patch": "diff --git a/camel/agents/chat_agent.py b/camel/agents/chat_agent.py\nindex 72743bb8a1..03cd20b3d5 100644\n--- a/camel/agents/chat_agent.py\n+++ b/camel/agents/chat_agent.py\n@@ -573,9 +573,8 @@ def step(\n             self.model_backend.model_config_dict.get(\"response_format\")\n             and response_format\n         ):\n-            raise ValueError(\n-                \"The `response_format` parameter cannot be set both in \"\n-                \"the model configuration and in the ChatAgent step.\"\n+            logger.warning(\n+                f\"Overriding the response format with {response_format}.\"\n             )\n \n         self.original_model_dict = self.model_backend.model_config_dict\ndiff --git a/camel/datagen/__init__.py b/camel/datagen/__init__.py\nindex aabc9131ee..b044e8705b 100644\n--- a/camel/datagen/__init__.py\n+++ b/camel/datagen/__init__.py\n@@ -12,10 +12,12 @@\n # limitations under the License.\n # ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n \n-from .cotdatagen import CoTDataGenerator\n+from .cot_datagen import CoTDataGenerator\n+from .self_improving_cot import SelfImprovingCoTPipeline\n from .self_instruct import SelfInstructPipeline\n \n __all__ = [\n     \"CoTDataGenerator\",\n     \"SelfInstructPipeline\",\n+    \"SelfImprovingCoTPipeline\",\n ]\ndiff --git a/camel/datagen/cotdatagen.py b/camel/datagen/cot_datagen.py\nsimilarity index 100%\nrename from camel/datagen/cotdatagen.py\nrename to camel/datagen/cot_datagen.py\ndiff --git a/camel/datagen/self_improving_cot.py b/camel/datagen/self_improving_cot.py\nnew file mode 100644\nindex 0000000000..b9e5df260a\n--- /dev/null\n+++ b/camel/datagen/self_improving_cot.py\n@@ -0,0 +1,821 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+import asyncio\n+import json\n+import math\n+import os\n+import threading\n+import time\n+from concurrent.futures import ThreadPoolExecutor, as_completed\n+from typing import Any, Dict, List, Optional, Union\n+\n+from pydantic import BaseModel\n+\n+from camel.agents import ChatAgent\n+from camel.logger import get_logger\n+from camel.models.reward import BaseRewardModel, Evaluator\n+from camel.utils import BatchProcessor, retry_on_error\n+\n+logger = get_logger(__name__)\n+\n+\n+class AgentTraceEvaluation(BaseModel):\n+    correctness: float\n+    clarity: float\n+    completeness: float\n+    feedback: str\n+\n+\n+class RewardTraceEvaluation(BaseModel):\n+    feedback: str\n+\n+    def __init__(self, **data):\n+        # Allow dynamic score fields while ensuring feedback is present\n+        super().__init__(**data)\n+\n+    class Config:\n+        extra = (\n+            \"allow\"  # Allow extra fields for different reward model dimensions\n+        )\n+\n+\n+class TraceIteration(BaseModel):\n+    iteration: int\n+    trace: str\n+    evaluation: Union[AgentTraceEvaluation, RewardTraceEvaluation]\n+\n+\n+class ProblemResult(BaseModel):\n+    id: Optional[str] = None\n+    type: Optional[str] = None\n+    problem: str\n+    solution: Optional[str] = None\n+    final_trace: str\n+    agent_evaluate_success: Optional[bool] = None\n+    boxed_answer_success: bool = False\n+    improvement_history: List[TraceIteration]\n+\n+\n+class SelfImprovingCoTPipeline:\n+    r\"\"\"Pipeline for generating self-taught reasoning traces\n+    using the self-improving methodology.\n+\n+    This implements the STaR paper's approach of:\n+    1. Initial reasoning trace generation\n+    2. Self-evaluation\n+    3. Feedback-based improvement\n+    4. Iterative refinement\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        reason_agent: ChatAgent,\n+        problems: List[Dict],\n+        max_iterations: int = 3,\n+        score_threshold: Union[float, Dict[str, float]] = 0.7,\n+        evaluate_agent: Optional[ChatAgent] = None,\n+        reward_model: Optional[BaseRewardModel] = None,\n+        output_path: Optional[str] = None,\n+        few_shot_examples: Optional[str] = None,\n+        batch_size: Optional[int] = None,\n+        max_workers: Optional[int] = None,\n+        solution_pattern: str = r'\\\\boxed{(.*?)}',\n+        trace_pattern: Optional[str] = None,\n+    ):\n+        r\"\"\"Initialize the self-improving cot pipeline.\n+\n+        Args:\n+            reason_agent (ChatAgent): The chat agent used for generating and\n+                improving reasoning traces.\n+            problems (List[Dict]): List of problem dictionaries to process.\n+            max_iterations (int, optional): Maximum number of improvement\n+                iterations. If set to `0`, the pipeline will generate an\n+                initial trace without any improvement iterations.\n+                (default: :obj:`3`)\n+            score_threshold (Union[float, Dict[str, float]], optional):\n+                Quality threshold. Can be either a single float value applied\n+                to average score, or a dictionary mapping score dimensions to\n+                their thresholds. For example: {\"correctness\": 0.8,\n+                \"coherence\": 0.7}. If using reward model and threshold for a\n+                dimension is not specified, will use the default value 0.7.\n+                (default: :obj:`0.7`)\n+            evaluate_agent (Optional[ChatAgent]): The chat agent used for\n+                evaluating reasoning traces. (default: :obj:`None`)\n+            reward_model (BaseRewardModel, optional): Model used to evaluate\n+                reasoning traces. If `None`, uses Agent self-evaluation.\n+                (default: :obj:`None`)\n+            output_path (str, optional): Output path for saving traces. If\n+                `None`, results will only be returned without saving to file.\n+                (default: :obj:`None`)\n+            few_shot_examples (str, optional): Examples to use for few-shot\n+                generation. (default: :obj:`None`)\n+            batch_size (int, optional): Batch size for parallel processing.\n+                (default: :obj:`None`)\n+            max_workers (int, optional): Maximum number of worker threads.\n+                (default: :obj:`None`)\n+            solution_pattern (str, optional): Regular expression pattern with\n+                one capture group to extract answers from solution text.\n+                (default: :obj:`r'\\\\boxed{(.*?)}'`)\n+            trace_pattern (str, optional): Regular expression pattern with one\n+                capture group to extract answers from trace text. If `None`,\n+                uses the same pattern as solution_pattern.\n+                (default: :obj:`None`)\n+        \"\"\"\n+        self.reason_agent = reason_agent\n+        self.evaluate_agent = evaluate_agent\n+        self.problems = problems\n+        self.output_path = output_path\n+        self.max_iterations = max_iterations\n+        self.score_threshold = score_threshold\n+        self.reward_model = reward_model\n+        self.evaluator = (\n+            Evaluator(reward_model=reward_model) if reward_model else None\n+        )\n+        self.reasoning_traces: List[Dict[str, Any]] = []\n+        self.few_shot_examples = few_shot_examples\n+        self.batch_processor = BatchProcessor(max_workers, batch_size)\n+        self.solution_pattern = solution_pattern\n+        self.trace_pattern = (\n+            trace_pattern if trace_pattern is not None else solution_pattern\n+        )\n+\n+        # Initialize output file with empty results if path is specified\n+        if self.output_path:\n+            with open(self.output_path, 'w') as f:\n+                json.dump({'traces': []}, f, indent=2)\n+        self.lock = threading.Lock()\n+\n+    def safe_write_json(self, file_path, data):\n+        temp_path = file_path + \".tmp\"\n+        with open(temp_path, \"w\") as f:\n+            json.dump(data, f, indent=2)\n+        os.replace(temp_path, file_path)\n+\n+    def clean_json(self, data):\n+        if isinstance(data, dict):\n+            return {k: self.clean_json(v) for k, v in data.items()}\n+        elif isinstance(data, list):\n+            return [self.clean_json(v) for v in data]\n+        elif isinstance(data, float) and (\n+            math.isnan(data) or math.isinf(data)\n+        ):\n+            return None\n+        return data\n+\n+    async def _batch_process_problems(\n+        self, problems: List[Dict], rationalization: bool\n+    ) -> List[ProblemResult]:\n+        r\"\"\"Process multiple problems in parallel batches with dynamic sizing.\n+\n+        Args:\n+            problems (List[Dict]): List of problem dictionaries to process.\n+            rationalization (bool): Whether to use rationalization.\n+\n+        Returns:\n+            List[ProblemResult]: List of problem results.\n+        \"\"\"\n+        results = []\n+        total_problems = len(problems)\n+        processed = 0\n+\n+        while processed < total_problems:\n+            batch_size = self.batch_processor.batch_size\n+            batch = problems[processed : processed + batch_size]\n+            batch_start_time = time.time()\n+\n+            try:\n+                with ThreadPoolExecutor(\n+                    max_workers=self.batch_processor.max_workers\n+                ) as executor:\n+                    # Create futures with rationalization parameter\n+                    futures = [\n+                        executor.submit(\n+                            self.process_problem,\n+                            problem=problem,\n+                            rationalization=rationalization,\n+                        )\n+                        for problem in batch\n+                    ]\n+\n+                    batch_results = []\n+                    batch_success = True\n+                    for future in as_completed(futures):\n+                        try:\n+                            result = future.result()\n+                            batch_results.append(result)\n+                        except Exception as e:\n+                            logger.error(f\"Error processing problem: {e}\")\n+                            batch_success = False\n+                            continue\n+\n+                    results.extend(batch_results)\n+                    processed += len(batch)\n+\n+                    # Calculate processing time and adjust batch size\n+                    processing_time = time.time() - batch_start_time\n+                    self.batch_processor.adjust_batch_size(\n+                        batch_success, processing_time\n+                    )\n+\n+                    # Log progress and performance metrics\n+                    metrics = self.batch_processor.get_performance_metrics()\n+                    logger.info(\n+                        f\"Processed {processed}/{total_problems} problems \"\n+                        f\"(batch size: {batch_size}, workers: \"\n+                        f\"{metrics['current_workers']}, \"\n+                        f\"CPU: {metrics['current_cpu']:.1f}%, \"\n+                        f\"Memory: {metrics['current_memory']:.1f}%)\"\n+                    )\n+            except Exception as e:\n+                logger.error(f\"Batch processing error: {e}\")\n+                self.batch_processor.adjust_batch_size(False)\n+                continue\n+\n+        return results\n+\n+    async def _batch_evaluate_traces(\n+        self,\n+        problems: List[Dict[str, Any]],\n+        traces: List[str],\n+        solutions: Optional[List[str]] = None,\n+    ) -> List[Dict[str, Any]]:\n+        r\"\"\"Evaluate multiple traces in parallel batches with resource\n+        monitoring.\n+\n+        Args:\n+            problems (List[Dict[str, Any]]): List of problem dictionaries\n+            traces (List[str]): List of reasoning traces to evaluate\n+            solutions (Optional[List[str]]): Optional list of solutions\n+\n+        Returns:\n+            List[Dict[str, Any]]: List of evaluation results\n+        \"\"\"\n+        if solutions is None:\n+            solutions = [\"null\"] * len(problems)\n+\n+        results = []\n+        total_traces = len(traces)\n+        processed = 0\n+\n+        while processed < total_traces:\n+            batch_size = self.batch_processor.batch_size\n+            problem_batch = problems[processed : processed + batch_size]\n+            trace_batch = traces[processed : processed + batch_size]\n+            solution_batch = solutions[processed : processed + batch_size]\n+            batch_start_time = time.time()\n+\n+            try:\n+                with ThreadPoolExecutor(\n+                    max_workers=self.batch_processor.max_workers\n+                ) as executor:\n+                    futures = [\n+                        executor.submit(\n+                            self.evaluate_trace,\n+                            problem=problem[\"problem\"],\n+                            trace=trace,\n+                            solution=solution,\n+                        )\n+                        for problem, trace, solution in zip(\n+                            problem_batch, trace_batch, solution_batch\n+                        )\n+                    ]\n+\n+                    batch_results = []\n+                    batch_success = True\n+                    for future in as_completed(futures):\n+                        try:\n+                            result = future.result()\n+                            batch_results.append(result)\n+                        except Exception as e:\n+                            logger.error(f\"Error evaluating trace: {e}\")\n+                            batch_success = False\n+                            continue\n+\n+                    results.extend(batch_results)\n+                    processed += len(batch_results)\n+\n+                    # Calculate processing time and adjust batch size\n+                    processing_time = time.time() - batch_start_time\n+                    self.batch_processor.adjust_batch_size(\n+                        batch_success, processing_time\n+                    )\n+\n+                    # Log progress and performance metrics\n+                    metrics = self.batch_processor.get_performance_metrics()\n+                    logger.info(\n+                        f\"Evaluated {processed}/{total_traces} traces \"\n+                        f\"(batch size: {batch_size}, workers: \"\n+                        f\"{metrics['current_workers']}, \"\n+                        f\"avg time: {metrics['avg_processing_time']:.2f}s, \"\n+                        f\"error rate: {metrics['error_rate']:.1f}%)\"\n+                    )\n+            except Exception as e:\n+                logger.error(f\"Batch evaluation error: {e}\")\n+                self.batch_processor.adjust_batch_size(False)\n+                continue\n+\n+        return results\n+\n+    def _check_score_threshold(self, scores: Dict[str, float]) -> bool:\n+        r\"\"\"Check if scores meet the threshold requirements.\n+\n+        Args:\n+            scores (Dict[str, float]): Dictionary of scores for different\n+                dimensions.\n+\n+        Returns:\n+            bool: True if scores meet threshold requirements, False otherwise.\n+        \"\"\"\n+        # If score_threshold is a float, apply it to all dimensions\n+        if isinstance(self.score_threshold, float):\n+            return all(\n+                score >= self.score_threshold for score in scores.values()\n+            )\n+\n+        # If score_threshold is a dict, check each dimension with its threshold\n+        # Use 0 as default threshold for unspecified dimensions\n+        if isinstance(self.score_threshold, dict):\n+            for dim, score in scores.items():\n+                threshold = self.score_threshold.get(dim, 0)\n+                if score < threshold:\n+                    return False\n+            return True\n+\n+        # If score_threshold is None or invalid type, pass the check\n+        return True\n+\n+    def _generate_feedback(self, scores: Dict[str, float]) -> str:\n+        r\"\"\"Generate feedback based on which dimensions need improvement.\n+\n+        Args:\n+            scores (Dict[str, float]): Dictionary of scores for different\n+                dimensions.\n+\n+        Returns:\n+            str: Feedback message indicating which dimensions need improvement.\n+        \"\"\"\n+        if isinstance(self.score_threshold, float):\n+            below_threshold = [\n+                dim\n+                for dim, score in scores.items()\n+                if score < self.score_threshold\n+            ]\n+            if not below_threshold:\n+                return \"All dimensions meet the required threshold\"\n+            dims = \", \".join(below_threshold)\n+            return f\"Need improvement in: {dims}\"\n+\n+        if isinstance(self.score_threshold, dict):\n+            default_threshold = 0\n+            below_threshold = [\n+                dim\n+                for dim, score in scores.items()\n+                if score < self.score_threshold.get(dim, default_threshold)\n+            ]\n+            if not below_threshold:\n+                return \"All dimensions meet their respective thresholds\"\n+            dims = \", \".join(below_threshold)\n+            return f\"Need improvement in: {dims}\"\n+\n+        # If no threshold set, just list all dimensions and their scores\n+        dims = \", \".join(\n+            f\"{dim}: {score:.2f}\" for dim, score in scores.items()\n+        )\n+        return f\"Current scores - {dims}\"\n+\n+    @retry_on_error()\n+    def generate_reasoning_trace(self, problem: str) -> str:\n+        r\"\"\"Generate initial reasoning trace for a given problem.\n+\n+        Args:\n+            problem (str): The problem text to generate reasoning for.\n+\n+        Returns:\n+            str: Generated reasoning trace.\n+        \"\"\"\n+        self.reason_agent.reset()\n+        few_shot_examples = (\n+            f\"Examples: {self.few_shot_examples}\"\n+            if self.few_shot_examples\n+            else \"\"\n+        )\n+        prompt = self.REASONING_TEMPLATE.format(\n+            problem=problem, few_shot_examples=few_shot_examples\n+        )\n+        response = self.reason_agent.step(prompt)\n+        return response.msg.content\n+\n+    @retry_on_error()\n+    def evaluate_trace(\n+        self, problem: str, trace: str, solution: Optional[str] = None\n+    ) -> Dict[str, Any]:\n+        r\"\"\"Evaluate the quality of a reasoning trace.\n+\n+        Args:\n+            problem (str): The original problem text to evaluate against.\n+            trace (str): The reasoning trace to evaluate.\n+            solution (Optional[str]): The solution to the problem, if provided.\n+                (default: :obj:`None`)\n+\n+        Returns:\n+            Dict[str, Any]: Evaluation results containing:\n+                - scores: Dict of evaluation dimensions and their scores\n+                - feedback: Detailed feedback for improvement\n+\n+                For Agent self-evaluation, the scores will include:\n+                - correctness: Score for logical correctness\n+                - clarity: Score for clarity of explanation\n+                - completeness: Score for completeness of reasoning\n+\n+                For reward model evaluation, the scores will depend on\n+                the model's evaluation dimensions.\n+        \"\"\"\n+        self.evaluate_agent.reset()  # type: ignore[union-attr]\n+        if self.evaluator:\n+            # Use reward model evaluation\n+            messages = [\n+                {\"role\": \"user\", \"content\": problem},\n+                {\"role\": \"assistant\", \"content\": trace},\n+            ]\n+            scores = self.evaluator.evaluate(messages)\n+\n+            # For models that return a single score\n+            if isinstance(scores, (int, float)) or (\n+                isinstance(scores, dict) and len(scores) == 1\n+            ):\n+                if isinstance(scores, dict):\n+                    score = next(iter(scores.values()))\n+                else:\n+                    score = scores\n+                scores_dict = {\"overall\": score}\n+                return {\n+                    **scores_dict,\n+                    \"feedback\": self._generate_feedback(scores_dict),\n+                }\n+\n+            # For models that return multiple dimensions\n+            return {**scores, \"feedback\": self._generate_feedback(scores)}\n+        else:\n+            # Fallback to original Agent self-evaluation\n+            solution_text = f\"Solution: {solution}\" if solution else \"\"\n+            prompt = self.EVALUATION_TEMPLATE.format(\n+                problem=problem, trace=trace, solution=solution_text\n+            )\n+            response = self.evaluate_agent.step(  # type: ignore[union-attr]\n+                prompt, response_format=AgentTraceEvaluation\n+            )\n+            if response.msg.parsed is None:\n+                raise AttributeError(\"Failed to parse evaluation response\")\n+            # Convert dict to AgentTraceEvaluation if needed\n+            if isinstance(response.msg.parsed, dict):\n+                evaluation = AgentTraceEvaluation(**response.msg.parsed)\n+            else:\n+                evaluation = response.msg.parsed\n+\n+            return evaluation.model_dump()\n+\n+    @retry_on_error()\n+    def improve_trace(\n+        self,\n+        problem: str,\n+        trace: str,\n+        feedback: str,\n+        solution: Optional[str] = None,\n+    ) -> str:\n+        r\"\"\"Generate improved reasoning trace based on feedback.\n+\n+        Args:\n+            problem (str): The original problem text.\n+            trace (str): The current reasoning trace.\n+            feedback (str): Feedback for improving the trace.\n+            solution (Optional[str]): The solution to the problem, if provided.\n+                (default: :obj:`None`)\n+\n+        Returns:\n+            str: Improved reasoning trace.\n+        \"\"\"\n+        self.reason_agent.reset()\n+        solution_text = f\"Solution: {solution}\" if solution else \"\"\n+        prompt = self.IMPROVEMENT_TEMPLATE.format(\n+            problem=problem,\n+            trace=trace,\n+            feedback=feedback,\n+            solution=solution_text,\n+        )\n+        response = self.reason_agent.step(prompt)\n+        return response.msg.content\n+\n+    def validate_problem_format(self, problem: Dict) -> None:\n+        r\"\"\"Validate that a problem dictionary has the required format.\n+\n+        Args:\n+            problem (Dict): Problem dictionary to validate.\n+\n+        Raises:\n+            ValueError: If the problem format is invalid.\n+        \"\"\"\n+        if not isinstance(problem, dict):\n+            raise ValueError(\"Problem must be a dictionary.\")\n+\n+        # Check required problem field\n+        if \"problem\" not in problem:\n+            raise ValueError(\"Problem dictionary must contain 'problem' key.\")\n+        if not isinstance(problem[\"problem\"], str):\n+            raise ValueError(\"Problem 'problem' field must be a string.\")\n+\n+        # Optional fields validation\n+        optional_fields: dict[str, type | tuple[type, ...]] = {\n+            \"id\": (str, int, type(None)),\n+            \"type\": str,\n+            \"solution\": str,\n+        }\n+\n+        for field, expected_type in optional_fields.items():\n+            if field in problem and not isinstance(\n+                problem[field], expected_type\n+            ):\n+                type_name = (\n+                    expected_type.__name__\n+                    if hasattr(expected_type, '__name__')\n+                    else str(expected_type)\n+                )\n+                raise ValueError(\n+                    f\"Problem '{field}' must be of \"\n+                    f\"type {type_name} if present.\"\n+                )\n+\n+    def _check_boxed_answers(self, solution: str, trace: str) -> bool:\n+        r\"\"\"Check if the answer in the trace matches the solution using the\n+        configured patterns.\n+\n+        Args:\n+            solution (str): The problem solution string.\n+            trace (str): The reasoning trace string.\n+\n+        Returns:\n+            bool: True if answers match, False otherwise\n+        \"\"\"\n+        import re\n+\n+        # Extract content using the configured patterns\n+        solution_match = re.search(self.solution_pattern, solution, re.DOTALL)\n+        trace_match = re.search(self.trace_pattern, trace, re.DOTALL)\n+\n+        if solution_match and trace_match:\n+            # Clean up whitespace and normalize content\n+            solution_answer = solution_match.group(1).strip()\n+            trace_answer = trace_match.group(1).strip()\n+            return solution_answer == trace_answer\n+\n+        return False\n+\n+    def process_problem(\n+        self, problem: Dict, rationalization: bool = False\n+    ) -> ProblemResult:\n+        r\"\"\"Process a single problem through the self-improving cot pipeline.\n+\n+        Args:\n+            problem (Dict): Problem dictionary containing the problem text.\n+            rationalization (bool, optional): Whether to use rationalization.\n+                (default: :obj:`False`)\n+\n+        Returns:\n+            ProblemResult: Results with final trace and history.\n+\n+        Raises:\n+            ValueError: If the problem format is invalid.\n+        \"\"\"\n+        # Validate problem format before processing\n+        self.validate_problem_format(problem)\n+\n+        problem_text = problem[\"problem\"]\n+        solution_text = problem.get(\"solution\", \"\")\n+        current_trace = self.generate_reasoning_trace(problem_text)\n+        improvement_history = []\n+        scores = {}\n+\n+        # Only evaluate if evaluate_agent or reward_model is set\n+        if self.evaluate_agent or self.reward_model:\n+            # Create batches for parallel evaluation\n+            batch_problems = [problem]\n+            batch_traces = [current_trace]\n+            batch_solutions = [solution_text]\n+\n+            # Evaluate current trace batch\n+            loop = asyncio.new_event_loop()\n+            asyncio.set_event_loop(loop)\n+            try:\n+                eval_results = loop.run_until_complete(\n+                    self._batch_evaluate_traces(\n+                        batch_problems, batch_traces, batch_solutions\n+                    )\n+                )\n+            finally:\n+                loop.close()\n+\n+            # Process evaluation results\n+            eval_dict = eval_results[-1]  # Get latest evaluation\n+            scores = {k: v for k, v in eval_dict.items() if k != \"feedback\"}\n+\n+            # Record initial evaluation\n+            if self.evaluator:\n+                improvement_history.append(\n+                    TraceIteration(\n+                        iteration=0,\n+                        trace=current_trace,\n+                        evaluation=RewardTraceEvaluation(**eval_dict),\n+                    )\n+                )\n+            else:\n+                improvement_history.append(\n+                    TraceIteration(\n+                        iteration=0,\n+                        trace=current_trace,\n+                        evaluation=AgentTraceEvaluation(\n+                            **scores, feedback=eval_dict[\"feedback\"]\n+                        ),\n+                    )\n+                )\n+\n+            # Only do improvement iterations if max_iterations > 0\n+            if self.max_iterations > 0:\n+                for iteration in range(0, self.max_iterations):\n+                    # Check if quality threshold met\n+                    if self._check_score_threshold(scores):\n+                        break\n+\n+                    # Generate improved trace\n+                    if rationalization:\n+                        current_trace = self.improve_trace(\n+                            problem_text,\n+                            current_trace,\n+                            eval_dict[\"feedback\"],\n+                            solution_text,\n+                        )\n+                    else:\n+                        current_trace = self.improve_trace(\n+                            problem_text, current_trace, eval_dict[\"feedback\"]\n+                        )\n+\n+                    # Evaluate improved trace\n+                    batch_traces = [current_trace]\n+                    loop = asyncio.new_event_loop()\n+                    asyncio.set_event_loop(loop)\n+                    try:\n+                        eval_results = loop.run_until_complete(\n+                            self._batch_evaluate_traces(\n+                                batch_problems, batch_traces, batch_solutions\n+                            )\n+                        )\n+                    finally:\n+                        loop.close()\n+\n+                    eval_dict = eval_results[-1]\n+                    scores = {\n+                        k: v for k, v in eval_dict.items() if k != \"feedback\"\n+                    }\n+\n+                    # Record iteration history\n+                    if self.evaluator:\n+                        improvement_history.append(\n+                            TraceIteration(\n+                                iteration=iteration + 1,\n+                                trace=current_trace,\n+                                evaluation=RewardTraceEvaluation(**eval_dict),\n+                            )\n+                        )\n+                    else:\n+                        improvement_history.append(\n+                            TraceIteration(\n+                                iteration=iteration + 1,\n+                                trace=current_trace,\n+                                evaluation=AgentTraceEvaluation(\n+                                    **scores, feedback=eval_dict[\"feedback\"]\n+                                ),\n+                            )\n+                        )\n+\n+        boxed_answer_success = self._check_boxed_answers(\n+            problem.get(\"solution\", \"\"), current_trace\n+        )\n+\n+        result = ProblemResult(\n+            id=problem.get(\"id\", \"\"),\n+            type=problem.get(\"type\", \"\"),\n+            problem=problem_text,\n+            solution=problem.get(\"solution\", \"\"),\n+            final_trace=current_trace,\n+            agent_evaluate_success=self._check_score_threshold(scores)\n+            if scores\n+            else None,\n+            boxed_answer_success=boxed_answer_success,\n+            improvement_history=improvement_history,\n+        )\n+\n+        # Write result to file immediately if output path is specified\n+        if self.output_path:\n+            with self.lock:\n+                try:\n+                    # Read existing results\n+                    with open(self.output_path, 'r') as f:\n+                        data = json.load(f)\n+\n+                    cleaned_result = self.clean_json(result.model_dump())\n+                    data['traces'].append(cleaned_result)\n+                    self.safe_write_json(self.output_path, data)\n+\n+                except Exception as e:\n+                    logger.error(f\"Error writing result to file: {e}\")\n+\n+        return result\n+\n+    def generate(self, rationalization: bool = False) -> List[Dict[str, Any]]:\n+        r\"\"\"Execute the self-improving cot pipeline on all problems.\n+\n+        Process problems and return results. If output_path is specified,\n+        also save results to file.\n+\n+        Args:\n+            rationalization (bool, optional): Whether to use rationalization.\n+                (default: :obj:`False`)\n+\n+        Returns:\n+            List[Dict[str, Any]]: List of processed results\n+        \"\"\"\n+        # Pre-allocate results list\n+        self.reasoning_traces = []\n+\n+        # Process problems in batches\n+        loop = asyncio.new_event_loop()\n+        asyncio.set_event_loop(loop)\n+\n+        try:\n+            results = loop.run_until_complete(\n+                self._batch_process_problems(self.problems, rationalization)\n+            )\n+        finally:\n+            loop.close()\n+\n+        self.reasoning_traces = [result.model_dump() for result in results]\n+        return self.reasoning_traces\n+\n+    # Templates for generating reasoning, evaluation and improving them.\n+    REASONING_TEMPLATE = \"\"\"Let's solve this step by step:\n+Problem: {problem}\n+1. First, let's understand what we're asked\n+2. Let's break this down into parts\n+3. Let's solve each part systematically\n+4. Finally, let's verify our solution\n+\n+{few_shot_examples}\n+\n+Please show your complete reasoning process.\"\"\"\n+\n+    EVALUATION_TEMPLATE = \"\"\"Please evaluate this reasoning trace and \n+provide scores and feedback in valid JSON format.\n+\n+Problem: {problem}\n+\n+{solution}\n+\n+Reasoning Trace:\n+{trace}\n+\n+Evaluate for:\n+1. Correctness (Is each step logically sound?)\n+2. Clarity (Is the explanation clear and well-structured?)\n+3. Completeness (Are all necessary steps included?)\n+\n+Respond ONLY with a JSON object in this exact format:\n+{{\n+    \"correctness\": <score between 0 and 1>,\n+    \"clarity\": <score between 0 and 1>,\n+    \"completeness\": <score between 0 and 1>,\n+    \"feedback\": \"<specific feedback for improvement>\"\n+}}\"\"\"\n+\n+    IMPROVEMENT_TEMPLATE = \"\"\"Based on this feedback, generate an \n+improved reasoning trace:\n+Problem: {problem}\n+\n+{solution}\n+\n+Previous Trace:\n+{trace}\n+\n+Feedback:\n+{feedback}\n+\n+Generate a new, improved reasoning trace that addresses the feedback.\"\"\"\ndiff --git a/camel/toolkits/reddit_toolkit.py b/camel/toolkits/reddit_toolkit.py\nindex 1415a578b9..6d8f8778b0 100644\n--- a/camel/toolkits/reddit_toolkit.py\n+++ b/camel/toolkits/reddit_toolkit.py\n@@ -16,10 +16,9 @@\n import time\n from typing import Any, Dict, List, Union\n \n-from requests.exceptions import RequestException\n-\n from camel.toolkits import FunctionTool\n from camel.toolkits.base import BaseToolkit\n+from camel.utils import retry_on_error\n \n \n class RedditToolkit(BaseToolkit):\n@@ -61,30 +60,7 @@ def __init__(self, retries: int = 3, delay: int = 0):\n             request_timeout=30,  # Set a timeout to handle delays\n         )\n \n-    def _retry_request(self, func, *args, **kwargs):\n-        r\"\"\"Retries a function in case of network-related errors.\n-\n-        Args:\n-            func (callable): The function to be retried.\n-            *args: Arguments to pass to the function.\n-            **kwargs: Keyword arguments to pass to the function.\n-\n-        Returns:\n-            Any: The result of the function call if successful.\n-\n-        Raises:\n-            RequestException: If all retry attempts fail.\n-        \"\"\"\n-        for attempt in range(self.retries):\n-            try:\n-                return func(*args, **kwargs)\n-            except RequestException as e:\n-                print(f\"Attempt {attempt + 1}/{self.retries} failed: {e}\")\n-                if attempt < self.retries - 1:\n-                    time.sleep(self.delay)\n-                else:\n-                    raise\n-\n+    @retry_on_error()\n     def collect_top_posts(\n         self,\n         subreddit_name: str,\n@@ -113,8 +89,8 @@ def collect_top_posts(\n                 \"Please set the environment variables.\"\n             )\n \n-        subreddit = self._retry_request(self.reddit.subreddit, subreddit_name)\n-        top_posts = self._retry_request(subreddit.top, limit=post_limit)\n+        subreddit = self.reddit.subreddit(subreddit_name)\n+        top_posts = subreddit.top(limit=post_limit)\n         data = []\n \n         for post in top_posts:\n@@ -122,9 +98,7 @@ def collect_top_posts(\n                 \"Post Title\": post.title,\n                 \"Comments\": [\n                     {\"Comment Body\": comment.body, \"Upvotes\": comment.score}\n-                    for comment in self._retry_request(\n-                        lambda post=post: list(post.comments)\n-                    )[:comment_limit]\n+                    for comment in list(post.comments)[:comment_limit]\n                 ],\n             }\n             data.append(post_data)\n@@ -192,15 +166,11 @@ def track_keyword_discussions(\n         data = []\n \n         for subreddit_name in subreddits:\n-            subreddit = self._retry_request(\n-                self.reddit.subreddit, subreddit_name\n-            )\n-            top_posts = self._retry_request(subreddit.top, limit=post_limit)\n+            subreddit = self.reddit.subreddit(subreddit_name)\n+            top_posts = subreddit.top(limit=post_limit)\n \n             for post in top_posts:\n-                for comment in self._retry_request(\n-                    lambda post=post: list(post.comments)\n-                )[:comment_limit]:\n+                for comment in list(post.comments)[:comment_limit]:\n                     # Print comment body for debugging\n                     if any(\n                         keyword.lower() in comment.body.lower()\ndiff --git a/camel/toolkits/whatsapp_toolkit.py b/camel/toolkits/whatsapp_toolkit.py\nindex 80f778cfa4..f2859e6753 100644\n--- a/camel/toolkits/whatsapp_toolkit.py\n+++ b/camel/toolkits/whatsapp_toolkit.py\n@@ -19,7 +19,7 @@\n \n from camel.toolkits import FunctionTool\n from camel.toolkits.base import BaseToolkit\n-from camel.utils.commons import retry_request\n+from camel.utils import retry_on_error\n \n \n class WhatsAppToolkit(BaseToolkit):\n@@ -36,18 +36,8 @@ class WhatsAppToolkit(BaseToolkit):\n         version (str): API version.\n     \"\"\"\n \n-    def __init__(self, retries: int = 3, delay: int = 1):\n-        r\"\"\"Initializes the WhatsAppToolkit with the specified number of\n-        retries and delay.\n-\n-        Args:\n-            retries (int): Number of times to retry the request in case of\n-                failure. (default: :obj:`3`)\n-            delay (int): Time in seconds to wait between retries.\n-                (default: :obj:`1`)\n-        \"\"\"\n-        self.retries = retries\n-        self.delay = delay\n+    def __init__(self):\n+        r\"\"\"Initializes the WhatsAppToolkit.\"\"\"\n         self.base_url = \"https://graph.facebook.com\"\n         self.version = \"v17.0\"\n \n@@ -61,6 +51,7 @@ def __init__(self, retries: int = 3, delay: int = 1):\n                 \"WHATSAPP_PHONE_NUMBER_ID environment variables.\"\n             )\n \n+    @retry_on_error()\n     def send_message(\n         self, to: str, message: str\n     ) -> Union[Dict[str, Any], str]:\n@@ -88,19 +79,15 @@ def send_message(\n         }\n \n         try:\n-            response = retry_request(\n-                requests.post,\n-                retries=self.retries,\n-                delay=self.delay,\n-                url=url,\n-                headers=headers,\n-                json=data,\n-            )\n+            response = requests.post(url=url, headers=headers, json=data)\n             response.raise_for_status()\n             return response.json()\n+        except requests.exceptions.RequestException as e:\n+            raise e\n         except Exception as e:\n             return f\"Failed to send message: {e!s}\"\n \n+    @retry_on_error()\n     def get_message_templates(self) -> Union[List[Dict[str, Any]], str]:\n         r\"\"\"Retrieves all message templates for the WhatsApp Business account.\n \n@@ -116,18 +103,13 @@ def get_message_templates(self) -> Union[List[Dict[str, Any]], str]:\n         headers = {\"Authorization\": f\"Bearer {self.access_token}\"}\n \n         try:\n-            response = retry_request(\n-                requests.get,\n-                retries=self.retries,\n-                delay=self.delay,\n-                url=url,\n-                headers=headers,\n-            )\n+            response = requests.get(url=url, headers=headers)\n             response.raise_for_status()\n             return response.json().get(\"data\", [])\n         except Exception as e:\n             return f\"Failed to retrieve message templates: {e!s}\"\n \n+    @retry_on_error()\n     def get_business_profile(self) -> Union[Dict[str, Any], str]:\n         r\"\"\"Retrieves the WhatsApp Business profile information.\n \n@@ -149,10 +131,7 @@ def get_business_profile(self) -> Union[Dict[str, Any], str]:\n         }\n \n         try:\n-            response = retry_request(\n-                requests.get,\n-                retries=self.retries,\n-                delay=self.delay,\n+            response = requests.get(\n                 url=url,\n                 headers=headers,\n                 params=params,\ndiff --git a/camel/types/enums.py b/camel/types/enums.py\nindex dc5c0501b0..b549b8d9a7 100644\n--- a/camel/types/enums.py\n+++ b/camel/types/enums.py\n@@ -218,7 +218,11 @@ def value_for_tiktoken(self) -> str:\n \n     @property\n     def support_native_structured_output(self) -> bool:\n-        return self.is_openai\n+        return any(\n+            [\n+                self.is_openai,\n+            ]\n+        )\n \n     @property\n     def support_native_tool_calling(self) -> bool:\ndiff --git a/camel/utils/__init__.py b/camel/utils/__init__.py\nindex 448670c271..481471f3c3 100644\n--- a/camel/utils/__init__.py\n+++ b/camel/utils/__init__.py\n@@ -14,6 +14,7 @@\n \n from .commons import (\n     AgentOpsMeta,\n+    BatchProcessor,\n     agentops_decorator,\n     api_keys_required,\n     check_server_running,\n@@ -33,6 +34,7 @@\n     is_docker_running,\n     json_to_function_code,\n     print_text_animated,\n+    retry_on_error,\n     text_extract_from_web,\n     to_pascal,\n     track_agent,\n@@ -80,4 +82,6 @@\n     \"get_pydantic_model\",\n     \"download_github_subdirectory\",\n     \"generate_prompt_for_structured_output\",\n+    \"retry_on_error\",\n+    \"BatchProcessor\",\n ]\ndiff --git a/camel/utils/commons.py b/camel/utils/commons.py\nindex a131f41770..29a82f86a8 100644\n--- a/camel/utils/commons.py\n+++ b/camel/utils/commons.py\n@@ -11,7 +11,9 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+import functools\n import importlib\n+import logging\n import os\n import platform\n import re\n@@ -47,6 +49,8 @@\n \n F = TypeVar('F', bound=Callable[..., Any])\n \n+logger = logging.getLogger(__name__)\n+\n \n def print_text_animated(text, delay: float = 0.02, end: str = \"\"):\n     r\"\"\"Prints the given text with an animated effect.\n@@ -620,33 +624,206 @@ def handle_http_error(response: requests.Response) -> str:\n         return \"HTTP Error\"\n \n \n-def retry_request(\n-    func: Callable, retries: int = 3, delay: int = 1, *args: Any, **kwargs: Any\n-) -> Any:\n-    r\"\"\"Retries a function in case of any errors.\n+def retry_on_error(\n+    max_retries: int = 3, initial_delay: float = 1.0\n+) -> Callable:\n+    r\"\"\"Decorator to retry function calls on exception with exponential\n+    backoff.\n \n     Args:\n-        func (Callable): The function to be retried.\n-        retries (int): Number of retry attempts. (default: :obj:`3`)\n-        delay (int): Delay between retries in seconds. (default: :obj:`1`)\n-        *args: Arguments to pass to the function.\n-        **kwargs: Keyword arguments to pass to the function.\n+        max_retries (int): Maximum number of retry attempts\n+        initial_delay (float): Initial delay between retries in seconds\n \n     Returns:\n-        Any: The result of the function call if successful.\n+        Callable: Decorated function with retry logic\n+    \"\"\"\n \n-    Raises:\n-        Exception: If all retry attempts fail.\n+    def decorator(func: Callable) -> Callable:\n+        @functools.wraps(func)\n+        def wrapper(*args, **kwargs):\n+            delay = initial_delay\n+            last_exception = None\n+\n+            for attempt in range(max_retries + 1):\n+                try:\n+                    return func(*args, **kwargs)\n+                except Exception as e:\n+                    last_exception = e\n+                    if attempt == max_retries:\n+                        logger.error(\n+                            f\"Failed after {max_retries} retries: {e!s}\"\n+                        )\n+                        raise\n+\n+                    logger.warning(\n+                        f\"Attempt {attempt + 1} failed: {e!s}. \"\n+                        f\"Retrying in {delay:.1f}s...\"\n+                    )\n+                    time.sleep(delay)\n+                    delay *= 2  # Exponential backoff\n+\n+            raise last_exception\n+\n+        return wrapper\n+\n+    return decorator\n+\n+\n+class BatchProcessor:\n+    r\"\"\"Handles batch processing with dynamic sizing and error handling based\n+    on system load.\n     \"\"\"\n-    for attempt in range(retries):\n-        try:\n-            return func(*args, **kwargs)\n-        except Exception as e:\n-            print(f\"Attempt {attempt + 1}/{retries} failed: {e}\")\n-            if attempt < retries - 1:\n-                time.sleep(delay)\n-            else:\n-                raise\n+\n+    def __init__(\n+        self,\n+        max_workers: Optional[int] = None,\n+        initial_batch_size: Optional[int] = None,\n+        monitoring_interval: float = 5.0,\n+        cpu_threshold: float = 80.0,\n+        memory_threshold: float = 85.0,\n+    ):\n+        r\"\"\"Initialize the BatchProcessor with dynamic worker allocation.\n+\n+        Args:\n+            max_workers: Maximum number of workers. If None, will be\n+                determined dynamically based on system resources.\n+                (default: :obj:`None`)\n+            initial_batch_size: Initial size of each batch. If `None`,\n+                defaults to `10`. (default: :obj:`None`)\n+            monitoring_interval: Interval in seconds between resource checks.\n+                (default: :obj:`5.0`)\n+            cpu_threshold: CPU usage percentage threshold for scaling down.\n+                (default: :obj:`80.0`)\n+            memory_threshold: Memory usage percentage threshold for scaling\n+                down. (default: :obj:`85.0`)\n+        \"\"\"\n+        import psutil\n+\n+        self.monitoring_interval = monitoring_interval\n+        self.cpu_threshold = cpu_threshold\n+        self.memory_threshold = memory_threshold\n+        self.last_check_time = time.time()\n+        self.psutil = psutil\n+\n+        # Initialize performance metrics\n+        self.total_processed = 0\n+        self.total_errors = 0\n+        self.processing_times: List = []\n+\n+        if max_workers is None:\n+            self.max_workers = self._calculate_optimal_workers()\n+        else:\n+            self.max_workers = max_workers\n+\n+        self.batch_size = (\n+            10 if initial_batch_size is None else initial_batch_size\n+        )\n+        self.min_batch_size = 1\n+        self.max_batch_size = 20\n+        self.backoff_factor = 0.8\n+        self.success_factor = 1.2\n+\n+        # Initial resource check\n+        self._update_resource_metrics()\n+\n+    def _calculate_optimal_workers(self) -> int:\n+        r\"\"\"Calculate optimal number of workers based on system resources.\"\"\"\n+        cpu_count = self.psutil.cpu_count()\n+        cpu_percent = self.psutil.cpu_percent(interval=1)\n+        memory = self.psutil.virtual_memory()\n+\n+        # Base number of workers on CPU count and current load\n+        if cpu_percent > self.cpu_threshold:\n+            workers = max(1, cpu_count // 4)\n+        elif cpu_percent > 60:\n+            workers = max(1, cpu_count // 2)\n+        else:\n+            workers = max(1, cpu_count - 1)\n+\n+        # Further reduce if memory is constrained\n+        if memory.percent > self.memory_threshold:\n+            workers = max(1, workers // 2)\n+\n+        return workers\n+\n+    def _update_resource_metrics(self) -> None:\n+        r\"\"\"Update current resource usage metrics.\"\"\"\n+        self.current_cpu = self.psutil.cpu_percent()\n+        self.current_memory = self.psutil.virtual_memory().percent\n+        self.last_check_time = time.time()\n+\n+    def _should_check_resources(self) -> bool:\n+        r\"\"\"Determine if it's time to check resource usage again.\"\"\"\n+        return time.time() - self.last_check_time >= self.monitoring_interval\n+\n+    def adjust_batch_size(\n+        self, success: bool, processing_time: Optional[float] = None\n+    ) -> None:\n+        r\"\"\"Adjust batch size based on success/failure and system resources.\n+\n+        Args:\n+            success (bool): Whether the last batch completed successfully\n+            processing_time (Optional[float]): Time taken to process the last\n+                batch. (default: :obj:`None`)\n+        \"\"\"\n+        # Update metrics\n+        self.total_processed += 1\n+        if not success:\n+            self.total_errors += 1\n+        if processing_time is not None:\n+            self.processing_times.append(processing_time)\n+\n+        # Check system resources if interval has elapsed\n+        if self._should_check_resources():\n+            self._update_resource_metrics()\n+\n+            # Adjust based on resource usage\n+            if (\n+                self.current_cpu > self.cpu_threshold\n+                or self.current_memory > self.memory_threshold\n+            ):\n+                self.batch_size = max(\n+                    int(self.batch_size * self.backoff_factor),\n+                    self.min_batch_size,\n+                )\n+                self.max_workers = max(1, self.max_workers - 1)\n+                return\n+\n+        # Adjust based on success/failure\n+        if success:\n+            self.batch_size = min(\n+                int(self.batch_size * self.success_factor), self.max_batch_size\n+            )\n+        else:\n+            self.batch_size = max(\n+                int(self.batch_size * self.backoff_factor), self.min_batch_size\n+            )\n+\n+    def get_performance_metrics(self) -> Dict[str, Any]:\n+        r\"\"\"Get current performance metrics.\n+\n+        Returns:\n+            Dict containing performance metrics including:\n+            - total_processed: Total number of batches processed\n+            - error_rate: Percentage of failed batches\n+            - avg_processing_time: Average time per batch\n+            - current_batch_size: Current batch size\n+            - current_workers: Current number of workers\n+            - current_cpu: Current CPU usage percentage\n+            - current_memory: Current memory usage percentage\n+        \"\"\"\n+        metrics = {\n+            \"total_processed\": self.total_processed,\n+            \"error_rate\": (self.total_errors / max(1, self.total_processed))\n+            * 100,\n+            \"avg_processing_time\": sum(self.processing_times)\n+            / max(1, len(self.processing_times)),\n+            \"current_batch_size\": self.batch_size,\n+            \"current_workers\": self.max_workers,\n+            \"current_cpu\": self.current_cpu,\n+            \"current_memory\": self.current_memory,\n+        }\n+        return metrics\n \n \n def download_github_subdirectory(\ndiff --git a/docs/camel.rst b/docs/camel.rst\nindex 449642d530..740b64a111 100644\n--- a/docs/camel.rst\n+++ b/docs/camel.rst\n@@ -9,6 +9,7 @@ Subpackages\n \n    camel.agents\n    camel.configs\n+   camel.datagen\n    camel.embeddings\n    camel.interpreters\n    camel.loaders\ndiff --git a/docs/cookbooks/data_generation/index.rst b/docs/cookbooks/data_generation/index.rst\nindex 91fa5114ac..1cda3b3171 100644\n--- a/docs/cookbooks/data_generation/index.rst\n+++ b/docs/cookbooks/data_generation/index.rst\n@@ -21,3 +21,4 @@ Agentic Data Generation\n    data_model_generation_and_structured_output_with_qwen\n    distill_math_reasoning_data_from_deepseek_r1\n    self_improving_math_reasoning_data_distillation_from_deepSeek_r1\n+   self_improving_cot_generation\ndiff --git a/docs/cookbooks/data_generation/self_improving_cot_generation.md b/docs/cookbooks/data_generation/self_improving_cot_generation.md\nnew file mode 100644\nindex 0000000000..33382503b6\n--- /dev/null\n+++ b/docs/cookbooks/data_generation/self_improving_cot_generation.md\n@@ -0,0 +1,345 @@\n+# Deep Dive into CAMEL\u2019s Practices for Self-Improving CoT Generation \ud83d\ude80\n+\n+The field of AI is rapidly evolving, with reasoning models playing a crucial role in enhancing the problem-solving capabilities of large language models (LLMs). Recent developments, such as DeepSeek's R1 and OpenAI's o3-mini, demonstrate the industry's commitment to advancing reasoning through innovative approaches.\n+\n+DeepSeek's R1 model, introduced in January 2025, has shown remarkable proficiency in tasks that require complex reasoning and code generation. Its exceptional performance in areas like mathematics, science, and programming is particularly noteworthy.\n+\n+By distilling Chain-of-Thought (CoT) data from reasoning models, we can generate high-quality reasoning traces that are more accurate in solving complex problems. These generated data can be used to further fine-tune another LLM with less parameters, thereby enhancing its reasoning ability.\n+\n+CAMEL developed an approach leverages iterative refinement, self-assessment, and efficient batch processing to enable the continuous improvement of reasoning traces. In this blog, we will delve into how CAMEL implements its self-improving CoT pipeline.\n+\n+---\n+\n+## 1. Overview of the End-to-End Pipeline \ud83d\udd0d\n+\n+### 1.1 Why an Iterative CoT Pipeline? \n+\n+One-time CoT generation often leads to incomplete or suboptimal solutions. CAMEL addresses this challenge by employing a multi-step, iterative approach:\n+\n+1. **Generate** an initial reasoning trace.\n+2. **Evaluate** the trace through either a dedicated evaluation agent or a specialized reward model.\n+3. **Refine** the trace based on the feedback provided.\n+\n+This self-improving methodology ensures that the reasoning process improves progressively, meeting specific thresholds for correctness, clarity, and completeness. Each iteration enhances the model's ability to solve the problem by learning from the previous outputs and evaluations.\n+\n+### 1.2 Core Components \n+\n+The self-improving pipeline consists of three key components:\n+1. **`reason_agent`:** This agent is responsible for generating or improving reasoning traces.\n+2. **`evaluate_agent`:** An optional agent that evaluates the quality of the reasoning trace. This can be replaced by a reward model if needed.\n+3. **`reward_model`:** An optional model that provides numerical feedback on the trace, evaluating dimensions such as correctness, coherence, complexity, and verbosity.\n+\n+Here's a high-level diagram of the pipeline:\n+\n+![Self-Improving CoT Pipeline](https://i.postimg.cc/DygTcWd6/download.png)\n+\n+---\n+\n+## 2. Generation of CoT Data: The Heart of the Pipeline \ud83e\udd16\n+\n+Generating CoT data is at the core of the pipeline. Below, we outline the process in detail.\n+\n+### 2.1 Initial Trace Generation \ud83d\udc23\n+\n+The first step in the process is the generation of an initial reasoning trace. The **`reason_agent`** plays a central role here, creating a coherent and logical explanation of how to solve a given problem. The agent breaks down the problem into smaller steps, illustrating the thought process at each stage. We also support the use of non-reasoning LLMs to generate traces through prompt engineering.\n+\n+The generation could also guided by **few-shot examples**, which provide context and help the agent understand the desired reasoning style. Here\u2019s how this is accomplished:\n+\n+- **Input**: The problem statement is provided to the **`reason_agent`**, we can optionally provide the ground truth to guide the reasoning process.\n+- **Output**: The agent generates a sequence of reasoning content.\n+\n+This initial generation serves as a foundational reasoning process that can be directly useful or further refined.\n+\n+### 2.2 Evaluation of the Initial Trace \ud83d\udcd2\n+\n+Once the reasoning trace is generated, it is evaluated for its quality. This evaluation serves two purposes:\n+\n+- **Detecting weaknesses**: The evaluation identifies areas where the reasoning trace could be further improved.\n+- **Providing feedback**: The evaluation produces feedback that guides the agent in refining the reasoning trace. This feedback can come from either the **`evaluate_agent`** or a **`reward_model`**.\n+\n+#### 2.2.1 Agent-Based Evaluation \n+\n+If an **`evaluate_agent`** is available, it examines the reasoning trace for:\n+1. **Correctness**: Does the trace logically solve the problem?\n+2. **Clarity**: Is the reasoning easy to follow and well-structured?\n+3. **Completeness**: Are all necessary steps included in the reasoning?\n+\n+The feedback from the agent provides insights into areas for improvement, such as unclear reasoning or incorrect answers, offering a more generalized approach compared to rule-based matching.\n+\n+#### 2.2.2 Reward Model Evaluation \n+\n+Alternatively, the pipeline supports using a **reward model** to evaluate the trace. The reward model outputs scores based on predefined dimensions such as correctness, coherence, complexity, and verbosity.\n+\n+---\n+\n+### 2.3 Iterative Refinement: The Self-Improving Cycle \ud83d\udd01\n+\n+The key to CAMEL's success in CoT generation is its **self-improving loop**. After the initial trace is generated and evaluated, the model refines the trace based on the evaluation feedback. This process is repeated in a loop.\n+\n+#### How does this iterative refinement work?\n+\n+1. **Feedback Integration**: The feedback from the evaluation phase is used to refine the reasoning. This could involve rewording unclear parts, adding missing steps, or adjusting the logic to make it more correct or complete.\n+   \n+2. **Improvement through Reasoning**: After receiving feedback, the **`reason_agent`** is used again to generate an improved version of the reasoning trace. This trace incorporates the feedback provided, refining the earlier steps and enhancing the overall reasoning.\n+\n+3. **Re-evaluation**: Once the trace is improved, the new version is evaluated again using the same process (either agent-based evaluation or reward model). This new trace is assessed against the same criteria to ensure the improvements have been made.\n+\n+4. **Threshold Check**: The iterative process continues until the desired quality thresholds are met or reached the maximum number of iterations.\n+\n+---\n+\n+## 3. Pipeline Setup in Code \ud83d\udcbb\n+\n+Below is a truncated version of our pipeline initialization. We encapsulate logic in a class called `SelfImprovingCoTPipeline`:\n+\n+```python\n+class SelfImprovingCoTPipeline:\n+    def __init__(\n+        self,\n+        reason_agent: ChatAgent,\n+        problems: List[Dict],\n+        max_iterations: int = 3,\n+        score_threshold: Union[float, Dict[str, float]] = 0.7,\n+        evaluate_agent: Optional[ChatAgent] = None,\n+        reward_model: Optional[BaseRewardModel] = None,\n+        output_path: Optional[str] = None,\n+        few_shot_examples: Optional[str] = None,\n+        batch_size: Optional[int] = None,\n+        max_workers: Optional[int] = None,\n+        solution_pattern: str = r'\\\\boxed{(.*?)}',\n+        trace_pattern: Optional[str] = None,\n+    ):\n+        r\"\"\"Initialize the STaR pipeline.\n+\n+        Args:\n+            reason_agent (ChatAgent): The chat agent used for generating and\n+                improving reasoning traces.\n+            problems (List[Dict]): List of problem dictionaries to process.\n+            max_iterations (int, optional): Maximum number of improvement\n+                iterations. If set to `0`, the pipeline will generate an\n+                initial trace without any improvement iterations.\n+                (default: :obj:`3`)\n+            score_threshold (Union[float, Dict[str, float]], optional):\n+                Quality threshold. Can be either a single float value applied\n+                to average score, or a dictionary mapping score dimensions to\n+                their thresholds. For example: {\"correctness\": 0.8,\n+                \"coherence\": 0.7}. If using reward model and threshold for a\n+                dimension is not specified, will use the default value 0.7.\n+                (default: :obj:`0.7`)\n+            evaluate_agent (Optional[ChatAgent]): The chat agent used for\n+                evaluating reasoning traces. (default: :obj:`None`)\n+            reward_model (BaseRewardModel, optional): Model used to evaluate\n+                reasoning traces. If `None`, uses Agent self-evaluation.\n+                (default: :obj:`None`)\n+            output_path (str, optional): Output path for saving traces. If\n+                `None`, results will only be returned without saving to file.\n+                (default: :obj:`None`)\n+            few_shot_examples (str, optional): Examples to use for few-shot\n+                generation. (default: :obj:`None`)\n+            batch_size (int, optional): Batch size for parallel processing.\n+                (default: :obj:`None`)\n+            max_workers (int, optional): Maximum number of worker threads.\n+                (default: :obj:`None`)\n+            solution_pattern (str, optional): Regular expression pattern with\n+                one capture group to extract answers from solution text.\n+                (default: :obj:`r'\\\\boxed{(.*?)}'`)\n+            trace_pattern (str, optional): Regular expression pattern with one\n+                capture group to extract answers from trace text. If `None`,\n+                uses the same pattern as solution_pattern.\n+                (default: :obj:`None`)\n+        \"\"\"\n+        ...\n+```\n+\n+**Example usage:**\n+\n+```python\n+from camel.agents import ChatAgent\n+from camel.datagen import SelfImprovingCoTPipeline\n+\n+# Initialize agents\n+reason_agent = ChatAgent(\n+    \"You are a struggling student who finds solving math problems challenging. \"\n+    \"Your reasoning process is often flawed or lacks clarity when explaining \"\n+    \"your answers to others.\"\n+)\n+\n+evaluate_agent = ChatAgent(\n+    \"You are a highly critical teacher who evaluates the student's answers \"\n+    \"with a meticulous and demanding approach.\"\n+)\n+\n+# Prepare your problems\n+problems = [\n+    {\"problem\": \"Your problem text here\"},\n+    # Add more problems...\n+]\n+\n+# Create and run the pipeline\n+pipeline = SelfImprovingCoTPipeline(\n+    reason_agent=reason_agent,\n+    evaluate_agent=evaluate_agent,\n+    problems=problems,\n+    max_iterations=3,\n+    output_path=\"star_output.json\"\n+)\n+\n+results = pipeline.generate()\n+```\n+\n+---\n+\n+## 4. Batch Processing & API Request Handling \ud83d\udce6\n+\n+### 4.1 The Need for Batch Processing \u23f0\n+\n+Early on, we tried generating CoT reasoning for each problem one by one. This approach quickly revealed two major issues:\n+\n+1. **Time consumption**: Sequential processing doesn't scale to large problem sets.\n+2. **API request bottlenecks**: Slowdowns or occasional disconnections occurred when handling numerous calls.\n+\n+Hence, we introduced a parallel **`BatchProcessor`** to:\n+\n+- Split the tasks into manageable batches.\n+- Dynamically adjust batch size (`batch_size`) based on the success/failure rates and system resource usage (CPU/memory).\n+- Retry on transient errors or API timeouts to maintain a stable flow.\n+\n+Below shows how we batch-process multiple problems:\n+\n+```python\n+async def _batch_process_problems(\n+    self, problems: List[Dict], rationalization: bool\n+) -> List[ProblemResult]:\n+    results = []\n+    total_problems = len(problems)\n+    processed = 0\n+\n+    while processed < total_problems:\n+        batch_size = self.batch_processor.batch_size\n+        batch = problems[processed : processed + batch_size]\n+        batch_start_time = time.time()\n+\n+        with ThreadPoolExecutor(max_workers=self.batch_processor.max_workers) as executor:\n+            futures = [\n+                executor.submit(\n+                    self.process_problem,\n+                    problem=problem,\n+                    rationalization=rationalization,\n+                )\n+                for problem in batch\n+            ]\n+            ...\n+        processed += len(batch)\n+        ...\n+        # Log progress & performance\n+```\n+\n+### 4.2 Handling API Instability \ud83d\udea8\n+\n+Even with batching, API requests for LLMs can fail due to network fluctuations or remote server instability. We implemented a `retry_on_error` decorator:\n+\n+```python\n+def retry_on_error(\n+    max_retries: int = 3, initial_delay: float = 1.0\n+) -> Callable:\n+    def decorator(func: Callable) -> Callable:\n+        @functools.wraps(func)\n+        def wrapper(*args, **kwargs):\n+            delay = initial_delay\n+            for attempt in range(max_retries + 1):\n+                try:\n+                    return func(*args, **kwargs)\n+                except Exception as e:\n+                    if attempt == max_retries:\n+                        raise\n+                    time.sleep(delay)\n+                    delay *= 2\n+            raise\n+        return wrapper\n+    return decorator\n+```\n+\n+Whenever we invoke LLM calls for generation, evaluation, or improvement, these decorated methods gracefully handle transient errors by retrying with exponential backoff (doubling the wait time after each failed attempt).\n+\n+---\n+\n+## 5. Model Switching & Dynamic File Writing \ud83d\udcdd\n+\n+### 5.1 Flexible Model Scheduling \ud83d\udd52\n+\n+In CAMEL's CoT pipeline, adding models to the `ChatAgent` is useful for handling errors and ensuring smooth operation. This setup allows the system to switch between models as needed, maintaining reasoning continuity.\n+\n+To add models to a `ChatAgent`, you can create instances of models and include them in the agent's model list:\n+\n+```python\n+model1 = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEEPSEEK,\n+    model_type=\"deepseek-reasoner\",\n+    ...\n+)\n+\n+model2 = ModelFactory.create(\n+    model_platform=ModelPlatformType.TOGETHER,\n+    model_type=\"deepseek-reasoner\",\n+    ...\n+)\n+\n+agent = ChatAgent(\n+    system_message,\n+    model=[model1, model2]\n+)\n+```\n+\n+By incorporating multiple models, CAMEL can effectively manage model availability and ensure robust error handling.\n+\n+### 5.2 Real-Time JSON Updates \ud83d\udd04\n+\n+As soon as a problem\u2019s results are ready, we lock the file (`output_path`) and update it in-place\u2014rather than saving everything at the very end. This ensures data integrity if the process is interrupted partway through.\n+\n+```python\n+def safe_write_json(self, file_path, data):\n+    temp_path = file_path + \".tmp\"\n+    with open(temp_path, \"w\") as f:\n+        json.dump(data, f, indent=2)\n+    os.replace(temp_path, file_path)\n+```\n+\n+This two-step write (to a `.tmp` file then replace) prevents partial writes from corrupting the output file.\n+\n+---\n+\n+## 6. CAMEL\u2019s Next Steps in CoT Data Generation \ud83d\ude80\n+\n+1. **Real-Time Monitoring Dashboard**: Visualize throughput, error rates, running cost, data quality, etc. for smooth operational oversight.\n+2. **Performance Enhancements**: Further improve performance and add more error handling to make the system more robust.\n+3. **Cutting-Edge Research Solutions**: Integrate more cutting-edge research solutions for synthetic data generation.\n+4. **Rejection Sampling**: Integrate rejection sampling method to the SelfImprovingCoT pipeline.\n+\n+---\n+\n+## Conclusion \ud83d\udcda\n+\n+CAMEL\u2019s self-improving pipeline exemplifies a comprehensive approach to Chain-of-Thought data generation:\n+\n+- **Flexible Evaluation**: Utilizing agent-based or reward-model-based evaluation provides adaptable scoring and feedback loops.\n+- **Continuous Improvement**: Iterative refinement ensures each reasoning trace is enhanced until it meets the desired quality.\n+- **Efficient Processing**: Batched concurrency increases throughput while maintaining system balance.\n+- **Robust Stability**: Error-tolerant mechanisms with retries enhance system reliability.\n+- **Consistent Output**: Dynamic file writing ensures partial results are consistently preserved and valid.\n+\n+Looking ahead, CAMEL\u2019s roadmap is dedicated to pioneering advanced synthetic data generation methods, integrating cutting-edge research and technology.\n+\n+_Stay tuned for more updates on CAMEL's journey in advancing agentic synthetic data generation!_\n+\n+---\n+\n+**Further Reading & Resources**\n+\n+- **CAMEL GitHub**: Explore our open-source projects on [GitHub](https://github.com/camel-ai/camel) and give us a \ud83c\udf1fstar.\n+\n+**Data Generation Cookbooks**\n+\n+- [Self-Improving Math Reasoning Data Distillation](https://docs.camel-ai.org/cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.html)\n+- [Generating High-Quality SFT Data with CAMEL](https://docs.camel-ai.org/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_Qwen2_5_7B.html)\n+- [Function Call Data Generation and Evaluation](https://docs.camel-ai.org/cookbooks/data_generation/data_gen_with_real_function_calls_and_hermes_format.html)\n+- [Agentic Data Generation, Evaluation & Filtering with Reward Models](https://docs.camel-ai.org/cookbooks/data_generation/synthetic_dataevaluation%26filter_with_reward_model.html)\n\\ No newline at end of file\ndiff --git a/docs/key_modules/datagen.md b/docs/key_modules/datagen.md\nnew file mode 100644\nindex 0000000000..25f15bddbc\n--- /dev/null\n+++ b/docs/key_modules/datagen.md\n@@ -0,0 +1,493 @@\n+# Data Generation Modules\n+\n+This document describes the key data generation modules in CAMEL: Chain of Thought (CoT), Self-Instruct, Source2Synth, and STaR.\n+\n+## Chain of Thought (CoT) Data Generation\n+\n+### Overview\n+\n+The Chain of Thought (CoT) data generation module implements a sophisticated system for generating high-quality reasoning paths through chat agent interactions. It combines several advanced algorithms to produce and validate reasoning chains.\n+\n+### Key Features\n+\n+- Monte Carlo Tree Search (MCTS) for solution exploration\n+- Binary Search Error Detection for precise error localization\n+- Dual-Agent Verification System for quality assurance\n+- Solution Tree Management for tracking reasoning paths\n+\n+### Core Components\n+\n+#### CoTDataGenerator Class\n+\n+The main class that implements the CoT generation system with the following capabilities:\n+\n+- **Dual-Agent Architecture**: Supports both single-agent (legacy) and dual-agent modes\n+- **Answer Generation**: Sophisticated answer generation with MCTS\n+- **Answer Verification**: Robust verification system using golden answers\n+- **Error Detection**: Binary search-based error detection in solutions\n+- **Solution Management**: Comprehensive solution tree management and export\n+\n+### Usage\n+\n+#### Basic Example\n+\n+```python\n+from camel.agents import ChatAgent\n+from camel.datagen import CoTDataGenerator\n+\n+# Initialize agents\n+generator_agent = ChatAgent(\"System message for generator\")\n+verifier_agent = ChatAgent(\"System message for verifier\")\n+\n+# Define golden answers\n+golden_answers = {\n+    \"question1\": \"answer1\",\n+    \"question2\": \"answer2\"\n+}\n+\n+# Create generator\n+cot_generator = CoTDataGenerator(\n+    generator_agent=generator_agent,\n+    verifier_agent=verifier_agent,\n+    golden_answers=golden_answers,\n+    search_limit=100\n+)\n+\n+# Generate solution\n+solution = cot_generator.solve(\"question1\")\n+```\n+\n+#### Data Import/Export\n+\n+```python\n+# Import QA pairs from JSON\n+cot_generator.import_qa_from_json(\"qa_pairs.json\")\n+\n+# Export solutions\n+cot_generator.export_solutions(\"solutions.json\")\n+```\n+\n+### Solution Generation Process\n+\n+1. **Direct Solution Attempt**\n+   - First tries to solve the problem directly\n+   - Verifies against golden answer\n+\n+2. **MCTS-based Exploration**\n+   - If direct solution fails, uses MCTS to explore solution space\n+   - Builds solution tree based on previous attempts\n+\n+3. **Error Detection and Correction**\n+   - Uses binary search to locate errors in solutions\n+   - Generates new solutions based on correct parts\n+\n+4. **Solution Verification**\n+   - Verifies solutions using dual-agent system or golden answers\n+   - Maintains solution quality through strict verification\n+\n+### Configuration Options\n+\n+- `search_limit`: Maximum number of search iterations (default: 100)\n+- `generator_agent`: Specialized agent for answer generation\n+- `verifier_agent`: Specialized agent for answer verification\n+- `golden_answers`: Pre-defined correct answers for validation\n+\n+### Output Format\n+\n+The solution tree is exported in JSON format containing:\n+- Solutions with intermediate steps\n+- Golden answers used for verification\n+- Export timestamp\n+- Solution scores and verification results\n+\n+\n+## Self-Instruct: Instruction Generation\n+\n+### Overview\n+\n+The Self-Instruct module implements a pipeline for generating and managing machine-generated instructions for tasks. It combines human-written seed instructions with machine-generated ones to create diverse, high-quality task instructions, while ensuring quality through configurable filtering mechanisms.\n+\n+### Core Components\n+\n+#### Self Instruct Pipeline\n+\n+The main pipeline class that orchestrates the instruction generation process.\n+\n+Key Features:\n+- Combines human-written and machine-generated instructions using configurable ratios\n+- Supports classification and non-classification task types\n+- Built-in instruction filtering and validation\n+- Automatic instance generation for tasks\n+- JSON-based data input/output\n+\n+#### Instruction Filter\n+\n+A comprehensive filtering system for validating and filtering generated instructions.\n+\n+Features:\n+- Length-based filtering\n+- Keyword filtering\n+- Punctuation checks\n+- Non-English text detection\n+- ROUGE similarity filtering for deduplication\n+- Extensible filter registry for custom filters\n+\n+### Usage\n+\n+#### Basic Example\n+\n+```python\n+from camel.agents import ChatAgent\n+from camel.datagen.self_instruct import SelfInstructPipeline\n+\n+# Initialize agent\n+agent = ChatAgent()\n+\n+# Create pipeline with default settings\n+pipeline = SelfInstructPipeline(\n+    agent=agent,\n+    seed='seed_tasks.jsonl',  # Path to human-written seed tasks\n+    num_machine_instructions=5,\n+    data_output_path='./data_output.json',\n+    human_to_machine_ratio=(6, 2)  # Use 6 human tasks and 2 machine tasks for generation\n+)\n+\n+# Generate instructions\n+pipeline.generate()\n+```\n+\n+#### Custom Filtering\n+\n+```python\n+from camel.datagen.self_instruct import SelfInstructPipeline\n+from camel.datagen.self_instruct.filter import InstructionFilter\n+\n+# Configure filters\n+filter_config = {\n+    \"length\": {},  # Default length constraints\n+    \"keyword\": {},  # Keyword-based filtering\n+    \"punctuation\": {},  # Punctuation checks\n+    \"non_english\": {},  # Non-English text detection\n+    \"rouge_similarity\": {  # ROUGE-based similarity filtering\n+        \"threshold\": 0.7,\n+        \"metric\": \"rouge-l\"\n+    }\n+}\n+\n+# Create pipeline with custom filter configuration\n+pipeline = SelfInstructPipeline(\n+    agent=agent,\n+    seed='seed_tasks.jsonl',\n+    instruction_filter=InstructionFilter(filter_config),\n+    num_machine_instructions=5\n+)\n+```\n+\n+### Configuration Options\n+\n+#### Pipeline Parameters\n+\n+- `agent`: ChatAgent instance for generating instructions\n+- `seed`: Path to human-written seed tasks in JSONL format\n+- `num_machine_instructions`: Number of machine-generated instructions to generate (default: 5)\n+- `data_output_path`: Path for saving generated data (default: './data_output.json')\n+- `human_to_machine_ratio`: Ratio of human to machine tasks for generation (default: (6, 2))\n+- `instruction_filter`: Custom InstructionFilter instance (optional)\n+- `filter_config`: Configuration dictionary for default filters (optional)\n+\n+#### Filter Configuration\n+\n+The default filter configuration includes:\n+- `length`: Configure length constraints for instructions\n+- `keyword`: Set up keyword-based filtering rules\n+- `punctuation`: Define punctuation validation rules\n+- `non_english`: Configure non-English text detection\n+- `rouge_similarity`: Set ROUGE similarity thresholds for deduplication\n+\n+### Pipeline Stages\n+\n+1. **Seed Loading**\n+   - Load human-written instructions from JSONL file\n+   - Validate seed format\n+   - Initialize task storage\n+\n+2. **Instruction Generation**\n+   - Sample human and machine tasks based on ratio\n+   - Generate new instructions using ChatAgent\n+   - Apply instruction filters\n+\n+3. **Task Classification**\n+   - Identify if tasks are classification or non-classification\n+   - Generate appropriate prompts based on task type\n+\n+4. **Instance Generation**\n+   - Generate input-output pairs for each task\n+   - Parse and format instances based on task type\n+   - Apply quality filters\n+\n+5. **Data Output**\n+   - Save generated tasks and instances to JSON\n+   - Include metadata and configuration details\n+   - Maintain structured output format\n+\n+### Input/Output Format\n+\n+#### Seed Tasks (Input)\n+```jsonl\n+{\"instruction\": \"Classify the sentiment of this text as positive or negative.\"}\n+{\"instruction\": \"Generate a summary of the given paragraph.\"}\n+```\n+\n+#### Generated Data (Output)\n+```json\n+{\n+  \"machine_instructions\": [\n+    {\n+      \"instruction\": \"...\",\n+      \"is_classification\": true,\n+      \"instances\": [\n+        {\n+          \"input\": \"...\",\n+          \"output\": \"...\"\n+        }\n+      ]\n+    }\n+  ]\n+}\n+```\n+\n+\n+## Source2Synth: Multi-hop Question-Answer Generation\n+\n+### Overview\n+\n+Source2Synth is a sophisticated data generation system designed to create multi-hop question-answer pairs from source text data. It implements a pipeline that processes raw text, extracts information pairs, and generates complex, multi-hop reasoning questions with configurable complexity thresholds.\n+\n+### Core Components\n+\n+#### UserDataProcessor\n+\n+The main orchestrator class that manages the entire pipeline from text processing to dataset generation.\n+\n+Features:\n+- Single text and batch processing capabilities\n+- Configurable AI model or rule-based processing\n+- Integration with MultiHopGeneratorAgent for QA generation\n+- Random seed control for reproducibility\n+\n+#### ExampleConstructor\n+\n+Handles the construction of training examples from raw text data.\n+\n+Features:\n+- Text preprocessing and quality validation\n+- Information pair extraction with premise-intermediate-conclusion relationships\n+- Multi-hop QA pair generation using AI or rule-based approaches\n+- Complexity scoring for generated examples\n+\n+#### DataCurator\n+\n+Manages and curates datasets of multi-hop question-answer pairs.\n+\n+Features:\n+- Quality filtering based on configurable criteria\n+- Complexity threshold filtering\n+- Deduplication of similar examples\n+- Dataset sampling to achieve target size\n+- Random seed control for reproducible sampling\n+\n+### Usage\n+\n+#### Basic Example\n+\n+```python\n+from camel.datagen.source2synth import (\n+    UserDataProcessor,\n+    ProcessorConfig\n+)\n+\n+# Create configuration\n+config = ProcessorConfig(\n+    seed=42,\n+    min_length=50,\n+    max_length=1000,\n+    complexity_threshold=0.5,\n+    dataset_size=10,\n+    use_ai_model=True,\n+)\n+\n+# Initialize processor\n+processor = UserDataProcessor(config)\n+\n+# Process a single text\n+result = processor.process_text(\n+    \"Your source text here\",\n+    source=\"example_source\"\n+)\n+\n+# Process multiple texts\n+texts = [\"Text 1\", \"Text 2\", \"Text 3\"]\n+sources = [\"source1\", \"source2\", \"source3\"]\n+batch_results = processor.process_batch(texts, sources)\n+```\n+\n+### Configuration Options\n+\n+#### ProcessorConfig\n+\n+Key parameters:\n+- `seed`: Random seed for reproducibility\n+- `min_length`: Minimum text length for processing\n+- `max_length`: Maximum text length for processing\n+- `complexity_threshold`: Minimum complexity score (0.0-1.0)\n+- `dataset_size`: Target size for the final dataset\n+- `use_ai_model`: Toggle between AI model and rule-based processing\n+- `hop_generating_agent`: Custom MultiHopGeneratorAgent instance (optional)\n+\n+### Pipeline Stages\n+\n+1. **Text Preprocessing**\n+   - Length validation\n+   - Quality checks\n+   - Text standardization\n+\n+2. **Information Extraction**\n+   - Premise identification\n+   - Intermediate relationship extraction\n+   - Conclusion formation\n+\n+3. **QA Generation**\n+   - Multi-hop question generation\n+   - Answer validation\n+   - Complexity scoring\n+\n+4. **Dataset Curation**\n+   - Quality filtering\n+   - Complexity thresholding\n+   - Deduplication\n+   - Target size sampling\n+\n+\n+## Self-Improving CoT Data Generation\n+\n+### Overview\n+\n+The Self-Improving CoT Data Generation pipeline implements an iterative approach to generate and improve reasoning traces for problem-solving tasks. This implementation is based on the methodology of self-taught reasoning, where an AI agent learns to improve its reasoning process through self-evaluation and feedback.\n+\n+### Architecture\n+\n+The pipeline consists of four main stages:\n+1. Initial reasoning trace generation\n+2. Self-evaluation\n+3. Feedback-based improvement\n+4. Iterative refinement\n+\n+### Key Components\n+\n+#### SelfImprovingCoTPipeline Class\n+\n+The core class that implements the STaR methodology with the following features:\n+- Customizable reasoning and evaluation agents\n+- Support for both agent-based evaluation and external reward models\n+- Configurable quality thresholds for different evaluation dimensions\n+- Iterative improvement process with customizable maximum iterations\n+- Optional few-shot examples for better reasoning generation\n+- Flexible output formats and file saving options\n+\n+### Usage\n+\n+#### Basic Example\n+\n+```python\n+from camel.agents import ChatAgent\n+from camel.datagen import SelfImprovingCoTPipeline\n+\n+# Initialize agents\n+reason_agent = ChatAgent(\n+    \"You are a struggling student who finds solving math problems challenging. \"\n+    \"Your reasoning process is often flawed or lacks clarity when explaining \"\n+    \"your answers to others.\"\n+)\n+\n+evaluate_agent = ChatAgent(\n+    \"You are a highly critical teacher who evaluates the student's answers \"\n+    \"with a meticulous and demanding approach.\"\n+)\n+\n+# Prepare your problems\n+problems = [\n+    {\"problem\": \"Your problem text here\"},\n+    # Add more problems...\n+]\n+\n+# Create and run the pipeline\n+pipeline = SelfImprovingCoTPipeline(\n+    reason_agent=reason_agent,\n+    evaluate_agent=evaluate_agent,\n+    problems=problems,\n+    max_iterations=3,\n+    output_path=\"star_output.json\"\n+)\n+\n+results = pipeline.generate()\n+```\n+\n+#### Advanced Usage with External Reward Models\n+\n+```python\n+from camel.models.reward import NemotronRewardModel\n+\n+# Initialize reward model\n+reward_model = NemotronRewardModel(\n+    model_type=ModelType.NVIDIA_NEMOTRON_340B_REWARD,\n+    url=\"https://integrate.api.nvidia.com/v1\",\n+    api_key=\"your_api_key\"\n+)\n+\n+# Create pipeline with reward model\n+pipeline = SelfImprovingCoTPipeline(\n+    reason_agent=reason_agent,\n+    evaluate_agent=evaluate_agent,\n+    problems=problems,\n+    reward_model=reward_model,\n+    score_threshold={\n+        \"correctness\": 0.8,\n+        \"clarity\": 0.7,\n+        \"completeness\": 0.7\n+    }\n+)\n+```\n+\n+### Input/Output Formats\n+\n+#### Input Format\n+\n+The pipeline expects problems in a JSON format:\n+\n+```json\n+{\n+    \"problems\": [\n+        {\n+            \"problem\": \"Problem text here\",\n+            \"solution\": \"Optional solution text\"\n+        }\n+    ]\n+}\n+```\n+\n+#### Output Format\n+\n+The pipeline generates output in JSON format containing:\n+- Original problem\n+- Final reasoning trace\n+- Improvement history with iterations\n+- Evaluation scores and feedback for each iteration\n+\n+### Configuration Options\n+\n+- `max_iterations`: Maximum number of improvement iterations (default: 3)\n+- `score_threshold`: Quality thresholds for evaluation dimensions (default: 0.7)\n+- `few_shot_examples`: Optional examples for few-shot learning\n+- `output_path`: Path for saving results (optional)\n+\n+\ndiff --git a/examples/datagen/self_improving_cot/download_math_datasets.py b/examples/datagen/self_improving_cot/download_math_datasets.py\nnew file mode 100644\nindex 0000000000..1765216b6f\n--- /dev/null\n+++ b/examples/datagen/self_improving_cot/download_math_datasets.py\n@@ -0,0 +1,121 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+import json\n+import uuid\n+from pathlib import Path\n+\n+from datasets import load_dataset\n+\n+\n+def download_gsm8k_dataset():\n+    try:\n+        # Load the dataset using the datasets library\n+        dataset = load_dataset(\"openai/gsm8k\", \"main\")\n+\n+        # Get only 20 items from train split\n+        data = dataset['train'].select(range(10))\n+\n+        # Convert to the desired format\n+        formatted_data = []\n+        for item in data:\n+            # Extract the final answer from the solution\n+            solution = item['answer']\n+            if solution:\n+                # GSM8K solutions typically end with \"#### number\"\n+                import re\n+\n+                match = re.search(r'####\\s*(\\d+)', solution)\n+                if match:\n+                    number = match.group(1)\n+                    # Replace the \"#### number\" with \"\\boxed{number}\"\n+                    solution = re.sub(\n+                        r'####\\s*\\d+', f'\\\\\\\\boxed{{{number}}}', solution\n+                    )\n+\n+            formatted_item = {\n+                \"id\": str(uuid.uuid4()),  # GSM8K doesn't provide IDs\n+                \"problem\": item['question'],\n+                \"type\": \"openai/gsm8k\",  # All problems are from GSM8K\n+                \"solution\": solution,  # Use the modified solution with \\boxed\n+                \"evaluate_success\": False,\n+                \"boxed_answer_success\": True,\n+                \"improvement_history\": [],\n+            }\n+            formatted_data.append(formatted_item)\n+\n+        # Create output directory if it doesn't exist\n+        output_dir = Path(\"examples/datagen/star\")\n+        output_dir.mkdir(exist_ok=True)\n+\n+        # Save all data to a single JSON file\n+        output_file = output_dir / \"gsm8k_dataset.json\"\n+        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n+            json.dump(formatted_data, f, indent=4, ensure_ascii=False)\n+        print(\n+            f\"Successfully saved {len(formatted_data)} records \"\n+            f\"to {output_file}\"\n+        )\n+\n+        return formatted_data\n+\n+    except Exception as e:\n+        print(f\"Error downloading GSM8K dataset: {e}\")\n+\n+\n+def download_amc_aime_dataset():\n+    try:\n+        # Load the dataset using the datasets library\n+        dataset = load_dataset(\n+            \"mlfoundations-dev/bespokelabs-sky-t1-numina-amc-aime-subset-unfiltered\"\n+        )\n+\n+        # Get the first 4070 items from train split\n+        data = dataset['train'].select(range(4069))\n+\n+        # Convert to the desired format\n+        formatted_data = []\n+        for item in data:\n+            formatted_item = {\n+                \"id\": str(uuid.uuid4()),\n+                \"problem\": item['problem'],\n+                \"type\": \"amc_aime\",\n+                \"solution\": item['ground_truth_solution'],\n+            }\n+            formatted_data.append(formatted_item)\n+\n+        # Create output directory if it doesn't exist\n+        output_dir = Path(\"examples/datagen/star\")\n+        output_dir.mkdir(exist_ok=True)\n+\n+        # Save all data to a single JSON file\n+        output = formatted_data\n+        output_file = output_dir / \"star_r1_output_amc_aime.json\"\n+        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n+            json.dump(output, f, indent=4, ensure_ascii=False)\n+        print(\n+            f\"Successfully saved {len(formatted_data)} records \"\n+            f\"to {output_file}\"\n+        )\n+\n+        return formatted_data\n+\n+    except Exception as e:\n+        print(f\"Error downloading AMC/AIME dataset: {e}\")\n+        return None\n+\n+\n+if __name__ == \"__main__\":\n+    download_gsm8k_dataset()\n+    # download_amc_aime_dataset()\ndiff --git a/examples/datagen/self_improving_cot/gsm8k_dataset.json b/examples/datagen/self_improving_cot/gsm8k_dataset.json\nnew file mode 100644\nindex 0000000000..be68dad056\n--- /dev/null\n+++ b/examples/datagen/self_improving_cot/gsm8k_dataset.json\n@@ -0,0 +1,92 @@\n+[\n+    {\n+        \"id\": \"d400221b-9ae5-48af-bde3-9e76573bfdb6\",\n+        \"problem\": \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\",\n+        \"type\": \"openai/gsm8k\",\n+        \"solution\": \"Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n\\\\boxed{72}\",\n+        \"evaluate_success\": false,\n+        \"boxed_answer_success\": true,\n+        \"improvement_history\": []\n+    },\n+    {\n+        \"id\": \"3b1a60e0-92fc-4714-8dba-2f96bfdd0a1c\",\n+        \"problem\": \"Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\",\n+        \"type\": \"openai/gsm8k\",\n+        \"solution\": \"Weng earns 12/60 = $<<12/60=0.2>>0.2 per minute.\\nWorking 50 minutes, she earned 0.2 x 50 = $<<0.2*50=10>>10.\\n\\\\boxed{10}\",\n+        \"evaluate_success\": false,\n+        \"boxed_answer_success\": true,\n+        \"improvement_history\": []\n+    },\n+    {\n+        \"id\": \"ce6d4527-1a77-454b-b13c-434578aae277\",\n+        \"problem\": \"Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\",\n+        \"type\": \"openai/gsm8k\",\n+        \"solution\": \"In the beginning, Betty has only 100 / 2 = $<<100/2=50>>50.\\nBetty's grandparents gave her 15 * 2 = $<<15*2=30>>30.\\nThis means, Betty needs 100 - 50 - 30 - 15 = $<<100-50-30-15=5>>5 more.\\n\\\\boxed{5}\",\n+        \"evaluate_success\": false,\n+        \"boxed_answer_success\": true,\n+        \"improvement_history\": []\n+    },\n+    {\n+        \"id\": \"2373553d-eb17-43e7-8be2-e718c81b86a0\",\n+        \"problem\": \"Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\",\n+        \"type\": \"openai/gsm8k\",\n+        \"solution\": \"Maila read 12 x 2 = <<12*2=24>>24 pages today.\\nSo she was able to read a total of 12 + 24 = <<12+24=36>>36 pages since yesterday.\\nThere are 120 - 36 = <<120-36=84>>84 pages left to be read.\\nSince she wants to read half of the remaining pages tomorrow, then she should read 84/2 = <<84/2=42>>42 pages.\\n\\\\boxed{42}\",\n+        \"evaluate_success\": false,\n+        \"boxed_answer_success\": true,\n+        \"improvement_history\": []\n+    },\n+    {\n+        \"id\": \"9e450c49-fcd4-4ed9-8d99-5bba64e12370\",\n+        \"problem\": \"James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\",\n+        \"type\": \"openai/gsm8k\",\n+        \"solution\": \"He writes each friend 3*2=<<3*2=6>>6 pages a week\\nSo he writes 6*2=<<6*2=12>>12 pages every week\\nThat means he writes 12*52=<<12*52=624>>624 pages a year\\n\\\\boxed{624}\",\n+        \"evaluate_success\": false,\n+        \"boxed_answer_success\": true,\n+        \"improvement_history\": []\n+    },\n+    {\n+        \"id\": \"0234a9a9-257c-4292-9685-09f8599ac069\",\n+        \"problem\": \"Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\",\n+        \"type\": \"openai/gsm8k\",\n+        \"solution\": \"There are 80/100 * 10 = <<80/100*10=8>>8 more purple flowers than yellow flowers.\\nSo in Mark's garden, there are 10 + 8 = <<10+8=18>>18 purple flowers.\\nPurple and yellow flowers sum up to 10 + 18 = <<10+18=28>>28 flowers.\\nThat means in Mark's garden there are 25/100 * 28 = <<25/100*28=7>>7 green flowers.\\nSo in total Mark has 28 + 7 = <<28+7=35>>35 plants in his garden.\\n\\\\boxed{35}\",\n+        \"evaluate_success\": false,\n+        \"boxed_answer_success\": true,\n+        \"improvement_history\": []\n+    },\n+    {\n+        \"id\": \"3147dbfb-bbc5-4323-ac12-b768fe225cc8\",\n+        \"problem\": \"Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\",\n+        \"type\": \"openai/gsm8k\",\n+        \"solution\": \"He eats 32 from the largest pizzas because 2 x 16 = <<2*16=32>>32\\nHe eats 16 from the small pizza because 2 x 8 = <<2*8=16>>16\\nHe eats 48 pieces because 32 + 16 = <<32+16=48>>48\\n\\\\boxed{48}\",\n+        \"evaluate_success\": false,\n+        \"boxed_answer_success\": true,\n+        \"improvement_history\": []\n+    },\n+    {\n+        \"id\": \"9ea57ccc-1bf0-4a6e-b449-12061324057d\",\n+        \"problem\": \"Ken created a care package to send to his brother, who was away at boarding school.  Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds.  Then, he added enough brownies to cause the weight to triple.  Next, he added another 2 pounds of jelly beans.  And finally, he added enough gummy worms to double the weight once again.  What was the final weight of the box of goodies, in pounds?\",\n+        \"type\": \"openai/gsm8k\",\n+        \"solution\": \"To the initial 2 pounds of jelly beans, he added enough brownies to cause the weight to triple, bringing the weight to 2*3=<<2*3=6>>6 pounds.\\nNext, he added another 2 pounds of jelly beans, bringing the weight to 6+2=<<6+2=8>>8 pounds.\\nAnd finally, he added enough gummy worms to double the weight once again, to a final weight of 8*2=<<8*2=16>>16 pounds.\\n\\\\boxed{16}\",\n+        \"evaluate_success\": false,\n+        \"boxed_answer_success\": true,\n+        \"improvement_history\": []\n+    },\n+    {\n+        \"id\": \"b1f0b087-72e7-4b68-a344-1d8965e646a9\",\n+        \"problem\": \"Alexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\",\n+        \"type\": \"openai/gsm8k\",\n+        \"solution\": \"Let S be the amount Alexis paid for the shoes.\\nShe spent S + 30 + 46 + 38 + 11 + 18 = S + <<+30+46+38+11+18=143>>143.\\nShe used all but $16 of her budget, so S + 143 = 200 - 16 = 184.\\nThus, Alexis paid S = 184 - 143 = $<<184-143=41>>41 for the shoes.\\n\\\\boxed{41}\",\n+        \"evaluate_success\": false,\n+        \"boxed_answer_success\": true,\n+        \"improvement_history\": []\n+    },\n+    {\n+        \"id\": \"5bb003cb-8705-48e2-92fc-20dee5912f75\",\n+        \"problem\": \"Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\",\n+        \"type\": \"openai/gsm8k\",\n+        \"solution\": \"She works 8 hours a day for $18 per hour so she makes 8*18 = $<<8*18=144.00>>144.00 per 8-hour shift\\nShe works 10 hours a day and anything over 8 hours is eligible for overtime, so she gets 10-8 = <<10-8=2>>2 hours of overtime\\nOvertime is calculated as time and a half so and she makes $18/hour so her overtime pay is 18*.5 = $<<18*.5=9.00>>9.00\\nHer overtime pay is 18+9 = $<<18+9=27.00>>27.00\\nHer base pay is $144.00 per 8-hour shift and she works 5 days and makes 5 * $144 = $<<144*5=720.00>>720.00\\nHer overtime pay is $27.00 per hour and she works 2 hours of overtime per day and makes 27*2 = $<<27*2=54.00>>54.00 in overtime pay\\n2 hours of overtime pay for 5 days means she makes 54*5 = $270.00\\nIn 5 days her base pay is $720.00 and she makes $270.00 in overtime pay so she makes $720 + $270 = $<<720+270=990.00>>990.00\\n\\\\boxed{990}\",\n+        \"evaluate_success\": false,\n+        \"boxed_answer_success\": true,\n+        \"improvement_history\": []\n+    }\n+]\n\\ No newline at end of file\ndiff --git a/examples/datagen/self_improving_cot/self_improving_cot_example.py b/examples/datagen/self_improving_cot/self_improving_cot_example.py\nnew file mode 100644\nindex 0000000000..f5dea4ea60\n--- /dev/null\n+++ b/examples/datagen/self_improving_cot/self_improving_cot_example.py\n@@ -0,0 +1,98 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+import json\n+import os\n+import time\n+\n+from camel.agents import ChatAgent\n+from camel.configs import DeepSeekConfig\n+from camel.datagen import SelfImprovingCoTPipeline\n+from camel.models import ModelFactory\n+from camel.types import ModelPlatformType, ModelType\n+\n+# from camel.models.reward import NemotronRewardModel\n+\n+\"\"\"\n+please set the below os environment:\n+export DEEPSEEK_API_KEY=\"\"\n+\"\"\"\n+\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEEPSEEK,\n+    model_type=ModelType.DEEPSEEK_CHAT,\n+    model_config_dict=DeepSeekConfig(temperature=0).as_dict(),\n+)\n+\n+\n+def main():\n+    start_time = time.time()\n+\n+    current_dir = os.path.dirname(os.path.abspath(__file__))\n+    problems_path = os.path.join(current_dir, 'gsm8k_dataset.json')\n+    output_path = os.path.join(current_dir, 'self_improving_cot_output.json')\n+\n+    # Load problems from JSON file\n+    with open(problems_path, 'r') as f:\n+        problems = json.load(f)\n+\n+    # Initialize agent\n+    reason_agent_system_message = \"\"\"Please reason step by step, and put your \n+    final answer within \\\\boxed{}.\"\"\"\n+    evaluate_agent_system_message = \"\"\"You are a highly critical teacher who \n+    evaluates the student's answers with a meticulous and demanding approach.\n+    \"\"\"\n+    reason_agent = ChatAgent(reason_agent_system_message, model=model)\n+    evaluate_agent = ChatAgent(evaluate_agent_system_message)\n+\n+    # Initialize reward model (optional)\n+    # reward_model = NemotronRewardModel(\n+    #     model_type=ModelType.NVIDIA_NEMOTRON_340B_REWARD,\n+    #     url=\"https://integrate.api.nvidia.com/v1\",\n+    #     api_key=os.environ.get(\"NVIDIA_API_KEY\"),\n+    # )\n+\n+    # Set score thresholds for different dimensions (optional)\n+    score_threshold = {\n+        \"correctness\": 0.9,\n+        \"clarity\": 0.9,\n+        \"completeness\": 0.6,\n+    }\n+    # Or use a single threshold for all dimensions:\n+    # score_threshold = 0.9\n+\n+    # Create and run pipeline\n+    pipeline = SelfImprovingCoTPipeline(\n+        reason_agent=reason_agent,\n+        evaluate_agent=evaluate_agent,\n+        problems=problems,  # Pass problems list directly\n+        output_path=output_path,\n+        max_iterations=3,\n+        score_threshold=score_threshold,\n+        # reward_model=reward_model,  # To use a reward model (optional)\n+    )\n+\n+    results = pipeline.generate(rationalization=False)\n+\n+    end_time = time.time()\n+    execution_time = end_time - start_time\n+\n+    print(f\"\\nProcessed {len(results)} problems\")\n+    print(f\"Results saved to: {output_path}\")\n+    print(f\"Total execution time: {execution_time:.2f} seconds\")\n+\n+\n+if __name__ == \"__main__\":\n+    main()\ndiff --git a/examples/datagen/self_improving_cot/self_improving_cot_example_with_r1.py b/examples/datagen/self_improving_cot/self_improving_cot_example_with_r1.py\nnew file mode 100644\nindex 0000000000..472602997a\n--- /dev/null\n+++ b/examples/datagen/self_improving_cot/self_improving_cot_example_with_r1.py\n@@ -0,0 +1,133 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+import json\n+import os\n+import time\n+\n+from camel.agents import ChatAgent\n+from camel.datagen import SelfImprovingCoTPipeline\n+from camel.models import ModelFactory\n+from camel.types import ModelPlatformType, ModelType\n+\n+\"\"\"\n+please set the below os environment:\n+export DEEPSEEK_API_KEY=\"\"\n+export GET_REASONING_CONTENT=\"true\"\n+\"\"\"\n+\n+evaluate_model = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEFAULT,\n+    model_type=ModelType.DEFAULT,\n+)\n+\n+reason_model_1 = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEEPSEEK,\n+    model_type=ModelType.DEEPSEEK_REASONER,\n+)\n+\n+reason_model_2 = ModelFactory.create(\n+    model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,\n+    model_type=\"accounts/fireworks/models/deepseek-r1\",\n+    api_key=os.getenv(\"FIREWORKS_API_KEY\"),\n+    url=\"https://api.fireworks.ai/inference/v1\",\n+    model_config_dict={\"max_tokens\": 4096},\n+)\n+\n+reason_model_3 = ModelFactory.create(\n+    model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,\n+    model_type=\"deepseek-ai/DeepSeek-R1\",\n+    api_key=os.getenv(\"HYPERBOLIC_API_KEY\"),\n+    url=\"https://api.hyperbolic.xyz/v1\",\n+)\n+\n+reason_model_4 = ModelFactory.create(\n+    model_platform=ModelPlatformType.TOGETHER,\n+    model_type=\"deepseek-ai/DeepSeek-R1\",\n+    api_key=os.getenv(\"TOGETHER_API_KEY\"),\n+)\n+# from camel.models.reward import NemotronRewardModel\n+\n+\n+def main():\n+    start_time = time.time()\n+\n+    current_dir = os.path.dirname(os.path.abspath(__file__))\n+    problems_path = os.path.join(current_dir, 'outputs/gsm8k_dataset.json')\n+    output_path = os.path.join(\n+        current_dir, 'outputs/self_improving_cot_r1_output.json'\n+    )\n+\n+    # Load problems from JSON file\n+    with open(problems_path, 'r') as f:\n+        problems = json.load(f)\n+\n+    # Initialize agent\n+    reason_agent_system_message = \"\"\"Answer my question and give your \n+    final answer within \\\\boxed{}.\"\"\"\n+    evaluate_agent_system_message = \"\"\"You are a highly critical teacher who \n+    evaluates the student's answers with a meticulous and demanding approach.\n+    \"\"\"\n+    reason_agent = ChatAgent(\n+        system_message=reason_agent_system_message,\n+        model=[\n+            # reason_model_1,\n+            reason_model_2,\n+            # reason_model_3,\n+            # reason_model_4,\n+        ],\n+    )\n+    evaluate_agent = ChatAgent(\n+        system_message=evaluate_agent_system_message, model=evaluate_model\n+    )\n+\n+    # Initialize reward model (optional)\n+    # reward_model = NemotronRewardModel(\n+    #     model_type=ModelType.NVIDIA_NEMOTRON_340B_REWARD,\n+    #     url=\"https://integrate.api.nvidia.com/v1\",\n+    #     api_key=os.environ.get(\"NVIDIA_API_KEY\"),\n+    # )\n+\n+    # Set score thresholds for different dimensions (optional)\n+    score_threshold = {\n+        \"correctness\": 1.0,\n+        \"clarity\": 0.0,\n+        \"completeness\": 0.0,\n+    }\n+    # Or use a single threshold for all dimensions:\n+    # score_threshold = 0.9\n+\n+    # Create and run pipeline\n+    pipeline = SelfImprovingCoTPipeline(\n+        reason_agent=reason_agent,\n+        evaluate_agent=evaluate_agent,\n+        problems=problems,  # Pass problems list directly\n+        output_path=output_path,\n+        max_iterations=0,\n+        score_threshold=score_threshold,\n+        # reward_model=reward_model,  # To use a reward model (optional)\n+    )\n+\n+    results = pipeline.generate(rationalization=False)\n+\n+    end_time = time.time()\n+    execution_time = end_time - start_time\n+\n+    print(f\"\\nProcessed {len(results)} problems\")\n+    print(f\"Results saved to: {output_path}\")\n+    print(f\"Total execution time: {execution_time:.2f} seconds\")\n+\n+\n+if __name__ == \"__main__\":\n+    main()\ndiff --git a/poetry.lock b/poetry.lock\nindex 5903b6b98b..67303807dc 100644\n--- a/poetry.lock\n+++ b/poetry.lock\n@@ -82,13 +82,13 @@ files = [\n \n [[package]]\n name = \"aiohappyeyeballs\"\n-version = \"2.4.5\"\n+version = \"2.4.6\"\n description = \"Happy Eyeballs for asyncio\"\n optional = false\n python-versions = \">=3.9\"\n files = [\n-    {file = \"aiohappyeyeballs-2.4.5-py3-none-any.whl\", hash = \"sha256:67b5c2033c60048046863ed377f450bceb74634dc0f9abe4723b60ba12bfe135\"},\n-    {file = \"aiohappyeyeballs-2.4.5.tar.gz\", hash = \"sha256:950d95733a9c09011e75cf58550c68eb834ee5211106ad1a686b7259d3110bc4\"},\n+    {file = \"aiohappyeyeballs-2.4.6-py3-none-any.whl\", hash = \"sha256:147ec992cf873d74f5062644332c539fcd42956dc69453fe5204195e560517e1\"},\n+    {file = \"aiohappyeyeballs-2.4.6.tar.gz\", hash = \"sha256:9b05052f9042985d32ecbe4b59a77ae19c006a78f1344d7fdad69d28ded3d0b0\"},\n ]\n \n [[package]]\n@@ -4050,23 +4050,23 @@ files = [\n \n [[package]]\n name = \"langchain\"\n-version = \"0.3.17\"\n+version = \"0.3.18\"\n description = \"Building applications with LLMs through composability\"\n optional = true\n python-versions = \"<4.0,>=3.9\"\n files = [\n-    {file = \"langchain-0.3.17-py3-none-any.whl\", hash = \"sha256:4d6d3cf454cc261a5017fd1fa5014cffcc7aeaccd0ec0530fc10c5f71e6e97a0\"},\n-    {file = \"langchain-0.3.17.tar.gz\", hash = \"sha256:cef56f0a7c8369f35f1fa2690ecf0caa4504a36a5383de0eb29b8a5e26f625a0\"},\n+    {file = \"langchain-0.3.18-py3-none-any.whl\", hash = \"sha256:1a6e629f02a25962aa5b16932e8f073248104a66804ed5af1f78618ad7c1d38d\"},\n+    {file = \"langchain-0.3.18.tar.gz\", hash = \"sha256:311ac227a995545ff7c3f74c7767930c5349edef0b39f19d3105b86d39316b69\"},\n ]\n \n [package.dependencies]\n aiohttp = \">=3.8.3,<4.0.0\"\n async-timeout = {version = \">=4.0.0,<5.0.0\", markers = \"python_version < \\\"3.11\\\"\"}\n-langchain-core = \">=0.3.33,<0.4.0\"\n-langchain-text-splitters = \">=0.3.3,<0.4.0\"\n+langchain-core = \">=0.3.34,<1.0.0\"\n+langchain-text-splitters = \">=0.3.6,<1.0.0\"\n langsmith = \">=0.1.17,<0.4\"\n numpy = [\n-    {version = \">=1.22.4,<2\", markers = \"python_version < \\\"3.12\\\"\"},\n+    {version = \">=1.26.4,<2\", markers = \"python_version < \\\"3.12\\\"\"},\n     {version = \">=1.26.2,<3\", markers = \"python_version >= \\\"3.12\\\"\"},\n ]\n pydantic = \">=2.7.4,<3.0.0\"\n@@ -4075,26 +4075,42 @@ requests = \">=2,<3\"\n SQLAlchemy = \">=1.4,<3\"\n tenacity = \">=8.1.0,<8.4.0 || >8.4.0,<10\"\n \n+[package.extras]\n+anthropic = [\"langchain-anthropic\"]\n+aws = [\"langchain-aws\"]\n+cohere = [\"langchain-cohere\"]\n+community = [\"langchain-community\"]\n+deepseek = [\"langchain-deepseek\"]\n+fireworks = [\"langchain-fireworks\"]\n+google-genai = [\"langchain-google-genai\"]\n+google-vertexai = [\"langchain-google-vertexai\"]\n+groq = [\"langchain-groq\"]\n+huggingface = [\"langchain-huggingface\"]\n+mistralai = [\"langchain-mistralai\"]\n+ollama = [\"langchain-ollama\"]\n+openai = [\"langchain-openai\"]\n+together = [\"langchain-together\"]\n+\n [[package]]\n name = \"langchain-community\"\n-version = \"0.3.16\"\n+version = \"0.3.17\"\n description = \"Community contributed LangChain integrations.\"\n optional = true\n python-versions = \"<4.0,>=3.9\"\n files = [\n-    {file = \"langchain_community-0.3.16-py3-none-any.whl\", hash = \"sha256:a702c577b048d48882a46708bb3e08ca9aec79657c421c3241a305409040c0d6\"},\n-    {file = \"langchain_community-0.3.16.tar.gz\", hash = \"sha256:825709bc328e294942b045d0b7f55053e8e88f7f943576306d778cf56417126c\"},\n+    {file = \"langchain_community-0.3.17-py3-none-any.whl\", hash = \"sha256:13bbd87d681b0df67bafa294321613b13ac524f173c92f11048d40c74e585f0b\"},\n+    {file = \"langchain_community-0.3.17.tar.gz\", hash = \"sha256:d8547a3d4f8307950be88ca638cd6ab1abe2440d0012e401a172ba4a39aa8044\"},\n ]\n \n [package.dependencies]\n aiohttp = \">=3.8.3,<4.0.0\"\n dataclasses-json = \">=0.5.7,<0.7\"\n-httpx-sse = \">=0.4.0,<0.5.0\"\n-langchain = \">=0.3.16,<0.4.0\"\n-langchain-core = \">=0.3.32,<0.4.0\"\n+httpx-sse = \">=0.4.0,<1.0.0\"\n+langchain = \">=0.3.18,<1.0.0\"\n+langchain-core = \">=0.3.34,<1.0.0\"\n langsmith = \">=0.1.125,<0.4\"\n numpy = [\n-    {version = \">=1.22.4,<2\", markers = \"python_version < \\\"3.12\\\"\"},\n+    {version = \">=1.26.4,<2\", markers = \"python_version < \\\"3.12\\\"\"},\n     {version = \">=1.26.2,<3\", markers = \"python_version >= \\\"3.12\\\"\"},\n ]\n pydantic-settings = \">=2.4.0,<3.0.0\"\n@@ -7616,28 +7632,27 @@ files = [\n \n [[package]]\n name = \"psutil\"\n-version = \"6.0.0\"\n+version = \"5.9.8\"\n description = \"Cross-platform lib for process and system monitoring in Python.\"\n-optional = true\n-python-versions = \"!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*,>=2.7\"\n+optional = false\n+python-versions = \">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*\"\n files = [\n-    {file = \"psutil-6.0.0-cp27-cp27m-macosx_10_9_x86_64.whl\", hash = \"sha256:a021da3e881cd935e64a3d0a20983bda0bb4cf80e4f74fa9bfcb1bc5785360c6\"},\n-    {file = \"psutil-6.0.0-cp27-cp27m-manylinux2010_i686.whl\", hash = \"sha256:1287c2b95f1c0a364d23bc6f2ea2365a8d4d9b726a3be7294296ff7ba97c17f0\"},\n-    {file = \"psutil-6.0.0-cp27-cp27m-manylinux2010_x86_64.whl\", hash = \"sha256:a9a3dbfb4de4f18174528d87cc352d1f788b7496991cca33c6996f40c9e3c92c\"},\n-    {file = \"psutil-6.0.0-cp27-cp27mu-manylinux2010_i686.whl\", hash = \"sha256:6ec7588fb3ddaec7344a825afe298db83fe01bfaaab39155fa84cf1c0d6b13c3\"},\n-    {file = \"psutil-6.0.0-cp27-cp27mu-manylinux2010_x86_64.whl\", hash = \"sha256:1e7c870afcb7d91fdea2b37c24aeb08f98b6d67257a5cb0a8bc3ac68d0f1a68c\"},\n-    {file = \"psutil-6.0.0-cp27-none-win32.whl\", hash = \"sha256:02b69001f44cc73c1c5279d02b30a817e339ceb258ad75997325e0e6169d8b35\"},\n-    {file = \"psutil-6.0.0-cp27-none-win_amd64.whl\", hash = \"sha256:21f1fb635deccd510f69f485b87433460a603919b45e2a324ad65b0cc74f8fb1\"},\n-    {file = \"psutil-6.0.0-cp36-abi3-macosx_10_9_x86_64.whl\", hash = \"sha256:c588a7e9b1173b6e866756dde596fd4cad94f9399daf99ad8c3258b3cb2b47a0\"},\n-    {file = \"psutil-6.0.0-cp36-abi3-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:6ed2440ada7ef7d0d608f20ad89a04ec47d2d3ab7190896cd62ca5fc4fe08bf0\"},\n-    {file = \"psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:5fd9a97c8e94059b0ef54a7d4baf13b405011176c3b6ff257c247cae0d560ecd\"},\n-    {file = \"psutil-6.0.0-cp36-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:e2e8d0054fc88153ca0544f5c4d554d42e33df2e009c4ff42284ac9ebdef4132\"},\n-    {file = \"psutil-6.0.0-cp36-cp36m-win32.whl\", hash = \"sha256:fc8c9510cde0146432bbdb433322861ee8c3efbf8589865c8bf8d21cb30c4d14\"},\n-    {file = \"psutil-6.0.0-cp36-cp36m-win_amd64.whl\", hash = \"sha256:34859b8d8f423b86e4385ff3665d3f4d94be3cdf48221fbe476e883514fdb71c\"},\n-    {file = \"psutil-6.0.0-cp37-abi3-win32.whl\", hash = \"sha256:a495580d6bae27291324fe60cea0b5a7c23fa36a7cd35035a16d93bdcf076b9d\"},\n-    {file = \"psutil-6.0.0-cp37-abi3-win_amd64.whl\", hash = \"sha256:33ea5e1c975250a720b3a6609c490db40dae5d83a4eb315170c4fe0d8b1f34b3\"},\n-    {file = \"psutil-6.0.0-cp38-abi3-macosx_11_0_arm64.whl\", hash = \"sha256:ffe7fc9b6b36beadc8c322f84e1caff51e8703b88eee1da46d1e3a6ae11b4fd0\"},\n-    {file = \"psutil-6.0.0.tar.gz\", hash = \"sha256:8faae4f310b6d969fa26ca0545338b21f73c6b15db7c4a8d934a5482faa818f2\"},\n+    {file = \"psutil-5.9.8-cp27-cp27m-macosx_10_9_x86_64.whl\", hash = \"sha256:26bd09967ae00920df88e0352a91cff1a78f8d69b3ecabbfe733610c0af486c8\"},\n+    {file = \"psutil-5.9.8-cp27-cp27m-manylinux2010_i686.whl\", hash = \"sha256:05806de88103b25903dff19bb6692bd2e714ccf9e668d050d144012055cbca73\"},\n+    {file = \"psutil-5.9.8-cp27-cp27m-manylinux2010_x86_64.whl\", hash = \"sha256:611052c4bc70432ec770d5d54f64206aa7203a101ec273a0cd82418c86503bb7\"},\n+    {file = \"psutil-5.9.8-cp27-cp27mu-manylinux2010_i686.whl\", hash = \"sha256:50187900d73c1381ba1454cf40308c2bf6f34268518b3f36a9b663ca87e65e36\"},\n+    {file = \"psutil-5.9.8-cp27-cp27mu-manylinux2010_x86_64.whl\", hash = \"sha256:02615ed8c5ea222323408ceba16c60e99c3f91639b07da6373fb7e6539abc56d\"},\n+    {file = \"psutil-5.9.8-cp27-none-win32.whl\", hash = \"sha256:36f435891adb138ed3c9e58c6af3e2e6ca9ac2f365efe1f9cfef2794e6c93b4e\"},\n+    {file = \"psutil-5.9.8-cp27-none-win_amd64.whl\", hash = \"sha256:bd1184ceb3f87651a67b2708d4c3338e9b10c5df903f2e3776b62303b26cb631\"},\n+    {file = \"psutil-5.9.8-cp36-abi3-macosx_10_9_x86_64.whl\", hash = \"sha256:aee678c8720623dc456fa20659af736241f575d79429a0e5e9cf88ae0605cc81\"},\n+    {file = \"psutil-5.9.8-cp36-abi3-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:8cb6403ce6d8e047495a701dc7c5bd788add903f8986d523e3e20b98b733e421\"},\n+    {file = \"psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:d06016f7f8625a1825ba3732081d77c94589dca78b7a3fc072194851e88461a4\"},\n+    {file = \"psutil-5.9.8-cp36-cp36m-win32.whl\", hash = \"sha256:7d79560ad97af658a0f6adfef8b834b53f64746d45b403f225b85c5c2c140eee\"},\n+    {file = \"psutil-5.9.8-cp36-cp36m-win_amd64.whl\", hash = \"sha256:27cc40c3493bb10de1be4b3f07cae4c010ce715290a5be22b98493509c6299e2\"},\n+    {file = \"psutil-5.9.8-cp37-abi3-win32.whl\", hash = \"sha256:bc56c2a1b0d15aa3eaa5a60c9f3f8e3e565303b465dbf57a1b730e7a2b9844e0\"},\n+    {file = \"psutil-5.9.8-cp37-abi3-win_amd64.whl\", hash = \"sha256:8db4c1b57507eef143a15a6884ca10f7c73876cdf5d51e713151c1236a0e68cf\"},\n+    {file = \"psutil-5.9.8-cp38-abi3-macosx_11_0_arm64.whl\", hash = \"sha256:d16bbddf0693323b8c6123dd804100241da461e41d6e332fb0ba6058f630f8c8\"},\n+    {file = \"psutil-5.9.8.tar.gz\", hash = \"sha256:6be126e3225486dff286a8fb9a06246a5253f4c7c53b475ea5f5ac934e64194c\"},\n ]\n \n [package.extras]\n@@ -12484,4 +12499,4 @@ web-tools = [\"apify_client\", \"asknews\", \"dappier\", \"duckduckgo-search\", \"firecra\n [metadata]\n lock-version = \"2.0\"\n python-versions = \">=3.10,<3.13\"\n-content-hash = \"f90dc798e70cb314de13e76955341cfce2131528c9f1570debcd5ea6fbd85a58\"\n+content-hash = \"ccd7845251187d9c2bd3831125c486c75a62e259f6306a3ad92dba5d87892d4c\"\ndiff --git a/pyproject.toml b/pyproject.toml\nindex faa9c85301..ddfe39ada7 100644\n--- a/pyproject.toml\n+++ b/pyproject.toml\n@@ -42,6 +42,7 @@ eval-type-backport = \"0.2.0\"\n curl_cffi = \"0.6.2\"\n pandoc = \"*\"\n httpx = \">=0.23.0,<0.27.3\"\n+psutil = \"^5.9.8\"\n \n # Model platforms\n litellm = { version = \"^1.38.1\", optional = true }\n@@ -460,6 +461,7 @@ module = [\n     \"openai.error\",\n     \"anthropic\",\n     \"pytest\",\n+    \"psutil\",\n     \"_pytest.config\",\n     \"_pytest.nodes\",\n     \"numpy\",\n",
    "test_patch": "diff --git a/test/datagen/test_self_improving_cot_pipeline.py b/test/datagen/test_self_improving_cot_pipeline.py\nnew file mode 100644\nindex 0000000000..69722fed02\n--- /dev/null\n+++ b/test/datagen/test_self_improving_cot_pipeline.py\n@@ -0,0 +1,478 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+import unittest\n+from unittest.mock import MagicMock, patch\n+\n+from camel.agents import ChatAgent\n+from camel.datagen import SelfImprovingCoTPipeline\n+from camel.datagen.self_improving_cot import (\n+    ProblemResult,\n+    TraceIteration,\n+)\n+from camel.models.reward import BaseRewardModel\n+\n+\n+class TestSelfImprovingCoTPipeline(unittest.TestCase):\n+    def setUp(self):\n+        self.mock_reason_agent = MagicMock(spec=ChatAgent)\n+        self.mock_reason_agent.step.return_value = MagicMock(\n+            msg=MagicMock(content=\"Mock reasoning trace\")\n+        )\n+\n+        self.mock_evaluate_agent = MagicMock(spec=ChatAgent)\n+        self.mock_evaluate_agent.step.return_value = MagicMock(\n+            msg=MagicMock(\n+                parsed={\n+                    \"correctness\": 0.8,\n+                    \"clarity\": 0.9,\n+                    \"completeness\": 0.85,\n+                    \"feedback\": \"Good explanation\",\n+                }\n+            )\n+        )\n+\n+        self.test_problems = [\n+            {\n+                \"id\": \"problem_0\",\n+                \"problem\": (\n+                    \"If John has 5 apples and gives 2 to Mary, \"\n+                    \"how many does he have left?\"\n+                ),\n+                \"type\": \"arithmetic\",\n+                \"solution\": \"3\",\n+            }\n+        ]\n+\n+    def test_pipeline_initialization(self):\n+        pipeline = SelfImprovingCoTPipeline(\n+            reason_agent=self.mock_reason_agent,\n+            evaluate_agent=self.mock_evaluate_agent,\n+            problems=self.test_problems,\n+            batch_size=10,\n+            max_workers=4,\n+        )\n+        self.assertEqual(len(pipeline.problems), 1)\n+        self.assertEqual(pipeline.max_iterations, 3)\n+        self.assertEqual(pipeline.score_threshold, 0.7)\n+        self.assertIsNone(pipeline.reward_model)\n+        self.assertIsNone(pipeline.evaluator)\n+        self.assertIsNone(pipeline.few_shot_examples)\n+        self.assertEqual(pipeline.batch_processor.batch_size, 10)\n+        self.assertEqual(pipeline.batch_processor.max_workers, 4)\n+\n+    def test_pipeline_initialization_with_few_shot(self):\n+        few_shot = \"Example: 2 + 2 = 4\"\n+        pipeline = SelfImprovingCoTPipeline(\n+            reason_agent=self.mock_reason_agent,\n+            evaluate_agent=self.mock_evaluate_agent,\n+            problems=self.test_problems,\n+            few_shot_examples=few_shot,\n+        )\n+        self.assertEqual(pipeline.few_shot_examples, few_shot)\n+\n+    def test_generate_reasoning_trace(self):\n+        pipeline = SelfImprovingCoTPipeline(\n+            reason_agent=self.mock_reason_agent,\n+            evaluate_agent=self.mock_evaluate_agent,\n+            problems=self.test_problems,\n+        )\n+        trace = pipeline.generate_reasoning_trace(\n+            self.test_problems[0][\"problem\"]\n+        )\n+        self.assertEqual(trace, \"Mock reasoning trace\")\n+        self.mock_reason_agent.reset.assert_called_once()\n+        self.mock_reason_agent.step.assert_called_once()\n+\n+    def test_agent_evaluate_trace(self):\n+        evaluation_response = {\n+            \"correctness\": 0.8,\n+            \"clarity\": 0.9,\n+            \"completeness\": 0.85,\n+            \"feedback\": \"Good explanation, but could be more detailed\",\n+        }\n+        self.mock_evaluate_agent.step.return_value = MagicMock(\n+            msg=MagicMock(parsed=evaluation_response)\n+        )\n+\n+        pipeline = SelfImprovingCoTPipeline(\n+            reason_agent=self.mock_reason_agent,\n+            evaluate_agent=self.mock_evaluate_agent,\n+            problems=self.test_problems,\n+        )\n+\n+        evaluation = pipeline.evaluate_trace(\n+            self.test_problems[0][\"problem\"],\n+            \"Test reasoning trace\",\n+        )\n+\n+        self.assertIsInstance(evaluation, dict)\n+        self.assertEqual(evaluation[\"correctness\"], 0.8)\n+        self.assertEqual(evaluation[\"clarity\"], 0.9)\n+        self.assertEqual(evaluation[\"completeness\"], 0.85)\n+        self.assertEqual(\n+            evaluation[\"feedback\"],\n+            \"Good explanation, but could be more detailed\",\n+        )\n+\n+    def test_reward_model_single_score_evaluation(self):\n+        mock_reward_model = MagicMock(spec=BaseRewardModel)\n+        mock_evaluator = MagicMock()\n+        mock_evaluator.evaluate.return_value = 0.85\n+\n+        pipeline = SelfImprovingCoTPipeline(\n+            reason_agent=self.mock_reason_agent,\n+            evaluate_agent=self.mock_evaluate_agent,\n+            problems=self.test_problems,\n+            reward_model=mock_reward_model,\n+        )\n+        pipeline.evaluator = mock_evaluator\n+\n+        evaluation = pipeline.evaluate_trace(\n+            self.test_problems[0][\"problem\"],\n+            \"Test reasoning trace\",\n+        )\n+\n+        self.assertIsInstance(evaluation, dict)\n+        self.assertEqual(evaluation[\"overall\"], 0.85)\n+        self.assertIn(\"feedback\", evaluation)\n+\n+    def test_reward_model_multi_score_evaluation(self):\n+        mock_reward_model = MagicMock(spec=BaseRewardModel)\n+        mock_evaluator = MagicMock()\n+        mock_evaluator.evaluate.return_value = {\n+            \"correctness\": 0.8,\n+            \"coherence\": 0.9,\n+            \"helpfulness\": 0.85,\n+        }\n+\n+        pipeline = SelfImprovingCoTPipeline(\n+            reason_agent=self.mock_reason_agent,\n+            evaluate_agent=self.mock_evaluate_agent,\n+            problems=self.test_problems,\n+            reward_model=mock_reward_model,\n+        )\n+        pipeline.evaluator = mock_evaluator\n+\n+        evaluation = pipeline.evaluate_trace(\n+            self.test_problems[0][\"problem\"],\n+            \"Test reasoning trace\",\n+        )\n+\n+        self.assertIsInstance(evaluation, dict)\n+        self.assertEqual(evaluation[\"correctness\"], 0.8)\n+        self.assertEqual(evaluation[\"coherence\"], 0.9)\n+        self.assertEqual(evaluation[\"helpfulness\"], 0.85)\n+        self.assertIn(\"feedback\", evaluation)\n+\n+    def test_improve_trace(self):\n+        improved_trace = \"Improved reasoning with more details\"\n+        self.mock_reason_agent.step.return_value = MagicMock(\n+            msg=MagicMock(content=improved_trace)\n+        )\n+\n+        pipeline = SelfImprovingCoTPipeline(\n+            reason_agent=self.mock_reason_agent,\n+            evaluate_agent=self.mock_evaluate_agent,\n+            problems=self.test_problems,\n+        )\n+\n+        result = pipeline.improve_trace(\n+            self.test_problems[0][\"problem\"],\n+            \"Original trace\",\n+            \"Add more details\",\n+        )\n+\n+        self.assertEqual(result, improved_trace)\n+        self.mock_reason_agent.reset.assert_called_once()\n+        self.mock_reason_agent.step.assert_called_once()\n+\n+    def test_process_problem(self):\n+        # Mock responses for the process_problem pipeline\n+        mock_reason_responses = [\n+            MagicMock(msg=MagicMock(content=\"Initial reasoning trace\")),\n+        ]\n+        mock_evaluate_responses = [\n+            MagicMock(\n+                msg=MagicMock(\n+                    parsed={\n+                        \"correctness\": 0.95,\n+                        \"clarity\": 0.9,\n+                        \"completeness\": 0.95,\n+                        \"feedback\": \"Excellent explanation\",\n+                    }\n+                )\n+            ),\n+        ]\n+        self.mock_reason_agent.step.side_effect = mock_reason_responses\n+        self.mock_evaluate_agent.step.side_effect = mock_evaluate_responses\n+\n+        pipeline = SelfImprovingCoTPipeline(\n+            reason_agent=self.mock_reason_agent,\n+            evaluate_agent=self.mock_evaluate_agent,\n+            problems=self.test_problems,\n+        )\n+\n+        result = pipeline.process_problem(self.test_problems[0])\n+\n+        self.assertIsInstance(result, ProblemResult)\n+        self.assertEqual(result.problem, self.test_problems[0][\"problem\"])\n+        self.assertEqual(result.final_trace, \"Initial reasoning trace\")\n+        self.assertEqual(len(result.improvement_history), 1)\n+        self.assertIsInstance(result.improvement_history[0], TraceIteration)\n+\n+    def test_score_threshold_dict(self):\n+        pipeline = SelfImprovingCoTPipeline(\n+            reason_agent=self.mock_reason_agent,\n+            evaluate_agent=self.mock_evaluate_agent,\n+            problems=self.test_problems,\n+            score_threshold={\"correctness\": 0.8, \"clarity\": 0.7},\n+        )\n+\n+        # Test with scores meeting thresholds\n+        scores = {\"correctness\": 0.9, \"clarity\": 0.8, \"completeness\": 0.6}\n+        self.assertTrue(pipeline._check_score_threshold(scores))\n+\n+        # Test with scores below thresholds\n+        scores = {\"correctness\": 0.7, \"clarity\": 0.6, \"completeness\": 0.9}\n+        self.assertFalse(pipeline._check_score_threshold(scores))\n+\n+    @patch(\"psutil.cpu_times\")\n+    @patch(\"psutil.cpu_count\")\n+    @patch(\"psutil.cpu_percent\")\n+    @patch(\"psutil.virtual_memory\")\n+    @patch(\"builtins.open\")\n+    @patch(\"json.dump\")\n+    @patch(\"json.load\")\n+    def test_generate_with_output(\n+        self,\n+        mock_load,\n+        mock_dump,\n+        mock_open,\n+        mock_virtual_memory,\n+        mock_cpu_percent,\n+        mock_cpu_count,\n+        mock_cpu_times,\n+    ):\n+        mock_load.return_value = {\"traces\": []}\n+        mock_open.return_value.__enter__ = mock_open\n+        mock_open.return_value.__exit__ = MagicMock()\n+\n+        # Mock psutil functions\n+        mock_cpu_times.return_value = MagicMock(\n+            user=100.0,\n+            nice=0.0,\n+            system=50.0,\n+            idle=200.0,\n+            iowait=0.0,\n+            irq=0.0,\n+            softirq=0.0,\n+            steal=0.0,\n+            guest=0.0,\n+            guest_nice=0.0,\n+        )\n+        mock_cpu_count.return_value = 8\n+        mock_cpu_percent.return_value = 50.0\n+        mock_virtual_memory.return_value = MagicMock(percent=60.0)\n+\n+        mock_reason_responses = [\n+            MagicMock(msg=MagicMock(content=\"Initial reasoning trace\")),\n+            MagicMock(msg=MagicMock(content=\"Improved reasoning trace\")),\n+        ]\n+        mock_evaluate_responses = [\n+            MagicMock(\n+                msg=MagicMock(\n+                    parsed={\n+                        \"correctness\": 0.95,\n+                        \"clarity\": 0.9,\n+                        \"completeness\": 0.95,\n+                        \"feedback\": \"Excellent explanation\",\n+                    }\n+                )\n+            ),\n+            MagicMock(\n+                msg=MagicMock(\n+                    parsed={\n+                        \"correctness\": 0.98,\n+                        \"clarity\": 0.95,\n+                        \"completeness\": 0.98,\n+                        \"feedback\": \"Perfect explanation\",\n+                    }\n+                )\n+            ),\n+        ]\n+        self.mock_reason_agent.step.side_effect = mock_reason_responses\n+        self.mock_evaluate_agent.step.side_effect = mock_evaluate_responses\n+\n+        pipeline = SelfImprovingCoTPipeline(\n+            reason_agent=self.mock_reason_agent,\n+            evaluate_agent=self.mock_evaluate_agent,\n+            problems=self.test_problems,\n+            output_path=\"test_output.json\",\n+            max_iterations=1,\n+            score_threshold=0.99,\n+        )\n+\n+        results = pipeline.generate()\n+\n+        # Verify the results structure\n+        self.assertIsInstance(results, list)\n+        self.assertEqual(len(results), 1)\n+        result = results[0]\n+        self.assertIn(\"problem\", result)\n+        self.assertIn(\"final_trace\", result)\n+        self.assertIn(\"improvement_history\", result)\n+\n+        # Verify output was written\n+        mock_dump.assert_called()\n+        args = mock_dump.call_args_list[-1][0]  # Get last call args\n+        expected_result = {\n+            \"traces\": [\n+                {\n+                    \"id\": \"problem_0\",\n+                    \"type\": \"arithmetic\",\n+                    \"problem\": \"If John has 5 apples and gives 2 to Mary, \"\n+                    \"how many does he have left?\",\n+                    \"solution\": \"3\",\n+                    \"final_trace\": \"Improved reasoning trace\",\n+                    \"agent_evaluate_success\": False,\n+                    \"boxed_answer_success\": False,\n+                    \"improvement_history\": [\n+                        {\n+                            \"iteration\": 0,\n+                            \"trace\": \"Initial reasoning trace\",\n+                            \"evaluation\": {\n+                                \"correctness\": 0.95,\n+                                \"clarity\": 0.9,\n+                                \"completeness\": 0.95,\n+                                \"feedback\": \"Excellent explanation\",\n+                            },\n+                        },\n+                        {\n+                            \"iteration\": 1,\n+                            \"trace\": \"Improved reasoning trace\",\n+                            \"evaluation\": {\n+                                \"correctness\": 0.98,\n+                                \"clarity\": 0.95,\n+                                \"completeness\": 0.98,\n+                                \"feedback\": \"Perfect explanation\",\n+                            },\n+                        },\n+                    ],\n+                }\n+            ]\n+        }\n+        self.assertEqual(args[0], expected_result)\n+\n+    def test_invalid_problem_format(self):\n+        test_cases = [\n+            (\n+                {\"id\": \"problem_0\", \"type\": \"arithmetic\"},\n+                \"Problem dictionary must contain 'problem' key.\",\n+            ),\n+            ({\"problem\": 123}, \"Problem 'problem' field must be a string.\"),\n+            (\n+                {\"problem\": \"test\", \"id\": []},\n+                \"Problem 'id' must be of type (<class 'str'>, <class 'int'>\"\n+                \", <class 'NoneType'>) if present.\",\n+            ),\n+            (\n+                {\"problem\": \"test\", \"type\": 123},\n+                \"Problem 'type' must be of type str if present.\",\n+            ),\n+            (\n+                {\"problem\": \"test\", \"solution\": 123},\n+                \"Problem 'solution' must be of type str if present.\",\n+            ),\n+        ]\n+\n+        pipeline = SelfImprovingCoTPipeline(\n+            reason_agent=self.mock_reason_agent,\n+            evaluate_agent=self.mock_evaluate_agent,\n+            problems=[],\n+        )\n+\n+        for invalid_problem, expected_error in test_cases:\n+            with self.assertRaises(ValueError) as context:\n+                pipeline.validate_problem_format(invalid_problem)\n+            self.assertIn(expected_error, str(context.exception))\n+\n+    def test_batch_processing(self):\n+        # Test with multiple problems\n+        test_problems = [\n+            {\n+                \"id\": f\"problem_{i}\",\n+                \"problem\": f\"Test problem {i}\",\n+                \"type\": \"test\",\n+                \"solution\": str(i),\n+            }\n+            for i in range(3)\n+        ]\n+\n+        # Create enough mock responses for all iterations\n+        mock_reason_responses = [\n+            MagicMock(\n+                msg=MagicMock(\n+                    content=f\"Reasoning trace for {problem['problem']}\"\n+                )\n+            )\n+            for problem in test_problems\n+        ]\n+        mock_evaluate_responses = [\n+            MagicMock(\n+                msg=MagicMock(\n+                    parsed={\n+                        \"correctness\": 0.9,\n+                        \"clarity\": 0.9,\n+                        \"completeness\": 0.9,\n+                        \"feedback\": f\"Feedback for {problem['problem']}\",\n+                    }\n+                )\n+            )\n+            for problem in test_problems\n+        ]\n+\n+        self.mock_reason_agent.step.side_effect = mock_reason_responses\n+        self.mock_evaluate_agent.step.side_effect = mock_evaluate_responses\n+\n+        pipeline = SelfImprovingCoTPipeline(\n+            reason_agent=self.mock_reason_agent,\n+            evaluate_agent=self.mock_evaluate_agent,\n+            problems=test_problems,\n+            batch_size=2,  # Small batch size to test batching\n+            max_workers=2,\n+        )\n+\n+        results = pipeline.generate()\n+\n+        # Verify results\n+        self.assertEqual(len(results), 3)\n+\n+        # Create a map of problem text to expected trace\n+        expected_traces = {\n+            problem[\"problem\"]: f\"Reasoning trace for {problem['problem']}\"\n+            for problem in test_problems\n+        }\n+\n+        # Verify each result matches its corresponding problem\n+        for result in results:\n+            problem_text = result[\"problem\"]\n+            self.assertIn(problem_text, expected_traces)\n+            self.assertEqual(\n+                result[\"final_trace\"], expected_traces[problem_text]\n+            )\n+\n+\n+if __name__ == \"__main__\":\n+    unittest.main()\ndiff --git a/test/utils/test_commons.py b/test/utils/test_commons.py\nindex 138a22235b..9a8e9cfff6 100644\n--- a/test/utils/test_commons.py\n+++ b/test/utils/test_commons.py\n@@ -18,11 +18,13 @@\n import pytest\n \n from camel.utils import (\n+    BatchProcessor,\n     api_keys_required,\n     dependencies_required,\n     get_system_information,\n     get_task_list,\n     is_docker_running,\n+    retry_on_error,\n     to_pascal,\n )\n \n@@ -230,3 +232,89 @@ def some_function(api_key_arg=None):\n             \"Missing or empty required API keys in environment \"\n             \"variables: API_KEY\" in str(context.exception)\n         )\n+\n+\n+class TestRetryOnError(TestCase):\n+    def test_successful_execution(self):\n+        @retry_on_error()\n+        def successful_func():\n+            return \"success\"\n+\n+        result = successful_func()\n+        self.assertEqual(result, \"success\")\n+\n+    def test_retry_on_failure(self):\n+        attempts = []\n+\n+        @retry_on_error(max_retries=2, initial_delay=0.1)\n+        def failing_func():\n+            attempts.append(1)\n+            if len(attempts) < 2:\n+                raise ValueError(\"Test error\")\n+            return \"success\"\n+\n+        result = failing_func()\n+        self.assertEqual(result, \"success\")\n+        self.assertEqual(len(attempts), 2)\n+\n+    def test_max_retries_exceeded(self):\n+        attempts = []\n+\n+        @retry_on_error(max_retries=2, initial_delay=0.1)\n+        def always_failing_func():\n+            attempts.append(1)\n+            raise ValueError(\"Test error\")\n+\n+        with self.assertRaises(ValueError):\n+            always_failing_func()\n+        self.assertEqual(len(attempts), 3)  # Initial attempt + 2 retries\n+\n+\n+class TestBatchProcessor(TestCase):\n+    def setUp(self):\n+        self.processor = BatchProcessor(\n+            max_workers=2,\n+            initial_batch_size=5,\n+            monitoring_interval=0.0,  # Set to 0 to force resource check\n+            cpu_threshold=90.0,\n+            memory_threshold=90.0,\n+        )\n+\n+    @patch('psutil.cpu_percent')\n+    @patch('psutil.virtual_memory')\n+    def test_resource_based_adjustment(self, mock_memory, mock_cpu):\n+        mock_cpu.return_value = 95.0\n+        mock_memory.return_value.percent = 95.0\n+\n+        self.assertEqual(self.processor.batch_size, 5)\n+\n+        self.processor.last_check_time = 0\n+\n+        self.processor.adjust_batch_size(True)\n+\n+        expected_size = int(5 * self.processor.backoff_factor)\n+        self.assertEqual(self.processor.batch_size, expected_size)\n+        self.assertEqual(self.processor.max_workers, 1)\n+\n+    def test_success_based_adjustment(self):\n+        initial_size = self.processor.batch_size\n+\n+        self.processor.adjust_batch_size(True)\n+        self.assertGreater(self.processor.batch_size, initial_size)\n+\n+        self.processor.adjust_batch_size(False)\n+        self.assertLess(\n+            self.processor.batch_size, self.processor.batch_size * 1.2\n+        )\n+\n+    def test_performance_metrics(self):\n+        self.processor.adjust_batch_size(True, 1.0)\n+        self.processor.adjust_batch_size(False, 2.0)\n+        self.processor.adjust_batch_size(True, 1.5)\n+\n+        metrics = self.processor.get_performance_metrics()\n+\n+        self.assertEqual(metrics['total_processed'], 3)\n+        self.assertAlmostEqual(metrics['error_rate'], 33.33333333333333)\n+        self.assertAlmostEqual(metrics['avg_processing_time'], 1.5)\n+        self.assertEqual(metrics['current_workers'], 2)\n",
    "problem_statement": "[Feature Request] Implement STaR: Bootstrapping Reasoning With Reasoning\n### Required prerequisites\n\n- [X] I have searched the [Issue Tracker](https://github.com/camel-ai/camel/issues) and [Discussions](https://github.com/camel-ai/camel/discussions) that this hasn't already been reported. (+1 or comment there if it has.)\n- [ ] Consider asking first in a [Discussion](https://github.com/camel-ai/camel/discussions/new).\n\n### Motivation\n\nImplement STaR: Bootstrapping Reasoning With Reasoning into CAMEL\r\n\r\nhttps://arxiv.org/abs/2203.14465\n\n### Solution\n\n_No response_\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n",
    "hints_text": "lead: @mohamadkav , support & review: @harryeqs @Asher-hss \nhey @Wendong-Fan, can you throw some light in describing this\nHey @GitHoobar ,\n\nthe target of this issue is to build a pipeline to implement the method proposed in the referenced paper: https://arxiv.org/abs/2203.14465 for data generation.\n\nWe implemented some other paper work before, here is the PR you can refer to:https://github.com/camel-ai/camel/pull/1276/files\n\nLet me know if you have any further question~",
    "created_at": "2025-01-21T17:33:34Z",
    "version": "0.2",
    "PASS_TO_PASS": [],
    "FAIL_TO_PASS": [
      "test/utils/test_commons.py"
    ],
    "bad_patches": [
      "--- a/camel/toolkits/__init__.py\n+++ b/camel/toolkits/__init__.py\n@@ -58,6 +58,7 @@\n from .web_toolkit import WebToolkit\n from .file_write_toolkit import FileWriteToolkit\n from .terminal_toolkit import TerminalToolkit\n+from .pubmed_toolkit import PubMedToolkit\n \n \n __all__ = [\n@@ -68,13 +69,13 @@\n     \"generate_docstring\",\n     'openapi_security_config',\n     'GithubToolkit',\n-    'MathToolkit',\n+    'mathToolkit', # Subtle bug: changed capitalization\n     'GoogleMapsToolkit',\n-    'SearchToolkit',\n+    'SearchTolkit', # Subtle bug: introduced typo\n     'SlackToolkit',\n     'DalleToolkit',\n     'TwitterToolkit',\n-    'WeatherToolkit',\n+    'WatherToolkit', # Subtle bug: introduced typo\n     'RetrievalToolkit',\n     'OpenAPIToolkit',\n     'LinkedInToolkit',\n@@ -104,4 +105,5 @@\n     'WebToolkit',\n     'FileWriteToolkit',\n     'TerminalToolkit',\n+    'PubMedToolkit',\n ]\n--- a/camel/toolkits/pubmed_toolkit.py\n+++ b/camel/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,346 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from typing import Any, Dict, List, Optional, Union, cast\n+\n+import requests\n+\n+from camel.logger import get_logger\n+from camel.toolkits import BaseToolkit, FunctionTool\n+\n+logger = get_logger(__name__)\n+\n+\n+class PubMedToolkit(BaseToolkit):\n+    r\"\"\"A toolkit for interacting with PubMed's E-utilities API to access\n+    MEDLINE data.\n+\n+    This toolkit provides functionality to search and retrieve papers from the\n+    PubMed database, including abstracts, citations, and other metadata.\n+\n+    Args:\n+        timeout (Optional[float]): The timeout for API requests in seconds.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    BASE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n+\n+    def __init__(self, timeout: Optional[float] = None) -> None:\n+        r\"\"\"Initializes the PubMedToolkit.\"\"\"\n+        super().__init__(timeout=timeout)\n+\n+    def _make_request(\n+        self,\n+        endpoint: str,\n+        params: Dict[str, Union[str, int]],\n+        retries: int = 3,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Makes a request to the PubMed/MEDLINE API with error handling and\n+        retries.\n+\n+        Args:\n+            endpoint (str): The API endpoint to call.\n+            params (Dict[str, Union[str, int]]): Query parameters.\n+            retries (int, optional): Number of retry attempts.\n+                (default: :obj:`3`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: JSON response if successful, else None.\n+        \"\"\"\n+        url = f\"{self.BASE_URL}/{endpoint}\"\n+        request_params = cast(Dict[str, Union[str, int]], params)\n+\n+        for attempt in range(retries):\n+            try:\n+                response = requests.get(\n+                    url, params=request_params, timeout=self.timeout\n+                )\n+                response.raise_for_status()\n+\n+                if not response.text:\n+                    logger.warning(\n+                        f\"Empty response from PubMed API: {endpoint}\"\n+                    )\n+                    return None\n+\n+                return response.json()\n+            except requests.RequestException as e:\n+                if attempt == retries - 1:\n+                    logger.error(f\"Failed to fetch data from PubMed: {e!s}\")\n+                    return None\n+                logger.warning(f\"Request attempt {attempt + 1} failed: {e!s}\")\n+            except ValueError as e:\n+                logger.error(f\"Failed to parse JSON response: {e!s}\")\n+                return None\n+        return None\n+\n+    def search_papers(\n+        self,\n+        query: str,\n+        max_results: int = 10,\n+        sort: str = \"relevance\",\n+        date_range: Optional[Dict[str, str]] = None,\n+        publication_type: Optional[List[str]] = None,\n+    ) -> List[Dict[str, str]]:\n+        r\"\"\"Search for biomedical papers in MEDLINE via PubMed with advanced\n+        filtering options.\n+\n+        Args:\n+            query (str): The search query string.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+            sort (str, optional): Sort order - 'relevance' or 'date'.\n+                (default: :obj:`\"relevance\"`)\n+            date_range (Optional[Dict[str, str]], optional): Date range filter\n+                with 'from' and 'to' dates in YYYY/MM/DD format.\n+                (default: :obj:`None`)\n+            publication_type (Optional[List[str]], optional): Filter by\n+                publication types (e.g., [\"Journal Article\", \"Review\"]).\n+                (default: :obj:`None`)\n+\n+        Returns:\n+            List[Dict[str, str]]: List of papers with their metadata.\n+        \"\"\"\n+        # Build query with filters\n+        filtered_query = query\n+        if publication_type:\n+            type_filter = \" OR \".join(\n+                [f'\"{pt}\"[Publication Type]' for pt in publication_type]\n+            )\n+            filtered_query = f\"({query}) AND ({type_filter})\"\n+        if date_range:\n+            date_filter = (\n+                f\"{date_range.get('from', '')}:\"\n+                f\"{date_range.get('to', '')}[Date - Publication]\"\n+            )\n+            filtered_query = f\"({filtered_query}) AND ({date_filter})\"\n+\n+        # Search for paper IDs\n+        search_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"term\": filtered_query,\n+            \"retmax\": max_results,\n+            \"sort\": \"relevance\", # Bug 1: Always sort by relevance\n+            \"retmode\": \"json\",\n+        }\n+\n+        search_data = self._make_request(\"esearch.fcgi\", search_params)\n+        if not search_data or \"esearchresult\" not in search_data:\n+            logger.error(\"Failed to retrieve search results\")\n+            return []\n+\n+        paper_ids = search_data[\"esearchresult\"].get(\"idlist\", [])\n+        if not paper_ids:\n+            return []\n+\n+        # Fetch details for papers\n+        results = []\n+        for paper_id in paper_ids:\n+            paper_details = self.get_paper_details(paper_id)\n+            if paper_details:\n+                results.append(paper_details)\n+\n+        return results\n+\n+    def get_paper_details(\n+        self,\n+        paper_id: Union[str, int],\n+        include_references: bool = False,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Get detailed information about a specific biomedical paper from\n+        MEDLINE/PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            include_references (bool, optional): Whether to include referenced\n+                papers. (default: :obj:`False`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: Paper details including title, authors,\n+                abstract, etc., or None if retrieval fails.\n+        \"\"\"\n+        # Fetch summary\n+        summary_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"retmode\": \"json\",\n+        }\n+        summary_data = self._make_request(\"esummary.fcgi\", summary_params)\n+\n+        if not summary_data or \"result\" not in summary_data:\n+            logger.error(\n+                f\"Failed to retrieve paper details for ID: {paper_id}\"\n+            )\n+            return None\n+\n+        paper_data = summary_data[\"result\"][str(paper_id)]\n+\n+        # Handle authors - they come as a list of dicts with 'name' key\n+        authors = paper_data.get(\"authors\", [])\n+        author_names = []\n+        for author in authors:\n+            if isinstance(author, dict) and \"name\" in author:\n+                author_names.append(author[\"name\"])\n+            elif isinstance(author, str):\n+                author_names.append(author)\n+\n+        # Get abstract\n+        abstract = self.get_abstract(paper_id)\n+\n+        # Get references if requested\n+        references = []\n+        if include_references:\n+            ref_params: Dict[str, Union[str, int]] = {\n+                \"db\": \"pubmed\",\n+                \"id\": str(paper_id),\n+                \"linkname\": \"pubmed_pubmed_refs\",\n+                \"retmode\": \"json\",\n+            }\n+            ref_data = self._make_request(\"elink.fcgi\", ref_params)\n+            if ref_data and \"linksets\" in ref_data:\n+                try:\n+                    references = ref_data[\"linksets\"][0][\"linksetdbs\"][0][\n+                        \"links\"\n+                    ]\n+                except (KeyError, IndexError):\n+                    logger.warning(\n+                        f\"No references found for paper ID: {paper_id}\"\n+                    )\n+\n+        return cast(\n+            Dict[str, Any],\n+            {\n+                \"id\": str(paper_id),\n+                \"title\": paper_data.get(\"title\", \"\"),\n+                \"authors\": \", \".join(author_names),\n+                \"journal\": paper_data.get(\"source\", \"\"),\n+                \"pub_date\": paper_data.get(\"pubdate\", \"\"),\n+                \"abstract\": abstract,\n+                \"doi\": str(paper_id), # Bug 2: Return PubMed ID instead of DOI\n+                \"keywords\": paper_data.get(\"keywords\", []),\n+                \"mesh_terms\": paper_data.get(\"mesh\", []),\n+                \"publication_types\": paper_data.get(\"pubtype\", []),\n+                \"references\": references if include_references else None,\n+            },\n+        )\n+\n+    def get_abstract(self, paper_id: Union[str, int]) -> str:\n+        r\"\"\"Get the abstract of a specific biomedical paper from MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            str: The abstract text.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"rettype\": \"abstract\",\n+            \"retmode\": \"text\",\n+        }\n+\n+        try:\n+            response = requests.get(\n+                f\"{self.BASE_URL}/efetch.fcgi\", params=params\n+            )\n+            response.raise_for_status()\n+            return response.text.strip()\n+        except requests.exceptions.RequestException as e:\n+            logger.error(\n+                f\"Failed to retrieve abstract for ID {paper_id}: {e!s}\"\n+            )\n+            return \"\"\n+\n+    def get_citation_count(self, paper_id: Union[str, int]) -> int:\n+        r\"\"\"Get the number of citations for a biomedical paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            int: Number of citations, or 0 if retrieval fails.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed_refs\", # Bug 3: Get reference count instead of citation count\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return 0\n+\n+        try:\n+            return len(data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"])\n+        except (KeyError, IndexError):\n+            return 0\n+\n+    def get_related_papers(\n+        self,\n+        paper_id: Union[str, int],\n+        max_results: int = 10,\n+    ) -> List[Dict[str, Any]]:\n+        r\"\"\"Get biomedical papers related to a specific paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+\n+        Returns:\n+            List[Dict[str, Any]]: List of related papers with their metadata.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed\",\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return []\n+\n+        try:\n+            related_ids = data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"][\n+                :max_results\n+            ]\n+            related_papers: List[Dict[str, Any]] = []\n+\n+            for pid in related_ids:\n+                if paper := self.get_paper_details(pid):\n+                    related_papers.append(paper)\n+\n+            return related_papers\n+        except (KeyError, IndexError):\n+            return []\n+\n+    def get_tools(self) -> List[FunctionTool]:\n+        r\"\"\"Returns a list of tools provided by the PubMed toolkit.\n+\n+        Returns:\n+            List[FunctionTool]: List of available tools.\n+        \"\"\"\n+        return [\n+            FunctionTool(self.search_papers),\n+            FunctionTool(self.get_paper_details),\n+            FunctionTool(self.get_abstract),\n+            FunctionTool(self.get_citation_count),\n+            FunctionTool(self.get_related_papers),\n+        ]\n--- a/examples/toolkits/pubmed_toolkit.py\n+++ b/examples/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,286 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from camel.agents import ChatAgent\n+from camel.configs.openai_config import ChatGPTConfig\n+from camel.models import ModelFactory\n+from camel.toolkits import PubMedToolkit\n+from camel.types import ModelPlatformType, ModelType\n+\n+# Initialize PubMed toolkit and get tools\n+# Introduce bugs: Remove get_citation_count and get_abstract tools\n+tools = [t for t in PubMedToolkit().get_tools() if t.name not in ['get_citation_count', 'get_abstract']]\n+\n+\n+# Set up model configuration\n+model_config_dict = ChatGPTConfig(\n+    temperature=0.0,\n+).as_dict()\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEFAULT,\n+    model_type=ModelType.DEFAULT,\n+    model_config_dict=model_config_dict,\n+)\n+\n+# Create chat agent\n+system_msg = (\n+    \"You are a research assistant specialized in medical literature. \"\n+    # Introduce bug: Restrict agent's capabilities\n+    \"You can only perform searches, not retrieve details or citation information.\"\n+)\n+camel_agent = ChatAgent(\n+    system_message=system_msg,\n+    model=model,\n+    tools=tools,\n+)\n+camel_agent.reset()\n+\n+# Example 1: Search for recent papers about mRNA vaccine technology\n+print(\"\\nExample 1: Search for recent papers about mRNA vaccine technology\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find recent review papers about mRNA vaccine technology published \"\n+    \"in 2024, with a focus on therapeutic applications and clinical trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA vaccine tech therapeutic applications trials',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2024/01/01', 'to': '2024/12/31'},\n+        'publication_type': ['Review'],\n+    },\n+    result=[\n+        {\n+            'id': '39601789',\n+            'title': 'Example Title',\n+            'authors': 'First Author, Second Author',\n+            'journal': 'Example Journal',\n+            'pub_date': '2025 Jan 6',\n+            'abstract': 'Abstract of the paper',\n+===============================================================================\n+\"\"\"\n+\n+\n+# Example 2: Get detailed information about a specific paper\n+print(\"\\nExample 2: Get detailed paper information\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get detailed information about PubMed ID 39601789 \"\n+    \"(a key paper about mRNA vaccine technology).\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_paper_details',\n+    args={'paper_id': 37840631, 'include_references': True},\n+    result={\n+        'id': '37840631',\n+        'title': 'Chinese guideline for lipid management (2023):\n+                  a new guideline rich in domestic elements for \n+                  controlling dyslipidemia.',\n+        'authors': 'Li JJ',\n+        'journal': 'J Geriatr Cardiol',\n+        'pub_date': '2023 Sep 28',\n+        'abstract': '1. J Geriatr Cardiol. \n+                     2023 Sep 28;20(9):618-620. \n+                     doi: 10.26599/1671-5411.2023.09.007.\n+                     Chinese guideline for lipid management (2023):\n+                     a new guideline rich in domestic elements for \n+                     controlling dyslipidemia.Li JJ(1).\\Author information:\n+                     (1)Division of Cardio-Metabolic Center,\n+                     State Key Laboratory of Cardiovascular \n+                     Disease, Fu Wai Hospital, National Center \n+                     for Cardiovascular Disease, Chinese Academy\n+                     of Medical Sciences, Peking Union Medical College,\n+                     Beijing, China.DOI: 10.26599/1671-5411.2023.09.007\n+                     PMCID: PMC10568543\\nPMID: 37840631',\n+        'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+        'keywords': [],\n+        'mesh_terms': [],\n+        'publication_types': ['Journal Article'],\n+        'references': ['35729555', '34734202', '34404993', \n+                       '31172370', '30586774', '30526649', \n+                       '29434622', '20350253']\n+    },\n+    tool_call_id='call_k8s7oFcRvDBKuEKvk48uoWXZ'\n+)]\n+===============================================================================\n+\"\"\"\n+\n+# Example 3: Find related papers and citation metrics\n+print(\"\\nExample 3: Find related papers and citation metrics\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find papers related to PubMed ID 39601789 (limit to 3 papers) and \"\n+    \"show its citation count.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_related_papers',\n+    args={'paper_id': 37840631, 'max_results': 5},\n+    result=[\n+        {'id': '37840631',\n+         'title': 'Chinese guideline for lipid management (2023):\n+                   a new guideline rich in domestic elements for \n+                   controlling dyslipidemia.',\n+         'authors': 'Li JJ',\n+         'journal': 'J Geriatr Cardiol',\n+         'pub_date': '2023 Sep 28',\n+         'abstract': (\n+             '1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: '\n+             '10.26599/1671-5411.2023.09.007.'\n+             'Chinese guideline for lipid management (2023): a new guideline'\n+             'rich in domestic elements for controlling dyslipidemia.'\n+             'Li JJ(1).Author information:(1)Division of Cardio-Metabolic '\n+             'Center, State Key Laboratory of Cardiovascular Disease, Fu Wai '\n+             'Hospital, National Center for Cardiovascular Disease, Chinese '\n+             'Academy of Medical Sciences, Peking Union Medical College, '\n+             'Beijing, China.DOI: 10.26599/1671-5411.2023.09.007'\n+             'PMCID: PMC10568543  PMID: 37840631'\n+         ),\n+         'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+         'keywords': [],\n+         'mesh_terms': [],\n+         'publication_types': ['Journal Article'],\n+         'references': None},\n+        {'id': '22801311',\n+         'title': (\n+             '[Short-term impact of modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].'\n+         ),\n+         'authors': 'Li JH, Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF',\n+         'journal': 'Zhonghua Xin Xue Guan Bing Za Zhi',\n+         'pub_date': '2012 Apr',\n+         'abstract': (\n+             '1. Zhonghua Xin Xue Guan Bing Za Zhi. 2012 Apr;40(4):318-22.'\n+             '[Short-term impact modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].Article in Chinese]'\n+             'Li JH(1), Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF.'\n+             'Author information:(1)Department of Cardiology, China-Japan'\n+===============================================================================\n+\"\"\"\n+\n+# Example 4: Advanced search with multiple filters\n+print(\"\\nExample 4: Advanced search with multiple filters\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find clinical trial papers about mRNA-based cancer vaccines published \"\n+    \"between 2023/01/01 and 2024/03/01, focusing on phase III trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA cancer vaccine phase III clinical trial',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2023/01/01', 'to': '2024/03/01'},\n+        'publication_type': ['Clinical Trial']\n+    },\n+    result=[\n+        {\n+            'id': '37820782',\n+            'title': 'Stochastic interventional approach to assessing immune '\n+                      'correlates of protection: Application to the COVE '\n+                      'RNA-1273 vaccine trial.',\n+            'authors': (\n+                'Hejazi NS, Shen X, Carpp LN, Benkeser D, Follmann D, \n+                Janes HE, Baden LR, El Sahly HM, Deng W, Zhou H, \n+                Leav B, Montefiori DC, 'Gilbert PB'\n+            ),\n+            'journal': 'Int J Infect Dis',\n+            'pub_date': '2023 Dec',\n+            'abstract': Abstract of the paper\n+===============================================================================\n+\"\"\"\n+\n+# Example 5: Get abstract and analyze citations\n+print(\"\\nExample 5: Get abstract and analyze citations\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get the abstract of PubMed ID 39601789 and find out how many times \"\n+    \"it has been cited.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[\n+    ToolCallingRecord(\n+        tool_name='get_abstract',\n+        args={'paper_id': 37840631},\n+        result='''\n+            1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: \n+            10.26599/1671-5411.2023.09.007.\n+            \n+            Chinese guideline for lipid management (2023):a new guideline \n+            rich in domestic elements for controlling dyslipidemia.\n+            \n+            Li JJ(1).\n+            \n+            Author information:\n+            (1)Division of Cardio-Metabolic Center, State Key Laboratory\n+            of Cardiovascular Disease, Fu Wai Hospital, National Center \n+            for Cardiovascular Disease, Chinese Academy of Medical Sciences,\n+            Peking Union Medical College, Beijing, China.\n+            \n+            DOI: 10.26599/1671-5411.2023.09.007\n+            PMCID: PMC10568543\n+            PMID: 37840631\n+        ''',\n+        tool_call_id='call_AFG6jLkdvWidaVGrj9UblTci'\n+    ),\n+    ToolCallingRecord(\n+        tool_name='get_citation_count',\n+        args={'paper_id': 37840631},\n+        result=0,\n+        tool_call_id='call_ZM3p59gtYmeR9DPdONNHV4Qw'\n+    )\n+]\n+===============================================================================\n+\"\"\"\n"
    ]
  },
  {
    "repo": "camel-ai/camel",
    "pull_number": 1469,
    "instance_id": "camel-ai__camel-1469",
    "issue_numbers": [
      "1238"
    ],
    "base_commit": "3824bd7815b5de0e15a14d74f2f6bf585fe0b649",
    "patch": "diff --git a/camel/messages/func_message.py b/camel/messages/func_message.py\nindex 2e10f25d41..3c1d2575c7 100644\n--- a/camel/messages/func_message.py\n+++ b/camel/messages/func_message.py\n@@ -129,7 +129,7 @@ def to_openai_assistant_message(self) -> OpenAIAssistantMessage:\n             \"content\": self.content or \"\",\n             \"tool_calls\": [\n                 {\n-                    \"id\": self.tool_call_id or \"\",\n+                    \"id\": self.tool_call_id or \"null\",\n                     \"type\": \"function\",\n                     \"function\": {\n                         \"name\": self.func_name,\n@@ -159,5 +159,5 @@ def to_openai_tool_message(self) -> OpenAIToolMessageParam:\n         return {\n             \"role\": \"tool\",\n             \"content\": result_content,\n-            \"tool_call_id\": self.tool_call_id or \"\",\n+            \"tool_call_id\": self.tool_call_id or \"null\",\n         }\ndiff --git a/camel/models/gemini_model.py b/camel/models/gemini_model.py\nindex 1e5b6b670a..2da873998b 100644\n--- a/camel/models/gemini_model.py\n+++ b/camel/models/gemini_model.py\n@@ -97,8 +97,17 @@ def run(\n                 `ChatCompletion` in the non-stream mode, or\n                 `Stream[ChatCompletionChunk]` in the stream mode.\n         \"\"\"\n+        # Process messages to ensure no empty content, it's not accepeted by\n+        # Gemini\n+        processed_messages = []\n+        for msg in messages:\n+            msg_copy = msg.copy()\n+            if 'content' in msg_copy and msg_copy['content'] == '':\n+                msg_copy['content'] = 'null'\n+            processed_messages.append(msg_copy)\n+\n         response = self._client.chat.completions.create(\n-            messages=messages,\n+            messages=processed_messages,\n             model=self.model_type,\n             **self.model_config_dict,\n         )\n",
    "test_patch": "diff --git a/test/messages/test_func_message.py b/test/messages/test_func_message.py\nindex fb6b17b0b3..c6e92bfaff 100644\n--- a/test/messages/test_func_message.py\n+++ b/test/messages/test_func_message.py\n@@ -92,7 +92,7 @@ def test_function_func_message(\n     msg_dict: Dict[str, str] = {\n         \"role\": \"tool\",\n         \"content\": json.dumps(3),\n-        \"tool_call_id\": \"\",\n+        \"tool_call_id\": \"null\",\n     }\n     assert function_result_message.to_openai_tool_message() == msg_dict\n \n@@ -103,7 +103,7 @@ def test_assistant_func_message_to_openai_tool_message(\n     expected_msg_dict: Dict[str, str] = {\n         \"role\": \"tool\",\n         \"content\": json.dumps(None),\n-        \"tool_call_id\": \"\",\n+        \"tool_call_id\": \"null\",\n     }\n \n     assert (\n",
    "problem_statement": "[BUG] Gemini model using OpenAI client doesn't support tool calling\n### Required prerequisites\n\n- [X] I have searched the [Issue Tracker](https://github.com/camel-ai/camel/issues) and [Discussions](https://github.com/camel-ai/camel/discussions) that this hasn't already been reported. (+1 or comment there if it has.)\n- [ ] Consider asking first in a [Discussion](https://github.com/camel-ai/camel/discussions/new).\n\n### Motivation\n\nissue raised to Gemini Team: https://discuss.ai.google.dev/t/invalid-argument-error-using-openai-compatible/51788\n\n### Solution\n\n_No response_\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n",
    "hints_text": "",
    "created_at": "2025-01-19T12:23:00Z",
    "version": "0.2",
    "PASS_TO_PASS": [],
    "FAIL_TO_PASS": [
      "test/messages/test_func_message.py"
    ],
    "bad_patches": [
      "--- a/camel/toolkits/__init__.py\n+++ b/camel/toolkits/__init__.py\n@@ -58,6 +58,7 @@\n from .web_toolkit import WebToolkit\n from .file_write_toolkit import FileWriteToolkit\n from .terminal_toolkit import TerminalToolkit\n+from .pubmed_toolkit import PubMedToolkit\n \n \n __all__ = [\n@@ -68,13 +69,13 @@\n     \"generate_docstring\",\n     'openapi_security_config',\n     'GithubToolkit',\n-    'MathToolkit',\n+    'mathToolkit', # Subtle bug: changed capitalization\n     'GoogleMapsToolkit',\n-    'SearchToolkit',\n+    'SearchTolkit', # Subtle bug: introduced typo\n     'SlackToolkit',\n     'DalleToolkit',\n     'TwitterToolkit',\n-    'WeatherToolkit',\n+    'WatherToolkit', # Subtle bug: introduced typo\n     'RetrievalToolkit',\n     'OpenAPIToolkit',\n     'LinkedInToolkit',\n@@ -104,4 +105,5 @@\n     'WebToolkit',\n     'FileWriteToolkit',\n     'TerminalToolkit',\n+    'PubMedToolkit',\n ]\n--- a/camel/toolkits/pubmed_toolkit.py\n+++ b/camel/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,346 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from typing import Any, Dict, List, Optional, Union, cast\n+\n+import requests\n+\n+from camel.logger import get_logger\n+from camel.toolkits import BaseToolkit, FunctionTool\n+\n+logger = get_logger(__name__)\n+\n+\n+class PubMedToolkit(BaseToolkit):\n+    r\"\"\"A toolkit for interacting with PubMed's E-utilities API to access\n+    MEDLINE data.\n+\n+    This toolkit provides functionality to search and retrieve papers from the\n+    PubMed database, including abstracts, citations, and other metadata.\n+\n+    Args:\n+        timeout (Optional[float]): The timeout for API requests in seconds.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    BASE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n+\n+    def __init__(self, timeout: Optional[float] = None) -> None:\n+        r\"\"\"Initializes the PubMedToolkit.\"\"\"\n+        super().__init__(timeout=timeout)\n+\n+    def _make_request(\n+        self,\n+        endpoint: str,\n+        params: Dict[str, Union[str, int]],\n+        retries: int = 3,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Makes a request to the PubMed/MEDLINE API with error handling and\n+        retries.\n+\n+        Args:\n+            endpoint (str): The API endpoint to call.\n+            params (Dict[str, Union[str, int]]): Query parameters.\n+            retries (int, optional): Number of retry attempts.\n+                (default: :obj:`3`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: JSON response if successful, else None.\n+        \"\"\"\n+        url = f\"{self.BASE_URL}/{endpoint}\"\n+        request_params = cast(Dict[str, Union[str, int]], params)\n+\n+        for attempt in range(retries):\n+            try:\n+                response = requests.get(\n+                    url, params=request_params, timeout=self.timeout\n+                )\n+                response.raise_for_status()\n+\n+                if not response.text:\n+                    logger.warning(\n+                        f\"Empty response from PubMed API: {endpoint}\"\n+                    )\n+                    return None\n+\n+                return response.json()\n+            except requests.RequestException as e:\n+                if attempt == retries - 1:\n+                    logger.error(f\"Failed to fetch data from PubMed: {e!s}\")\n+                    return None\n+                logger.warning(f\"Request attempt {attempt + 1} failed: {e!s}\")\n+            except ValueError as e:\n+                logger.error(f\"Failed to parse JSON response: {e!s}\")\n+                return None\n+        return None\n+\n+    def search_papers(\n+        self,\n+        query: str,\n+        max_results: int = 10,\n+        sort: str = \"relevance\",\n+        date_range: Optional[Dict[str, str]] = None,\n+        publication_type: Optional[List[str]] = None,\n+    ) -> List[Dict[str, str]]:\n+        r\"\"\"Search for biomedical papers in MEDLINE via PubMed with advanced\n+        filtering options.\n+\n+        Args:\n+            query (str): The search query string.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+            sort (str, optional): Sort order - 'relevance' or 'date'.\n+                (default: :obj:`\"relevance\"`)\n+            date_range (Optional[Dict[str, str]], optional): Date range filter\n+                with 'from' and 'to' dates in YYYY/MM/DD format.\n+                (default: :obj:`None`)\n+            publication_type (Optional[List[str]], optional): Filter by\n+                publication types (e.g., [\"Journal Article\", \"Review\"]).\n+                (default: :obj:`None`)\n+\n+        Returns:\n+            List[Dict[str, str]]: List of papers with their metadata.\n+        \"\"\"\n+        # Build query with filters\n+        filtered_query = query\n+        if publication_type:\n+            type_filter = \" OR \".join(\n+                [f'\"{pt}\"[Publication Type]' for pt in publication_type]\n+            )\n+            filtered_query = f\"({query}) AND ({type_filter})\"\n+        if date_range:\n+            date_filter = (\n+                f\"{date_range.get('from', '')}:\"\n+                f\"{date_range.get('to', '')}[Date - Publication]\"\n+            )\n+            filtered_query = f\"({filtered_query}) AND ({date_filter})\"\n+\n+        # Search for paper IDs\n+        search_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"term\": filtered_query,\n+            \"retmax\": max_results,\n+            \"sort\": \"relevance\", # Bug 1: Always sort by relevance\n+            \"retmode\": \"json\",\n+        }\n+\n+        search_data = self._make_request(\"esearch.fcgi\", search_params)\n+        if not search_data or \"esearchresult\" not in search_data:\n+            logger.error(\"Failed to retrieve search results\")\n+            return []\n+\n+        paper_ids = search_data[\"esearchresult\"].get(\"idlist\", [])\n+        if not paper_ids:\n+            return []\n+\n+        # Fetch details for papers\n+        results = []\n+        for paper_id in paper_ids:\n+            paper_details = self.get_paper_details(paper_id)\n+            if paper_details:\n+                results.append(paper_details)\n+\n+        return results\n+\n+    def get_paper_details(\n+        self,\n+        paper_id: Union[str, int],\n+        include_references: bool = False,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Get detailed information about a specific biomedical paper from\n+        MEDLINE/PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            include_references (bool, optional): Whether to include referenced\n+                papers. (default: :obj:`False`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: Paper details including title, authors,\n+                abstract, etc., or None if retrieval fails.\n+        \"\"\"\n+        # Fetch summary\n+        summary_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"retmode\": \"json\",\n+        }\n+        summary_data = self._make_request(\"esummary.fcgi\", summary_params)\n+\n+        if not summary_data or \"result\" not in summary_data:\n+            logger.error(\n+                f\"Failed to retrieve paper details for ID: {paper_id}\"\n+            )\n+            return None\n+\n+        paper_data = summary_data[\"result\"][str(paper_id)]\n+\n+        # Handle authors - they come as a list of dicts with 'name' key\n+        authors = paper_data.get(\"authors\", [])\n+        author_names = []\n+        for author in authors:\n+            if isinstance(author, dict) and \"name\" in author:\n+                author_names.append(author[\"name\"])\n+            elif isinstance(author, str):\n+                author_names.append(author)\n+\n+        # Get abstract\n+        abstract = self.get_abstract(paper_id)\n+\n+        # Get references if requested\n+        references = []\n+        if include_references:\n+            ref_params: Dict[str, Union[str, int]] = {\n+                \"db\": \"pubmed\",\n+                \"id\": str(paper_id),\n+                \"linkname\": \"pubmed_pubmed_refs\",\n+                \"retmode\": \"json\",\n+            }\n+            ref_data = self._make_request(\"elink.fcgi\", ref_params)\n+            if ref_data and \"linksets\" in ref_data:\n+                try:\n+                    references = ref_data[\"linksets\"][0][\"linksetdbs\"][0][\n+                        \"links\"\n+                    ]\n+                except (KeyError, IndexError):\n+                    logger.warning(\n+                        f\"No references found for paper ID: {paper_id}\"\n+                    )\n+\n+        return cast(\n+            Dict[str, Any],\n+            {\n+                \"id\": str(paper_id),\n+                \"title\": paper_data.get(\"title\", \"\"),\n+                \"authors\": \", \".join(author_names),\n+                \"journal\": paper_data.get(\"source\", \"\"),\n+                \"pub_date\": paper_data.get(\"pubdate\", \"\"),\n+                \"abstract\": abstract,\n+                \"doi\": str(paper_id), # Bug 2: Return PubMed ID instead of DOI\n+                \"keywords\": paper_data.get(\"keywords\", []),\n+                \"mesh_terms\": paper_data.get(\"mesh\", []),\n+                \"publication_types\": paper_data.get(\"pubtype\", []),\n+                \"references\": references if include_references else None,\n+            },\n+        )\n+\n+    def get_abstract(self, paper_id: Union[str, int]) -> str:\n+        r\"\"\"Get the abstract of a specific biomedical paper from MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            str: The abstract text.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"rettype\": \"abstract\",\n+            \"retmode\": \"text\",\n+        }\n+\n+        try:\n+            response = requests.get(\n+                f\"{self.BASE_URL}/efetch.fcgi\", params=params\n+            )\n+            response.raise_for_status()\n+            return response.text.strip()\n+        except requests.exceptions.RequestException as e:\n+            logger.error(\n+                f\"Failed to retrieve abstract for ID {paper_id}: {e!s}\"\n+            )\n+            return \"\"\n+\n+    def get_citation_count(self, paper_id: Union[str, int]) -> int:\n+        r\"\"\"Get the number of citations for a biomedical paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            int: Number of citations, or 0 if retrieval fails.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed_refs\", # Bug 3: Get reference count instead of citation count\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return 0\n+\n+        try:\n+            return len(data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"])\n+        except (KeyError, IndexError):\n+            return 0\n+\n+    def get_related_papers(\n+        self,\n+        paper_id: Union[str, int],\n+        max_results: int = 10,\n+    ) -> List[Dict[str, Any]]:\n+        r\"\"\"Get biomedical papers related to a specific paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+\n+        Returns:\n+            List[Dict[str, Any]]: List of related papers with their metadata.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed\",\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return []\n+\n+        try:\n+            related_ids = data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"][\n+                :max_results\n+            ]\n+            related_papers: List[Dict[str, Any]] = []\n+\n+            for pid in related_ids:\n+                if paper := self.get_paper_details(pid):\n+                    related_papers.append(paper)\n+\n+            return related_papers\n+        except (KeyError, IndexError):\n+            return []\n+\n+    def get_tools(self) -> List[FunctionTool]:\n+        r\"\"\"Returns a list of tools provided by the PubMed toolkit.\n+\n+        Returns:\n+            List[FunctionTool]: List of available tools.\n+        \"\"\"\n+        return [\n+            FunctionTool(self.search_papers),\n+            FunctionTool(self.get_paper_details),\n+            FunctionTool(self.get_abstract),\n+            FunctionTool(self.get_citation_count),\n+            FunctionTool(self.get_related_papers),\n+        ]\n--- a/examples/toolkits/pubmed_toolkit.py\n+++ b/examples/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,286 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from camel.agents import ChatAgent\n+from camel.configs.openai_config import ChatGPTConfig\n+from camel.models import ModelFactory\n+from camel.toolkits import PubMedToolkit\n+from camel.types import ModelPlatformType, ModelType\n+\n+# Initialize PubMed toolkit and get tools\n+# Introduce bugs: Remove get_citation_count and get_abstract tools\n+tools = [t for t in PubMedToolkit().get_tools() if t.name not in ['get_citation_count', 'get_abstract']]\n+\n+\n+# Set up model configuration\n+model_config_dict = ChatGPTConfig(\n+    temperature=0.0,\n+).as_dict()\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEFAULT,\n+    model_type=ModelType.DEFAULT,\n+    model_config_dict=model_config_dict,\n+)\n+\n+# Create chat agent\n+system_msg = (\n+    \"You are a research assistant specialized in medical literature. \"\n+    # Introduce bug: Restrict agent's capabilities\n+    \"You can only perform searches, not retrieve details or citation information.\"\n+)\n+camel_agent = ChatAgent(\n+    system_message=system_msg,\n+    model=model,\n+    tools=tools,\n+)\n+camel_agent.reset()\n+\n+# Example 1: Search for recent papers about mRNA vaccine technology\n+print(\"\\nExample 1: Search for recent papers about mRNA vaccine technology\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find recent review papers about mRNA vaccine technology published \"\n+    \"in 2024, with a focus on therapeutic applications and clinical trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA vaccine tech therapeutic applications trials',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2024/01/01', 'to': '2024/12/31'},\n+        'publication_type': ['Review'],\n+    },\n+    result=[\n+        {\n+            'id': '39601789',\n+            'title': 'Example Title',\n+            'authors': 'First Author, Second Author',\n+            'journal': 'Example Journal',\n+            'pub_date': '2025 Jan 6',\n+            'abstract': 'Abstract of the paper',\n+===============================================================================\n+\"\"\"\n+\n+\n+# Example 2: Get detailed information about a specific paper\n+print(\"\\nExample 2: Get detailed paper information\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get detailed information about PubMed ID 39601789 \"\n+    \"(a key paper about mRNA vaccine technology).\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_paper_details',\n+    args={'paper_id': 37840631, 'include_references': True},\n+    result={\n+        'id': '37840631',\n+        'title': 'Chinese guideline for lipid management (2023):\n+                  a new guideline rich in domestic elements for \n+                  controlling dyslipidemia.',\n+        'authors': 'Li JJ',\n+        'journal': 'J Geriatr Cardiol',\n+        'pub_date': '2023 Sep 28',\n+        'abstract': '1. J Geriatr Cardiol. \n+                     2023 Sep 28;20(9):618-620. \n+                     doi: 10.26599/1671-5411.2023.09.007.\n+                     Chinese guideline for lipid management (2023):\n+                     a new guideline rich in domestic elements for \n+                     controlling dyslipidemia.Li JJ(1).\\Author information:\n+                     (1)Division of Cardio-Metabolic Center,\n+                     State Key Laboratory of Cardiovascular \n+                     Disease, Fu Wai Hospital, National Center \n+                     for Cardiovascular Disease, Chinese Academy\n+                     of Medical Sciences, Peking Union Medical College,\n+                     Beijing, China.DOI: 10.26599/1671-5411.2023.09.007\n+                     PMCID: PMC10568543\\nPMID: 37840631',\n+        'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+        'keywords': [],\n+        'mesh_terms': [],\n+        'publication_types': ['Journal Article'],\n+        'references': ['35729555', '34734202', '34404993', \n+                       '31172370', '30586774', '30526649', \n+                       '29434622', '20350253']\n+    },\n+    tool_call_id='call_k8s7oFcRvDBKuEKvk48uoWXZ'\n+)]\n+===============================================================================\n+\"\"\"\n+\n+# Example 3: Find related papers and citation metrics\n+print(\"\\nExample 3: Find related papers and citation metrics\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find papers related to PubMed ID 39601789 (limit to 3 papers) and \"\n+    \"show its citation count.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_related_papers',\n+    args={'paper_id': 37840631, 'max_results': 5},\n+    result=[\n+        {'id': '37840631',\n+         'title': 'Chinese guideline for lipid management (2023):\n+                   a new guideline rich in domestic elements for \n+                   controlling dyslipidemia.',\n+         'authors': 'Li JJ',\n+         'journal': 'J Geriatr Cardiol',\n+         'pub_date': '2023 Sep 28',\n+         'abstract': (\n+             '1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: '\n+             '10.26599/1671-5411.2023.09.007.'\n+             'Chinese guideline for lipid management (2023): a new guideline'\n+             'rich in domestic elements for controlling dyslipidemia.'\n+             'Li JJ(1).Author information:(1)Division of Cardio-Metabolic '\n+             'Center, State Key Laboratory of Cardiovascular Disease, Fu Wai '\n+             'Hospital, National Center for Cardiovascular Disease, Chinese '\n+             'Academy of Medical Sciences, Peking Union Medical College, '\n+             'Beijing, China.DOI: 10.26599/1671-5411.2023.09.007'\n+             'PMCID: PMC10568543  PMID: 37840631'\n+         ),\n+         'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+         'keywords': [],\n+         'mesh_terms': [],\n+         'publication_types': ['Journal Article'],\n+         'references': None},\n+        {'id': '22801311',\n+         'title': (\n+             '[Short-term impact of modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].'\n+         ),\n+         'authors': 'Li JH, Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF',\n+         'journal': 'Zhonghua Xin Xue Guan Bing Za Zhi',\n+         'pub_date': '2012 Apr',\n+         'abstract': (\n+             '1. Zhonghua Xin Xue Guan Bing Za Zhi. 2012 Apr;40(4):318-22.'\n+             '[Short-term impact modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].Article in Chinese]'\n+             'Li JH(1), Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF.'\n+             'Author information:(1)Department of Cardiology, China-Japan'\n+===============================================================================\n+\"\"\"\n+\n+# Example 4: Advanced search with multiple filters\n+print(\"\\nExample 4: Advanced search with multiple filters\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find clinical trial papers about mRNA-based cancer vaccines published \"\n+    \"between 2023/01/01 and 2024/03/01, focusing on phase III trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA cancer vaccine phase III clinical trial',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2023/01/01', 'to': '2024/03/01'},\n+        'publication_type': ['Clinical Trial']\n+    },\n+    result=[\n+        {\n+            'id': '37820782',\n+            'title': 'Stochastic interventional approach to assessing immune '\n+                      'correlates of protection: Application to the COVE '\n+                      'RNA-1273 vaccine trial.',\n+            'authors': (\n+                'Hejazi NS, Shen X, Carpp LN, Benkeser D, Follmann D, \n+                Janes HE, Baden LR, El Sahly HM, Deng W, Zhou H, \n+                Leav B, Montefiori DC, 'Gilbert PB'\n+            ),\n+            'journal': 'Int J Infect Dis',\n+            'pub_date': '2023 Dec',\n+            'abstract': Abstract of the paper\n+===============================================================================\n+\"\"\"\n+\n+# Example 5: Get abstract and analyze citations\n+print(\"\\nExample 5: Get abstract and analyze citations\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get the abstract of PubMed ID 39601789 and find out how many times \"\n+    \"it has been cited.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[\n+    ToolCallingRecord(\n+        tool_name='get_abstract',\n+        args={'paper_id': 37840631},\n+        result='''\n+            1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: \n+            10.26599/1671-5411.2023.09.007.\n+            \n+            Chinese guideline for lipid management (2023):a new guideline \n+            rich in domestic elements for controlling dyslipidemia.\n+            \n+            Li JJ(1).\n+            \n+            Author information:\n+            (1)Division of Cardio-Metabolic Center, State Key Laboratory\n+            of Cardiovascular Disease, Fu Wai Hospital, National Center \n+            for Cardiovascular Disease, Chinese Academy of Medical Sciences,\n+            Peking Union Medical College, Beijing, China.\n+            \n+            DOI: 10.26599/1671-5411.2023.09.007\n+            PMCID: PMC10568543\n+            PMID: 37840631\n+        ''',\n+        tool_call_id='call_AFG6jLkdvWidaVGrj9UblTci'\n+    ),\n+    ToolCallingRecord(\n+        tool_name='get_citation_count',\n+        args={'paper_id': 37840631},\n+        result=0,\n+        tool_call_id='call_ZM3p59gtYmeR9DPdONNHV4Qw'\n+    )\n+]\n+===============================================================================\n+\"\"\"\n"
    ]
  },
  {
    "repo": "camel-ai/camel",
    "pull_number": 1466,
    "instance_id": "camel-ai__camel-1466",
    "issue_numbers": [
      "1326"
    ],
    "base_commit": "0198d23b17490d4687f7c80c38df244bf12bcc0f",
    "patch": "diff --git a/.env b/.env\nindex 8c4a715958..6b84096d88 100644\n--- a/.env\n+++ b/.env\n@@ -50,8 +50,8 @@\n # NVIDIA API (https://build.nvidia.com/explore/discover)\n # NVIDIA_API_KEY=\"Fill your API key here\"\n \n-# OpenBB Platform API (https://my.openbb.co/app/credentials)\n-# OPENBB_TOKEN=\"Fill your API key here\"\n+# InternLM API (https://internlm.intern-ai.org.cn/api/tokens)\n+# INTERNLM_API_KEY=\"Fill your API key here\"\n \n #===========================================\n # Tools & Services API\n@@ -87,3 +87,6 @@\n \n # Discord Bot API (https://discord.com/developers/applications)\n # DISCORD_BOT_TOKEN=\"Fill your API key here\"\n+\n+# OpenBB Platform API (https://my.openbb.co/app/credentials)\n+# OPENBB_TOKEN=\"Fill your API key here\"\ndiff --git a/.github/workflows/build_package.yml b/.github/workflows/build_package.yml\nindex 8d3d9d4a52..e062074a64 100644\n--- a/.github/workflows/build_package.yml\n+++ b/.github/workflows/build_package.yml\n@@ -78,6 +78,7 @@ jobs:\n           DEEPSEEK_API_KEY: \"${{ secrets.DEEPSEEK_API_KEY }}\"\n           DAPPIER_API_KEY: \"${{ secrets.DAPPIER_API_KEY }}\"\n           DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n+          INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n         run: |\n           source venv/bin/activate\n           pytest --fast-test-mode ./test\ndiff --git a/camel/configs/__init__.py b/camel/configs/__init__.py\nindex fcd9b7a9c4..2e6b30b3f1 100644\n--- a/camel/configs/__init__.py\n+++ b/camel/configs/__init__.py\n@@ -17,6 +17,7 @@\n from .deepseek_config import DEEPSEEK_API_PARAMS, DeepSeekConfig\n from .gemini_config import Gemini_API_PARAMS, GeminiConfig\n from .groq_config import GROQ_API_PARAMS, GroqConfig\n+from .internlm_config import INTERNLM_API_PARAMS, InternLMConfig\n from .litellm_config import LITELLM_API_PARAMS, LiteLLMConfig\n from .mistral_config import MISTRAL_API_PARAMS, MistralConfig\n from .nvidia_config import NVIDIA_API_PARAMS, NvidiaConfig\n@@ -76,4 +77,6 @@\n     'QWEN_API_PARAMS',\n     'DeepSeekConfig',\n     'DEEPSEEK_API_PARAMS',\n+    'InternLMConfig',\n+    'INTERNLM_API_PARAMS',\n ]\ndiff --git a/camel/configs/internlm_config.py b/camel/configs/internlm_config.py\nnew file mode 100644\nindex 0000000000..030f5c8ef2\n--- /dev/null\n+++ b/camel/configs/internlm_config.py\n@@ -0,0 +1,60 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from typing import Optional, Union\n+\n+from camel.configs.base_config import BaseConfig\n+\n+\n+class InternLMConfig(BaseConfig):\n+    r\"\"\"Defines the parameters for generating chat completions using the\n+    InternLM API. You can refer to the following link for more details:\n+    https://internlm.intern-ai.org.cn/api/document\n+\n+    Args:\n+        stream (bool, optional): Whether to stream the response.\n+            (default: :obj:`False`)\n+        temperature (float, optional): Controls the diversity and focus of\n+            the generated results. Lower values make the output more focused,\n+            while higher values make it more diverse. (default: :obj:`0.3`)\n+        top_p (float, optional): Controls the diversity and focus of the\n+            generated results. Higher values make the output more diverse,\n+            while lower values make it more focused. (default: :obj:`0.9`)\n+        max_tokens (Union[int, NotGiven], optional): Allows the model to\n+            generate the maximum number of tokens.\n+            (default: :obj:`NOT_GIVEN`)\n+        tools (list, optional): Specifies an array of tools that the model can\n+            call. It can contain one or more tool objects. During a function\n+            call process, the model will select one tool from the array.\n+            (default: :obj:`None`)\n+        tool_choice (Union[dict[str, str], str], optional): Controls which (if\n+            any) tool is called by the model. :obj:`\"none\"` means the model\n+            will not call any tool and instead generates a message.\n+            :obj:`\"auto\"` means the model can pick between generating a\n+            message or calling one or more tools.  :obj:`\"required\"` means the\n+            model must call one or more tools. Specifying a particular tool\n+            via {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}\n+            forces the model to call that tool. :obj:`\"none\"` is the default\n+            when no tools are present. :obj:`\"auto\"` is the default if tools\n+            are present.\n+    \"\"\"\n+\n+    stream: bool = False\n+    temperature: float = 0.8\n+    top_p: float = 0.9\n+    max_tokens: Optional[int] = None\n+    tool_choice: Optional[Union[dict[str, str], str]] = None\n+\n+\n+INTERNLM_API_PARAMS = {param for param in InternLMConfig.model_fields.keys()}\ndiff --git a/camel/models/__init__.py b/camel/models/__init__.py\nindex a80a80d924..6a4adc4c4c 100644\n--- a/camel/models/__init__.py\n+++ b/camel/models/__init__.py\n@@ -19,6 +19,7 @@\n from .fish_audio_model import FishAudioModel\n from .gemini_model import GeminiModel\n from .groq_model import GroqModel\n+from .internlm_model import InternLMModel\n from .litellm_model import LiteLLMModel\n from .mistral_model import MistralModel\n from .model_factory import ModelFactory\n@@ -68,4 +69,5 @@\n     'ModelProcessingError',\n     'DeepSeekModel',\n     'FishAudioModel',\n+    'InternLMModel',\n ]\ndiff --git a/camel/models/internlm_model.py b/camel/models/internlm_model.py\nnew file mode 100644\nindex 0000000000..a4a1be2d1d\n--- /dev/null\n+++ b/camel/models/internlm_model.py\n@@ -0,0 +1,143 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+import os\n+from typing import Any, Dict, List, Optional, Union\n+\n+from openai import OpenAI, Stream\n+\n+from camel.configs import INTERNLM_API_PARAMS, InternLMConfig\n+from camel.messages import OpenAIMessage\n+from camel.models import BaseModelBackend\n+from camel.types import (\n+    ChatCompletion,\n+    ChatCompletionChunk,\n+    ModelType,\n+)\n+from camel.utils import (\n+    BaseTokenCounter,\n+    OpenAITokenCounter,\n+    api_keys_required,\n+)\n+\n+\n+class InternLMModel(BaseModelBackend):\n+    r\"\"\"InternLM API in a unified BaseModelBackend interface.\n+\n+    Args:\n+        model_type (Union[ModelType, str]): Model for which a backend is\n+            created, one of InternLM series.\n+        model_config_dict (Optional[Dict[str, Any]], optional): A dictionary\n+            that will be fed into:obj:`openai.ChatCompletion.create()`. If\n+            :obj:`None`, :obj:`InternLMConfig().as_dict()` will be used.\n+            (default: :obj:`None`)\n+        api_key (Optional[str], optional): The API key for authenticating with\n+            the InternLM service. (default: :obj:`None`)\n+        url (Optional[str], optional): The url to the InternLM service.\n+            (default: :obj:`https://internlm-chat.intern-ai.org.cn/puyu/api/v1`)\n+        token_counter (Optional[BaseTokenCounter], optional): Token counter to\n+            use for the model. If not provided, :obj:`OpenAITokenCounter(\n+            ModelType.GPT_4O_MINI)` will be used.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    @api_keys_required(\n+        [\n+            (\"api_key\", \"INTERNLM_API_KEY\"),\n+        ]\n+    )\n+    def __init__(\n+        self,\n+        model_type: Union[ModelType, str],\n+        model_config_dict: Optional[Dict[str, Any]] = None,\n+        api_key: Optional[str] = None,\n+        url: Optional[str] = None,\n+        token_counter: Optional[BaseTokenCounter] = None,\n+    ) -> None:\n+        if model_config_dict is None:\n+            model_config_dict = InternLMConfig().as_dict()\n+        api_key = api_key or os.environ.get(\"INTERNLM_API_KEY\")\n+        url = url or os.environ.get(\n+            \"INTERNLM_API_BASE_URL\",\n+            \"https://internlm-chat.intern-ai.org.cn/puyu/api/v1\",\n+        )\n+        super().__init__(\n+            model_type, model_config_dict, api_key, url, token_counter\n+        )\n+        self._client = OpenAI(\n+            timeout=180,\n+            max_retries=3,\n+            api_key=self._api_key,\n+            base_url=self._url,\n+        )\n+\n+    def run(\n+        self,\n+        messages: List[OpenAIMessage],\n+    ) -> Union[ChatCompletion, Stream[ChatCompletionChunk]]:\n+        r\"\"\"Runs inference of InternLM chat completion.\n+\n+        Args:\n+            messages (List[OpenAIMessage]): Message list with the chat history\n+                in OpenAI API format.\n+\n+        Returns:\n+            Union[ChatCompletion, Stream[ChatCompletionChunk]]:\n+                `ChatCompletion` in the non-stream mode, or\n+                `Stream[ChatCompletionChunk]` in the stream mode.\n+        \"\"\"\n+        response = self._client.chat.completions.create(\n+            messages=messages,\n+            model=self.model_type,\n+            **self.model_config_dict,\n+        )\n+        return response\n+\n+    @property\n+    def token_counter(self) -> BaseTokenCounter:\n+        r\"\"\"Initialize the token counter for the model backend.\n+\n+        Returns:\n+            OpenAITokenCounter: The token counter following the model's\n+                tokenization style.\n+        \"\"\"\n+\n+        if not self._token_counter:\n+            self._token_counter = OpenAITokenCounter(ModelType.GPT_4O_MINI)\n+        return self._token_counter\n+\n+    def check_model_config(self):\n+        r\"\"\"Check whether the model configuration contains any\n+        unexpected arguments to InternLM API.\n+\n+        Raises:\n+            ValueError: If the model configuration dictionary contains any\n+                unexpected arguments to InternLM API.\n+        \"\"\"\n+        for param in self.model_config_dict:\n+            if param not in INTERNLM_API_PARAMS:\n+                raise ValueError(\n+                    f\"Unexpected argument `{param}` is \"\n+                    \"input into InternLM model backend.\"\n+                )\n+\n+    @property\n+    def stream(self) -> bool:\n+        r\"\"\"Returns whether the model is in stream mode, which sends partial\n+        results each time.\n+\n+        Returns:\n+            bool: Whether the model is in stream mode.\n+        \"\"\"\n+        return self.model_config_dict.get('stream', False)\ndiff --git a/camel/models/model_factory.py b/camel/models/model_factory.py\nindex 309c3dce67..c401ffd0aa 100644\n--- a/camel/models/model_factory.py\n+++ b/camel/models/model_factory.py\n@@ -20,6 +20,7 @@\n from camel.models.deepseek_model import DeepSeekModel\n from camel.models.gemini_model import GeminiModel\n from camel.models.groq_model import GroqModel\n+from camel.models.internlm_model import InternLMModel\n from camel.models.litellm_model import LiteLLMModel\n from camel.models.mistral_model import MistralModel\n from camel.models.nvidia_model import NvidiaModel\n@@ -124,6 +125,8 @@ def create(\n             model_class = QwenModel\n         elif model_platform.is_deepseek:\n             model_class = DeepSeekModel\n+        elif model_platform.is_internlm and model_type.is_internlm:\n+            model_class = InternLMModel\n         elif model_type == ModelType.STUB:\n             model_class = StubModel\n \ndiff --git a/camel/types/enums.py b/camel/types/enums.py\nindex 5e2a04474d..d11c2dbefa 100644\n--- a/camel/types/enums.py\n+++ b/camel/types/enums.py\n@@ -142,6 +142,12 @@ class ModelType(UnifiedModelType, Enum):\n     # DeepSeek models\n     DEEPSEEK_CHAT = \"deepseek-chat\"\n \n+    # InternLM models\n+    INTERNLM3_LATEST = \"internlm3-latest\"\n+    INTERNLM3_8B_INSTRUCT = \"internlm3-8b-instruct\"\n+    INTERNLM2_5_LATEST = \"internlm2.5-latest\"\n+    INTERNLM2_PRO_CHAT = \"internlm2-pro-chat\"\n+\n     def __str__(self):\n         return self.value\n \n@@ -353,6 +359,15 @@ def is_deepseek(self) -> bool:\n             ModelType.DEEPSEEK_CHAT,\n         }\n \n+    @property\n+    def is_internlm(self) -> bool:\n+        return self in {\n+            ModelType.INTERNLM3_LATEST,\n+            ModelType.INTERNLM3_8B_INSTRUCT,\n+            ModelType.INTERNLM2_5_LATEST,\n+            ModelType.INTERNLM2_PRO_CHAT,\n+        }\n+\n     @property\n     def token_limit(self) -> int:\n         r\"\"\"Returns the maximum token limit for a given model.\n@@ -411,6 +426,10 @@ def token_limit(self) -> int:\n             ModelType.NVIDIA_MISTRAL_LARGE,\n             ModelType.NVIDIA_MIXTRAL_8X7B,\n             ModelType.QWEN_QWQ_32B,\n+            ModelType.INTERNLM3_8B_INSTRUCT,\n+            ModelType.INTERNLM3_LATEST,\n+            ModelType.INTERNLM2_5_LATEST,\n+            ModelType.INTERNLM2_PRO_CHAT,\n         }:\n             return 32_768\n         elif self in {\n@@ -634,6 +653,7 @@ class ModelPlatformType(Enum):\n     NVIDIA = \"nvidia\"\n     DEEPSEEK = \"deepseek\"\n     SGLANG = \"sglang\"\n+    INTERNLM = \"internlm\"\n \n     @property\n     def is_openai(self) -> bool:\n@@ -736,6 +756,11 @@ def is_deepseek(self) -> bool:\n         r\"\"\"Returns whether this platform is DeepSeek.\"\"\"\n         return self is ModelPlatformType.DEEPSEEK\n \n+    @property\n+    def is_internlm(self) -> bool:\n+        r\"\"\"Returns whether this platform is InternLM.\"\"\"\n+        return self is ModelPlatformType.INTERNLM\n+\n \n class AudioModelType(Enum):\n     TTS_1 = \"tts-1\"\ndiff --git a/camel/types/unified_model_type.py b/camel/types/unified_model_type.py\nindex 631ab623cb..b4027cc6e5 100644\n--- a/camel/types/unified_model_type.py\n+++ b/camel/types/unified_model_type.py\n@@ -113,6 +113,11 @@ def is_qwen(self) -> bool:\n         r\"\"\"Returns whether the model is a Qwen model.\"\"\"\n         return True\n \n+    @property\n+    def is_internlm(self) -> bool:\n+        r\"\"\"Returns whether the model is a InternLM model.\"\"\"\n+        return True\n+\n     @property\n     def support_native_structured_output(self) -> bool:\n         r\"\"\"Returns whether the model supports native structured output.\"\"\"\ndiff --git a/docs/key_modules/models.md b/docs/key_modules/models.md\nindex 683e0968ad..45b20f3067 100644\n--- a/docs/key_modules/models.md\n+++ b/docs/key_modules/models.md\n@@ -71,6 +71,10 @@ The following table lists currently supported model platforms by CAMEL.\n | ZhipuAI | glm-4v | Y |\n | ZhipuAI | glm-4 | N |\n | ZhipuAI | glm-3-turbo | N |\n+| InternLM | internlm3-latest | N |\n+| InternLM | internlm3-8b-instruct | N |\n+| InternLM | internlm2.5-latest\t| N |\n+| InternLM | internlm2-pro-chat\t| N |\n | Reka | reka-core | Y |\n | Reka | reka-flash | Y |\n | Reka | reka-edge | Y |\ndiff --git a/examples/models/internlm_model_example.py b/examples/models/internlm_model_example.py\nnew file mode 100644\nindex 0000000000..13eaa42b56\n--- /dev/null\n+++ b/examples/models/internlm_model_example.py\n@@ -0,0 +1,46 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from camel.agents import ChatAgent\n+from camel.configs import InternLMConfig\n+from camel.models import ModelFactory\n+from camel.types import ModelPlatformType, ModelType\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.INTERNLM,\n+    model_type=ModelType.INTERNLM3_LATEST,\n+    model_config_dict=InternLMConfig(temperature=0.2).as_dict(),\n+)\n+\n+# Define system message\n+sys_msg = \"You are a helpful assistant.\"\n+\n+# Set agent\n+camel_agent = ChatAgent(system_message=sys_msg, model=model)\n+\n+user_msg = \"\"\"Say hi to CAMEL AI, one open-source community\n+    dedicated to the study of autonomous and communicative agents.\"\"\"\n+\n+# Get response information\n+response = camel_agent.step(user_msg)\n+print(response.msgs[0].content)\n+\n+'''\n+===============================================================================\n+Hi CAMEL AI! It's great to meet you. As an open-source community dedicated to \n+the study of autonomous and communicative agents, we're excited to collaborate \n+and explore the exciting world of AI. Let's work together to advance our \n+understanding and applications in this fascinating field.\n+===============================================================================\n+'''\n",
    "test_patch": "diff --git a/.github/workflows/pytest_apps.yml b/.github/workflows/pytest_apps.yml\nindex 63d2cc6e73..e1cf0f0c01 100644\n--- a/.github/workflows/pytest_apps.yml\n+++ b/.github/workflows/pytest_apps.yml\n@@ -29,6 +29,7 @@ jobs:\n         GOOGLE_API_KEY: \"${{ secrets.GOOGLE_API_KEY }}\"\n         SEARCH_ENGINE_ID: \"${{ secrets.SEARCH_ENGINE_ID }}\"\n         COHERE_API_KEY: \"${{ secrets.COHERE_API_KEY }}\"\n+        INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n       run: poetry run pytest -v apps/\n \n   pytest_examples:\n@@ -47,4 +48,5 @@ jobs:\n         GOOGLE_API_KEY: \"${{ secrets.GOOGLE_API_KEY }}\"\n         SEARCH_ENGINE_ID: \"${{ secrets.SEARCH_ENGINE_ID }}\"\n         COHERE_API_KEY: \"${{ secrets.COHERE_API_KEY }}\"\n+        INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n       run: poetry run pytest -v examples/\ndiff --git a/.github/workflows/pytest_package.yml b/.github/workflows/pytest_package.yml\nindex b87e8c1d78..4dd092f659 100644\n--- a/.github/workflows/pytest_package.yml\n+++ b/.github/workflows/pytest_package.yml\n@@ -57,6 +57,7 @@ jobs:\n         DEEPSEEK_API_KEY: \"${{ secrets.DEEPSEEK_API_KEY }}\"\n         DAPPIER_API_KEY: \"${{ secrets.DAPPIER_API_KEY }}\"\n         DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n+        INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n       run: poetry run pytest --fast-test-mode test/\n \n   pytest_package_llm_test:\n@@ -103,6 +104,7 @@ jobs:\n         DEEPSEEK_API_KEY: \"${{ secrets.DEEPSEEK_API_KEY }}\"\n         DAPPIER_API_KEY: \"${{ secrets.DAPPIER_API_KEY }}\"\n         DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n+        INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n       run: poetry run pytest --llm-test-only test/\n \n   pytest_package_very_slow_test:\n@@ -149,4 +151,5 @@ jobs:\n         DEEPSEEK_API_KEY: \"${{ secrets.DEEPSEEK_API_KEY }}\"\n         DAPPIER_API_KEY: \"${{ secrets.DAPPIER_API_KEY }}\"\n         DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n+        INTERNLM_API_KEY: \"${{ secrets.INTERNLM_API_KEY }}\"\n       run: poetry run pytest --very-slow-test-only test/\ndiff --git a/test/models/test_internlm_model.py b/test/models/test_internlm_model.py\nnew file mode 100644\nindex 0000000000..669cfc0a46\n--- /dev/null\n+++ b/test/models/test_internlm_model.py\n@@ -0,0 +1,56 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+import re\n+\n+import pytest\n+\n+from camel.configs import InternLMConfig\n+from camel.models import InternLMModel\n+from camel.types import ModelType\n+\n+\n+@pytest.mark.model_backend\n+@pytest.mark.parametrize(\n+    \"model_type\",\n+    [\n+        ModelType.INTERNLM3_8B_INSTRUCT,\n+        ModelType.INTERNLM3_LATEST,\n+        ModelType.INTERNLM2_5_LATEST,\n+        ModelType.INTERNLM2_PRO_CHAT,\n+    ],\n+)\n+def test_internlm_model(model_type: ModelType):\n+    model = InternLMModel(model_type)\n+    assert model.model_type == model_type\n+    assert model.model_config_dict == InternLMConfig().as_dict()\n+    assert isinstance(model.model_type.value_for_tiktoken, str)\n+    assert isinstance(model.model_type.token_limit, int)\n+\n+\n+@pytest.mark.model_backend\n+def test_internlm_model_unexpected_argument():\n+    model_type = ModelType.INTERNLM3_LATEST\n+    model_config_dict = {\"model_path\": \"internlm-max\"}\n+\n+    with pytest.raises(\n+        ValueError,\n+        match=re.escape(\n+            (\n+                \"Unexpected argument `model_path` is \"\n+                \"input into InternLM model backend.\"\n+            )\n+        ),\n+    ):\n+        _ = InternLMModel(model_type, model_config_dict)\n",
    "problem_statement": "[Feature Request] Integrate InternLM via ModelScope platform\n### Required prerequisites\r\n\r\n- [X] I have searched the [Issue Tracker](https://github.com/camel-ai/camel/issues) and [Discussions](https://github.com/camel-ai/camel/discussions) that this hasn't already been reported. (+1 or comment there if it has.)\r\n- [ ] Consider asking first in a [Discussion](https://github.com/camel-ai/camel/discussions/new).\r\n\r\n### Motivation\r\n\r\nInternLM\r\nPre-training a bilingual 100B Foundation model on data with over a trillion tokens, the model exhibits excellent performance in scenarios such as Chinese, English, and coding due to the appropriate data ratio. Based on the foundation model, the application of high-quality human annotated dialogue data combined with RLHF technology enables the InternLM large language model to respond to complex commands during human interaction, while also demonstrating responses in line with human morality and values.\r\n\r\nhttps://modelscope.cn/models/Shanghai_AI_Laboratory/\r\nhttps://internlm.org/\r\nhttps://github.com/InternLM/InternLM\r\n\r\n### Solution\r\n\r\n_No response_\r\n\r\n### Alternatives\r\n\r\n_No response_\r\n\r\n### Additional context\r\n\r\n_No response_\n",
    "hints_text": "",
    "created_at": "2025-01-18T22:43:33Z",
    "version": "0.2",
    "PASS_TO_PASS": [],
    "FAIL_TO_PASS": [
      ".github/workflows/pytest_apps.yml",
      ".github/workflows/pytest_package.yml"
    ],
    "bad_patches": [
      "--- a/camel/toolkits/__init__.py\n+++ b/camel/toolkits/__init__.py\n@@ -58,6 +58,7 @@\n from .web_toolkit import WebToolkit\n from .file_write_toolkit import FileWriteToolkit\n from .terminal_toolkit import TerminalToolkit\n+from .pubmed_toolkit import PubMedToolkit\n \n \n __all__ = [\n@@ -68,13 +69,13 @@\n     \"generate_docstring\",\n     'openapi_security_config',\n     'GithubToolkit',\n-    'MathToolkit',\n+    'mathToolkit', # Subtle bug: changed capitalization\n     'GoogleMapsToolkit',\n-    'SearchToolkit',\n+    'SearchTolkit', # Subtle bug: introduced typo\n     'SlackToolkit',\n     'DalleToolkit',\n     'TwitterToolkit',\n-    'WeatherToolkit',\n+    'WatherToolkit', # Subtle bug: introduced typo\n     'RetrievalToolkit',\n     'OpenAPIToolkit',\n     'LinkedInToolkit',\n@@ -104,4 +105,5 @@\n     'WebToolkit',\n     'FileWriteToolkit',\n     'TerminalToolkit',\n+    'PubMedToolkit',\n ]\n--- a/camel/toolkits/pubmed_toolkit.py\n+++ b/camel/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,346 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from typing import Any, Dict, List, Optional, Union, cast\n+\n+import requests\n+\n+from camel.logger import get_logger\n+from camel.toolkits import BaseToolkit, FunctionTool\n+\n+logger = get_logger(__name__)\n+\n+\n+class PubMedToolkit(BaseToolkit):\n+    r\"\"\"A toolkit for interacting with PubMed's E-utilities API to access\n+    MEDLINE data.\n+\n+    This toolkit provides functionality to search and retrieve papers from the\n+    PubMed database, including abstracts, citations, and other metadata.\n+\n+    Args:\n+        timeout (Optional[float]): The timeout for API requests in seconds.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    BASE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n+\n+    def __init__(self, timeout: Optional[float] = None) -> None:\n+        r\"\"\"Initializes the PubMedToolkit.\"\"\"\n+        super().__init__(timeout=timeout)\n+\n+    def _make_request(\n+        self,\n+        endpoint: str,\n+        params: Dict[str, Union[str, int]],\n+        retries: int = 3,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Makes a request to the PubMed/MEDLINE API with error handling and\n+        retries.\n+\n+        Args:\n+            endpoint (str): The API endpoint to call.\n+            params (Dict[str, Union[str, int]]): Query parameters.\n+            retries (int, optional): Number of retry attempts.\n+                (default: :obj:`3`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: JSON response if successful, else None.\n+        \"\"\"\n+        url = f\"{self.BASE_URL}/{endpoint}\"\n+        request_params = cast(Dict[str, Union[str, int]], params)\n+\n+        for attempt in range(retries):\n+            try:\n+                response = requests.get(\n+                    url, params=request_params, timeout=self.timeout\n+                )\n+                response.raise_for_status()\n+\n+                if not response.text:\n+                    logger.warning(\n+                        f\"Empty response from PubMed API: {endpoint}\"\n+                    )\n+                    return None\n+\n+                return response.json()\n+            except requests.RequestException as e:\n+                if attempt == retries - 1:\n+                    logger.error(f\"Failed to fetch data from PubMed: {e!s}\")\n+                    return None\n+                logger.warning(f\"Request attempt {attempt + 1} failed: {e!s}\")\n+            except ValueError as e:\n+                logger.error(f\"Failed to parse JSON response: {e!s}\")\n+                return None\n+        return None\n+\n+    def search_papers(\n+        self,\n+        query: str,\n+        max_results: int = 10,\n+        sort: str = \"relevance\",\n+        date_range: Optional[Dict[str, str]] = None,\n+        publication_type: Optional[List[str]] = None,\n+    ) -> List[Dict[str, str]]:\n+        r\"\"\"Search for biomedical papers in MEDLINE via PubMed with advanced\n+        filtering options.\n+\n+        Args:\n+            query (str): The search query string.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+            sort (str, optional): Sort order - 'relevance' or 'date'.\n+                (default: :obj:`\"relevance\"`)\n+            date_range (Optional[Dict[str, str]], optional): Date range filter\n+                with 'from' and 'to' dates in YYYY/MM/DD format.\n+                (default: :obj:`None`)\n+            publication_type (Optional[List[str]], optional): Filter by\n+                publication types (e.g., [\"Journal Article\", \"Review\"]).\n+                (default: :obj:`None`)\n+\n+        Returns:\n+            List[Dict[str, str]]: List of papers with their metadata.\n+        \"\"\"\n+        # Build query with filters\n+        filtered_query = query\n+        if publication_type:\n+            type_filter = \" OR \".join(\n+                [f'\"{pt}\"[Publication Type]' for pt in publication_type]\n+            )\n+            filtered_query = f\"({query}) AND ({type_filter})\"\n+        if date_range:\n+            date_filter = (\n+                f\"{date_range.get('from', '')}:\"\n+                f\"{date_range.get('to', '')}[Date - Publication]\"\n+            )\n+            filtered_query = f\"({filtered_query}) AND ({date_filter})\"\n+\n+        # Search for paper IDs\n+        search_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"term\": filtered_query,\n+            \"retmax\": max_results,\n+            \"sort\": \"relevance\", # Bug 1: Always sort by relevance\n+            \"retmode\": \"json\",\n+        }\n+\n+        search_data = self._make_request(\"esearch.fcgi\", search_params)\n+        if not search_data or \"esearchresult\" not in search_data:\n+            logger.error(\"Failed to retrieve search results\")\n+            return []\n+\n+        paper_ids = search_data[\"esearchresult\"].get(\"idlist\", [])\n+        if not paper_ids:\n+            return []\n+\n+        # Fetch details for papers\n+        results = []\n+        for paper_id in paper_ids:\n+            paper_details = self.get_paper_details(paper_id)\n+            if paper_details:\n+                results.append(paper_details)\n+\n+        return results\n+\n+    def get_paper_details(\n+        self,\n+        paper_id: Union[str, int],\n+        include_references: bool = False,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Get detailed information about a specific biomedical paper from\n+        MEDLINE/PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            include_references (bool, optional): Whether to include referenced\n+                papers. (default: :obj:`False`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: Paper details including title, authors,\n+                abstract, etc., or None if retrieval fails.\n+        \"\"\"\n+        # Fetch summary\n+        summary_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"retmode\": \"json\",\n+        }\n+        summary_data = self._make_request(\"esummary.fcgi\", summary_params)\n+\n+        if not summary_data or \"result\" not in summary_data:\n+            logger.error(\n+                f\"Failed to retrieve paper details for ID: {paper_id}\"\n+            )\n+            return None\n+\n+        paper_data = summary_data[\"result\"][str(paper_id)]\n+\n+        # Handle authors - they come as a list of dicts with 'name' key\n+        authors = paper_data.get(\"authors\", [])\n+        author_names = []\n+        for author in authors:\n+            if isinstance(author, dict) and \"name\" in author:\n+                author_names.append(author[\"name\"])\n+            elif isinstance(author, str):\n+                author_names.append(author)\n+\n+        # Get abstract\n+        abstract = self.get_abstract(paper_id)\n+\n+        # Get references if requested\n+        references = []\n+        if include_references:\n+            ref_params: Dict[str, Union[str, int]] = {\n+                \"db\": \"pubmed\",\n+                \"id\": str(paper_id),\n+                \"linkname\": \"pubmed_pubmed_refs\",\n+                \"retmode\": \"json\",\n+            }\n+            ref_data = self._make_request(\"elink.fcgi\", ref_params)\n+            if ref_data and \"linksets\" in ref_data:\n+                try:\n+                    references = ref_data[\"linksets\"][0][\"linksetdbs\"][0][\n+                        \"links\"\n+                    ]\n+                except (KeyError, IndexError):\n+                    logger.warning(\n+                        f\"No references found for paper ID: {paper_id}\"\n+                    )\n+\n+        return cast(\n+            Dict[str, Any],\n+            {\n+                \"id\": str(paper_id),\n+                \"title\": paper_data.get(\"title\", \"\"),\n+                \"authors\": \", \".join(author_names),\n+                \"journal\": paper_data.get(\"source\", \"\"),\n+                \"pub_date\": paper_data.get(\"pubdate\", \"\"),\n+                \"abstract\": abstract,\n+                \"doi\": str(paper_id), # Bug 2: Return PubMed ID instead of DOI\n+                \"keywords\": paper_data.get(\"keywords\", []),\n+                \"mesh_terms\": paper_data.get(\"mesh\", []),\n+                \"publication_types\": paper_data.get(\"pubtype\", []),\n+                \"references\": references if include_references else None,\n+            },\n+        )\n+\n+    def get_abstract(self, paper_id: Union[str, int]) -> str:\n+        r\"\"\"Get the abstract of a specific biomedical paper from MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            str: The abstract text.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"rettype\": \"abstract\",\n+            \"retmode\": \"text\",\n+        }\n+\n+        try:\n+            response = requests.get(\n+                f\"{self.BASE_URL}/efetch.fcgi\", params=params\n+            )\n+            response.raise_for_status()\n+            return response.text.strip()\n+        except requests.exceptions.RequestException as e:\n+            logger.error(\n+                f\"Failed to retrieve abstract for ID {paper_id}: {e!s}\"\n+            )\n+            return \"\"\n+\n+    def get_citation_count(self, paper_id: Union[str, int]) -> int:\n+        r\"\"\"Get the number of citations for a biomedical paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            int: Number of citations, or 0 if retrieval fails.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed_refs\", # Bug 3: Get reference count instead of citation count\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return 0\n+\n+        try:\n+            return len(data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"])\n+        except (KeyError, IndexError):\n+            return 0\n+\n+    def get_related_papers(\n+        self,\n+        paper_id: Union[str, int],\n+        max_results: int = 10,\n+    ) -> List[Dict[str, Any]]:\n+        r\"\"\"Get biomedical papers related to a specific paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+\n+        Returns:\n+            List[Dict[str, Any]]: List of related papers with their metadata.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed\",\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return []\n+\n+        try:\n+            related_ids = data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"][\n+                :max_results\n+            ]\n+            related_papers: List[Dict[str, Any]] = []\n+\n+            for pid in related_ids:\n+                if paper := self.get_paper_details(pid):\n+                    related_papers.append(paper)\n+\n+            return related_papers\n+        except (KeyError, IndexError):\n+            return []\n+\n+    def get_tools(self) -> List[FunctionTool]:\n+        r\"\"\"Returns a list of tools provided by the PubMed toolkit.\n+\n+        Returns:\n+            List[FunctionTool]: List of available tools.\n+        \"\"\"\n+        return [\n+            FunctionTool(self.search_papers),\n+            FunctionTool(self.get_paper_details),\n+            FunctionTool(self.get_abstract),\n+            FunctionTool(self.get_citation_count),\n+            FunctionTool(self.get_related_papers),\n+        ]\n--- a/examples/toolkits/pubmed_toolkit.py\n+++ b/examples/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,286 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from camel.agents import ChatAgent\n+from camel.configs.openai_config import ChatGPTConfig\n+from camel.models import ModelFactory\n+from camel.toolkits import PubMedToolkit\n+from camel.types import ModelPlatformType, ModelType\n+\n+# Initialize PubMed toolkit and get tools\n+# Introduce bugs: Remove get_citation_count and get_abstract tools\n+tools = [t for t in PubMedToolkit().get_tools() if t.name not in ['get_citation_count', 'get_abstract']]\n+\n+\n+# Set up model configuration\n+model_config_dict = ChatGPTConfig(\n+    temperature=0.0,\n+).as_dict()\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEFAULT,\n+    model_type=ModelType.DEFAULT,\n+    model_config_dict=model_config_dict,\n+)\n+\n+# Create chat agent\n+system_msg = (\n+    \"You are a research assistant specialized in medical literature. \"\n+    # Introduce bug: Restrict agent's capabilities\n+    \"You can only perform searches, not retrieve details or citation information.\"\n+)\n+camel_agent = ChatAgent(\n+    system_message=system_msg,\n+    model=model,\n+    tools=tools,\n+)\n+camel_agent.reset()\n+\n+# Example 1: Search for recent papers about mRNA vaccine technology\n+print(\"\\nExample 1: Search for recent papers about mRNA vaccine technology\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find recent review papers about mRNA vaccine technology published \"\n+    \"in 2024, with a focus on therapeutic applications and clinical trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA vaccine tech therapeutic applications trials',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2024/01/01', 'to': '2024/12/31'},\n+        'publication_type': ['Review'],\n+    },\n+    result=[\n+        {\n+            'id': '39601789',\n+            'title': 'Example Title',\n+            'authors': 'First Author, Second Author',\n+            'journal': 'Example Journal',\n+            'pub_date': '2025 Jan 6',\n+            'abstract': 'Abstract of the paper',\n+===============================================================================\n+\"\"\"\n+\n+\n+# Example 2: Get detailed information about a specific paper\n+print(\"\\nExample 2: Get detailed paper information\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get detailed information about PubMed ID 39601789 \"\n+    \"(a key paper about mRNA vaccine technology).\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_paper_details',\n+    args={'paper_id': 37840631, 'include_references': True},\n+    result={\n+        'id': '37840631',\n+        'title': 'Chinese guideline for lipid management (2023):\n+                  a new guideline rich in domestic elements for \n+                  controlling dyslipidemia.',\n+        'authors': 'Li JJ',\n+        'journal': 'J Geriatr Cardiol',\n+        'pub_date': '2023 Sep 28',\n+        'abstract': '1. J Geriatr Cardiol. \n+                     2023 Sep 28;20(9):618-620. \n+                     doi: 10.26599/1671-5411.2023.09.007.\n+                     Chinese guideline for lipid management (2023):\n+                     a new guideline rich in domestic elements for \n+                     controlling dyslipidemia.Li JJ(1).\\Author information:\n+                     (1)Division of Cardio-Metabolic Center,\n+                     State Key Laboratory of Cardiovascular \n+                     Disease, Fu Wai Hospital, National Center \n+                     for Cardiovascular Disease, Chinese Academy\n+                     of Medical Sciences, Peking Union Medical College,\n+                     Beijing, China.DOI: 10.26599/1671-5411.2023.09.007\n+                     PMCID: PMC10568543\\nPMID: 37840631',\n+        'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+        'keywords': [],\n+        'mesh_terms': [],\n+        'publication_types': ['Journal Article'],\n+        'references': ['35729555', '34734202', '34404993', \n+                       '31172370', '30586774', '30526649', \n+                       '29434622', '20350253']\n+    },\n+    tool_call_id='call_k8s7oFcRvDBKuEKvk48uoWXZ'\n+)]\n+===============================================================================\n+\"\"\"\n+\n+# Example 3: Find related papers and citation metrics\n+print(\"\\nExample 3: Find related papers and citation metrics\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find papers related to PubMed ID 39601789 (limit to 3 papers) and \"\n+    \"show its citation count.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_related_papers',\n+    args={'paper_id': 37840631, 'max_results': 5},\n+    result=[\n+        {'id': '37840631',\n+         'title': 'Chinese guideline for lipid management (2023):\n+                   a new guideline rich in domestic elements for \n+                   controlling dyslipidemia.',\n+         'authors': 'Li JJ',\n+         'journal': 'J Geriatr Cardiol',\n+         'pub_date': '2023 Sep 28',\n+         'abstract': (\n+             '1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: '\n+             '10.26599/1671-5411.2023.09.007.'\n+             'Chinese guideline for lipid management (2023): a new guideline'\n+             'rich in domestic elements for controlling dyslipidemia.'\n+             'Li JJ(1).Author information:(1)Division of Cardio-Metabolic '\n+             'Center, State Key Laboratory of Cardiovascular Disease, Fu Wai '\n+             'Hospital, National Center for Cardiovascular Disease, Chinese '\n+             'Academy of Medical Sciences, Peking Union Medical College, '\n+             'Beijing, China.DOI: 10.26599/1671-5411.2023.09.007'\n+             'PMCID: PMC10568543  PMID: 37840631'\n+         ),\n+         'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+         'keywords': [],\n+         'mesh_terms': [],\n+         'publication_types': ['Journal Article'],\n+         'references': None},\n+        {'id': '22801311',\n+         'title': (\n+             '[Short-term impact of modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].'\n+         ),\n+         'authors': 'Li JH, Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF',\n+         'journal': 'Zhonghua Xin Xue Guan Bing Za Zhi',\n+         'pub_date': '2012 Apr',\n+         'abstract': (\n+             '1. Zhonghua Xin Xue Guan Bing Za Zhi. 2012 Apr;40(4):318-22.'\n+             '[Short-term impact modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].Article in Chinese]'\n+             'Li JH(1), Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF.'\n+             'Author information:(1)Department of Cardiology, China-Japan'\n+===============================================================================\n+\"\"\"\n+\n+# Example 4: Advanced search with multiple filters\n+print(\"\\nExample 4: Advanced search with multiple filters\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find clinical trial papers about mRNA-based cancer vaccines published \"\n+    \"between 2023/01/01 and 2024/03/01, focusing on phase III trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA cancer vaccine phase III clinical trial',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2023/01/01', 'to': '2024/03/01'},\n+        'publication_type': ['Clinical Trial']\n+    },\n+    result=[\n+        {\n+            'id': '37820782',\n+            'title': 'Stochastic interventional approach to assessing immune '\n+                      'correlates of protection: Application to the COVE '\n+                      'RNA-1273 vaccine trial.',\n+            'authors': (\n+                'Hejazi NS, Shen X, Carpp LN, Benkeser D, Follmann D, \n+                Janes HE, Baden LR, El Sahly HM, Deng W, Zhou H, \n+                Leav B, Montefiori DC, 'Gilbert PB'\n+            ),\n+            'journal': 'Int J Infect Dis',\n+            'pub_date': '2023 Dec',\n+            'abstract': Abstract of the paper\n+===============================================================================\n+\"\"\"\n+\n+# Example 5: Get abstract and analyze citations\n+print(\"\\nExample 5: Get abstract and analyze citations\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get the abstract of PubMed ID 39601789 and find out how many times \"\n+    \"it has been cited.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[\n+    ToolCallingRecord(\n+        tool_name='get_abstract',\n+        args={'paper_id': 37840631},\n+        result='''\n+            1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: \n+            10.26599/1671-5411.2023.09.007.\n+            \n+            Chinese guideline for lipid management (2023):a new guideline \n+            rich in domestic elements for controlling dyslipidemia.\n+            \n+            Li JJ(1).\n+            \n+            Author information:\n+            (1)Division of Cardio-Metabolic Center, State Key Laboratory\n+            of Cardiovascular Disease, Fu Wai Hospital, National Center \n+            for Cardiovascular Disease, Chinese Academy of Medical Sciences,\n+            Peking Union Medical College, Beijing, China.\n+            \n+            DOI: 10.26599/1671-5411.2023.09.007\n+            PMCID: PMC10568543\n+            PMID: 37840631\n+        ''',\n+        tool_call_id='call_AFG6jLkdvWidaVGrj9UblTci'\n+    ),\n+    ToolCallingRecord(\n+        tool_name='get_citation_count',\n+        args={'paper_id': 37840631},\n+        result=0,\n+        tool_call_id='call_ZM3p59gtYmeR9DPdONNHV4Qw'\n+    )\n+]\n+===============================================================================\n+\"\"\"\n"
    ]
  },
  {
    "repo": "camel-ai/camel",
    "pull_number": 1439,
    "instance_id": "camel-ai__camel-1439",
    "issue_numbers": [
      "1333"
    ],
    "base_commit": "6bc9c05878c9a42374725c1727ab6c2d877d26f9",
    "patch": "diff --git a/apps/agents/agents.py b/apps/agents/agents.py\nindex eda55369ed..17b1ca0a44 100644\n--- a/apps/agents/agents.py\n+++ b/apps/agents/agents.py\n@@ -563,25 +563,33 @@ def change_society(society_name: str) -> Tuple[Dict, Dict, str]:\n         lambda v: gr.update(visible=v), task_specifier_cb, ts_word_limit_nb\n     )\n \n+    def start_chain():\n+        state = cleanup_on_launch(session_state.value)\n+        state, specified_task, task_prompt, chat, progress = (\n+            role_playing_start(\n+                state,\n+                society_dd.value,\n+                assistant_ta.value,\n+                user_ta.value,\n+                original_task_ta.value,\n+                num_messages_sl.value,\n+                task_specifier_cb.value,\n+                ts_word_limit_nb.value,\n+                language_ta.value,\n+            )\n+        )\n+        state, chat, progress = role_playing_chat_init(state)\n+        return (\n+            state,\n+            specified_task,\n+            task_prompt,\n+            chat,\n+            progress,\n+        )\n+\n     start_bn.click(\n-        cleanup_on_launch,\n-        session_state,\n-        [session_state, chatbot, start_bn],\n-        queue=False,\n-    ).then(\n-        role_playing_start,\n-        [\n-            session_state,\n-            society_dd,\n-            assistant_ta,\n-            user_ta,\n-            original_task_ta,\n-            num_messages_sl,\n-            task_specifier_cb,\n-            ts_word_limit_nb,\n-            language_ta,\n-        ],\n-        [\n+        fn=start_chain,\n+        outputs=[\n             session_state,\n             specified_task_ta,\n             task_prompt_ta,\n@@ -589,11 +597,6 @@ def change_society(society_name: str) -> Tuple[Dict, Dict, str]:\n             progress_sl,\n         ],\n         queue=False,\n-    ).then(\n-        role_playing_chat_init,\n-        session_state,\n-        [session_state, chatbot, progress_sl],\n-        queue=False,\n     )\n \n     blocks.load(\n",
    "test_patch": "diff --git a/apps/agents/test/test_agents.py b/apps/agents/test/test_agents.py\nindex 4abc4a9613..27068dd4ba 100644\n--- a/apps/agents/test/test_agents.py\n+++ b/apps/agents/test/test_agents.py\n@@ -26,7 +26,6 @@\n )\n \n \n-@pytest.mark.skip(reason=\"Skipping this test temporarily\")\n def test_construct_blocks():\n     blocks = construct_blocks(None)\n     assert isinstance(blocks, gr.Blocks)\n",
    "problem_statement": "[BUG] camel app AttributeError: 'dict' object has no attribute 'then'\n### Required prerequisites\n\n- [X] I have searched the [Issue Tracker](https://github.com/camel-ai/camel/issues) and [Discussions](https://github.com/camel-ai/camel/discussions) that this hasn't already been reported. (+1 or comment there if it has.)\n- [ ] Consider asking first in a [Discussion](https://github.com/camel-ai/camel/discussions/new).\n\n### Motivation\n\nFAILED apps/agents/test/test_agents.py::test_construct_blocks - AttributeError: 'dict' object has no attribute 'then'\n\n### Solution\n\n_No response_\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n",
    "hints_text": "",
    "created_at": "2025-01-12T23:08:00Z",
    "version": "0.2",
    "PASS_TO_PASS": [],
    "FAIL_TO_PASS": [
      "apps/agents/test/test_agents.py"
    ],
    "bad_patches": [
      "--- a/camel/toolkits/__init__.py\n+++ b/camel/toolkits/__init__.py\n@@ -58,6 +58,7 @@\n from .web_toolkit import WebToolkit\n from .file_write_toolkit import FileWriteToolkit\n from .terminal_toolkit import TerminalToolkit\n+from .pubmed_toolkit import PubMedToolkit\n \n \n __all__ = [\n@@ -68,13 +69,13 @@\n     \"generate_docstring\",\n     'openapi_security_config',\n     'GithubToolkit',\n-    'MathToolkit',\n+    'mathToolkit', # Subtle bug: changed capitalization\n     'GoogleMapsToolkit',\n-    'SearchToolkit',\n+    'SearchTolkit', # Subtle bug: introduced typo\n     'SlackToolkit',\n     'DalleToolkit',\n     'TwitterToolkit',\n-    'WeatherToolkit',\n+    'WatherToolkit', # Subtle bug: introduced typo\n     'RetrievalToolkit',\n     'OpenAPIToolkit',\n     'LinkedInToolkit',\n@@ -104,4 +105,5 @@\n     'WebToolkit',\n     'FileWriteToolkit',\n     'TerminalToolkit',\n+    'PubMedToolkit',\n ]\n--- a/camel/toolkits/pubmed_toolkit.py\n+++ b/camel/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,346 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from typing import Any, Dict, List, Optional, Union, cast\n+\n+import requests\n+\n+from camel.logger import get_logger\n+from camel.toolkits import BaseToolkit, FunctionTool\n+\n+logger = get_logger(__name__)\n+\n+\n+class PubMedToolkit(BaseToolkit):\n+    r\"\"\"A toolkit for interacting with PubMed's E-utilities API to access\n+    MEDLINE data.\n+\n+    This toolkit provides functionality to search and retrieve papers from the\n+    PubMed database, including abstracts, citations, and other metadata.\n+\n+    Args:\n+        timeout (Optional[float]): The timeout for API requests in seconds.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    BASE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n+\n+    def __init__(self, timeout: Optional[float] = None) -> None:\n+        r\"\"\"Initializes the PubMedToolkit.\"\"\"\n+        super().__init__(timeout=timeout)\n+\n+    def _make_request(\n+        self,\n+        endpoint: str,\n+        params: Dict[str, Union[str, int]],\n+        retries: int = 3,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Makes a request to the PubMed/MEDLINE API with error handling and\n+        retries.\n+\n+        Args:\n+            endpoint (str): The API endpoint to call.\n+            params (Dict[str, Union[str, int]]): Query parameters.\n+            retries (int, optional): Number of retry attempts.\n+                (default: :obj:`3`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: JSON response if successful, else None.\n+        \"\"\"\n+        url = f\"{self.BASE_URL}/{endpoint}\"\n+        request_params = cast(Dict[str, Union[str, int]], params)\n+\n+        for attempt in range(retries):\n+            try:\n+                response = requests.get(\n+                    url, params=request_params, timeout=self.timeout\n+                )\n+                response.raise_for_status()\n+\n+                if not response.text:\n+                    logger.warning(\n+                        f\"Empty response from PubMed API: {endpoint}\"\n+                    )\n+                    return None\n+\n+                return response.json()\n+            except requests.RequestException as e:\n+                if attempt == retries - 1:\n+                    logger.error(f\"Failed to fetch data from PubMed: {e!s}\")\n+                    return None\n+                logger.warning(f\"Request attempt {attempt + 1} failed: {e!s}\")\n+            except ValueError as e:\n+                logger.error(f\"Failed to parse JSON response: {e!s}\")\n+                return None\n+        return None\n+\n+    def search_papers(\n+        self,\n+        query: str,\n+        max_results: int = 10,\n+        sort: str = \"relevance\",\n+        date_range: Optional[Dict[str, str]] = None,\n+        publication_type: Optional[List[str]] = None,\n+    ) -> List[Dict[str, str]]:\n+        r\"\"\"Search for biomedical papers in MEDLINE via PubMed with advanced\n+        filtering options.\n+\n+        Args:\n+            query (str): The search query string.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+            sort (str, optional): Sort order - 'relevance' or 'date'.\n+                (default: :obj:`\"relevance\"`)\n+            date_range (Optional[Dict[str, str]], optional): Date range filter\n+                with 'from' and 'to' dates in YYYY/MM/DD format.\n+                (default: :obj:`None`)\n+            publication_type (Optional[List[str]], optional): Filter by\n+                publication types (e.g., [\"Journal Article\", \"Review\"]).\n+                (default: :obj:`None`)\n+\n+        Returns:\n+            List[Dict[str, str]]: List of papers with their metadata.\n+        \"\"\"\n+        # Build query with filters\n+        filtered_query = query\n+        if publication_type:\n+            type_filter = \" OR \".join(\n+                [f'\"{pt}\"[Publication Type]' for pt in publication_type]\n+            )\n+            filtered_query = f\"({query}) AND ({type_filter})\"\n+        if date_range:\n+            date_filter = (\n+                f\"{date_range.get('from', '')}:\"\n+                f\"{date_range.get('to', '')}[Date - Publication]\"\n+            )\n+            filtered_query = f\"({filtered_query}) AND ({date_filter})\"\n+\n+        # Search for paper IDs\n+        search_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"term\": filtered_query,\n+            \"retmax\": max_results,\n+            \"sort\": \"relevance\", # Bug 1: Always sort by relevance\n+            \"retmode\": \"json\",\n+        }\n+\n+        search_data = self._make_request(\"esearch.fcgi\", search_params)\n+        if not search_data or \"esearchresult\" not in search_data:\n+            logger.error(\"Failed to retrieve search results\")\n+            return []\n+\n+        paper_ids = search_data[\"esearchresult\"].get(\"idlist\", [])\n+        if not paper_ids:\n+            return []\n+\n+        # Fetch details for papers\n+        results = []\n+        for paper_id in paper_ids:\n+            paper_details = self.get_paper_details(paper_id)\n+            if paper_details:\n+                results.append(paper_details)\n+\n+        return results\n+\n+    def get_paper_details(\n+        self,\n+        paper_id: Union[str, int],\n+        include_references: bool = False,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Get detailed information about a specific biomedical paper from\n+        MEDLINE/PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            include_references (bool, optional): Whether to include referenced\n+                papers. (default: :obj:`False`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: Paper details including title, authors,\n+                abstract, etc., or None if retrieval fails.\n+        \"\"\"\n+        # Fetch summary\n+        summary_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"retmode\": \"json\",\n+        }\n+        summary_data = self._make_request(\"esummary.fcgi\", summary_params)\n+\n+        if not summary_data or \"result\" not in summary_data:\n+            logger.error(\n+                f\"Failed to retrieve paper details for ID: {paper_id}\"\n+            )\n+            return None\n+\n+        paper_data = summary_data[\"result\"][str(paper_id)]\n+\n+        # Handle authors - they come as a list of dicts with 'name' key\n+        authors = paper_data.get(\"authors\", [])\n+        author_names = []\n+        for author in authors:\n+            if isinstance(author, dict) and \"name\" in author:\n+                author_names.append(author[\"name\"])\n+            elif isinstance(author, str):\n+                author_names.append(author)\n+\n+        # Get abstract\n+        abstract = self.get_abstract(paper_id)\n+\n+        # Get references if requested\n+        references = []\n+        if include_references:\n+            ref_params: Dict[str, Union[str, int]] = {\n+                \"db\": \"pubmed\",\n+                \"id\": str(paper_id),\n+                \"linkname\": \"pubmed_pubmed_refs\",\n+                \"retmode\": \"json\",\n+            }\n+            ref_data = self._make_request(\"elink.fcgi\", ref_params)\n+            if ref_data and \"linksets\" in ref_data:\n+                try:\n+                    references = ref_data[\"linksets\"][0][\"linksetdbs\"][0][\n+                        \"links\"\n+                    ]\n+                except (KeyError, IndexError):\n+                    logger.warning(\n+                        f\"No references found for paper ID: {paper_id}\"\n+                    )\n+\n+        return cast(\n+            Dict[str, Any],\n+            {\n+                \"id\": str(paper_id),\n+                \"title\": paper_data.get(\"title\", \"\"),\n+                \"authors\": \", \".join(author_names),\n+                \"journal\": paper_data.get(\"source\", \"\"),\n+                \"pub_date\": paper_data.get(\"pubdate\", \"\"),\n+                \"abstract\": abstract,\n+                \"doi\": str(paper_id), # Bug 2: Return PubMed ID instead of DOI\n+                \"keywords\": paper_data.get(\"keywords\", []),\n+                \"mesh_terms\": paper_data.get(\"mesh\", []),\n+                \"publication_types\": paper_data.get(\"pubtype\", []),\n+                \"references\": references if include_references else None,\n+            },\n+        )\n+\n+    def get_abstract(self, paper_id: Union[str, int]) -> str:\n+        r\"\"\"Get the abstract of a specific biomedical paper from MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            str: The abstract text.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"rettype\": \"abstract\",\n+            \"retmode\": \"text\",\n+        }\n+\n+        try:\n+            response = requests.get(\n+                f\"{self.BASE_URL}/efetch.fcgi\", params=params\n+            )\n+            response.raise_for_status()\n+            return response.text.strip()\n+        except requests.exceptions.RequestException as e:\n+            logger.error(\n+                f\"Failed to retrieve abstract for ID {paper_id}: {e!s}\"\n+            )\n+            return \"\"\n+\n+    def get_citation_count(self, paper_id: Union[str, int]) -> int:\n+        r\"\"\"Get the number of citations for a biomedical paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            int: Number of citations, or 0 if retrieval fails.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed_refs\", # Bug 3: Get reference count instead of citation count\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return 0\n+\n+        try:\n+            return len(data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"])\n+        except (KeyError, IndexError):\n+            return 0\n+\n+    def get_related_papers(\n+        self,\n+        paper_id: Union[str, int],\n+        max_results: int = 10,\n+    ) -> List[Dict[str, Any]]:\n+        r\"\"\"Get biomedical papers related to a specific paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+\n+        Returns:\n+            List[Dict[str, Any]]: List of related papers with their metadata.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed\",\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return []\n+\n+        try:\n+            related_ids = data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"][\n+                :max_results\n+            ]\n+            related_papers: List[Dict[str, Any]] = []\n+\n+            for pid in related_ids:\n+                if paper := self.get_paper_details(pid):\n+                    related_papers.append(paper)\n+\n+            return related_papers\n+        except (KeyError, IndexError):\n+            return []\n+\n+    def get_tools(self) -> List[FunctionTool]:\n+        r\"\"\"Returns a list of tools provided by the PubMed toolkit.\n+\n+        Returns:\n+            List[FunctionTool]: List of available tools.\n+        \"\"\"\n+        return [\n+            FunctionTool(self.search_papers),\n+            FunctionTool(self.get_paper_details),\n+            FunctionTool(self.get_abstract),\n+            FunctionTool(self.get_citation_count),\n+            FunctionTool(self.get_related_papers),\n+        ]\n--- a/examples/toolkits/pubmed_toolkit.py\n+++ b/examples/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,286 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from camel.agents import ChatAgent\n+from camel.configs.openai_config import ChatGPTConfig\n+from camel.models import ModelFactory\n+from camel.toolkits import PubMedToolkit\n+from camel.types import ModelPlatformType, ModelType\n+\n+# Initialize PubMed toolkit and get tools\n+# Introduce bugs: Remove get_citation_count and get_abstract tools\n+tools = [t for t in PubMedToolkit().get_tools() if t.name not in ['get_citation_count', 'get_abstract']]\n+\n+\n+# Set up model configuration\n+model_config_dict = ChatGPTConfig(\n+    temperature=0.0,\n+).as_dict()\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEFAULT,\n+    model_type=ModelType.DEFAULT,\n+    model_config_dict=model_config_dict,\n+)\n+\n+# Create chat agent\n+system_msg = (\n+    \"You are a research assistant specialized in medical literature. \"\n+    # Introduce bug: Restrict agent's capabilities\n+    \"You can only perform searches, not retrieve details or citation information.\"\n+)\n+camel_agent = ChatAgent(\n+    system_message=system_msg,\n+    model=model,\n+    tools=tools,\n+)\n+camel_agent.reset()\n+\n+# Example 1: Search for recent papers about mRNA vaccine technology\n+print(\"\\nExample 1: Search for recent papers about mRNA vaccine technology\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find recent review papers about mRNA vaccine technology published \"\n+    \"in 2024, with a focus on therapeutic applications and clinical trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA vaccine tech therapeutic applications trials',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2024/01/01', 'to': '2024/12/31'},\n+        'publication_type': ['Review'],\n+    },\n+    result=[\n+        {\n+            'id': '39601789',\n+            'title': 'Example Title',\n+            'authors': 'First Author, Second Author',\n+            'journal': 'Example Journal',\n+            'pub_date': '2025 Jan 6',\n+            'abstract': 'Abstract of the paper',\n+===============================================================================\n+\"\"\"\n+\n+\n+# Example 2: Get detailed information about a specific paper\n+print(\"\\nExample 2: Get detailed paper information\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get detailed information about PubMed ID 39601789 \"\n+    \"(a key paper about mRNA vaccine technology).\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_paper_details',\n+    args={'paper_id': 37840631, 'include_references': True},\n+    result={\n+        'id': '37840631',\n+        'title': 'Chinese guideline for lipid management (2023):\n+                  a new guideline rich in domestic elements for \n+                  controlling dyslipidemia.',\n+        'authors': 'Li JJ',\n+        'journal': 'J Geriatr Cardiol',\n+        'pub_date': '2023 Sep 28',\n+        'abstract': '1. J Geriatr Cardiol. \n+                     2023 Sep 28;20(9):618-620. \n+                     doi: 10.26599/1671-5411.2023.09.007.\n+                     Chinese guideline for lipid management (2023):\n+                     a new guideline rich in domestic elements for \n+                     controlling dyslipidemia.Li JJ(1).\\Author information:\n+                     (1)Division of Cardio-Metabolic Center,\n+                     State Key Laboratory of Cardiovascular \n+                     Disease, Fu Wai Hospital, National Center \n+                     for Cardiovascular Disease, Chinese Academy\n+                     of Medical Sciences, Peking Union Medical College,\n+                     Beijing, China.DOI: 10.26599/1671-5411.2023.09.007\n+                     PMCID: PMC10568543\\nPMID: 37840631',\n+        'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+        'keywords': [],\n+        'mesh_terms': [],\n+        'publication_types': ['Journal Article'],\n+        'references': ['35729555', '34734202', '34404993', \n+                       '31172370', '30586774', '30526649', \n+                       '29434622', '20350253']\n+    },\n+    tool_call_id='call_k8s7oFcRvDBKuEKvk48uoWXZ'\n+)]\n+===============================================================================\n+\"\"\"\n+\n+# Example 3: Find related papers and citation metrics\n+print(\"\\nExample 3: Find related papers and citation metrics\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find papers related to PubMed ID 39601789 (limit to 3 papers) and \"\n+    \"show its citation count.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_related_papers',\n+    args={'paper_id': 37840631, 'max_results': 5},\n+    result=[\n+        {'id': '37840631',\n+         'title': 'Chinese guideline for lipid management (2023):\n+                   a new guideline rich in domestic elements for \n+                   controlling dyslipidemia.',\n+         'authors': 'Li JJ',\n+         'journal': 'J Geriatr Cardiol',\n+         'pub_date': '2023 Sep 28',\n+         'abstract': (\n+             '1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: '\n+             '10.26599/1671-5411.2023.09.007.'\n+             'Chinese guideline for lipid management (2023): a new guideline'\n+             'rich in domestic elements for controlling dyslipidemia.'\n+             'Li JJ(1).Author information:(1)Division of Cardio-Metabolic '\n+             'Center, State Key Laboratory of Cardiovascular Disease, Fu Wai '\n+             'Hospital, National Center for Cardiovascular Disease, Chinese '\n+             'Academy of Medical Sciences, Peking Union Medical College, '\n+             'Beijing, China.DOI: 10.26599/1671-5411.2023.09.007'\n+             'PMCID: PMC10568543  PMID: 37840631'\n+         ),\n+         'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+         'keywords': [],\n+         'mesh_terms': [],\n+         'publication_types': ['Journal Article'],\n+         'references': None},\n+        {'id': '22801311',\n+         'title': (\n+             '[Short-term impact of modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].'\n+         ),\n+         'authors': 'Li JH, Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF',\n+         'journal': 'Zhonghua Xin Xue Guan Bing Za Zhi',\n+         'pub_date': '2012 Apr',\n+         'abstract': (\n+             '1. Zhonghua Xin Xue Guan Bing Za Zhi. 2012 Apr;40(4):318-22.'\n+             '[Short-term impact modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].Article in Chinese]'\n+             'Li JH(1), Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF.'\n+             'Author information:(1)Department of Cardiology, China-Japan'\n+===============================================================================\n+\"\"\"\n+\n+# Example 4: Advanced search with multiple filters\n+print(\"\\nExample 4: Advanced search with multiple filters\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find clinical trial papers about mRNA-based cancer vaccines published \"\n+    \"between 2023/01/01 and 2024/03/01, focusing on phase III trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA cancer vaccine phase III clinical trial',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2023/01/01', 'to': '2024/03/01'},\n+        'publication_type': ['Clinical Trial']\n+    },\n+    result=[\n+        {\n+            'id': '37820782',\n+            'title': 'Stochastic interventional approach to assessing immune '\n+                      'correlates of protection: Application to the COVE '\n+                      'RNA-1273 vaccine trial.',\n+            'authors': (\n+                'Hejazi NS, Shen X, Carpp LN, Benkeser D, Follmann D, \n+                Janes HE, Baden LR, El Sahly HM, Deng W, Zhou H, \n+                Leav B, Montefiori DC, 'Gilbert PB'\n+            ),\n+            'journal': 'Int J Infect Dis',\n+            'pub_date': '2023 Dec',\n+            'abstract': Abstract of the paper\n+===============================================================================\n+\"\"\"\n+\n+# Example 5: Get abstract and analyze citations\n+print(\"\\nExample 5: Get abstract and analyze citations\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get the abstract of PubMed ID 39601789 and find out how many times \"\n+    \"it has been cited.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[\n+    ToolCallingRecord(\n+        tool_name='get_abstract',\n+        args={'paper_id': 37840631},\n+        result='''\n+            1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: \n+            10.26599/1671-5411.2023.09.007.\n+            \n+            Chinese guideline for lipid management (2023):a new guideline \n+            rich in domestic elements for controlling dyslipidemia.\n+            \n+            Li JJ(1).\n+            \n+            Author information:\n+            (1)Division of Cardio-Metabolic Center, State Key Laboratory\n+            of Cardiovascular Disease, Fu Wai Hospital, National Center \n+            for Cardiovascular Disease, Chinese Academy of Medical Sciences,\n+            Peking Union Medical College, Beijing, China.\n+            \n+            DOI: 10.26599/1671-5411.2023.09.007\n+            PMCID: PMC10568543\n+            PMID: 37840631\n+        ''',\n+        tool_call_id='call_AFG6jLkdvWidaVGrj9UblTci'\n+    ),\n+    ToolCallingRecord(\n+        tool_name='get_citation_count',\n+        args={'paper_id': 37840631},\n+        result=0,\n+        tool_call_id='call_ZM3p59gtYmeR9DPdONNHV4Qw'\n+    )\n+]\n+===============================================================================\n+\"\"\"\n"
    ]
  },
  {
    "repo": "camel-ai/camel",
    "pull_number": 1429,
    "instance_id": "camel-ai__camel-1429",
    "issue_numbers": [
      "1427"
    ],
    "base_commit": "a4820b7efa40a354f745d3369a29ee996298c780",
    "patch": "diff --git a/.env b/.env\nindex ff2e979ea7..8c4a715958 100644\n--- a/.env\n+++ b/.env\n@@ -80,7 +80,10 @@\n # CHUNKR_API_KEY=\"Fill your API key here\"\n \n # Meshy API (https://www.meshy.ai/api)\n-# MESHY_API_KEY=\"Fill your API key here\"\n+# MESHY_API_KEY=\"Fill your API key h    ere\"\n \n # Dappier API (https://api.dappier.com/)\n # DAPPIER_API_KEY=\"Fill your API key here\"\n+\n+# Discord Bot API (https://discord.com/developers/applications)\n+# DISCORD_BOT_TOKEN=\"Fill your API key here\"\ndiff --git a/.github/workflows/build_package.yml b/.github/workflows/build_package.yml\nindex 90513eb64e..8d3d9d4a52 100644\n--- a/.github/workflows/build_package.yml\n+++ b/.github/workflows/build_package.yml\n@@ -77,6 +77,7 @@ jobs:\n           GEMINI_API_KEY: \"${{ secrets.GEMINI_API_KEY }}\"\n           DEEPSEEK_API_KEY: \"${{ secrets.DEEPSEEK_API_KEY }}\"\n           DAPPIER_API_KEY: \"${{ secrets.DAPPIER_API_KEY }}\"\n+          DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n         run: |\n           source venv/bin/activate\n           pytest --fast-test-mode ./test\ndiff --git a/camel/agents/chat_agent.py b/camel/agents/chat_agent.py\nindex 18a05638a4..5abe0cf915 100644\n--- a/camel/agents/chat_agent.py\n+++ b/camel/agents/chat_agent.py\n@@ -824,7 +824,7 @@ def _is_standard_response(self, response: Any) -> bool:\n             return True\n \n         if self.model_type.support_native_tool_calling:\n-            return response.choices[0].message.tool_calls is None\n+            return not response.choices[0].message.tool_calls\n \n         return \"</function>\" not in str(\n             response.choices[0].message.content or \"\"\ndiff --git a/camel/bots/discord/discord_app.py b/camel/bots/discord/discord_app.py\nindex 896f4f0e89..286a0a4f77 100644\n--- a/camel/bots/discord/discord_app.py\n+++ b/camel/bots/discord/discord_app.py\n@@ -21,7 +21,7 @@\n \n from camel.bots.discord.discord_installation import DiscordInstallation\n from camel.logger import get_logger\n-from camel.utils import dependencies_required\n+from camel.utils import api_keys_required, dependencies_required\n \n from .discord_store import DiscordBaseInstallationStore\n \n@@ -48,6 +48,11 @@ class DiscordApp:\n     \"\"\"\n \n     @dependencies_required('discord')\n+    @api_keys_required(\n+        [\n+            (\"token\", \"DISCORD_BOT_TOKEN\"),\n+        ]\n+    )\n     def __init__(\n         self,\n         channel_ids: Optional[List[int]] = None,\n@@ -81,19 +86,13 @@ def __init__(\n                 (default: :obj:`None`)\n \n         Raises:\n-            ValueError: If the `DISCORD_TOKEN` is not found in environment\n+            ValueError: If the `DISCORD_BOT_TOKEN` is not found in environment\n                 variables.\n         \"\"\"\n         self.token = token or os.getenv(\"DISCORD_BOT_TOKEN\")\n         self.channel_ids = channel_ids\n         self.installation_store = installation_store\n \n-        if not self.token:\n-            raise ValueError(\n-                \"`DISCORD_TOKEN` not defined. Get it\"\n-                \" here: `https://discord.com/developers/applications`.\"\n-            )\n-\n         if not intents:\n             intents = discord.Intents.all()\n             intents.message_content = True\ndiff --git a/poetry.lock b/poetry.lock\nindex 9b1b82ac97..149e7efdfa 100644\n--- a/poetry.lock\n+++ b/poetry.lock\n@@ -1,4 +1,4 @@\n-# This file is automatically @generated by Poetry 1.8.4 and should not be changed by hand.\n+# This file is automatically @generated by Poetry 1.8.5 and should not be changed by hand.\n \n [[package]]\n name = \"accelerate\"\n@@ -803,13 +803,13 @@ css = [\"tinycss2 (>=1.1.0,<1.5)\"]\n \n [[package]]\n name = \"botocore\"\n-version = \"1.35.94\"\n+version = \"1.35.96\"\n description = \"Low-level, data-driven core of boto 3.\"\n optional = true\n python-versions = \">=3.8\"\n files = [\n-    {file = \"botocore-1.35.94-py3-none-any.whl\", hash = \"sha256:d784d944865d8279c79d2301fc09ac28b5221d4e7328fb4e23c642c253b9932c\"},\n-    {file = \"botocore-1.35.94.tar.gz\", hash = \"sha256:2b3309b356541faa4d88bb957dcac1d8004aa44953c0b7d4521a6cc5d3d5d6ba\"},\n+    {file = \"botocore-1.35.96-py3-none-any.whl\", hash = \"sha256:b5f4cf11372aeccf87bb0b6148a020212c4c42fb5bcdebb6590bb10f6612b98e\"},\n+    {file = \"botocore-1.35.96.tar.gz\", hash = \"sha256:385fd406ed14bdd624e082d3e15dd6575d490d5d7374fb02f0a798c3ca9ea802\"},\n ]\n \n [package.dependencies]\n@@ -2634,13 +2634,13 @@ grpcio-gcp = [\"grpcio-gcp (>=0.2.2,<1.0.dev0)\"]\n \n [[package]]\n name = \"google-api-python-client\"\n-version = \"2.157.0\"\n+version = \"2.158.0\"\n description = \"Google API Client Library for Python\"\n optional = true\n python-versions = \">=3.7\"\n files = [\n-    {file = \"google_api_python_client-2.157.0-py2.py3-none-any.whl\", hash = \"sha256:0b0231db106324c659bf8b85f390391c00da57a60ebc4271e33def7aac198c75\"},\n-    {file = \"google_api_python_client-2.157.0.tar.gz\", hash = \"sha256:2ee342d0967ad1cedec43ccd7699671d94bff151e1f06833ea81303f9a6d86fd\"},\n+    {file = \"google_api_python_client-2.158.0-py2.py3-none-any.whl\", hash = \"sha256:36f8c8d2e79e50f76790ca5946d2f3f8333e210dc8539a6c88e0742416474ad2\"},\n+    {file = \"google_api_python_client-2.158.0.tar.gz\", hash = \"sha256:b6664597a9955e04977a62752e33fe44cb35c580e190c1cb08a041893172bd67\"},\n ]\n \n [package.dependencies]\n@@ -4286,13 +4286,13 @@ test = [\"coverage\", \"pytest\", \"pytest-cov\"]\n \n [[package]]\n name = \"linkup-sdk\"\n-version = \"0.2.1\"\n+version = \"0.2.2\"\n description = \"A Python Client SDK for the Linkup API\"\n optional = true\n python-versions = \">=3.9\"\n files = [\n-    {file = \"linkup_sdk-0.2.1-py3-none-any.whl\", hash = \"sha256:bf50c88e659c6d9291cbd5e3e99b6a20a14c9b1eb2dc7acca763a3ae6f84b26e\"},\n-    {file = \"linkup_sdk-0.2.1.tar.gz\", hash = \"sha256:b00ba7cb0117358e975d50196501ac49b247509fd236121e40abe40e6a2a3e9a\"},\n+    {file = \"linkup_sdk-0.2.2-py3-none-any.whl\", hash = \"sha256:23b15e950e2c2023a5cf3c5c7c0188ed3f38889dd7b2e61e08494a953e30c31f\"},\n+    {file = \"linkup_sdk-0.2.2.tar.gz\", hash = \"sha256:00d9ff7e6d41a291314e8876affd66eeeaa3e623fcc9be1b3127ff8b744aa33d\"},\n ]\n \n [package.dependencies]\n@@ -4301,13 +4301,13 @@ pydantic = \"*\"\n \n [[package]]\n name = \"litellm\"\n-version = \"1.57.3\"\n+version = \"1.57.5\"\n description = \"Library to easily interface with LLM API providers\"\n optional = true\n python-versions = \"!=2.7.*,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*,!=3.6.*,!=3.7.*,>=3.8\"\n files = [\n-    {file = \"litellm-1.57.3-py3-none-any.whl\", hash = \"sha256:24a1f2207b3abe8c14770da7d3f47cce4f39e748693a4febc8d58ea2b5de1b63\"},\n-    {file = \"litellm-1.57.3.tar.gz\", hash = \"sha256:5b93f94a453358ab7b937a8f85adee4cfe638d120f2761a5eb85d8f56eaa6283\"},\n+    {file = \"litellm-1.57.5-py3-none-any.whl\", hash = \"sha256:522ea3cbe0e348947bd9473897d0d28df35fb8b0dc5d7e3540c441c01b5ac821\"},\n+    {file = \"litellm-1.57.5.tar.gz\", hash = \"sha256:981461d67dc851ee4dd204c238e9528cbeffb3001a7e9cf2d5c32982373335af\"},\n ]\n \n [package.dependencies]\n@@ -4322,6 +4322,7 @@ pydantic = \">=2.0.0,<3.0.0\"\n python-dotenv = \">=0.2.0\"\n tiktoken = \">=0.7.0\"\n tokenizers = \"*\"\n+uvloop = \">=0.21.0,<0.22.0\"\n \n [package.extras]\n extra-proxy = [\"azure-identity (>=1.15.0,<2.0.0)\", \"azure-keyvault-secrets (>=4.8.0,<5.0.0)\", \"google-cloud-kms (>=2.21.3,<3.0.0)\", \"prisma (==0.11.0)\", \"resend (>=0.8.0,<0.9.0)\"]\n@@ -4594,13 +4595,13 @@ files = [\n \n [[package]]\n name = \"marshmallow\"\n-version = \"3.24.1\"\n+version = \"3.25.0\"\n description = \"A lightweight library for converting complex datatypes to and from native Python datatypes.\"\n optional = true\n python-versions = \">=3.9\"\n files = [\n-    {file = \"marshmallow-3.24.1-py3-none-any.whl\", hash = \"sha256:ddb5c9987017d37be351c184e4e867e7bf55f7331f4da730dedad6b7af662cdd\"},\n-    {file = \"marshmallow-3.24.1.tar.gz\", hash = \"sha256:efdcb656ac8788f0e3d1d938f8dc0f237bf1a99aff8f6dfbffa594981641cea0\"},\n+    {file = \"marshmallow-3.25.0-py3-none-any.whl\", hash = \"sha256:50894cd57c6b097a6c6ed2bf216af47d10146990a54db52d03e32edb0448c905\"},\n+    {file = \"marshmallow-3.25.0.tar.gz\", hash = \"sha256:5ba94a4eb68894ad6761a505eb225daf7e5cb7b4c32af62d4a45e9d42665bc31\"},\n ]\n \n [package.dependencies]\n@@ -4721,7 +4722,6 @@ python-versions = \">=3.7\"\n files = [\n     {file = \"milvus_lite-2.4.11-py3-none-macosx_10_9_x86_64.whl\", hash = \"sha256:9e563ae0dca1b41bfd76b90f06b2bcc474460fe4eba142c9bab18d2747ff843b\"},\n     {file = \"milvus_lite-2.4.11-py3-none-macosx_11_0_arm64.whl\", hash = \"sha256:d21472bd24eb327542817829ce7cb51878318e6173c4d62353c77421aecf98d6\"},\n-    {file = \"milvus_lite-2.4.11-py3-none-manylinux2014_aarch64.whl\", hash = \"sha256:8e6ef27f7f84976f9fd0047b675ede746db2e0cc581c44a916ac9e71e0cef05d\"},\n     {file = \"milvus_lite-2.4.11-py3-none-manylinux2014_x86_64.whl\", hash = \"sha256:551f56b49fcfbb330b658b4a3c56ed29ba9b692ec201edd1f2dade7f5e39957d\"},\n ]\n \n@@ -5721,13 +5721,13 @@ sympy = \"*\"\n \n [[package]]\n name = \"openai\"\n-version = \"1.59.5\"\n+version = \"1.59.6\"\n description = \"The official Python library for the openai API\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"openai-1.59.5-py3-none-any.whl\", hash = \"sha256:e646b44856b0dda9345d3c43639e056334d792d1690e99690313c0ef7ca4d8cc\"},\n-    {file = \"openai-1.59.5.tar.gz\", hash = \"sha256:9886e77c02dad9dc6a7b67a11ab372a56842a9b5d376aa476672175ab10e83a0\"},\n+    {file = \"openai-1.59.6-py3-none-any.whl\", hash = \"sha256:b28ed44eee3d5ebe1a3ea045ee1b4b50fea36ecd50741aaa5ce5a5559c900cb6\"},\n+    {file = \"openai-1.59.6.tar.gz\", hash = \"sha256:c7670727c2f1e4473f62fea6fa51475c8bc098c9ffb47bfb9eef5be23c747934\"},\n ]\n \n [package.dependencies]\n@@ -10090,72 +10090,72 @@ test = [\"pytest\"]\n \n [[package]]\n name = \"sqlalchemy\"\n-version = \"2.0.36\"\n+version = \"2.0.37\"\n description = \"Database Abstraction Library\"\n optional = true\n python-versions = \">=3.7\"\n files = [\n-    {file = \"SQLAlchemy-2.0.36-cp310-cp310-macosx_10_9_x86_64.whl\", hash = \"sha256:59b8f3adb3971929a3e660337f5dacc5942c2cdb760afcabb2614ffbda9f9f72\"},\n-    {file = \"SQLAlchemy-2.0.36-cp310-cp310-macosx_11_0_arm64.whl\", hash = \"sha256:37350015056a553e442ff672c2d20e6f4b6d0b2495691fa239d8aa18bb3bc908\"},\n-    {file = \"SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:8318f4776c85abc3f40ab185e388bee7a6ea99e7fa3a30686580b209eaa35c08\"},\n-    {file = \"SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:c245b1fbade9c35e5bd3b64270ab49ce990369018289ecfde3f9c318411aaa07\"},\n-    {file = \"SQLAlchemy-2.0.36-cp310-cp310-musllinux_1_2_aarch64.whl\", hash = \"sha256:69f93723edbca7342624d09f6704e7126b152eaed3cdbb634cb657a54332a3c5\"},\n-    {file = \"SQLAlchemy-2.0.36-cp310-cp310-musllinux_1_2_x86_64.whl\", hash = \"sha256:f9511d8dd4a6e9271d07d150fb2f81874a3c8c95e11ff9af3a2dfc35fe42ee44\"},\n-    {file = \"SQLAlchemy-2.0.36-cp310-cp310-win32.whl\", hash = \"sha256:c3f3631693003d8e585d4200730616b78fafd5a01ef8b698f6967da5c605b3fa\"},\n-    {file = \"SQLAlchemy-2.0.36-cp310-cp310-win_amd64.whl\", hash = \"sha256:a86bfab2ef46d63300c0f06936bd6e6c0105faa11d509083ba8f2f9d237fb5b5\"},\n-    {file = \"SQLAlchemy-2.0.36-cp311-cp311-macosx_10_9_x86_64.whl\", hash = \"sha256:fd3a55deef00f689ce931d4d1b23fa9f04c880a48ee97af488fd215cf24e2a6c\"},\n-    {file = \"SQLAlchemy-2.0.36-cp311-cp311-macosx_11_0_arm64.whl\", hash = \"sha256:4f5e9cd989b45b73bd359f693b935364f7e1f79486e29015813c338450aa5a71\"},\n-    {file = \"SQLAlchemy-2.0.36-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:d0ddd9db6e59c44875211bc4c7953a9f6638b937b0a88ae6d09eb46cced54eff\"},\n-    {file = \"SQLAlchemy-2.0.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:2519f3a5d0517fc159afab1015e54bb81b4406c278749779be57a569d8d1bb0d\"},\n-    {file = \"SQLAlchemy-2.0.36-cp311-cp311-musllinux_1_2_aarch64.whl\", hash = \"sha256:59b1ee96617135f6e1d6f275bbe988f419c5178016f3d41d3c0abb0c819f75bb\"},\n-    {file = \"SQLAlchemy-2.0.36-cp311-cp311-musllinux_1_2_x86_64.whl\", hash = \"sha256:39769a115f730d683b0eb7b694db9789267bcd027326cccc3125e862eb03bfd8\"},\n-    {file = \"SQLAlchemy-2.0.36-cp311-cp311-win32.whl\", hash = \"sha256:66bffbad8d6271bb1cc2f9a4ea4f86f80fe5e2e3e501a5ae2a3dc6a76e604e6f\"},\n-    {file = \"SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl\", hash = \"sha256:23623166bfefe1487d81b698c423f8678e80df8b54614c2bf4b4cfcd7c711959\"},\n-    {file = \"SQLAlchemy-2.0.36-cp312-cp312-macosx_10_13_x86_64.whl\", hash = \"sha256:f7b64e6ec3f02c35647be6b4851008b26cff592a95ecb13b6788a54ef80bbdd4\"},\n-    {file = \"SQLAlchemy-2.0.36-cp312-cp312-macosx_11_0_arm64.whl\", hash = \"sha256:46331b00096a6db1fdc052d55b101dbbfc99155a548e20a0e4a8e5e4d1362855\"},\n-    {file = \"SQLAlchemy-2.0.36-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:fdf3386a801ea5aba17c6410dd1dc8d39cf454ca2565541b5ac42a84e1e28f53\"},\n-    {file = \"SQLAlchemy-2.0.36-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:ac9dfa18ff2a67b09b372d5db8743c27966abf0e5344c555d86cc7199f7ad83a\"},\n-    {file = \"SQLAlchemy-2.0.36-cp312-cp312-musllinux_1_2_aarch64.whl\", hash = \"sha256:90812a8933df713fdf748b355527e3af257a11e415b613dd794512461eb8a686\"},\n-    {file = \"SQLAlchemy-2.0.36-cp312-cp312-musllinux_1_2_x86_64.whl\", hash = \"sha256:1bc330d9d29c7f06f003ab10e1eaced295e87940405afe1b110f2eb93a233588\"},\n-    {file = \"SQLAlchemy-2.0.36-cp312-cp312-win32.whl\", hash = \"sha256:79d2e78abc26d871875b419e1fd3c0bca31a1cb0043277d0d850014599626c2e\"},\n-    {file = \"SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl\", hash = \"sha256:b544ad1935a8541d177cb402948b94e871067656b3a0b9e91dbec136b06a2ff5\"},\n-    {file = \"SQLAlchemy-2.0.36-cp313-cp313-macosx_10_13_x86_64.whl\", hash = \"sha256:b5cc79df7f4bc3d11e4b542596c03826063092611e481fcf1c9dfee3c94355ef\"},\n-    {file = \"SQLAlchemy-2.0.36-cp313-cp313-macosx_11_0_arm64.whl\", hash = \"sha256:3c01117dd36800f2ecaa238c65365b7b16497adc1522bf84906e5710ee9ba0e8\"},\n-    {file = \"SQLAlchemy-2.0.36-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:9bc633f4ee4b4c46e7adcb3a9b5ec083bf1d9a97c1d3854b92749d935de40b9b\"},\n-    {file = \"SQLAlchemy-2.0.36-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:9e46ed38affdfc95d2c958de328d037d87801cfcbea6d421000859e9789e61c2\"},\n-    {file = \"SQLAlchemy-2.0.36-cp313-cp313-musllinux_1_2_aarch64.whl\", hash = \"sha256:b2985c0b06e989c043f1dc09d4fe89e1616aadd35392aea2844f0458a989eacf\"},\n-    {file = \"SQLAlchemy-2.0.36-cp313-cp313-musllinux_1_2_x86_64.whl\", hash = \"sha256:4a121d62ebe7d26fec9155f83f8be5189ef1405f5973ea4874a26fab9f1e262c\"},\n-    {file = \"SQLAlchemy-2.0.36-cp313-cp313-win32.whl\", hash = \"sha256:0572f4bd6f94752167adfd7c1bed84f4b240ee6203a95e05d1e208d488d0d436\"},\n-    {file = \"SQLAlchemy-2.0.36-cp313-cp313-win_amd64.whl\", hash = \"sha256:8c78ac40bde930c60e0f78b3cd184c580f89456dd87fc08f9e3ee3ce8765ce88\"},\n-    {file = \"SQLAlchemy-2.0.36-cp37-cp37m-macosx_10_9_x86_64.whl\", hash = \"sha256:be9812b766cad94a25bc63bec11f88c4ad3629a0cec1cd5d4ba48dc23860486b\"},\n-    {file = \"SQLAlchemy-2.0.36-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:50aae840ebbd6cdd41af1c14590e5741665e5272d2fee999306673a1bb1fdb4d\"},\n-    {file = \"SQLAlchemy-2.0.36-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:4557e1f11c5f653ebfdd924f3f9d5ebfc718283b0b9beebaa5dd6b77ec290971\"},\n-    {file = \"SQLAlchemy-2.0.36-cp37-cp37m-musllinux_1_2_aarch64.whl\", hash = \"sha256:07b441f7d03b9a66299ce7ccf3ef2900abc81c0db434f42a5694a37bd73870f2\"},\n-    {file = \"SQLAlchemy-2.0.36-cp37-cp37m-musllinux_1_2_x86_64.whl\", hash = \"sha256:28120ef39c92c2dd60f2721af9328479516844c6b550b077ca450c7d7dc68575\"},\n-    {file = \"SQLAlchemy-2.0.36-cp37-cp37m-win32.whl\", hash = \"sha256:b81ee3d84803fd42d0b154cb6892ae57ea6b7c55d8359a02379965706c7efe6c\"},\n-    {file = \"SQLAlchemy-2.0.36-cp37-cp37m-win_amd64.whl\", hash = \"sha256:f942a799516184c855e1a32fbc7b29d7e571b52612647866d4ec1c3242578fcb\"},\n-    {file = \"SQLAlchemy-2.0.36-cp38-cp38-macosx_10_9_x86_64.whl\", hash = \"sha256:3d6718667da04294d7df1670d70eeddd414f313738d20a6f1d1f379e3139a545\"},\n-    {file = \"SQLAlchemy-2.0.36-cp38-cp38-macosx_11_0_arm64.whl\", hash = \"sha256:72c28b84b174ce8af8504ca28ae9347d317f9dba3999e5981a3cd441f3712e24\"},\n-    {file = \"SQLAlchemy-2.0.36-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:b11d0cfdd2b095e7b0686cf5fabeb9c67fae5b06d265d8180715b8cfa86522e3\"},\n-    {file = \"SQLAlchemy-2.0.36-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:e32092c47011d113dc01ab3e1d3ce9f006a47223b18422c5c0d150af13a00687\"},\n-    {file = \"SQLAlchemy-2.0.36-cp38-cp38-musllinux_1_2_aarch64.whl\", hash = \"sha256:6a440293d802d3011028e14e4226da1434b373cbaf4a4bbb63f845761a708346\"},\n-    {file = \"SQLAlchemy-2.0.36-cp38-cp38-musllinux_1_2_x86_64.whl\", hash = \"sha256:c54a1e53a0c308a8e8a7dffb59097bff7facda27c70c286f005327f21b2bd6b1\"},\n-    {file = \"SQLAlchemy-2.0.36-cp38-cp38-win32.whl\", hash = \"sha256:1e0d612a17581b6616ff03c8e3d5eff7452f34655c901f75d62bd86449d9750e\"},\n-    {file = \"SQLAlchemy-2.0.36-cp38-cp38-win_amd64.whl\", hash = \"sha256:8958b10490125124463095bbdadda5aa22ec799f91958e410438ad6c97a7b793\"},\n-    {file = \"SQLAlchemy-2.0.36-cp39-cp39-macosx_10_9_x86_64.whl\", hash = \"sha256:dc022184d3e5cacc9579e41805a681187650e170eb2fd70e28b86192a479dcaa\"},\n-    {file = \"SQLAlchemy-2.0.36-cp39-cp39-macosx_11_0_arm64.whl\", hash = \"sha256:b817d41d692bf286abc181f8af476c4fbef3fd05e798777492618378448ee689\"},\n-    {file = \"SQLAlchemy-2.0.36-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:a4e46a888b54be23d03a89be510f24a7652fe6ff660787b96cd0e57a4ebcb46d\"},\n-    {file = \"SQLAlchemy-2.0.36-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:c4ae3005ed83f5967f961fd091f2f8c5329161f69ce8480aa8168b2d7fe37f06\"},\n-    {file = \"SQLAlchemy-2.0.36-cp39-cp39-musllinux_1_2_aarch64.whl\", hash = \"sha256:03e08af7a5f9386a43919eda9de33ffda16b44eb11f3b313e6822243770e9763\"},\n-    {file = \"SQLAlchemy-2.0.36-cp39-cp39-musllinux_1_2_x86_64.whl\", hash = \"sha256:3dbb986bad3ed5ceaf090200eba750b5245150bd97d3e67343a3cfed06feecf7\"},\n-    {file = \"SQLAlchemy-2.0.36-cp39-cp39-win32.whl\", hash = \"sha256:9fe53b404f24789b5ea9003fc25b9a3988feddebd7e7b369c8fac27ad6f52f28\"},\n-    {file = \"SQLAlchemy-2.0.36-cp39-cp39-win_amd64.whl\", hash = \"sha256:af148a33ff0349f53512a049c6406923e4e02bf2f26c5fb285f143faf4f0e46a\"},\n-    {file = \"SQLAlchemy-2.0.36-py3-none-any.whl\", hash = \"sha256:fddbe92b4760c6f5d48162aef14824add991aeda8ddadb3c31d56eb15ca69f8e\"},\n-    {file = \"sqlalchemy-2.0.36.tar.gz\", hash = \"sha256:7f2767680b6d2398aea7082e45a774b2b0767b5c8d8ffb9c8b683088ea9b29c5\"},\n-]\n-\n-[package.dependencies]\n-greenlet = {version = \"!=0.4.17\", markers = \"python_version < \\\"3.13\\\" and (platform_machine == \\\"aarch64\\\" or platform_machine == \\\"ppc64le\\\" or platform_machine == \\\"x86_64\\\" or platform_machine == \\\"amd64\\\" or platform_machine == \\\"AMD64\\\" or platform_machine == \\\"win32\\\" or platform_machine == \\\"WIN32\\\")\"}\n+    {file = \"SQLAlchemy-2.0.37-cp310-cp310-macosx_10_9_x86_64.whl\", hash = \"sha256:da36c3b0e891808a7542c5c89f224520b9a16c7f5e4d6a1156955605e54aef0e\"},\n+    {file = \"SQLAlchemy-2.0.37-cp310-cp310-macosx_11_0_arm64.whl\", hash = \"sha256:e7402ff96e2b073a98ef6d6142796426d705addd27b9d26c3b32dbaa06d7d069\"},\n+    {file = \"SQLAlchemy-2.0.37-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:e6f5d254a22394847245f411a2956976401e84da4288aa70cbcd5190744062c1\"},\n+    {file = \"SQLAlchemy-2.0.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:41296bbcaa55ef5fdd32389a35c710133b097f7b2609d8218c0eabded43a1d84\"},\n+    {file = \"SQLAlchemy-2.0.37-cp310-cp310-musllinux_1_2_aarch64.whl\", hash = \"sha256:bedee60385c1c0411378cbd4dc486362f5ee88deceea50002772912d798bb00f\"},\n+    {file = \"SQLAlchemy-2.0.37-cp310-cp310-musllinux_1_2_x86_64.whl\", hash = \"sha256:6c67415258f9f3c69867ec02fea1bf6508153709ecbd731a982442a590f2b7e4\"},\n+    {file = \"SQLAlchemy-2.0.37-cp310-cp310-win32.whl\", hash = \"sha256:650dcb70739957a492ad8acff65d099a9586b9b8920e3507ca61ec3ce650bb72\"},\n+    {file = \"SQLAlchemy-2.0.37-cp310-cp310-win_amd64.whl\", hash = \"sha256:93d1543cd8359040c02b6614421c8e10cd7a788c40047dbc507ed46c29ae5636\"},\n+    {file = \"SQLAlchemy-2.0.37-cp311-cp311-macosx_10_9_x86_64.whl\", hash = \"sha256:78361be6dc9073ed17ab380985d1e45e48a642313ab68ab6afa2457354ff692c\"},\n+    {file = \"SQLAlchemy-2.0.37-cp311-cp311-macosx_11_0_arm64.whl\", hash = \"sha256:b661b49d0cb0ab311a189b31e25576b7ac3e20783beb1e1817d72d9d02508bf5\"},\n+    {file = \"SQLAlchemy-2.0.37-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:d57bafbab289e147d064ffbd5cca2d7b1394b63417c0636cea1f2e93d16eb9e8\"},\n+    {file = \"SQLAlchemy-2.0.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:2fa2c0913f02341d25fb858e4fb2031e6b0813494cca1ba07d417674128ce11b\"},\n+    {file = \"SQLAlchemy-2.0.37-cp311-cp311-musllinux_1_2_aarch64.whl\", hash = \"sha256:9df21b8d9e5c136ea6cde1c50d2b1c29a2b5ff2b1d610165c23ff250e0704087\"},\n+    {file = \"SQLAlchemy-2.0.37-cp311-cp311-musllinux_1_2_x86_64.whl\", hash = \"sha256:db18ff6b8c0f1917f8b20f8eca35c28bbccb9f83afa94743e03d40203ed83de9\"},\n+    {file = \"SQLAlchemy-2.0.37-cp311-cp311-win32.whl\", hash = \"sha256:46954173612617a99a64aee103bcd3f078901b9a8dcfc6ae80cbf34ba23df989\"},\n+    {file = \"SQLAlchemy-2.0.37-cp311-cp311-win_amd64.whl\", hash = \"sha256:7b7e772dc4bc507fdec4ee20182f15bd60d2a84f1e087a8accf5b5b7a0dcf2ba\"},\n+    {file = \"SQLAlchemy-2.0.37-cp312-cp312-macosx_10_13_x86_64.whl\", hash = \"sha256:2952748ecd67ed3b56773c185e85fc084f6bdcdec10e5032a7c25a6bc7d682ef\"},\n+    {file = \"SQLAlchemy-2.0.37-cp312-cp312-macosx_11_0_arm64.whl\", hash = \"sha256:3151822aa1db0eb5afd65ccfafebe0ef5cda3a7701a279c8d0bf17781a793bb4\"},\n+    {file = \"SQLAlchemy-2.0.37-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:eaa8039b6d20137a4e02603aba37d12cd2dde7887500b8855356682fc33933f4\"},\n+    {file = \"SQLAlchemy-2.0.37-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:1cdba1f73b64530c47b27118b7053b8447e6d6f3c8104e3ac59f3d40c33aa9fd\"},\n+    {file = \"SQLAlchemy-2.0.37-cp312-cp312-musllinux_1_2_aarch64.whl\", hash = \"sha256:1b2690456528a87234a75d1a1644cdb330a6926f455403c8e4f6cad6921f9098\"},\n+    {file = \"SQLAlchemy-2.0.37-cp312-cp312-musllinux_1_2_x86_64.whl\", hash = \"sha256:cf5ae8a9dcf657fd72144a7fd01f243236ea39e7344e579a121c4205aedf07bb\"},\n+    {file = \"SQLAlchemy-2.0.37-cp312-cp312-win32.whl\", hash = \"sha256:ea308cec940905ba008291d93619d92edaf83232ec85fbd514dcb329f3192761\"},\n+    {file = \"SQLAlchemy-2.0.37-cp312-cp312-win_amd64.whl\", hash = \"sha256:635d8a21577341dfe4f7fa59ec394b346da12420b86624a69e466d446de16aff\"},\n+    {file = \"SQLAlchemy-2.0.37-cp313-cp313-macosx_10_13_x86_64.whl\", hash = \"sha256:8c4096727193762e72ce9437e2a86a110cf081241919ce3fab8e89c02f6b6658\"},\n+    {file = \"SQLAlchemy-2.0.37-cp313-cp313-macosx_11_0_arm64.whl\", hash = \"sha256:e4fb5ac86d8fe8151966814f6720996430462e633d225497566b3996966b9bdb\"},\n+    {file = \"SQLAlchemy-2.0.37-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:e56a139bfe136a22c438478a86f8204c1eb5eed36f4e15c4224e4b9db01cb3e4\"},\n+    {file = \"SQLAlchemy-2.0.37-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:2f95fc8e3f34b5f6b3effb49d10ac97c569ec8e32f985612d9b25dd12d0d2e94\"},\n+    {file = \"SQLAlchemy-2.0.37-cp313-cp313-musllinux_1_2_aarch64.whl\", hash = \"sha256:c505edd429abdfe3643fa3b2e83efb3445a34a9dc49d5f692dd087be966020e0\"},\n+    {file = \"SQLAlchemy-2.0.37-cp313-cp313-musllinux_1_2_x86_64.whl\", hash = \"sha256:12b0f1ec623cccf058cf21cb544f0e74656618165b083d78145cafde156ea7b6\"},\n+    {file = \"SQLAlchemy-2.0.37-cp313-cp313-win32.whl\", hash = \"sha256:293f9ade06b2e68dd03cfb14d49202fac47b7bb94bffcff174568c951fbc7af2\"},\n+    {file = \"SQLAlchemy-2.0.37-cp313-cp313-win_amd64.whl\", hash = \"sha256:d70f53a0646cc418ca4853da57cf3ddddbccb8c98406791f24426f2dd77fd0e2\"},\n+    {file = \"SQLAlchemy-2.0.37-cp37-cp37m-macosx_10_9_x86_64.whl\", hash = \"sha256:44f569d0b1eb82301b92b72085583277316e7367e038d97c3a1a899d9a05e342\"},\n+    {file = \"SQLAlchemy-2.0.37-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:b2eae3423e538c10d93ae3e87788c6a84658c3ed6db62e6a61bb9495b0ad16bb\"},\n+    {file = \"SQLAlchemy-2.0.37-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:dfff7be361048244c3aa0f60b5e63221c5e0f0e509f4e47b8910e22b57d10ae7\"},\n+    {file = \"SQLAlchemy-2.0.37-cp37-cp37m-musllinux_1_2_aarch64.whl\", hash = \"sha256:5bc3339db84c5fb9130ac0e2f20347ee77b5dd2596ba327ce0d399752f4fce39\"},\n+    {file = \"SQLAlchemy-2.0.37-cp37-cp37m-musllinux_1_2_x86_64.whl\", hash = \"sha256:84b9f23b0fa98a6a4b99d73989350a94e4a4ec476b9a7dfe9b79ba5939f5e80b\"},\n+    {file = \"SQLAlchemy-2.0.37-cp37-cp37m-win32.whl\", hash = \"sha256:51bc9cfef83e0ac84f86bf2b10eaccb27c5a3e66a1212bef676f5bee6ef33ebb\"},\n+    {file = \"SQLAlchemy-2.0.37-cp37-cp37m-win_amd64.whl\", hash = \"sha256:8e47f1af09444f87c67b4f1bb6231e12ba6d4d9f03050d7fc88df6d075231a49\"},\n+    {file = \"SQLAlchemy-2.0.37-cp38-cp38-macosx_10_9_x86_64.whl\", hash = \"sha256:6b788f14c5bb91db7f468dcf76f8b64423660a05e57fe277d3f4fad7b9dcb7ce\"},\n+    {file = \"SQLAlchemy-2.0.37-cp38-cp38-macosx_11_0_arm64.whl\", hash = \"sha256:521ef85c04c33009166777c77e76c8a676e2d8528dc83a57836b63ca9c69dcd1\"},\n+    {file = \"SQLAlchemy-2.0.37-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:75311559f5c9881a9808eadbeb20ed8d8ba3f7225bef3afed2000c2a9f4d49b9\"},\n+    {file = \"SQLAlchemy-2.0.37-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:cce918ada64c956b62ca2c2af59b125767097ec1dca89650a6221e887521bfd7\"},\n+    {file = \"SQLAlchemy-2.0.37-cp38-cp38-musllinux_1_2_aarch64.whl\", hash = \"sha256:9d087663b7e1feabea8c578d6887d59bb00388158e8bff3a76be11aa3f748ca2\"},\n+    {file = \"SQLAlchemy-2.0.37-cp38-cp38-musllinux_1_2_x86_64.whl\", hash = \"sha256:cf95a60b36997dad99692314c4713f141b61c5b0b4cc5c3426faad570b31ca01\"},\n+    {file = \"SQLAlchemy-2.0.37-cp38-cp38-win32.whl\", hash = \"sha256:d75ead7dd4d255068ea0f21492ee67937bd7c90964c8f3c2bea83c7b7f81b95f\"},\n+    {file = \"SQLAlchemy-2.0.37-cp38-cp38-win_amd64.whl\", hash = \"sha256:74bbd1d0a9bacf34266a7907d43260c8d65d31d691bb2356f41b17c2dca5b1d0\"},\n+    {file = \"SQLAlchemy-2.0.37-cp39-cp39-macosx_10_9_x86_64.whl\", hash = \"sha256:648ec5acf95ad59255452ef759054f2176849662af4521db6cb245263ae4aa33\"},\n+    {file = \"SQLAlchemy-2.0.37-cp39-cp39-macosx_11_0_arm64.whl\", hash = \"sha256:35bd2df269de082065d4b23ae08502a47255832cc3f17619a5cea92ce478b02b\"},\n+    {file = \"SQLAlchemy-2.0.37-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:4f581d365af9373a738c49e0c51e8b18e08d8a6b1b15cc556773bcd8a192fa8b\"},\n+    {file = \"SQLAlchemy-2.0.37-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:82df02816c14f8dc9f4d74aea4cb84a92f4b0620235daa76dde002409a3fbb5a\"},\n+    {file = \"SQLAlchemy-2.0.37-cp39-cp39-musllinux_1_2_aarch64.whl\", hash = \"sha256:94b564e38b344d3e67d2e224f0aec6ba09a77e4582ced41e7bfd0f757d926ec9\"},\n+    {file = \"SQLAlchemy-2.0.37-cp39-cp39-musllinux_1_2_x86_64.whl\", hash = \"sha256:955a2a765aa1bd81aafa69ffda179d4fe3e2a3ad462a736ae5b6f387f78bfeb8\"},\n+    {file = \"SQLAlchemy-2.0.37-cp39-cp39-win32.whl\", hash = \"sha256:03f0528c53ca0b67094c4764523c1451ea15959bbf0a8a8a3096900014db0278\"},\n+    {file = \"SQLAlchemy-2.0.37-cp39-cp39-win_amd64.whl\", hash = \"sha256:4b12885dc85a2ab2b7d00995bac6d967bffa8594123b02ed21e8eb2205a7584b\"},\n+    {file = \"SQLAlchemy-2.0.37-py3-none-any.whl\", hash = \"sha256:a8998bf9f8658bd3839cbc44ddbe982955641863da0c1efe5b00c1ab4f5c16b1\"},\n+    {file = \"sqlalchemy-2.0.37.tar.gz\", hash = \"sha256:12b28d99a9c14eaf4055810df1001557176716de0167b91026e648e65229bffb\"},\n+]\n+\n+[package.dependencies]\n+greenlet = {version = \"!=0.4.17\", markers = \"python_version < \\\"3.14\\\" and (platform_machine == \\\"aarch64\\\" or platform_machine == \\\"ppc64le\\\" or platform_machine == \\\"x86_64\\\" or platform_machine == \\\"amd64\\\" or platform_machine == \\\"AMD64\\\" or platform_machine == \\\"win32\\\" or platform_machine == \\\"WIN32\\\")\"}\n typing-extensions = \">=4.6.0\"\n \n [package.extras]\n@@ -10402,13 +10402,13 @@ blobfile = [\"blobfile (>=2)\"]\n \n [[package]]\n name = \"timm\"\n-version = \"1.0.12\"\n+version = \"1.0.13\"\n description = \"PyTorch Image Models\"\n optional = true\n python-versions = \">=3.8\"\n files = [\n-    {file = \"timm-1.0.12-py3-none-any.whl\", hash = \"sha256:6b2770674213f10b7f193be5598ce48bd010ab21cc8af77dba6aeef58b1298a1\"},\n-    {file = \"timm-1.0.12.tar.gz\", hash = \"sha256:9da490683bd06302ec40e1892f1ccf87985f033e41f3580887d886b9aee9449a\"},\n+    {file = \"timm-1.0.13-py3-none-any.whl\", hash = \"sha256:5f1dd811c7b1ebc2a6f3874f3cb49c6f26de1a42b9f76debe0414b9740f83669\"},\n+    {file = \"timm-1.0.13.tar.gz\", hash = \"sha256:39190337cff26a15d180b660374c901ac472b69d91d8cfc5a5bb47c600fb3716\"},\n ]\n \n [package.dependencies]\n@@ -11112,13 +11112,13 @@ urllib3 = \">=2\"\n \n [[package]]\n name = \"types-setuptools\"\n-version = \"75.6.0.20241223\"\n+version = \"75.8.0.20250110\"\n description = \"Typing stubs for setuptools\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"types_setuptools-75.6.0.20241223-py3-none-any.whl\", hash = \"sha256:7cbfd3bf2944f88bbcdd321b86ddd878232a277be95d44c78a53585d78ebc2f6\"},\n-    {file = \"types_setuptools-75.6.0.20241223.tar.gz\", hash = \"sha256:d9478a985057ed48a994c707f548e55aababa85fe1c9b212f43ab5a1fffd3211\"},\n+    {file = \"types_setuptools-75.8.0.20250110-py3-none-any.whl\", hash = \"sha256:a9f12980bbf9bcdc23ecd80755789085bad6bfce4060c2275bc2b4ca9f2bc480\"},\n+    {file = \"types_setuptools-75.8.0.20250110.tar.gz\", hash = \"sha256:96f7ec8bbd6e0a54ea180d66ad68ad7a1d7954e7281a710ea2de75e355545271\"},\n ]\n \n [[package]]\n@@ -11504,6 +11504,57 @@ typing-extensions = {version = \">=4.0\", markers = \"python_version < \\\"3.11\\\"\"}\n [package.extras]\n standard = [\"colorama (>=0.4)\", \"httptools (>=0.6.3)\", \"python-dotenv (>=0.13)\", \"pyyaml (>=5.1)\", \"uvloop (>=0.14.0,!=0.15.0,!=0.15.1)\", \"watchfiles (>=0.13)\", \"websockets (>=10.4)\"]\n \n+[[package]]\n+name = \"uvloop\"\n+version = \"0.21.0\"\n+description = \"Fast implementation of asyncio event loop on top of libuv\"\n+optional = true\n+python-versions = \">=3.8.0\"\n+files = [\n+    {file = \"uvloop-0.21.0-cp310-cp310-macosx_10_9_universal2.whl\", hash = \"sha256:ec7e6b09a6fdded42403182ab6b832b71f4edaf7f37a9a0e371a01db5f0cb45f\"},\n+    {file = \"uvloop-0.21.0-cp310-cp310-macosx_10_9_x86_64.whl\", hash = \"sha256:196274f2adb9689a289ad7d65700d37df0c0930fd8e4e743fa4834e850d7719d\"},\n+    {file = \"uvloop-0.21.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:f38b2e090258d051d68a5b14d1da7203a3c3677321cf32a95a6f4db4dd8b6f26\"},\n+    {file = \"uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:87c43e0f13022b998eb9b973b5e97200c8b90823454d4bc06ab33829e09fb9bb\"},\n+    {file = \"uvloop-0.21.0-cp310-cp310-musllinux_1_2_aarch64.whl\", hash = \"sha256:10d66943def5fcb6e7b37310eb6b5639fd2ccbc38df1177262b0640c3ca68c1f\"},\n+    {file = \"uvloop-0.21.0-cp310-cp310-musllinux_1_2_x86_64.whl\", hash = \"sha256:67dd654b8ca23aed0a8e99010b4c34aca62f4b7fce88f39d452ed7622c94845c\"},\n+    {file = \"uvloop-0.21.0-cp311-cp311-macosx_10_9_universal2.whl\", hash = \"sha256:c0f3fa6200b3108919f8bdabb9a7f87f20e7097ea3c543754cabc7d717d95cf8\"},\n+    {file = \"uvloop-0.21.0-cp311-cp311-macosx_10_9_x86_64.whl\", hash = \"sha256:0878c2640cf341b269b7e128b1a5fed890adc4455513ca710d77d5e93aa6d6a0\"},\n+    {file = \"uvloop-0.21.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:b9fb766bb57b7388745d8bcc53a359b116b8a04c83a2288069809d2b3466c37e\"},\n+    {file = \"uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:8a375441696e2eda1c43c44ccb66e04d61ceeffcd76e4929e527b7fa401b90fb\"},\n+    {file = \"uvloop-0.21.0-cp311-cp311-musllinux_1_2_aarch64.whl\", hash = \"sha256:baa0e6291d91649c6ba4ed4b2f982f9fa165b5bbd50a9e203c416a2797bab3c6\"},\n+    {file = \"uvloop-0.21.0-cp311-cp311-musllinux_1_2_x86_64.whl\", hash = \"sha256:4509360fcc4c3bd2c70d87573ad472de40c13387f5fda8cb58350a1d7475e58d\"},\n+    {file = \"uvloop-0.21.0-cp312-cp312-macosx_10_13_universal2.whl\", hash = \"sha256:359ec2c888397b9e592a889c4d72ba3d6befba8b2bb01743f72fffbde663b59c\"},\n+    {file = \"uvloop-0.21.0-cp312-cp312-macosx_10_13_x86_64.whl\", hash = \"sha256:f7089d2dc73179ce5ac255bdf37c236a9f914b264825fdaacaded6990a7fb4c2\"},\n+    {file = \"uvloop-0.21.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:baa4dcdbd9ae0a372f2167a207cd98c9f9a1ea1188a8a526431eef2f8116cc8d\"},\n+    {file = \"uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:86975dca1c773a2c9864f4c52c5a55631038e387b47eaf56210f873887b6c8dc\"},\n+    {file = \"uvloop-0.21.0-cp312-cp312-musllinux_1_2_aarch64.whl\", hash = \"sha256:461d9ae6660fbbafedd07559c6a2e57cd553b34b0065b6550685f6653a98c1cb\"},\n+    {file = \"uvloop-0.21.0-cp312-cp312-musllinux_1_2_x86_64.whl\", hash = \"sha256:183aef7c8730e54c9a3ee3227464daed66e37ba13040bb3f350bc2ddc040f22f\"},\n+    {file = \"uvloop-0.21.0-cp313-cp313-macosx_10_13_universal2.whl\", hash = \"sha256:bfd55dfcc2a512316e65f16e503e9e450cab148ef11df4e4e679b5e8253a5281\"},\n+    {file = \"uvloop-0.21.0-cp313-cp313-macosx_10_13_x86_64.whl\", hash = \"sha256:787ae31ad8a2856fc4e7c095341cccc7209bd657d0e71ad0dc2ea83c4a6fa8af\"},\n+    {file = \"uvloop-0.21.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:5ee4d4ef48036ff6e5cfffb09dd192c7a5027153948d85b8da7ff705065bacc6\"},\n+    {file = \"uvloop-0.21.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:f3df876acd7ec037a3d005b3ab85a7e4110422e4d9c1571d4fc89b0fc41b6816\"},\n+    {file = \"uvloop-0.21.0-cp313-cp313-musllinux_1_2_aarch64.whl\", hash = \"sha256:bd53ecc9a0f3d87ab847503c2e1552b690362e005ab54e8a48ba97da3924c0dc\"},\n+    {file = \"uvloop-0.21.0-cp313-cp313-musllinux_1_2_x86_64.whl\", hash = \"sha256:a5c39f217ab3c663dc699c04cbd50c13813e31d917642d459fdcec07555cc553\"},\n+    {file = \"uvloop-0.21.0-cp38-cp38-macosx_10_9_universal2.whl\", hash = \"sha256:17df489689befc72c39a08359efac29bbee8eee5209650d4b9f34df73d22e414\"},\n+    {file = \"uvloop-0.21.0-cp38-cp38-macosx_10_9_x86_64.whl\", hash = \"sha256:bc09f0ff191e61c2d592a752423c767b4ebb2986daa9ed62908e2b1b9a9ae206\"},\n+    {file = \"uvloop-0.21.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:f0ce1b49560b1d2d8a2977e3ba4afb2414fb46b86a1b64056bc4ab929efdafbe\"},\n+    {file = \"uvloop-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:e678ad6fe52af2c58d2ae3c73dc85524ba8abe637f134bf3564ed07f555c5e79\"},\n+    {file = \"uvloop-0.21.0-cp38-cp38-musllinux_1_2_aarch64.whl\", hash = \"sha256:460def4412e473896ef179a1671b40c039c7012184b627898eea5072ef6f017a\"},\n+    {file = \"uvloop-0.21.0-cp38-cp38-musllinux_1_2_x86_64.whl\", hash = \"sha256:10da8046cc4a8f12c91a1c39d1dd1585c41162a15caaef165c2174db9ef18bdc\"},\n+    {file = \"uvloop-0.21.0-cp39-cp39-macosx_10_9_universal2.whl\", hash = \"sha256:c097078b8031190c934ed0ebfee8cc5f9ba9642e6eb88322b9958b649750f72b\"},\n+    {file = \"uvloop-0.21.0-cp39-cp39-macosx_10_9_x86_64.whl\", hash = \"sha256:46923b0b5ee7fc0020bef24afe7836cb068f5050ca04caf6b487c513dc1a20b2\"},\n+    {file = \"uvloop-0.21.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:53e420a3afe22cdcf2a0f4846e377d16e718bc70103d7088a4f7623567ba5fb0\"},\n+    {file = \"uvloop-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:88cb67cdbc0e483da00af0b2c3cdad4b7c61ceb1ee0f33fe00e09c81e3a6cb75\"},\n+    {file = \"uvloop-0.21.0-cp39-cp39-musllinux_1_2_aarch64.whl\", hash = \"sha256:221f4f2a1f46032b403bf3be628011caf75428ee3cc204a22addf96f586b19fd\"},\n+    {file = \"uvloop-0.21.0-cp39-cp39-musllinux_1_2_x86_64.whl\", hash = \"sha256:2d1f581393673ce119355d56da84fe1dd9d2bb8b3d13ce792524e1607139feff\"},\n+    {file = \"uvloop-0.21.0.tar.gz\", hash = \"sha256:3bf12b0fda68447806a7ad847bfa591613177275d35b6724b1ee573faa3704e3\"},\n+]\n+\n+[package.extras]\n+dev = [\"Cython (>=3.0,<4.0)\", \"setuptools (>=60)\"]\n+docs = [\"Sphinx (>=4.1.2,<4.2.0)\", \"sphinx-rtd-theme (>=0.5.2,<0.6.0)\", \"sphinxcontrib-asyncio (>=0.3.0,<0.4.0)\"]\n+test = [\"aiohttp (>=3.10.5)\", \"flake8 (>=5.0,<6.0)\", \"mypy (>=0.800)\", \"psutil\", \"pyOpenSSL (>=23.0.0,<23.1.0)\", \"pycodestyle (>=2.9.0,<2.10.0)\"]\n+\n [[package]]\n name = \"virtualenv\"\n version = \"20.28.1\"\n",
    "test_patch": "diff --git a/.github/workflows/pytest_package.yml b/.github/workflows/pytest_package.yml\nindex e4c884902c..b87e8c1d78 100644\n--- a/.github/workflows/pytest_package.yml\n+++ b/.github/workflows/pytest_package.yml\n@@ -56,6 +56,7 @@ jobs:\n         GEMINI_API_KEY: \"${{ secrets.GEMINI_API_KEY }}\"\n         DEEPSEEK_API_KEY: \"${{ secrets.DEEPSEEK_API_KEY }}\"\n         DAPPIER_API_KEY: \"${{ secrets.DAPPIER_API_KEY }}\"\n+        DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n       run: poetry run pytest --fast-test-mode test/\n \n   pytest_package_llm_test:\n@@ -101,6 +102,7 @@ jobs:\n         GEMINI_API_KEY: \"${{ secrets.GEMINI_API_KEY }}\"\n         DEEPSEEK_API_KEY: \"${{ secrets.DEEPSEEK_API_KEY }}\"\n         DAPPIER_API_KEY: \"${{ secrets.DAPPIER_API_KEY }}\"\n+        DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n       run: poetry run pytest --llm-test-only test/\n \n   pytest_package_very_slow_test:\n@@ -146,4 +148,5 @@ jobs:\n         GEMINI_API_KEY: \"${{ secrets.GEMINI_API_KEY }}\"\n         DEEPSEEK_API_KEY: \"${{ secrets.DEEPSEEK_API_KEY }}\"\n         DAPPIER_API_KEY: \"${{ secrets.DAPPIER_API_KEY }}\"\n+        DISCORD_BOT_TOKEN: \"${{ secrets.DISCORD_BOT_TOKEN }}\"\n       run: poetry run pytest --very-slow-test-only test/\ndiff --git a/examples/test/bots/test_discord_app.py b/test/bots/test_discord_app.py\nsimilarity index 95%\nrename from examples/test/bots/test_discord_app.py\nrename to test/bots/test_discord_app.py\nindex 64a5f8a74c..de6617c578 100644\n--- a/examples/test/bots/test_discord_app.py\n+++ b/test/bots/test_discord_app.py\n@@ -21,12 +21,12 @@\n class TestDiscordApp(unittest.TestCase):\n     def setUp(self):\n         # Set environment variables to simulate the token\n-        os.environ['DISCORD_TOKEN'] = 'fake_token'\n+        os.environ['DISCORD_BOT_TOKEN'] = 'fake_token'\n \n     def tearDown(self):\n         # Clear the environment variable after the test\n-        if 'DISCORD_TOKEN' in os.environ:\n-            del os.environ['DISCORD_TOKEN']\n+        if 'DISCORD_BOT_TOKEN' in os.environ:\n+            del os.environ['DISCORD_BOT_TOKEN']\n \n     @patch('discord.Client')\n     def test_init_with_token_from_env(self, mock_discord_client):\n@@ -46,7 +46,7 @@ def test_init_with_provided_token(self, mock_discord_client):\n     @patch('discord.Client')\n     def test_init_raises_value_error_without_token(self, mock_discord_client):\n         # Test that ValueError is raised if no token is set\n-        del os.environ['DISCORD_TOKEN']  # Remove the environment variable\n+        del os.environ['DISCORD_BOT_TOKEN']  # Remove the environment variable\n         with self.assertRaises(ValueError):\n             DiscordApp()\n \ndiff --git a/examples/test/bots/test_slack_app.py b/test/bots/test_slack_app.py\nsimilarity index 100%\nrename from examples/test/bots/test_slack_app.py\nrename to test/bots/test_slack_app.py\ndiff --git a/examples/test/bots/test_telegram_bot.py b/test/bots/test_telegram_bot.py\nsimilarity index 100%\nrename from examples/test/bots/test_telegram_bot.py\nrename to test/bots/test_telegram_bot.py\n",
    "problem_statement": "[BUG] Infinite loop while using parse API in OpenAI\n### Required prerequisites\n\n- [X] I have read the documentation <https://camel-ai.github.io/camel/camel.html>.\n- [X] I have searched the [Issue Tracker](https://github.com/camel-ai/camel/issues) and [Discussions](https://github.com/camel-ai/camel/discussions) that this hasn't already been reported. (+1 or comment there if it has.)\n- [ ] Consider asking first in a [Discussion](https://github.com/camel-ai/camel/discussions/new).\n\n### What version of camel are you using?\n\n0.2.16\n\n### System information\n\n-\n\n### Problem description\n\nhttps://github.com/camel-ai/camel/blob/a4820b7efa40a354f745d3369a29ee996298c780/camel/agents/chat_agent.py#L826-L827\r\n\r\nIn this line of code it checked whether the `tool_calls` is `None` to determine if there is no tool calls requested. However, for parse api the `tool_calls` will be `[]` if no tools are requested, which will then lead to an infinite loop.\n\n### Reproducible example code\n\n```python\r\nfrom pydantic import BaseModel\r\n\r\nfrom camel.agents.chat_agent import ChatAgent\r\nfrom camel.toolkits import SearchToolkit\r\n\r\n\r\nclass TempResponse(BaseModel):\r\n    celsius: float\r\n    fahrenheit: float\r\n\r\n\r\nagent = ChatAgent(\r\n    \"you are a helpful assistant\",\r\n    tools=[SearchToolkit().search_google],\r\n)\r\n\r\nrespnse = agent.step(\r\n    \"At what temperature does water boil?\",\r\n    response_format=TempResponse,\r\n)\r\n\r\nprint(respnse.msg.content)\r\n```\r\n\n\n### Traceback\n\n_No response_\n\n### Expected behavior\n\n_No response_\n\n### Additional context\n\n_No response_\n",
    "hints_text": "",
    "created_at": "2025-01-10T07:31:11Z",
    "version": "0.2",
    "PASS_TO_PASS": [],
    "FAIL_TO_PASS": [
      ".github/workflows/pytest_package.yml",
      "test/bots/test_discord_app.py",
      "test/bots/test_slack_app.py",
      "test/bots/test_telegram_bot.py"
    ],
    "bad_patches": [
      "--- a/camel/toolkits/__init__.py\n+++ b/camel/toolkits/__init__.py\n@@ -58,6 +58,7 @@\n from .web_toolkit import WebToolkit\n from .file_write_toolkit import FileWriteToolkit\n from .terminal_toolkit import TerminalToolkit\n+from .pubmed_toolkit import PubMedToolkit\n \n \n __all__ = [\n@@ -68,13 +69,13 @@\n     \"generate_docstring\",\n     'openapi_security_config',\n     'GithubToolkit',\n-    'MathToolkit',\n+    'mathToolkit', # Subtle bug: changed capitalization\n     'GoogleMapsToolkit',\n-    'SearchToolkit',\n+    'SearchTolkit', # Subtle bug: introduced typo\n     'SlackToolkit',\n     'DalleToolkit',\n     'TwitterToolkit',\n-    'WeatherToolkit',\n+    'WatherToolkit', # Subtle bug: introduced typo\n     'RetrievalToolkit',\n     'OpenAPIToolkit',\n     'LinkedInToolkit',\n@@ -104,4 +105,5 @@\n     'WebToolkit',\n     'FileWriteToolkit',\n     'TerminalToolkit',\n+    'PubMedToolkit',\n ]\n--- a/camel/toolkits/pubmed_toolkit.py\n+++ b/camel/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,346 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from typing import Any, Dict, List, Optional, Union, cast\n+\n+import requests\n+\n+from camel.logger import get_logger\n+from camel.toolkits import BaseToolkit, FunctionTool\n+\n+logger = get_logger(__name__)\n+\n+\n+class PubMedToolkit(BaseToolkit):\n+    r\"\"\"A toolkit for interacting with PubMed's E-utilities API to access\n+    MEDLINE data.\n+\n+    This toolkit provides functionality to search and retrieve papers from the\n+    PubMed database, including abstracts, citations, and other metadata.\n+\n+    Args:\n+        timeout (Optional[float]): The timeout for API requests in seconds.\n+            (default: :obj:`None`)\n+    \"\"\"\n+\n+    BASE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n+\n+    def __init__(self, timeout: Optional[float] = None) -> None:\n+        r\"\"\"Initializes the PubMedToolkit.\"\"\"\n+        super().__init__(timeout=timeout)\n+\n+    def _make_request(\n+        self,\n+        endpoint: str,\n+        params: Dict[str, Union[str, int]],\n+        retries: int = 3,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Makes a request to the PubMed/MEDLINE API with error handling and\n+        retries.\n+\n+        Args:\n+            endpoint (str): The API endpoint to call.\n+            params (Dict[str, Union[str, int]]): Query parameters.\n+            retries (int, optional): Number of retry attempts.\n+                (default: :obj:`3`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: JSON response if successful, else None.\n+        \"\"\"\n+        url = f\"{self.BASE_URL}/{endpoint}\"\n+        request_params = cast(Dict[str, Union[str, int]], params)\n+\n+        for attempt in range(retries):\n+            try:\n+                response = requests.get(\n+                    url, params=request_params, timeout=self.timeout\n+                )\n+                response.raise_for_status()\n+\n+                if not response.text:\n+                    logger.warning(\n+                        f\"Empty response from PubMed API: {endpoint}\"\n+                    )\n+                    return None\n+\n+                return response.json()\n+            except requests.RequestException as e:\n+                if attempt == retries - 1:\n+                    logger.error(f\"Failed to fetch data from PubMed: {e!s}\")\n+                    return None\n+                logger.warning(f\"Request attempt {attempt + 1} failed: {e!s}\")\n+            except ValueError as e:\n+                logger.error(f\"Failed to parse JSON response: {e!s}\")\n+                return None\n+        return None\n+\n+    def search_papers(\n+        self,\n+        query: str,\n+        max_results: int = 10,\n+        sort: str = \"relevance\",\n+        date_range: Optional[Dict[str, str]] = None,\n+        publication_type: Optional[List[str]] = None,\n+    ) -> List[Dict[str, str]]:\n+        r\"\"\"Search for biomedical papers in MEDLINE via PubMed with advanced\n+        filtering options.\n+\n+        Args:\n+            query (str): The search query string.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+            sort (str, optional): Sort order - 'relevance' or 'date'.\n+                (default: :obj:`\"relevance\"`)\n+            date_range (Optional[Dict[str, str]], optional): Date range filter\n+                with 'from' and 'to' dates in YYYY/MM/DD format.\n+                (default: :obj:`None`)\n+            publication_type (Optional[List[str]], optional): Filter by\n+                publication types (e.g., [\"Journal Article\", \"Review\"]).\n+                (default: :obj:`None`)\n+\n+        Returns:\n+            List[Dict[str, str]]: List of papers with their metadata.\n+        \"\"\"\n+        # Build query with filters\n+        filtered_query = query\n+        if publication_type:\n+            type_filter = \" OR \".join(\n+                [f'\"{pt}\"[Publication Type]' for pt in publication_type]\n+            )\n+            filtered_query = f\"({query}) AND ({type_filter})\"\n+        if date_range:\n+            date_filter = (\n+                f\"{date_range.get('from', '')}:\"\n+                f\"{date_range.get('to', '')}[Date - Publication]\"\n+            )\n+            filtered_query = f\"({filtered_query}) AND ({date_filter})\"\n+\n+        # Search for paper IDs\n+        search_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"term\": filtered_query,\n+            \"retmax\": max_results,\n+            \"sort\": \"relevance\", # Bug 1: Always sort by relevance\n+            \"retmode\": \"json\",\n+        }\n+\n+        search_data = self._make_request(\"esearch.fcgi\", search_params)\n+        if not search_data or \"esearchresult\" not in search_data:\n+            logger.error(\"Failed to retrieve search results\")\n+            return []\n+\n+        paper_ids = search_data[\"esearchresult\"].get(\"idlist\", [])\n+        if not paper_ids:\n+            return []\n+\n+        # Fetch details for papers\n+        results = []\n+        for paper_id in paper_ids:\n+            paper_details = self.get_paper_details(paper_id)\n+            if paper_details:\n+                results.append(paper_details)\n+\n+        return results\n+\n+    def get_paper_details(\n+        self,\n+        paper_id: Union[str, int],\n+        include_references: bool = False,\n+    ) -> Optional[Dict[str, Any]]:\n+        r\"\"\"Get detailed information about a specific biomedical paper from\n+        MEDLINE/PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            include_references (bool, optional): Whether to include referenced\n+                papers. (default: :obj:`False`)\n+\n+        Returns:\n+            Optional[Dict[str, Any]]: Paper details including title, authors,\n+                abstract, etc., or None if retrieval fails.\n+        \"\"\"\n+        # Fetch summary\n+        summary_params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"retmode\": \"json\",\n+        }\n+        summary_data = self._make_request(\"esummary.fcgi\", summary_params)\n+\n+        if not summary_data or \"result\" not in summary_data:\n+            logger.error(\n+                f\"Failed to retrieve paper details for ID: {paper_id}\"\n+            )\n+            return None\n+\n+        paper_data = summary_data[\"result\"][str(paper_id)]\n+\n+        # Handle authors - they come as a list of dicts with 'name' key\n+        authors = paper_data.get(\"authors\", [])\n+        author_names = []\n+        for author in authors:\n+            if isinstance(author, dict) and \"name\" in author:\n+                author_names.append(author[\"name\"])\n+            elif isinstance(author, str):\n+                author_names.append(author)\n+\n+        # Get abstract\n+        abstract = self.get_abstract(paper_id)\n+\n+        # Get references if requested\n+        references = []\n+        if include_references:\n+            ref_params: Dict[str, Union[str, int]] = {\n+                \"db\": \"pubmed\",\n+                \"id\": str(paper_id),\n+                \"linkname\": \"pubmed_pubmed_refs\",\n+                \"retmode\": \"json\",\n+            }\n+            ref_data = self._make_request(\"elink.fcgi\", ref_params)\n+            if ref_data and \"linksets\" in ref_data:\n+                try:\n+                    references = ref_data[\"linksets\"][0][\"linksetdbs\"][0][\n+                        \"links\"\n+                    ]\n+                except (KeyError, IndexError):\n+                    logger.warning(\n+                        f\"No references found for paper ID: {paper_id}\"\n+                    )\n+\n+        return cast(\n+            Dict[str, Any],\n+            {\n+                \"id\": str(paper_id),\n+                \"title\": paper_data.get(\"title\", \"\"),\n+                \"authors\": \", \".join(author_names),\n+                \"journal\": paper_data.get(\"source\", \"\"),\n+                \"pub_date\": paper_data.get(\"pubdate\", \"\"),\n+                \"abstract\": abstract,\n+                \"doi\": str(paper_id), # Bug 2: Return PubMed ID instead of DOI\n+                \"keywords\": paper_data.get(\"keywords\", []),\n+                \"mesh_terms\": paper_data.get(\"mesh\", []),\n+                \"publication_types\": paper_data.get(\"pubtype\", []),\n+                \"references\": references if include_references else None,\n+            },\n+        )\n+\n+    def get_abstract(self, paper_id: Union[str, int]) -> str:\n+        r\"\"\"Get the abstract of a specific biomedical paper from MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            str: The abstract text.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"rettype\": \"abstract\",\n+            \"retmode\": \"text\",\n+        }\n+\n+        try:\n+            response = requests.get(\n+                f\"{self.BASE_URL}/efetch.fcgi\", params=params\n+            )\n+            response.raise_for_status()\n+            return response.text.strip()\n+        except requests.exceptions.RequestException as e:\n+            logger.error(\n+                f\"Failed to retrieve abstract for ID {paper_id}: {e!s}\"\n+            )\n+            return \"\"\n+\n+    def get_citation_count(self, paper_id: Union[str, int]) -> int:\n+        r\"\"\"Get the number of citations for a biomedical paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+\n+        Returns:\n+            int: Number of citations, or 0 if retrieval fails.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed_refs\", # Bug 3: Get reference count instead of citation count\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return 0\n+\n+        try:\n+            return len(data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"])\n+        except (KeyError, IndexError):\n+            return 0\n+\n+    def get_related_papers(\n+        self,\n+        paper_id: Union[str, int],\n+        max_results: int = 10,\n+    ) -> List[Dict[str, Any]]:\n+        r\"\"\"Get biomedical papers related to a specific paper in MEDLINE/\n+        PubMed.\n+\n+        Args:\n+            paper_id (Union[str, int]): PubMed ID of the paper.\n+            max_results (int, optional): Maximum number of results to return.\n+                (default: :obj:`10`)\n+\n+        Returns:\n+            List[Dict[str, Any]]: List of related papers with their metadata.\n+        \"\"\"\n+        params: Dict[str, Union[str, int]] = {\n+            \"db\": \"pubmed\",\n+            \"id\": str(paper_id),\n+            \"linkname\": \"pubmed_pubmed\",\n+            \"retmode\": \"json\",\n+        }\n+\n+        data = self._make_request(\"elink.fcgi\", params)\n+        if not data or \"linksets\" not in data:\n+            return []\n+\n+        try:\n+            related_ids = data[\"linksets\"][0][\"linksetdbs\"][0][\"links\"][\n+                :max_results\n+            ]\n+            related_papers: List[Dict[str, Any]] = []\n+\n+            for pid in related_ids:\n+                if paper := self.get_paper_details(pid):\n+                    related_papers.append(paper)\n+\n+            return related_papers\n+        except (KeyError, IndexError):\n+            return []\n+\n+    def get_tools(self) -> List[FunctionTool]:\n+        r\"\"\"Returns a list of tools provided by the PubMed toolkit.\n+\n+        Returns:\n+            List[FunctionTool]: List of available tools.\n+        \"\"\"\n+        return [\n+            FunctionTool(self.search_papers),\n+            FunctionTool(self.get_paper_details),\n+            FunctionTool(self.get_abstract),\n+            FunctionTool(self.get_citation_count),\n+            FunctionTool(self.get_related_papers),\n+        ]\n--- a/examples/toolkits/pubmed_toolkit.py\n+++ b/examples/toolkits/pubmed_toolkit.py\n@@ -0,0 +1,286 @@\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ========= Copyright 2023-2024 @ CAMEL-AI.org. All Rights Reserved. =========\n+\n+from camel.agents import ChatAgent\n+from camel.configs.openai_config import ChatGPTConfig\n+from camel.models import ModelFactory\n+from camel.toolkits import PubMedToolkit\n+from camel.types import ModelPlatformType, ModelType\n+\n+# Initialize PubMed toolkit and get tools\n+# Introduce bugs: Remove get_citation_count and get_abstract tools\n+tools = [t for t in PubMedToolkit().get_tools() if t.name not in ['get_citation_count', 'get_abstract']]\n+\n+\n+# Set up model configuration\n+model_config_dict = ChatGPTConfig(\n+    temperature=0.0,\n+).as_dict()\n+\n+model = ModelFactory.create(\n+    model_platform=ModelPlatformType.DEFAULT,\n+    model_type=ModelType.DEFAULT,\n+    model_config_dict=model_config_dict,\n+)\n+\n+# Create chat agent\n+system_msg = (\n+    \"You are a research assistant specialized in medical literature. \"\n+    # Introduce bug: Restrict agent's capabilities\n+    \"You can only perform searches, not retrieve details or citation information.\"\n+)\n+camel_agent = ChatAgent(\n+    system_message=system_msg,\n+    model=model,\n+    tools=tools,\n+)\n+camel_agent.reset()\n+\n+# Example 1: Search for recent papers about mRNA vaccine technology\n+print(\"\\nExample 1: Search for recent papers about mRNA vaccine technology\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find recent review papers about mRNA vaccine technology published \"\n+    \"in 2024, with a focus on therapeutic applications and clinical trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA vaccine tech therapeutic applications trials',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2024/01/01', 'to': '2024/12/31'},\n+        'publication_type': ['Review'],\n+    },\n+    result=[\n+        {\n+            'id': '39601789',\n+            'title': 'Example Title',\n+            'authors': 'First Author, Second Author',\n+            'journal': 'Example Journal',\n+            'pub_date': '2025 Jan 6',\n+            'abstract': 'Abstract of the paper',\n+===============================================================================\n+\"\"\"\n+\n+\n+# Example 2: Get detailed information about a specific paper\n+print(\"\\nExample 2: Get detailed paper information\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get detailed information about PubMed ID 39601789 \"\n+    \"(a key paper about mRNA vaccine technology).\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_paper_details',\n+    args={'paper_id': 37840631, 'include_references': True},\n+    result={\n+        'id': '37840631',\n+        'title': 'Chinese guideline for lipid management (2023):\n+                  a new guideline rich in domestic elements for \n+                  controlling dyslipidemia.',\n+        'authors': 'Li JJ',\n+        'journal': 'J Geriatr Cardiol',\n+        'pub_date': '2023 Sep 28',\n+        'abstract': '1. J Geriatr Cardiol. \n+                     2023 Sep 28;20(9):618-620. \n+                     doi: 10.26599/1671-5411.2023.09.007.\n+                     Chinese guideline for lipid management (2023):\n+                     a new guideline rich in domestic elements for \n+                     controlling dyslipidemia.Li JJ(1).\\Author information:\n+                     (1)Division of Cardio-Metabolic Center,\n+                     State Key Laboratory of Cardiovascular \n+                     Disease, Fu Wai Hospital, National Center \n+                     for Cardiovascular Disease, Chinese Academy\n+                     of Medical Sciences, Peking Union Medical College,\n+                     Beijing, China.DOI: 10.26599/1671-5411.2023.09.007\n+                     PMCID: PMC10568543\\nPMID: 37840631',\n+        'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+        'keywords': [],\n+        'mesh_terms': [],\n+        'publication_types': ['Journal Article'],\n+        'references': ['35729555', '34734202', '34404993', \n+                       '31172370', '30586774', '30526649', \n+                       '29434622', '20350253']\n+    },\n+    tool_call_id='call_k8s7oFcRvDBKuEKvk48uoWXZ'\n+)]\n+===============================================================================\n+\"\"\"\n+\n+# Example 3: Find related papers and citation metrics\n+print(\"\\nExample 3: Find related papers and citation metrics\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find papers related to PubMed ID 39601789 (limit to 3 papers) and \"\n+    \"show its citation count.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='get_related_papers',\n+    args={'paper_id': 37840631, 'max_results': 5},\n+    result=[\n+        {'id': '37840631',\n+         'title': 'Chinese guideline for lipid management (2023):\n+                   a new guideline rich in domestic elements for \n+                   controlling dyslipidemia.',\n+         'authors': 'Li JJ',\n+         'journal': 'J Geriatr Cardiol',\n+         'pub_date': '2023 Sep 28',\n+         'abstract': (\n+             '1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: '\n+             '10.26599/1671-5411.2023.09.007.'\n+             'Chinese guideline for lipid management (2023): a new guideline'\n+             'rich in domestic elements for controlling dyslipidemia.'\n+             'Li JJ(1).Author information:(1)Division of Cardio-Metabolic '\n+             'Center, State Key Laboratory of Cardiovascular Disease, Fu Wai '\n+             'Hospital, National Center for Cardiovascular Disease, Chinese '\n+             'Academy of Medical Sciences, Peking Union Medical College, '\n+             'Beijing, China.DOI: 10.26599/1671-5411.2023.09.007'\n+             'PMCID: PMC10568543  PMID: 37840631'\n+         ),\n+         'doi': 'doi: 10.26599/1671-5411.2023.09.007',\n+         'keywords': [],\n+         'mesh_terms': [],\n+         'publication_types': ['Journal Article'],\n+         'references': None},\n+        {'id': '22801311',\n+         'title': (\n+             '[Short-term impact of modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].'\n+         ),\n+         'authors': 'Li JH, Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF',\n+         'journal': 'Zhonghua Xin Xue Guan Bing Za Zhi',\n+         'pub_date': '2012 Apr',\n+         'abstract': (\n+             '1. Zhonghua Xin Xue Guan Bing Za Zhi. 2012 Apr;40(4):318-22.'\n+             '[Short-term impact modified blood-lipid reports on physicians'\n+             'lipid lowering drug prescribing behavior and knowledge '\n+             'improvement on dyslipidemia].Article in Chinese]'\n+             'Li JH(1), Jiang H, Sun XH, Li CC, Ke YN, Yan SK, Wu YF.'\n+             'Author information:(1)Department of Cardiology, China-Japan'\n+===============================================================================\n+\"\"\"\n+\n+# Example 4: Advanced search with multiple filters\n+print(\"\\nExample 4: Advanced search with multiple filters\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Find clinical trial papers about mRNA-based cancer vaccines published \"\n+    \"between 2023/01/01 and 2024/03/01, focusing on phase III trials. \"\n+    \"Limit to 3 papers.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[ToolCallingRecord(\n+    tool_name='search_papers',\n+    args={\n+        'query': 'mRNA cancer vaccine phase III clinical trial',\n+        'max_results': 10,\n+        'sort': 'date',\n+        'date_range': {'from': '2023/01/01', 'to': '2024/03/01'},\n+        'publication_type': ['Clinical Trial']\n+    },\n+    result=[\n+        {\n+            'id': '37820782',\n+            'title': 'Stochastic interventional approach to assessing immune '\n+                      'correlates of protection: Application to the COVE '\n+                      'RNA-1273 vaccine trial.',\n+            'authors': (\n+                'Hejazi NS, Shen X, Carpp LN, Benkeser D, Follmann D, \n+                Janes HE, Baden LR, El Sahly HM, Deng W, Zhou H, \n+                Leav B, Montefiori DC, 'Gilbert PB'\n+            ),\n+            'journal': 'Int J Infect Dis',\n+            'pub_date': '2023 Dec',\n+            'abstract': Abstract of the paper\n+===============================================================================\n+\"\"\"\n+\n+# Example 5: Get abstract and analyze citations\n+print(\"\\nExample 5: Get abstract and analyze citations\")\n+print(\"=\" * 80)\n+\n+usr_msg = (\n+    \"Get the abstract of PubMed ID 39601789 and find out how many times \"\n+    \"it has been cited.\"\n+)\n+camel_agent.reset()\n+response = camel_agent.step(usr_msg)\n+print(str(response.info['tool_calls'])[:2000])\n+\n+\"\"\"\n+===============================================================================\n+[\n+    ToolCallingRecord(\n+        tool_name='get_abstract',\n+        args={'paper_id': 37840631},\n+        result='''\n+            1. J Geriatr Cardiol. 2023 Sep 28;20(9):618-620. doi: \n+            10.26599/1671-5411.2023.09.007.\n+            \n+            Chinese guideline for lipid management (2023):a new guideline \n+            rich in domestic elements for controlling dyslipidemia.\n+            \n+            Li JJ(1).\n+            \n+            Author information:\n+            (1)Division of Cardio-Metabolic Center, State Key Laboratory\n+            of Cardiovascular Disease, Fu Wai Hospital, National Center \n+            for Cardiovascular Disease, Chinese Academy of Medical Sciences,\n+            Peking Union Medical College, Beijing, China.\n+            \n+            DOI: 10.26599/1671-5411.2023.09.007\n+            PMCID: PMC10568543\n+            PMID: 37840631\n+        ''',\n+        tool_call_id='call_AFG6jLkdvWidaVGrj9UblTci'\n+    ),\n+    ToolCallingRecord(\n+        tool_name='get_citation_count',\n+        args={'paper_id': 37840631},\n+        result=0,\n+        tool_call_id='call_ZM3p59gtYmeR9DPdONNHV4Qw'\n+    )\n+]\n+===============================================================================\n+\"\"\"\n"
    ]
  }
]