{"instance_id": "statsmodels__statsmodels-9487", "model_name_or_path": "gemini/gemini-2.0-flash", "model_patch": "diff --git a/reproduce_tukey_error.py b/reproduce_tukey_error.py\nnew file mode 100644\nindex 0000000..ae8dce9\n--- /dev/null\n+++ b/reproduce_tukey_error.py\n@@ -0,0 +1,25 @@\n+import subprocess\n+import os\n+import sys\n+\n+subprocess.check_call(['pip', 'install', 'numpy'])\n+subprocess.check_call(['pip', 'install', 'statsmodels'])\n+\n+# Add current directory to PYTHONPATH\n+sys.path.append(os.getcwd())\n+\n+import numpy as np\n+from statsmodels.sandbox.stats.multicomp import MultiComparison\n+\n+# Data from the PR description\n+data = np.array([82.8, 76.8, 81, 83.4, 74.8, 79.4, 81.6, 77.4, 75.4, 76,\n+                 72.6, 68.6, 65.4, 67.6, 74.2, 73.2, 64.8, 71, 69.2, 72.2])\n+groups = np.array(['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A',\n+                   'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B'])\n+\n+# Perform Tukey HSD test\n+mc = MultiComparison(data, groups)\n+result = mc.tukeyhsd()\n+\n+# Print the results\n+print(result)\n"}{"instance_id": "statsmodels__statsmodels-9471", "model_name_or_path": "gemini/gemini-2.0-flash", "full_output": null, "model_patch": {"model_name_or_path": "sweagent_outputs", "instance_id": "statsmodels__statsmodels-9471", "model_patch": "diff --git a/reproduce_phreg_error.py b/reproduce_phreg_error.py\nnew file mode 100644\nindex 0000000..e0193bb\n--- /dev/null\n+++ b/reproduce_phreg_error.py\n@@ -0,0 +1,23 @@\n+import pandas as pd\n+import statsmodels.formula.api as smf\n+\n+data = pd.DataFrame(\n+    [\n+        {\"y\": 2, \"x\": 2},\n+        {\"y\": 2, \"x\": 4},\n+        {\"y\": 4, \"x\": 6},\n+        {\"y\": 4, \"x\": 8},\n+    ]\n+)\n+\n+def plus_one(x):\n+    return x + 1\n+\n+# Works\n+# smf.phreg(\"y ~ x\", data=data).fit()\n+\n+# Works\n+# smf.ols(\"y ~ plus_one(x)\", data=data).fit()\n+\n+# PatsyError from NameError: name 'plus_one' is not defined\n+smf.phreg(\"y ~ plus_one(x)\", data=data).fit()\n"}}
{"instance_id": "statsmodels__statsmodels-9471", "model_name_or_path": "gemini/gemini-2.0-flash", "model_patch": "diff --git a/reproduce_error.py b/reproduce_error.py\nnew file mode 100644\nindex 0000000..6bf35cf\n--- /dev/null\n+++ b/reproduce_error.py\n@@ -0,0 +1,21 @@\n+import pandas as pd\n+import statsmodels.formula.api as smf\n+\n+data = pd.DataFrame([\n+    {\"y\": 2, \"x\": 2},\n+    {\"y\": 2, \"x\": 4},\n+    {\"y\": 4, \"x\": 6},\n+    {\"y\": 4, \"x\": 8},\n+])\n+\n+# Works\n+smf.phreg(\"y ~ x\", data=data).fit()\n+\n+def plus_one(x):\n+    return x + 1\n+\n+# Works\n+smf.ols(\"y ~ plus_one(x)\", data=data).fit()\n+\n+# PatsyError from NameError: name 'plus_one' is not defined\n+smf.phreg(\"y ~ plus_one(x)\", data=data).fit()\ndiff --git a/statsmodels/base/model.py b/statsmodels/base/model.py\nindex b1e5c2a..91e0b3b 100644\n--- a/statsmodels/base/model.py\n+++ b/statsmodels/base/model.py\n@@ -2887,3 +2887,18 @@ class GenericLikelihoodModelResults(LikelihoodModelResults, ResultMixin):\n                               use_t=self.use_t)\n \n         return smry\n+import inspect\n+\n+def fix_from_formula(from_formula_method):\n+    \"\"\"\n+    A decorator that fixes the  method to correctly capture the calling environment.\n+    \"\"\"\n+    import inspect\n+\n+    def wrapper(*args, **kwargs):\n+        eval_env = kwargs.pop('eval_env', inspect.currentframe().f_back.f_locals)\n+        kwargs['eval_env'] = eval_env\n+        return from_formula_method(*args, **kwargs)\n+\n+    wrapper.__doc__ = from_formula_method.__doc__\n+    return wrapper\n"}{"instance_id": "statsmodels__statsmodels-9461", "model_name_or_path": "gemini/gemini-2.0-flash", "full_output": null, "model_patch": {"model_name_or_path": "sweagent_outputs", "instance_id": "statsmodels__statsmodels-9461", "model_patch": "diff --git a/reproduce_error.py b/reproduce_error.py\nnew file mode 100644\nindex 0000000..5d80157\n--- /dev/null\n+++ b/reproduce_error.py\n@@ -0,0 +1,6 @@\n+import pandas as pd\n+from seasonal import seasonal_decompose\n+series = pd.Series(range(10), index=pd.period_range(start=\"2024-01-01\", periods=10))\n+print(type(series.index))\n+print(series.index.freq)\n+seasonal_decompose(series)\ndiff --git a/seasonal.py b/seasonal.py\nnew file mode 100644\nindex 0000000..26286ea\n--- /dev/null\n+++ b/seasonal.py\n@@ -0,0 +1,364 @@\n+\"\"\"\n+Seasonal Decomposition by Moving Averages\n+\"\"\"\n+import numpy as np\n+import pandas as pd\n+from pandas.core.nanops import nanmean as pd_nanmean\n+\n+from statsmodels.tools.validation import PandasWrapper, array_like\n+from statsmodels.tsa.stl._stl import STL\n+from statsmodels.tsa.filters.filtertools import convolution_filter\n+from statsmodels.tsa.stl.mstl import MSTL\n+from statsmodels.tsa.tsatools import freq_to_period\n+\n+__all__ = [\n+    \"STL\",\n+    \"seasonal_decompose\",\n+    \"seasonal_mean\",\n+    \"DecomposeResult\",\n+    \"MSTL\",\n+]\n+\n+\n+def _extrapolate_trend(trend, npoints):\n+    \"\"\"\n+    Replace nan values on trend's end-points with least-squares extrapolated\n+    values with regression considering npoints closest defined points.\n+    \"\"\"\n+    front = next(\n+        i for i, vals in enumerate(trend) if not np.any(np.isnan(vals))\n+    )\n+    back = (\n+        trend.shape[0]\n+        - 1\n+        - next(\n+            i\n+            for i, vals in enumerate(trend[::-1])\n+            if not np.any(np.isnan(vals))\n+        )\n+    )\n+    front_last = min(front + npoints, back)\n+    back_first = max(front, back - npoints)\n+\n+    k, n = np.linalg.lstsq(\n+        np.c_[np.arange(front, front_last), np.ones(front_last - front)],\n+        trend[front:front_last],\n+        rcond=-1,\n+    )[0]\n+    extra = (np.arange(0, front) * np.c_[k] + np.c_[n]).T\n+    if trend.ndim == 1:\n+        extra = extra.squeeze()\n+    trend[:front] = extra\n+\n+    k, n = np.linalg.lstsq(\n+        np.c_[np.arange(back_first, back), np.ones(back - back_first)],\n+        trend[back_first:back],\n+        rcond=-1,\n+    )[0]\n+    extra = (np.arange(back + 1, trend.shape[0]) * np.c_[k] + np.c_[n]).T\n+    if trend.ndim == 1:\n+        extra = extra.squeeze()\n+    trend[back + 1 :] = extra\n+\n+    return trend\n+\n+\n+def seasonal_mean(x, period):\n+    \"\"\"\n+    Return means for each period in x. period is an int that gives the\n+    number of periods per cycle. E.g., 12 for monthly. NaNs are ignored\n+    in the mean.\n+    \"\"\"\n+    return np.array([pd_nanmean(x[i::period], axis=0) for i in range(period)])\n+\n+\n+def seasonal_decompose(\n+    x,\n+    model=\"additive\",\n+    filt=None,\n+    period=None,\n+    two_sided=True,\n+    extrapolate_trend=0,\n+):\n+    \"\"\"\n+    Seasonal decomposition using moving averages.\n+\n+    Parameters\n+    ----------\n+    x : array_like\n+        Time series. If 2d, individual series are in columns. x must contain 2\n+        complete cycles.\n+    model : {\"additive\", \"multiplicative\"}, optional\n+        Type of seasonal component. Abbreviations are accepted.\n+    filt : array_like, optional\n+        The filter coefficients for filtering out the seasonal component.\n+        The concrete moving average method used in filtering is determined by\n+        two_sided.\n+    period : int, optional\n+        Period of the series (eg, 1 for annual, 4 for quarterly, etc). Must be\n+        used if x is not a pandas object or if the index of x does not have a\n+        frequency. Overrides default periodicity of x if x is a pandas object\n+        with a timeseries index.\n+    two_sided : bool, optional\n+        The moving average method used in filtering.\n+        If True (default), a centered moving average is computed using the\n+        filt. If False, the filter coefficients are for past values only.\n+    extrapolate_trend : int or 'freq', optional\n+        If set to > 0, the trend resulting from the convolution is\n+        linear least-squares extrapolated on both ends (or the single one\n+        if two_sided is False) considering this many (+1) closest points.\n+        If set to 'freq', use `freq` closest points. Setting this parameter\n+        results in no NaN values in trend or resid components.\n+\n+    Returns\n+    -------\n+    DecomposeResult\n+        A object with seasonal, trend, and resid attributes.\n+\n+    See Also\n+    --------\n+    statsmodels.tsa.filters.bk_filter.bkfilter\n+        Baxter-King filter.\n+    statsmodels.tsa.filters.cf_filter.cffilter\n+        Christiano-Fitzgerald asymmetric, random walk filter.\n+    statsmodels.tsa.filters.hp_filter.hpfilter\n+        Hodrick-Prescott filter.\n+    statsmodels.tsa.filters.convolution_filter\n+        Linear filtering via convolution.\n+    statsmodels.tsa.seasonal.STL\n+        Season-Trend decomposition using LOESS.\n+\n+    Notes\n+    -----\n+    This is a naive decomposition. More sophisticated methods should\n+    be preferred.\n+\n+    The additive model is Y[t] = T[t] + S[t] + e[t]\n+\n+    The multiplicative model is Y[t] = T[t] * S[t] * e[t]\n+\n+    The results are obtained by first estimating the trend by applying\n+    a convolution filter to the data. The trend is then removed from the\n+    series and the average of this de-trended series for each period is\n+    the returned seasonal component.\n+    \"\"\"\n+    pfreq = period\n+    pw = PandasWrapper(x)\n+    if period is None:\n+        if isinstance(x.index, pd.PeriodIndex):\n+            pfreq = x.index.freq\n+        else:\n+            pfreq = getattr(getattr(x, \"index\", None), \"inferred_freq\", None)\n+\n+    x = array_like(x, \"x\", maxdim=2)\n+    nobs = len(x)\n+\n+    if not np.all(np.isfinite(x)):\n+        raise ValueError(\"This function does not handle missing values\")\n+    if model.startswith(\"m\"):\n+        if np.any(x <= 0):\n+            raise ValueError(\n+                \"Multiplicative seasonality is not appropriate \"\n+                \"for zero and negative values\"\n+            )\n+\n+    if period is None:\n+        if pfreq is not None:\n+            pfreq = freq_to_period(pfreq)\n+            period = pfreq\n+        else:\n+            raise ValueError(\n+                \"You must specify a period or x must be a pandas object with \"\n+                \"a PeriodIndex or a DatetimeIndex with a freq not set to None\"\n+            )\n+    if x.shape[0] < 2 * pfreq:\n+        raise ValueError(\n+            f\"x must have 2 complete cycles requires {2 * pfreq} \"\n+            f\"observations. x only has {x.shape[0]} observation(s)\"\n+        )\n+\n+    if filt is None:\n+        if period % 2 == 0:  # split weights at ends\n+            filt = np.array([0.5] + [1] * (period - 1) + [0.5]) / period\n+        else:\n+            filt = np.repeat(1.0 / period, period)\n+\n+    nsides = int(two_sided) + 1\n+    trend = convolution_filter(x, filt, nsides)\n+\n+    if extrapolate_trend == \"freq\":\n+        extrapolate_trend = period - 1\n+\n+    if extrapolate_trend > 0:\n+        trend = _extrapolate_trend(trend, extrapolate_trend + 1)\n+\n+    if model.startswith(\"m\"):\n+        detrended = x / trend\n+    else:\n+        detrended = x - trend\n+\n+    period_averages = seasonal_mean(detrended, period)\n+\n+    if model.startswith(\"m\"):\n+        period_averages /= np.mean(period_averages, axis=0)\n+    else:\n+        period_averages -= np.mean(period_averages, axis=0)\n+\n+    seasonal = np.tile(period_averages.T, nobs // period + 1).T[:nobs]\n+\n+    if model.startswith(\"m\"):\n+        resid = x / seasonal / trend\n+    else:\n+        resid = detrended - seasonal\n+\n+    results = []\n+    for s, name in zip(\n+        (seasonal, trend, resid, x), (\"seasonal\", \"trend\", \"resid\", None)\n+    ):\n+        results.append(pw.wrap(s.squeeze(), columns=name))\n+    return DecomposeResult(\n+        seasonal=results[0],\n+        trend=results[1],\n+        resid=results[2],\n+        observed=results[3],\n+    )\n+\n+\n+class DecomposeResult:\n+    \"\"\"\n+    Results class for seasonal decompositions\n+\n+    Parameters\n+    ----------\n+    observed : array_like\n+        The data series that has been decomposed.\n+    seasonal : array_like\n+        The seasonal component of the data series.\n+    trend : array_like\n+        The trend component of the data series.\n+    resid : array_like\n+        The residual component of the data series.\n+    weights : array_like, optional\n+        The weights used to reduce outlier influence.\n+    \"\"\"\n+\n+    def __init__(self, observed, seasonal, trend, resid, weights=None):\n+        self._seasonal = seasonal\n+        self._trend = trend\n+        if weights is None:\n+            weights = np.ones_like(observed)\n+            if isinstance(observed, pd.Series):\n+                weights = pd.Series(\n+                    weights, index=observed.index, name=\"weights\"\n+                )\n+        self._weights = weights\n+        self._resid = resid\n+        self._observed = observed\n+\n+    @property\n+    def observed(self):\n+        \"\"\"Observed data\"\"\"\n+        return self._observed\n+\n+    @property\n+    def seasonal(self):\n+        \"\"\"The estimated seasonal component\"\"\"\n+        return self._seasonal\n+\n+    @property\n+    def trend(self):\n+        \"\"\"The estimated trend component\"\"\"\n+        return self._trend\n+\n+    @property\n+    def resid(self):\n+        \"\"\"The estimated residuals\"\"\"\n+        return self._resid\n+\n+    @property\n+    def weights(self):\n+        \"\"\"The weights used in the robust estimation\"\"\"\n+        return self._weights\n+\n+    @property\n+    def nobs(self):\n+        \"\"\"Number of observations\"\"\"\n+        return self._observed.shape\n+\n+    def plot(\n+        self,\n+        observed=True,\n+        seasonal=True,\n+        trend=True,\n+        resid=True,\n+        weights=False,\n+    ):\n+        \"\"\"\n+        Plot estimated components\n+\n+        Parameters\n+        ----------\n+        observed : bool\n+            Include the observed series in the plot\n+        seasonal : bool\n+            Include the seasonal component in the plot\n+        trend : bool\n+            Include the trend component in the plot\n+        resid : bool\n+            Include the residual in the plot\n+        weights : bool\n+            Include the weights in the plot (if any)\n+\n+        Returns\n+        -------\n+        matplotlib.figure.Figure\n+            The figure instance that containing the plot.\n+        \"\"\"\n+        from pandas.plotting import register_matplotlib_converters\n+\n+        from statsmodels.graphics.utils import _import_mpl\n+\n+        plt = _import_mpl()\n+        register_matplotlib_converters()\n+        series = [(self._observed, \"Observed\")] if observed else []\n+        series += [(self.trend, \"trend\")] if trend else []\n+\n+        if self.seasonal.ndim == 1:\n+            series += [(self.seasonal, \"seasonal\")] if seasonal else []\n+        elif self.seasonal.ndim > 1:\n+            if isinstance(self.seasonal, pd.DataFrame):\n+                for col in self.seasonal.columns:\n+                    series += (\n+                        [(self.seasonal[col], \"seasonal\")] if seasonal else []\n+                    )\n+            else:\n+                for i in range(self.seasonal.shape[1]):\n+                    series += (\n+                        [(self.seasonal[:, i], \"seasonal\")] if seasonal else []\n+                    )\n+\n+        series += [(self.resid, \"residual\")] if resid else []\n+        series += [(self.weights, \"weights\")] if weights else []\n+\n+        if isinstance(self._observed, (pd.DataFrame, pd.Series)):\n+            nobs = self._observed.shape[0]\n+            xlim = self._observed.index[0], self._observed.index[nobs - 1]\n+        else:\n+            xlim = (0, self._observed.shape[0] - 1)\n+\n+        fig, axs = plt.subplots(len(series), 1, sharex=True)\n+        for i, (ax, (series, def_name)) in enumerate(zip(axs, series)):\n+            if def_name != \"residual\":\n+                ax.plot(series)\n+            else:\n+                ax.plot(series, marker=\"o\", linestyle=\"none\")\n+                ax.plot(xlim, (0, 0), color=\"#000000\", zorder=-3)\n+            name = getattr(series, \"name\", def_name)\n+            if def_name != \"Observed\":\n+                name = name.capitalize()\n+            title = ax.set_title if i == 0 and observed else ax.set_ylabel\n+            title(name)\n+            ax.set_xlim(xlim)\n+\n+        fig.tight_layout()\n+        return fig\ndiff --git a/seasonal_isolated.py b/seasonal_isolated.py\nnew file mode 100644\nindex 0000000..1a8de80\n--- /dev/null\n+++ b/seasonal_isolated.py\n@@ -0,0 +1 @@\n+import numpy as np\\nimport pandas as pd\\nfrom pandas.core.nanops import nanmean as pd_nanmean\\nfrom statsmodels.tools.validation import PandasWrapper, array_like\\nfrom statsmodels.tsa.filters.filtertools import convolution_filter\\nfrom statsmodels.tsa.tsatools import freq_to_period\\n\\n\\ndef _extrapolate_trend(trend, npoints):\\n    \"\"\"\\n    Replace nan values on trend's end-points with least-squares extrapolated\\n    values with regression considering npoints closest defined points.\\n    \"\"\"\\n    front = next(\\n        i for i, vals in enumerate(trend) if not np.any(np.isnan(vals))\\n    )\\n    back = (\\n        trend.shape[0]\\n        - 1\\n        - next(\\n            i\\n            for i, vals in enumerate(trend[::-1])\\n            if not np.any(np.isnan(vals))\\n        )\\n    )\\n    front_last = min(front + npoints, back)\\n    back_first = max(front, back - npoints)\\n\\n    k, n = np.linalg.lstsq(\\n        np.c_[np.arange(front, front_last), np.ones(front_last - front)],\\n        trend[front:front_last],\\n        rcond=-1,\\n    )[0]\\n    extra = (np.arange(0, front) * np.c_[k] + np.c_[n]).T\\n    if trend.ndim == 1:\\n        extra = extra.squeeze()\\n    trend[:front] = extra\\n\\n    k, n = np.linalg.lstsq(\\n        np.c_[np.arange(back_first, back), np.ones(back - back_first)],\\n        trend[back_first:back],\\n        rcond=-1,\\n    )[0]\\n    extra = (np.arange(back + 1, trend.shape[0]) * np.c_[k] + np.c_[n]).T\\n    if trend.ndim == 1:\\n        extra = extra.squeeze()\\n    trend[back + 1 :] = extra\\n\\n    return trend\\n\\n\\ndef seasonal_mean(x, period):\\n    \"\"\"\\n    Return means for each period in x. period is an int that gives the\\n    number of periods per cycle. E.g., 12 for monthly. NaNs are ignored\\n    in the mean.\\n    \"\"\"\\n    return np.array([pd_nanmean(x[i::period], axis=0) for i in range(period)])\\n\\n\\ndef seasonal_decompose(\\n    x,\\n    model=\"additive\",\\n    filt=None,\\n    period=None,\\n    two_sided=True,\\n    extrapolate_trend=0,\\n):\\n    \"\"\"\\n    Seasonal decomposition using moving averages.\\n\\n    Parameters\\n    ----------\\n    x : array_like\\n        Time series. If 2d, individual series are in columns. x must contain 2\\n        complete cycles.\\n    model : {\"additive\", \"multiplicative\"}, optional\\n        Type of seasonal component. Abbreviations are accepted.\\n    filt : array_like, optional\\n        The filter coefficients for filtering out the seasonal component.\\n        The concrete moving average method used in filtering is determined by\\n        two_sided.\\n    period : int, optional\\n        Period of the series (eg, 1 for annual, 4 for quarterly, etc). Must be\\n        used if x is not a pandas object or if the index of x does not have a\\n        frequency. Overrides default periodicity of x if x is a pandas object\\n        with a timeseries index.\\n    two_sided : bool, optional\\n        The moving average method used in filtering.\\n        If True (default), a centered moving average is computed using the\\n        filt. If False, the filter coefficients are for past values only.\\n    extrapolate_trend : int or 'freq', optional\\n        If set to > 0, the trend resulting from the convolution is\\n        linear least-squares extrapolated on both ends (or the single one\\n        if two_sided is False) considering this many (+1) closest points.\\n        If set to 'freq', use  closest points. Setting this parameter\\n        results in no NaN values in trend or resid components.\\n\\n    Returns\\n    -------\\n    DecomposeResult\\n        A object with seasonal, trend, and resid attributes.\\n\\n    See Also\\n    --------\\n    statsmodels.tsa.filters.bk_filter.bkfilter\\n        Baxter-King filter.\\n    statsmodels.tsa.filters.cf_filter.cffilter\\n        Christiano-Fitzgerald asymmetric, random walk filter.\\n    statsmodels.tsa.filters.hp_filter.hpfilter\\n        Hodrick-Prescott filter.\\n    statsmodels.tsa.filters.convolution_filter\\n        Linear filtering via convolution.\\n    statsmodels.tsa.seasonal.STL\\n        Season-Trend decomposition using LOESS.\\n\\n    Notes\\n    -----\\n    This is a naive decomposition. More sophisticated methods should\\n    be preferred.\\n\\n    The additive model is Y[t] = T[t] + S[t] + e[t]\\n\\n    The multiplicative model is Y[t] = T[t] * S[t] * e[t]\\n\\n    The results are obtained by first estimating the trend by applying\\n    a convolution filter to the data. The trend is then removed from the\\n    series and the average of this de-trended series for each period is\\n    the returned seasonal component.\\n    \"\"\"\\n    pfreq = period\\n    pw = PandasWrapper(x)\\n    if period is None:\\n        if isinstance(x.index, pd.PeriodIndex):\\n            pfreq = x.index.freq\\n        else:\\n            pfreq = getattr(getattr(x, \"index\", None), \"inferred_freq\", None)\\n\\n        if pfreq is not None:\\n            pfreq = freq_to_period(pfreq)\\n            period = pfreq\\n        else:\\n            raise ValueError(\\n                \"You must specify a period or x must be a pandas object with \"\\n                \"a PeriodIndex or a DatetimeIndex with a freq not set to None\"\\n            )\\n    if x.shape[0] < 2 * period:\\n        raise ValueError(\\n            f\"x must have 2 complete cycles requires {2 * period} \"\\n            f\"observations. x only has {x.shape[0]} observation(s)\"\\n        )\\n\\n    if filt is None:\\n        if period % 2 == 0:  # split weights at ends\\n            filt = np.array([0.5] + [1] * (period - 1) + [0.5]) / period\\n        else:\\n            filt = np.repeat(1.0 / period, period)\\n\\n    nsides = int(two_sided) + 1\\n    trend = convolution_filter(x, filt, nsides)\\n\\n    if extrapolate_trend == \"freq\":\\n        extrapolate_trend = period - 1\\n\\n    if extrapolate_trend > 0:\\n        trend = _extrapolate_trend(trend, extrapolate_trend + 1)\\n\\n    if model.startswith(\"m\"):\\n        detrended = x / trend\\n    else:\\n        detrended = x - trend\\n\\n    period_averages = seasonal_mean(detrended, period)\\n\\n    if model.startswith(\"m\"):\\n        period_averages /= np.mean(period_averages, axis=0)\\n    else:\\n        period_averages -= np.mean(period_averages, axis=0)\\n\\n    seasonal = np.tile(period_averages.T, x.shape[0] // period + 1).T[: x.shape[0]]\\n\\n    if model.startswith(\"m\"):\\n        resid = x / seasonal / trend\\n    else:\\n        resid = detrended - seasonal\\n\\n    results = []\\n    for s, name in zip(\\n        (seasonal, trend, resid, x), (\"seasonal\", \"trend\", \"resid\", None)\\n    ):\\n        results.append(pw.wrap(s.squeeze(), columns=name))\\n    return DecomposeResult(\\n        seasonal=results[0],\\n        trend=results[1],\\n        resid=results[2],\\n        observed=results[3],\\n    )\\n\\n\\nclass DecomposeResult:\\n    \"\"\"\\n    Results class for seasonal decompositions\\n\\n    Parameters\\n    ----------\\n    observed : array_like\\n        The data series that has been decomposed.\\n    seasonal : array_like\\n        The seasonal component of the data series.\\n    trend : array_like\\n        The trend component of the data series.\\n    resid : array_like\\n        The residual component of the data series.\\n    weights : array_like, optional\\n        The weights used to reduce outlier influence.\\n    \"\"\"\\n\\n    def __init__(self, observed, seasonal, trend, resid, weights=None):\\n        self._seasonal = seasonal\\n        self._trend = trend\\n        if weights is None:\\n            weights = np.ones_like(observed)\\n            if isinstance(observed, pd.Series):\\n                weights = pd.Series(\\n                    weights, index=observed.index, name=\"weights\"\\n                )\\n        self._weights = weights\\n        self._resid = resid\\n        self._observed = observed\\n\\n    @property\\n    def observed(self):\\n        \"\"\"Observed data\"\"\"\\n        return self._observed\\n\\n    @property\\n    def seasonal(self):\\n        \"\"\"The estimated seasonal component\"\"\"\\n        return self._seasonal\\n\\n    @property\\n    def trend(self):\\n        \"\"\"The estimated trend component\"\"\"\\n        return self._trend\\n\\n    @property\\n    def resid(self):\\n        \"\"\"The estimated residuals\"\"\"\\n        return self._resid\\n\\n    @property\\n    def weights(self):\\n        \"\"\"The weights used in the robust estimation\"\"\"\\n        return self._weights\\n\\n    @property\\n    def nobs(self):\\n        \"\"\"Number of observations\"\"\"\\n        return self._observed.shape\\n\n\\ No newline at end of file\ndiff --git a/statsmodels/tsa/seasonal.py b/statsmodels/tsa/seasonal.py\nindex 636336b..d122a0a 100644\n--- a/statsmodels/tsa/seasonal.py\n+++ b/statsmodels/tsa/seasonal.py\n@@ -145,7 +145,10 @@ def seasonal_decompose(\n     pfreq = period\n     pw = PandasWrapper(x)\n     if period is None:\n-        pfreq = getattr(getattr(x, \"index\", None), \"inferred_freq\", None)\n+        if isinstance(x.index, pd.PeriodIndex):\n+            pfreq = x.index.freq\n+        else:\n+            if isinstance(x.index, pd.PeriodIndex): pfreq = x.index.freq; else: pfreq = getattr(getattr(x, \"index\", None), \"inferred_freq\", None)\n \n     x = array_like(x, \"x\", maxdim=2)\n     nobs = len(x)\n"}}